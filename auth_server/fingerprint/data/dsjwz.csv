num,url,title,content
1,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658993&idx=3&sn=829390f00beb0593ba010fa6a9b47b62&chksm=bd4c3d628a3bb4742e085c449e5eac932ca7982b9dda077fb524b3758fad86746fb631d66275&scene=27,手把手 | 教材太贵？一小段Python代码帮你自动翻页和扫描,大数据文摘作品 编译：Rita、黄文畅、云舟 反思通常是一件有益的事，对程序员来说就更是如此。我的第一个Python项目距今已经两年，但我仍然常常想起它，所以我写了这篇文章与大家分享。作为一名航空航天工程专业的学生，我第一次学习Python是想要避免使用电子表格。当时的我还不知道这是一个多么明智的决定。 我的Python启蒙书是Al Sweigart先生写的《Python编程快速上手——让繁琐工作自动化》（Automate the Boring Stuff with Python）。这是一本很好的应用型书籍，它包含了一些能够完成有用任务的简单程序。当我面对一个新的问题时，我会寻找一切机会去使用它来解决问题。当时我遇到了一个亟待解决的问题——我需要使用一本价格高达200刀的教材。 购买一本教材，我个人的预算是不超过20刀（《让繁琐的工作自动化》在网上可以免费阅读）。而且我不愿意去租书。 我很想在完成第一次作业之前拥有这本教材。接下来我发现亚马逊的新用户有一周的免费阅读该书的权限。于是我利用这个免费资源完成了第一次的作业。虽然可以继续每周创建新的账号来读书，但我需要一个更好的办法。于是我打开了Python，开始了我的第一个编程应用。 在《让繁琐的工作自动化》这本书里，有很多有用的库。pyautogui就是其中之一，它可以让你通过Python控制键盘和鼠标。 人们说对于一个拥有锤子的人来说，所有的问题看起来都像一颗钉子，这种说法太贴切了。 Python和pyautogui使我能够自动地点击翻页键并截屏。当我把这两个操作结合起来后，教材的问题就迎刃而解了。 我写了我的第一个程序来自动翻阅每一页并且截屏。虽然最终的代码只有十行，我还是很骄傲，就像我在航空航天工程领域取得成就一样自豪。 以下是我的完整的代码： 运行这个代码很简单（我建议大家都试一试）。我将脚本保存为book_sreenshot.py，然后在同一个文件夹里终止了命令符并写道： 接下来，我有五秒钟的时间打开书并开至全屏。程序会完成接下来的事情：翻阅每一页并截屏，保存至pdf格式。我会把所有的pdf页面组合成一个文件，做成这本书的副本（不确定是否合法）。当然，这是一个糟糕的副本，因为它无法被检索。但是我找了一切借口去尽量使用这本“书”。 这个例子说明了两个关键点，这两点在我学习数据科学的过程中一直伴随着我： 学一个新技能最好的方法是找一个亟需解决的问题。 你不必等到完全精通一个技能才开始使用它。 依靠短短几行的代码和一本免费的在线图书，我编写了一段真正可以应用的程序。学习基础知识有时是很无聊的，当我第一次尝试学习Python时，因为搞不懂数据结构以及循环这类的概念，仅仅几个小时就放弃了。而调整策略以后，我开始为现实中的问题寻找解决方案，并且在这过程中学习到了基础知识。编程和数据科学有太多需要学习了，但是你不必一口吃成个大胖子，一次学完所有的知识。找到一个需要解决的问题，然后开始学习吧！ 在这之后，我做了一些更复杂的项目，但我仍然记得这段有趣的Python编程初体验。 原文链接： https://towardsdatascience.com/python-is-the-perfect-tool-for-any-problem-f2ba42889a85 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 
2,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658993&idx=2&sn=a0b5253e84ba1f971e645d1c439c5a9c&chksm=bd4c3d628a3bb474a1cd7f4d1db357987c0f271d42bf78c064b7f45b746d86ba0893c8557bd9&scene=27,业界 | 亚马逊正在考虑为Alexa添加支付功能，包括向好友转账,据外媒华尔街日报报道，零售巨头亚马逊正在计划为Alexa语音助手添加一项面对面的支付功能，此举无疑打响了与各大科技公司支付业务争夺市场的战争。 这家西雅图公司已从在线商务扩展到了云计算和娱乐业。亚马逊正在积极探索新的项目和能力，以使其在与Visa Inc和Mastercard Inc等银行和信用卡网络主导的支付行业的竞争中拥有更大的话语权。 亚马逊希望配备Alexa的用户能够直接转账给朋友 ，但是这一想法尚处在早期阶段，因为声控设备需要获得更多关于银行账户的信息，而不只是转账的信息。亚马逊也在努力为Alexa添加其他支付选项，包括允许配备Alexa的汽车司机通过语音在车站支付汽油费。 打进店内支付市场也是亚马逊的战略之一，其现在正与摩根大通在内的大银行进行谈判。 据知情人士透露，亚马逊CEO Jeff Bezos去年将金融服务作为公司战略的一项重要举措，该公司对其内部组织进行了重新规划，为了布局下一轮商业计划，亚马逊将数字钱包Amazon Pay并入了Alexa的团队中。 上个月，Amazon Pay副总裁Patrick Gauthier在一次会议上向零售商推荐Alexa的支付功能时说道：“我们真诚的邀请所有想创造未来的人加入我们。” 亚马逊的这一战略并不受零售商的欢迎，因为他们一直把亚马逊视为收入缩水的竞争对手。 亚马逊在其他方面也面临挑战。除了遭受隐私问题的严格审查，最近几天，美国总统唐纳德·特朗普在Twitter上特别提到亚马逊，批评亚马逊对传统零售商的影响，并质疑亚马逊是否缴纳了足够的税款。 20年前，亚马逊就以特别的方式改变了消费者的生活。亚马逊进军一度不被看好的支付业务，显示出了它是如何转型的。多年来，Visa、Mastercard和其他几家公司一直在争夺信用卡的市场份额。如今，亚马逊、苹果和Alphabet Inc旗下的谷歌等科技公司正在开展一场令人震惊的战斗。 它们试图通过移动设备，使消费者更容易支付， 但是现在还只是初期，因为美国消费者还没有像中国那样喜欢把钱放在手机钱包里。此外，因为通过亚马逊账户付款的消费者通常是通过借记卡或信用卡支付的，所以亚马逊的举措不太可能对信用卡网络或发卡机构产生重大影响。 亚马逊正在与谷歌助手展开激烈的竞争，作为一个独立的公司，p2p业务带来的热议远超过其与venmo和其大银行竞争带来的利润。 支付分析师表示，亚马逊的零售基础帮助它在支付方面取得了比一些竞争对手更大的进步。“他们专注于支持自己的核心竞争力。”研究新兴支付技术的高级分析师Thad Peterson说。 与许多竞争对手形成对比的是， 亚马逊试图让更多的商家在结账时使用Alexa支付选项，包括在线支付。 一种新的商店内支付方式可能会要求消费者在智能手机上使用他们的亚马逊账户，并扫描二维码完成注册。虽然交易仍可与信用卡或借记卡挂钩，但不会交换任何银行卡或现金。这一模式与Amazon Books的类似。另外亚马逊还希望将Alexa进一步嵌入到商店购物体验中。 素材来源： https://www.wsj.com/articles/hey-alexa-can-you-help-amazon-get-into-the-payments-business-1523007000 【今日机器学习概念】 Have a Great Definition 
3,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651659011&idx=2&sn=9e1a2cded53019e8d7cdeafc035d1406&chksm=bd4c3c908a3bb586bc39fbce172a9ba93b63be1ab161dc1063ddf957f86e63dc9431054eeaef&scene=27,资源 | 适合小朋友的Scratch动手项目！AI在生活中的19个应用,大数据文摘作品 编译：蒋宝尚、龙牧雪 人工智能已经写入中小学课程标准，但在中小学阶段就已经入门人工智能的童鞋恐怕还是比较少见。戳蓝字可以看两篇小学生和中学生的编程指南： 我12岁，4年码龄，我是这么学编程的 一位16岁CEO教你如何在高中阶段入门人工智能 如果你觉得Python对小朋友来说太难，那么图形化界面的Scratch编程语言可能是个不错的选择。我们找到了一个machine learning for kids的网站，上面搜集了各种和人工智能有关系的Scratch动手项目，一共19个，包括人脸识别、聊天机器人、教AI玩井字游戏等。虽然不能通过 这些项目直接 操作计算机，但在虚拟界面上，小朋友们将能感受到这些 生活中就能频繁接触到的AI系统背后的逻辑。 智能教室（Smart classroom） 在Scratch中创建一个智能助理使你更容易控制虚拟设备。 目的：训练电脑如何识别你的指令 难度：低 标签：数字助手、监督学习 让我开心（Make me happy） 在Scratch中创建一个角色，如果你对它说好话，它就会微笑，如果你对它说了一些坏话，就会哭。 目的：教计算机识别赞美和侮辱 难度：低 标签：情感分析、监督学习 在Scratch中制作一款卡片游戏，让其学习如何识别卡片。 目的：教计算机识别图标 难度：低 标签：图像分类、监督学习 在Scratch中制作一个邮件分拣系统，可以识别信封上的手写邮政编码。 目的：使计算机能够识别手写体 难度：低 标签：光学字符识别、手写识别、图像分类、监督学习 训练电脑可以将照片分组。 目的：教计算机识别物体的照片 难度：低 标签：图像分类、监督学习 在Scratch里制作一个手机，当能够识别出你的脸的时候手机就会解锁。 目的：训练计算机可以识别人脸 难度：低 标签：人脸识别、生物计量学、图像分类、监督学习 训练电脑能够预测你在早上如何去学校。 目的：教计算机做出预测 难度：低 标签：预测模型、监督学习 在Scratch中创建一个吃豆人游戏，并在游戏中能够躲避鬼魂。 目的：教计算机玩游戏 难度：中 标签：决策树学习 创建一个聊天机器人，可以回答你提的问题。 目的：教计算机识别问题 难度：中 标签：情感分析、监督学习 在Scratch中创建一个移动应用程序，可以根据人们的兴趣推荐旅游景点。 目的：教计算机提出建议 难度：中 标签：训练偏见、建议、监督学习 创建一个像哈利波特电影里一样的分院帽，能够根据你的语言特点将你分配到合适的学院。 目的：教计算机如何识别语言 难度：中 标签：文本分类、监督学习、众包 在Scratch中制作一个石头、剪刀、布的游戏。 目的：教计算机识别形状 难度：中 标签：图像分类、监督学习 在Scratch中制作游戏来测试是否可以通过封面判断一本书。 目的：教计算机识别视觉风格 难度：中 标签：图像分类、监督学习 在Scratch中制作“Where's Wally？”风格的游戏。 目的：教计算机在一张照片中寻找需要的内容 难度：中 标签：图像分类、监督学习、图像预处理 柠檬柚子傻傻分不清楚。如果电脑数据训练不够，显然会出现这种情况。 目的：了解电脑无法识别相似物品的原因 难度：中 标签：图像分类、监督学习、过度拟合 在Scratch中创建一个学校图书管理员，可以使合适的读者借到合适的书籍。 目的：教计算机提建议 难度：中 标签：预测模型、建议、监督学习 在Scratch中创建一个井字棋游戏。 目的：教计算机如何玩游戏 难度：高 标签：决策树学习、强化学习、分类数据 顶级王牌（Top Trumps） 训练一台电脑，以便能够在Scratch中玩顶级王牌纸牌游戏 目的：教计算机玩游戏 难度：高 标签：决策树学习、强化学习、分类数据 ﻿ 对一台电脑进行数据训练，使其能够识别新闻头条。 目的：测试电脑识别语言使用的能力 难度：高 标签：决策树学习、强化学习、分类数据 打开这个链接就能体验： https://machinelearningforkids.co.uk/#!/worksheets 【今日机器学习概念】 Have a Great Definition 
4,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651659030&idx=1&sn=7985b6dfb4ceea2fa1b1acf21418332b&chksm=bd4c3c858a3bb5937c99b7d8b51f70e4911d7dc215973f9f5f052af10131f5cc79569b870820&scene=27,手把手：用Python搭建一个加密货币交易模拟器，不用投钱就能玩,大数据文摘作品 编译：汪小七、黄文畅、小鱼 我虽然不是交易员，但对加密货币的交易非常感兴趣。然而，我不会在自己什么都不清楚的时候就盲目投资加密货币，所以在进行投资之前，我想先来测试一下自己的交易策略。 播音员：今天的道琼斯指数曲线是华盛顿天际线（林肯纪念堂、华盛顿纪念碑、美国国会大厦）的形状...（i.e.股市表现奇怪） 2018 3 7 2018 3 16 Python 9 目前，模拟器会给出用户资产的最佳出仓价，并与其原始投资价格进行比较，然后告诉用户最终的盈亏状况。接下来，我将介绍如何添加对流通货币的价格监控，如何编写和测试交易策略，还有如何构建用户界面等等。 Github  Github https://github.com/jamesfebin/CryptoTradingSimulator 数据库链接： https://drive.google.com/file/d/1OHhtrvOe-EWcX_8tipWo6tWYqkkYDkPw/view?usp=sharing 伪代码 在编写代码之前，明确我们接下来的每个步骤至关重要，否则编程时会陷入困惑。为了清楚起见，我们使用伪代码进行说明，伪代码并不是真实的代码，而是我们用自己的语言写的思维图。 我们无需按以上步骤依次进行代码编写，可以依据自己的能力从最简单的步骤开始编写，随着模拟器功能的不断完善，我们编程的能力和信心也逐渐提高，从而才可能完成整个项目。 Python2.7 CryptoSimulator 数据库下载链接： https://drive.google.com/file/d/1OHhtrvOe-EWcX_8tipWo6tWYqkkYDkPw/view?usp=sharing run.py py 欢迎页面 welcome 2018 3 7 7 39 sqlite3 sqlite3 run.py sqlite3 现在，我们编写代码来抓取起始时刻的价格数据并进行显示。 timestamp first_leg second_leg ask bid the exchange name BTC/USD BTC USD 以下几行代码就是用来抓取指定时间的价格数据。 coins{} 如果你看不懂代码，也别担心，只需要将整个程序包下载下来，运行，然后修改部分代码再运行，对比看看结果有什么不同，循环往复，慢慢你就开始理解代码的含义了。 fetchCoins() inputBuy() coins{} 然后我们需要把返回的参数传给模拟器。现在我们可以将上述代码块进行整合并放进主函数中。 runSimulation() “simulator.py” py runSimulation() runSimulation() 3 7 3 16  fetchBestBidPriceFromDB() runSimulation() 这里，再一次对上述代码块进行整合，结果如下： 现在整个程序已经基本完成了，但是我还想加个特效——就像在电影里，字幕中的字母会一个一个的蹦出来。 “drama.py” run.py simulator.py dramaticTyping print 搞定！现在我们已经编写了一个简易版的加密货币交易模拟器。 😊 API UI ~ 原文链接： https://hackernoon.com/how-to-build-a-simple-crypto-trading-simulator-part-1-4ccdddcd6b76 【今日机器学习概念】 Have a Great Definition 
5,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651659011&idx=1&sn=2c22e71a3cdcceb9d7e94323a7b36ba3&chksm=bd4c3c908a3bb5869648cc34e5500bdb99a5e1a260a0391afdc9c68afcfa4a3f63d8dd37db4c&scene=27,LeCun、Bengio、Hinton三巨头曾合体，Nature发文综述深度学习（论文精华）,大数据文摘作品 编译：张南星、笪洁琼、钱天培 深度学习三巨头Yann LeCun、 Yoshua Bengio、 Geoffrey Hinton 曾在Nature上共同发表一篇名为《深度学习》的综述文章，讲述了深度学习为传统机器学习带来的变革。 从2006年Geoffrey Hinton为世人展示深度学习的潜能算起，深度学习已经蓬勃发展走过了10多个年头。这一路走来，深度学习究竟取得了怎样的成就，又会何去何从呢？ 文摘菌节选了这篇论文的精华部分进行编译，对这些问题作出了回答。在公众号后台对话框内回复“ ”即可下载这篇论文~ 左起：Yann LeCun（Facebook）、 Geoffrey Hinton（谷歌/多伦多大学）、 Yoshua Bengio（蒙特利尔大学）、吴恩达（deeplearning.ai） 借助深度学习，由多重流程层组成的计算模型能够从不同层级的抽象数据中学习数据的特征。这些方法极大促进了先进技术的发展，包括语音识别、视觉对象识别、目标检测以及许多其他领域，诸如药物识别以及基因学研究。 使用反向传播算法，深度学习能够指出机器如何基于上一层的特征，通过改变内部参数来计算出下一层的特征，以发现大型数据集中错综复杂的结构。 深度卷积网络给图像、视频、语音与音频处理带来了极大突破，同时循环神经网络则给诸如文字及语音的顺序数据研究带来了希望 。 机器学习在许多方面都造福了现代社会：从网页搜索到电商网站上基于社交网络内容筛选做出的推荐，并且在消费品中的存在感越来越强，例如相机、智能电话等。 机器学习系统被用于识别图像中的物体、将语音转化为文本、匹配新物体、根据用户兴趣个性化推送或生产商品，也可以用于选择搜索结果中相关的内容。有趣的是，这些应用就是大名鼎鼎的深度学习实际应用。 传统机器学习技术难以处理原始的自然数据。近几十年来，建造一个模式识别或者机器学习系统，需要细致的策划以及丰富的领域知识，以设计特征抽取器来将原始数据（例如图像的像素值）转化为合适的内部表征或者特征矢量，学习子系统（如分类器）就能够从输入值发现规律。 特征学习通过一系列方法，让机器在输入原始数据后，自动发现检测或分类所必须的特征。 深度学习方法是拥有多层级的特征学习方法 ，使用简单但非线性的组件将每一层（从原始数据开始）的特征转化为更高阶、更抽象化的层级特征。通过结合足够多次的转化，能够得到非常复杂的函数。 对于分类任务，高阶特征能够放大输入值中用于区分的特点，并忽略掉无关的变量。 例如，图像类数据由像素值数组组成，从第一层特征学习得到的结果就很明显代表了图像中特定方向及位置上边缘是否存在。 第二层则忽略掉边缘位置的微小变化，通过边缘的特定变化来探寻图像主要特点。第三层则将这些特点组合在一起，形成一个更大的、与常见物体某一组成部分相似的集合，后续的层次则通过将这些部分组合在一起，识别物体。 深度学习一个重要的特点就是， 。 深度学习很大程度上帮助解决了人工智能界多年来无法成功解决的问题。 它非常擅长于发掘多维数据中错综复杂的结构，也因此能够应用于科学、商业以及政府中的多个领域。 除了攻下图像识别、语音识别的城墙之外，深度学习还在其他机器学习方面攻下一城，包括预测潜在的药物分子的活性、分析粒子加速数据、重构大脑回路，以及预测基因表达及疾病中非编码DNA突变的影响。 也许更令人惊叹的，是深度学习在自然语言理解方面的突出表现，尤其是主题分类、情绪分析、问题回答以及语言翻译。 我们认为深度学习在不远的未来会取得更大的成就，而且只需要少量的人工操作，它就能充分利用可用计算资源及积累的数据。深度神经网络中新学习算法及架构的出现将会推动它的进步。 监督学习 不论深度与否，机器学习中最为常见的形式是 。想象一下，现在我们需要建造一个系统，它能够识别图像中的物体是否为容器，例如房子、车辆、人，或者宠物等。首先我们会收集大量房子、车辆、人、宠物的数据集，并分别用标签标记类别。 在训练过程中，机器会识别每张图像上的物体，并且以分数矢量的方式产出结果到每个类别。我们希望目标类别得分最高，但是在训练之前，这是不可能发生的。 我们推导出一个目标函数来测量实际值与目标类别分数之间的差，然后机器将修正内部的可调整参数以减少错误。 在一个典型的深度学习系统中，可能存在着上千个、甚至上百万个可调整权重，以及大量用于训练的带标签案例。 在实际生产中，许多程序员会使用 。这个方法有以下几个步骤：展示几个案例的输入向量，计算输出结果及错误值，计算这些案例的平均梯度，然后对权重做出相应的调整。 这个流程将在许多个小案例集中重复多次进行训练，直到目标函数的平均梯度不再下降。 经过训练之后， 。其目的主要在于测试机器的推广能力——是否能在输入新结果的情况下得到合理的结果。 现在实际生产中，许多机器学习系统在人工提取特征的基础上使用 。一个两级线性分类器会对特征向量组件计算加权和，如果加权和高于阈值，这个输入将被分入为某一特定分类之下 。 但是线性分类器在图像识别、语音识别中的应用有较大限制，需要诸如特征提取器等深度学习方法以实现特征学习。 一个深度学习架构是由一系列简单组件组合而成，其中所有（或者大部分）都需要学习，并且许多都能计算出非线性的输入输出映射关系。其中每个组件都会充分利用输入，以提高选择性和不变性。 这些系统拥有多个非线性层（例如5-20层），能够支持极其复杂的函数，并对微小的细节保持敏感度，例如达到能区分萨摩耶和白狼的地步，同时忽略所占范围大的不相关变量，例如背景、姿势、光线以及周围的物体。 使用反向传播算法计算目标函数组件中多层堆叠权重的梯度，本质上是导数链式法则的一个实际应用。其中非常重要的一点在于，目标函数组件输入的导数（也就是梯度）能够通过这个组件输出的梯度倒推出来（或者是通过下一个组件的输入倒推）。 反向传播方程能够重复在所有组件中推广梯度值，从顶部（此网络产出预测的地方）开始，一直到底部（外部输入的地方）。一旦计算出这些梯度，就能很简单地算出每个组件权重的梯度了。 许多深度学习的应用都使用了 （例如每个分类的可能性）。层与层之间每个单元能计算出来自上一层输入的加权和，并把结果传给非线性函数。 20世纪90年代末，神经网络以及反向传播算法被大多数机器学习研究团体所抛弃，并且计算机视觉和语音识别研究者们也普遍忽略了它。大家都认为用很少的先验知识是不可能得到有用的多阶特征提取器。 但是在实践中，局部极小值在大型网络中并不是一个问题。无论最初的情况如何，系统得到的结果质量水平是类似的。最近的一些理论和实证结果都强有力地证明了，一般情况下局部最小值并不是一个严重问题。 2006年左右，加拿大高等研究院（CIFAR）的研究员让公众重新对深度反向传播网络产生了兴趣。研究员们发明了不需要标签数据就能进行特征发现的 程序。 这种无需训练的方法首次被大规模应用是在语音识别领域，快速图形处理器（ ）的发明使它得以在生产中得到应用，GPU极大方便了编程，让研究员能够以10到20倍的速度训练网络。 但是，在深度学习重新获得大众的青睐之后，似乎这种训练前算法只对小数据集有用。实际上，存在一种特定的深度反向传播网络比相邻层之间全连接的网络更加容易训练和应用。那就是 。 当人们开始对神经网络失去信心时，卷积神经网络取得了许多实践层面上的成功，最近在计算机视觉领域大受欢迎。 卷积神经网络被设计用来处理多重阵列形式的数据，例如由三个2D数组组成、包含了三个颜色通道像素灰度的彩色图像。 卷积神经网络背后有四个重要的思想，充分利用了自然信号的属性：局部联系、相同的权值、池化以及多个层级的使用。 一个典型的卷积神经网络架构由一系列阶段组成。最初的几个阶段由两个层级组成： 。 卷积层中的单元有组织地出现在特征地图中，每个单元都通过一个叫做滤波器组的权值组与上一层地图中的局部补丁连接。同一层的不同特征地图使用不同的滤波器组。 虽然卷积层主要用于探测与上一层特征的局部联系，池化层则主要是将语义上类似的特征合并为一个。一个典型的池化单元能计算一个特征地图（或者几个特征地图）中局部补丁的最大值。 相邻的池化单位从补丁中得到大于一行或一列的输入值，以减少特征的维度，并给微小的转换或变形创造不变性。 从20世纪90年代早期开始，卷积网络就已经广泛应用，即时延神经网络在语音识别以及文档阅读的应用。文档阅读系统使用卷积神经网络和规定了约束语言的概率模型进行训练。 到20世纪90年代末，这个系统阅读了全美超过10%的支票。后来微软部署了大量基于卷积网络的光学字符识别以及手写识别系统。卷积神经网络在20世纪90年代初还被用于自然图片中的目标识别，包括脸部、手部，以及人脸识别。 从21世纪早期，卷积网络在图像目标、区域的探测、分类以及识别上取得了巨大成功。 这些领域中标签数据资源非常丰富，例如交通信号识别、神经连接组学的生物图像分类等。最近的一个重大成就在于 。 由于图像的一个重要特点——可以在像素级别打上标签，卷积网络在图像上的应用可以在科技领域里发扬光大，包括 。 Mobileye和NVIDIA公司在他们的车辆视觉系统中就使用了基于卷积网络的方法。 尽管取得了一些成功，卷积网络还是被主流机器视觉以及机器学习研究团体忽视，直到2012年的ImageNet大赛。 当有人使用深度卷积网络处理了来自于网络的一百万张一千种图片数据集后，比之前最好的方法几乎降低了一半错误率。 这个来源于GPU和ReLU的成就在计算视觉领域引发了一项革命。 卷积神经网络现在几乎是所有识别和探测任务的主要方法，以及在一些人类行为分析的任务中也有应用。 从深度学习理论中可以看出，深度网络比不使用分布式表达的传统学习算法有两个指数级的优势。 这两个优势都来源于其组成成分和内部结构。首先，学习分布式表达能够让学习到的特征值一般化为新的组合形式，而非在训练中直接观察到的结果（例如n个二进位制特征能够组合为2的n次方个）。其次，深度网络中的特征层组合可能带来了另一个指数级优势。 多层神经网络中的隐藏层能通过学习，以一种更容易预测目标输出的方式找到网络输入的特征。这能通过训练一个多层神经网络 得到很好地体现。 特征寻找的主要问题在于逻辑驱动的认知算法和神经网络驱动的认知算法之间的不同。 逻辑驱动算法中，一个符号实例是唯一的资产，来推断是否与其他符号实例一致与否，其内部并没有与使用方式相关的结构。 如果需要对符号进行推断，需要选择恰当的参考标准才可以进行。相反，神经网络只需要使用大量活动向量集、权重方阵以及大规模非线性来完成“直觉性”推断，这和一些简单的常识性推断是一致的。 在引入神经语言模型之前，标准语言统计模型方式并没有涉及到分布式特征，它不能将模型推广到其他语义相关的文本中，但是神经语言模型可以，因为它能够将每个词语与具有真实值的特征联系起来，然后从语义上将与那个向量空间中相似的文本连接起来。 当反向传播算法最初被发明时，它最令人激动地用处在于训练 。涉及到顺序数据输入值时，例如语音以及语言，使用RNN是不错的办法。 RNN是非常具有优势的动态系统，当时训练这些系统是非常麻烦的，因为反向传播算法的梯度在每一时间步都有可能增长或降低，所以经过多次步骤之后，梯度会很明显的增长或消退。 幸好架构以及训练它们的办法，RNN非常擅长于预测文本中下一个词是什么，但同时也非常适合更复杂的任务。 在过去几年里，几位作者曾提出使用一个记忆模块来增强RNN。提议之一是 ，它通过使用一个类似于磁带一样的存储器来进行增强，以方便RNN能够从中选择读取或者写入；或者通过一个 实现增强，其在标准问题回答对标上有出色的表现。 虽然非监督学习催化了深度学习的复兴，但是仍然在单纯监督学习的光芒下黯然失色。本文中并没有过多讨论非监督学习，但是我们还是希望非监督学习的重要性在未来会变得更高。人类和动物的学习大多都是非监督的：我们是通过观察来发现世界的规律，而非别人手把手告诉我们每一个事物的名字。 人类视觉能够以一种非常机智、明确的方式积极地处理连续的视觉信息，并且在一个大而低分辨率的环境之下，集中于一个小而高分辨率的中心。 我们期待着，未来计算机视觉能够端到端训练系统，通过 两种方式，强化学习，精确决策“看哪儿”。集合了深度学习和强化学习的系统仍然在发展初期，但是它们在使用被动视觉系统中进行分类的任务完成上超出了预期，并且在电子游戏中表现出色。 自然语言理解是未来几年另一个机器学习蓄势待发的领域。我们期待着，通过使用RNN去理解句子或整个文档的过程能够变得更加容易，系统能够懂得如何一次选择一个部分进行理解。 最终，人工智能领域主要的进步将来自于集合了特征学习和复杂推理的系统。 虽然深度学习和简单推理已经在语音识别与手写字体识别上应用了很长一段时间，但是如果希望对大型向量进行操作，而非使用基于规则的符号表达式，仍然需要新的算法进行支持。 大数据文摘公众号后台对话框内回复 “三巨头” 可以获得这篇售价199美元的《Deep Learning 》论文哟~~ 论文原地址： https://www.nature.com/articles/nature14539 【今日机器学习概念】 Have a Great Definition 
6,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651659030&idx=2&sn=44b00a384d54027f13dbf36abf6f9d04&chksm=bd4c3c858a3bb5937fdab19a1b4e16fefabd231f82b281ea015def3162f8db03aeaf94f185fa&scene=27,业界 | 皮克斯经典动画电影怎样炼成？离不开数学、模型和算法,大数据文摘作品 编译：Z oe Zuo 、吴双、Aileen Pixar用技术带领动画师摆脱简单多边形的束缚，用几何学把故事描述得更加完美。 Tony DeRose在纽约数学博物馆讲厅的坐席间不断穿梭。他身着花哨的带扣T恤，一身Pixar员工的标准打扮，横竖看起来都不像印象中的刻板科学家。 他向观众席问好，其间坐着一群技术宅气质的小孩子、他们的爸爸妈妈、爷爷奶奶、数学老师、科学老师，当然还有年龄一把的数学宅及其朋友们。 一个二十来岁的小伙子，曾经在《汽车总动员2》的群体动画中有所贡献，把自己妈妈也带到了现场。这位母亲想见识一下DeRose是怎样带领团队把她儿子所做的工作搬上大荧幕的。 Derose说：“看到这么多各型各色的人都来听今天的演讲，感觉很棒。”登上讲台后，他问：“你们当中有多少人看过皮克斯(Pixar)的电影？”全场的人都举手了。“看过三五部的有多少人？”他停顿了一下，“那看过全部的呢？”最终有几十个观众举了手，差不多占到全场人数的四分之一。 动画师和游戏设计师也要研究微积分和组合数学 DeRose今天演讲的主题是“电影中的数学”。该主题就是他的本职工作：将算数、几何和代数的理论应用到软件中，从而渲染出物体或者驱动物理引擎。他解释说，无论是在皮克斯还是在其他电脑动画或电子游戏工作室，这道流程几乎是差不多的。 他今天在这儿的目的之一就是告诉大家，动画师和游戏设计师如果对事业有更高的追求，那么数学基础一定要扎实。 作为皮克斯的资深科学家，DeRose可不止是数学功底过硬，他还拥有计算机科学的博士学位，专攻计算物理学，曾在华盛顿大学做过十年的计算机科学与工程学教授。 DeRose此次演讲，是数字博物馆在曼哈顿中城新园区举办的“数学奇遇”系列演讲（Math Encounters lecture series）的首场。 在此之前，DeRose已经做过数次类似的演讲了，他每次都会分享皮克斯技术的新进展，回应粉丝们对新电影的期待。 在皮克斯动画制作中，头发、衣服、液体和气状物（比如云、烟雾和火）都有各自的物理引擎。这些基础引擎会根据具体情况进一步得到增强，以生成更为精确的效果。 DeRose说，“模拟水不难，难的是，怎样让模拟出来的水更像真实的水，可以被引导着向某方向流动。” 在动画《勇敢传说（Brave）》中，女主角梅莉达那满头浓密的动感十足的亮红色卷发就需要全新的物理引擎来模拟。 工作室的动画师绞尽脑汁，要让梅莉达的头发漂亮、富于表现力，甚至比真头发还要真。当然，这样的秀发模型所需的计算量还得在计算机能承受的范围之内。 DeRose说：“在现实世界里，发丝一直在发生着碰撞，这样才显得头发富有弹性且很浓密。梅莉达的头发包含了10万个单独的有限元。如果你懂点组合数学的话，就会知道，如果有n个物体，就会产生出n²种碰撞的可能。” 对于梅莉达的头发，那就是100亿种碰撞的可能了。怎样才能在短时间里渲染出这么多种头发碰撞的情形呢？ 对此，皮克斯设计出了一个新的空间数据结构，在不会过度损耗的情况下剔除无用的碰撞可能。 皮克斯就是要针对头发模拟创造出PNG或FLAC这种高水准的压缩算法，摒弃MP3或JPEG这类虽然省时间但是很粗糙的算法。 DeRose提到，计算机动画通常要模拟超大规模且又十分精细的物理模型，与物理学家平时进行的科学计算相比有过之而无不及。他的主要工作就是为物理模拟寻找更优的算法，在保证规模的同时还要兼顾细节。 DeRose说，“导演经常说‘唉，这只是背景里一个很细微的东西，看不到的。’导演其实是在撒谎。” 如果导演哪天又冒出新点子，致使物体或角色的物理机制发生改变，整个模拟过程就得重头再来，那样即使皮克斯所有的四个团队同时开工，也没法保证一年出一部片子。 DeRose对计算机动画制作最重要的贡献，就是设计出可快速生成高还原度的平滑曲线的算法，“主要问题就是将复杂的形状分解为计算机可以生成的图形。” 多年来，在计算机动画和电子游戏制中，都是用平面或多边形来表示三维物体。 然而，使用多边形的问题在于，放大细节看时还是能分辨出一个个多边形的棱角，尤其当略过单帧画面或个别像素时，就更容易产生这种错觉。业界的趋势是用曲面取代多边形，因为曲面在放大缩小画面时候都是平滑连续的。 但曲面仍然需要被迅速拆解成有限个数的点或者平面。对此，数学家发明了各种能快速生成平滑曲面的方法。这些曲面通常称为“细分曲面”（subdivision surfaces），因为他们是通过不断对线段取中点并连接而得出的。 细分曲面在皮克斯出品的《棋逢敌手（Geri's Game）》中首次得到应用。这部动画获得了1997年奥斯卡最佳短片奖。相较于先前以多边形为基础的动画，这部动画实现了惊天动地的飞跃，一举奠定了“皮克斯风格”。 DeRose改进自己对多维曲面上小波计算的研究成果，设计出一个生成曲面的新算法。这一算法起初只是用来应对制作特别棘手的动画形象，比如老人的鼻子、衣服褶皱的摆动等。如今皮克斯电影里几乎所有物体都运用了细分曲面。 DeRose展示了《超人总动员（The Incredibles）》的一幅剧照，他指着画面背景说：“这座建筑、每一扇窗户，这些所有物体的细节都是用细分曲面生成的，也许你会为此感到惊讶。” 从Derose与其他计算机科学家在学术界做出的应用性研究，到个别动画短片的尝试，而今曲面细分算法已然成为CG动画的行业标准。 DeRose和他的皮克斯研究团队仍在持续发论文，并将新技术应用于他们的动画引擎。然而，皮克斯今非昔比，它的研发部门和专利软件已经不似从前在业界一枝独秀了。 以前，一个角色模型的光照和着色、定义各种动作的参数等问题，首先是数学上的难题，然后是写代码上的挑战。 但是如今，像Blender这样的开源软件，几乎可以媲美皮克斯自主研发的软件可以直接做这些了。2012年夏天，皮克斯竟然将自己细分曲面的代码库开源了。 对此，DeRose解释：“过去十年，我们皮克斯领先业界，但现在，我们得依靠大家的贡献才能创造更大的价值。” 皮克斯最大的竞争优势在于，它擅长以数学驱动技术，不满足于制作出更漂亮的图形，还要讲出更动人的故事。 DeRose和皮克斯并没有躺在已有的成就上睡大觉。DeRose对着观众席的孩子和大人说：“在某个地方的某个车库里，一个聪明的孩子和朋友们正在搞大事呢。他们不仅在用Blender这样的工具，还在改进工具。他们，将成为下一个皮克斯。” 原文链接： https://www.theverge.com/platform/amp/2013/3/7/4074956/pixar-senior-scientist-derose-explains-how-math-makes-movies-games 【今日机器学习概念】 Have a Great Definition 
7,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651659011&idx=3&sn=0d4a991927eac61c7fa82c6774680722&chksm=bd4c3c908a3bb58669fb5ca3fc31114697c8f7f3fbbd70527d448d2f2e1edd79effa13bcba50&scene=27,报名 | 首届人工智能教育高峰论坛（杭州）,"人工智能浪潮风起云涌、席卷全球，它的迅速发展将深刻改变人类社会生活、改变世界。人工智能已成为国际竞争的新焦点，是未来全球竞争发展的核心产业。 会议背景 为全面实施创新驱动发展战略，进一步贯彻落实国家《新一代人工智能发展规划》，加快人工智能高层次人才培养，提高教育水平是当务之急。正是基于此，教育部高等学校计算机类专业教学指导委员会决定举办本次论坛。 本次论坛旨在了解人工智能行业发展动态，分享人工智能科研、教育与创新教学的成果与经验，交流产、学、研合作的可能。特邀请各高校相关院系、研究单位选派相关领导、课程负责人、骨干教师，企业负责人，参加本次论坛。 会议内容 人工智能发展及演进历程 人工智能技术前沿与研究进展 大数据、深度学习与人工智能 人工智能产业政策、规划、生态与发展 人工智能专业人才教育现状、机遇与挑战 人工智能培养体系与课程体系建设 人工智能实验平台建设与实践教学 人工智能专业教育与研究 校企合作、共建人工智能教育新生态 大会嘉宾 IEEE Fellow、国际导航与运动控制科学院院士、纽约科学院院士、联合国专家、首届全国高校国家级教学名师，中南大学信息科学与工程学院教授 陈   刚    教育部“长江学者”特聘教授、国家“万人计划”科技领军人才、教育部新世纪人才，浙江大学计算机学院院长、大数据智能计算重点实验室主任、教授 陈恩红 国家杰出青年基金获得者，中国科学技术大学计算机学院副院长、教授 费良宏    亚马逊AWS首席云计算技术顾问 古天龙    “国家百千万人才工程”人才，教育部高等学校计算机类专业教学指导委员会副主任委员，桂林电子科技大学校长、教授 黄河燕    中国人工智能学会副理事长，北京理工大学计算机学院院长、教授 焦李成    IEEE Fellow、中国人工智能学会副理事长、中国人工智能学会会士、教育部科技委学部委员、教育部创新团队首席专家、国家百千万人才工程入选者，西安电子科技大学人工智能学院教授、智能感知与计算国际联合研究中心主任、国家“111”创新引智基地主任 刘   宏    国家“万人计划”首批入选专家、国家“中青年科技创新领军人才”、中国人工智能学会副理事长，北京大学深圳研究生院科研处处长、智能机器人开放实验室主任、教授 马殿富    教育部高等学校计算机类专业教学指导委员会秘书长，北京航空航天大学计算机学院教授 孙富春    国家杰出青年基金获得者，清华大学智能技术与系统国家重点实验室副主任、计算机科学与技术系教授 谭建荣    中国工程院院士，国家973项目首席科学家，浙江大学机械工程学系主任、教授 陶建华    国家杰出青年基金获得者、中组部“万人计划”领军人才，中国科学院自动化所所长助理、模式识别国家重点实验室副主任、研究员，中国科学院大学人工智能技术学院院长助理 王万森    中国人工智能学会智能教育工作委员会主任，首都师范大学信息工程学院教授 周志华    ACM Fellow, AAAI Fellow, IEEE Fellow、欧洲科学院外籍院士，南京大学计算机系主任、人工智能学院院长 支持单位 教育部高等学校计算机类专业教学指导委员会 浙江大学 清华大学出版社 请各单位积极组织和推荐院系领导、课程负责人和骨干教师参加会议，参加会议的代表请于2018年4月13日前将回执发给组委会联系人。 论坛时间及地点 2018年4月20日至4月22日，4月20日下午报到。 1500元/人，住宿由会务组统一安排，交通、食宿费用自理。 会议地点： 杭州百瑞运河大饭店，浙江省杭州市拱墅区金华路58号，电话：0571—88126666 杭州百瑞运河大饭店，418元·间／天 贾斌 18601290130 邮    箱： jiabin01011@163.com 报名方式 1.扫下方二维码填写报名申请。 2.或戳 ，填写表单申请。 请各位与会者接到通知后，于2018年4月13日前，通过电子邮件的方式回复至组委会联系人，以收到会务组确认邮件为准。 【今日机器学习概念】 Have a Great Definition "
8,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658957&idx=1&sn=a37ea3500a9671bbadd9648d902e5b75&chksm=bd4c3d5e8a3bb4480a045d2b08bcf81cee54de8cf8eec2406f4ccc5aaac60730082833277d7b&scene=27,码农岗简历石沉大海？让Twitter HR来给你把把脉,想找份码农岗，以为只要刷题就够了？ 当然不是！你很可能连面试官的题目都碰不到。 要找到一份优质码农岗，一份出众的简历是必不可少的。 想象一下，火力全开的HR每天能够审300份以上简历，他们的时间平均分配到你的简历上，很可能1分钟都不到。 想要在这1分钟内捕获HR的心，就要求你的简历条条击中要点，而且不犯关键性错误。 事实证明，写简历既是一门艺术，也是一门科学，更是一项艰巨的任务。 今天，文摘菌找来了任职于Twitter的软件开发工程师Zhia Hwa和技术部门HR Kristin Simmons，让他们给大家讲解 简历黄金法则 简历雷区 其他小技巧 给刚毕业的童鞋们的建议 推荐一些有用的工具或资源 简历黄金法则 一份简历应该简短、简洁、易读。 这就意味着要一份简历要做到以下几点： 使用一致的字体（Arial / Times New Roman都可以），为保证阅读体验，字体不要使用超过三种大小。 最好使用四个区：工作经验，教育背景，技能，项目展示。 招聘官确实是会重点关注一些字眼的，如 Java，Python，Hadoop，real-time等。 GitHub可以，但是像Snapcha 就没什么必要了。 你可以附上一封求职信，或在简历开头加一个简短的摘要。这些信息告诉招聘官你是谁以及你为什么要申请这个职位。 假如你帮助一个网站扩大了规模，不要只是写个叙事文，在里面写上可以很好地衡量你的能力的标准，如“我帮助网站从每天1万次观看扩大到每天10万次观看。” 使用“设计了”，“实施了”，“执行了”，“推动了”和“计划了”等词语，多展示你自己吧！ 其他的文档类型，如word文档(.docx)，排好的格式可能在传送过程中会乱掉。 你应该从上到下，从里到外的熟知这两三个项目。通过你对这些项目的了解可以很好地展示你的工作热情和运用能力，而这正是任何公司都需要的两个重要特质。 以以下的简历对比为例： 左边的这个简历用的是.docx文档，格式很难保持一致。当这种情况发生时你也只能寄希望于招聘官安装了Microsoft Word应用程序并能正确打开你的简历了。 所以说转化成PDF档才是正确的打开方式，能省掉不少不必要的麻烦。 简历虽短但所经之路却是漫漫而修远兮。原因是招聘官每天会收到数百，甚至数千份简历，特别是大公司的情况可能会更严峻。想象一下，如果招聘官们在一份简历上花费1分钟，每天阅读300份简历，即每天需要300分钟（5小时），每周25小时。 简明扼要的简历恰恰印证了“简历一页就够”的谚语。但这是一条指南，而不是死规矩。如果你是一位应届大学毕业生，没有足够的经验来丰富你的简历，那么就坚持这一经验法则吧。 不要以为你的简历是你过去做的所有事情的倒序年表。换句话说，要用批判的思维来写你的简历。 这就意味着写简历时 ： 一家科技公司对你在高中暑假时做过零售员是不会有多大兴趣的。 列上你曾经使用过的技能，但是不要加上熟练程度，如“好”，“精通”等等。 如“大数据”，“实时”，“机器学习”，“Docker”和“batch streaming”。因为在面试过程中，你可能会被要求展示你对这些技术的了解。 大多数面试者都做了一些很炫酷的事情，但遗憾的是他们并没有让招聘官看到这些事情与招聘职位的相关性。 Microsoft Excel、Word等是大众都会的基本计算机技能，因此可以不用特意列在简历上。 本节将重点讨论我个人认为有用的小贴士。在我写简历时，这些小技巧帮助我调整了正确的语气和心态。 一份简历就是一个关于你的故事。想象一下，你正在向某个人娓娓讲述一个故事，而这个故事是关于你自己的。 招聘官想知道在你求职的领域里你是否聪明，是否有发展潜力。任何能表明你很聪明的东西都应该出现在你的简历上。 把简历当做一幅画，能把你的故事徐徐展开并给招聘官留下一个好印象。简历上应该列出你职业生涯中的一些亮点，遇见的挑战和障碍，以及这些如何让你成为一名优秀的候选人。 同样，与职位相关的专利，出版物或发明也是简历上的重要内容。 如果你的专利和申请的职位貌似不相干，但你可以解释出专利与申请职位其实是相关的，你就可以把它列在简历中。从这项“课外活动”中可以看出你除日常工作之外的激情，勇气和付出精神。 我认为理解这一项是至关重要的。简历并不是简单地展示一下你所做过事情，而是一个经过深思熟虑，精心编排的关于你的精彩故事。 谨慎选择简历应该包含什么，不包括什么。每个点都应该提供一个暗示或信号告诉招聘官你是谁，以及为什么你是他们要找的人。 我会在心里问自己：如果我只有60秒钟的时间来说服招聘官聘用我，那么能说服招聘官的点是什么？ 然后，我就从这个点开始前后延展，用具体的事情来支撑、丰富它。 可以举个栗子： “我是一位后端软件工程师，能自主学习并精通RESTful架构。我构建了高度可扩展的网络应用程序，这个程序扩展到了数百万用户，并大幅推动了公司的产品未来构想。” 我想强调的是以下几点： 后端软件工程师 RESTful架构 可延展性 产品的愿景 然后，我会根据这四个核心点来写我的简历。我做过的哪些事情表明了我对产品的热情，我作为后端工程师的技能，我在RESTful架构方面的设计经验，以及我可以通过衡量指标来展示产品的可扩展性。 给刚毕业的童鞋们的建议 对于刚从非技术领域转过来的新毕业生和求职人员，这部分你们可以关注下。 品牌是否重要？当然很重要。你毕业的学校和你实习的公司都是重要因素。 一些公司倾向于从一些特定的学校招募，如斯坦福大学，麻省理工学院和华盛顿大学等名牌学校。如果你去的是这些顶尖的计算机科学学校，那么你就已经比其他申请人有优势了。 如果你毕业的不是一所著名的学校，你也不用灰心，你还是有其他契机的。一个好名牌可以作为一个使招聘官注意到你的信号，但其他各种重要的信号也是不容忽略的。 首先，如果你不是斯坦福大学毕业的，你在科技公司也没有太多的经验，Kristin建议提供详细的信息来说明你正努力把现在的经验和你正在申请的科技公司的职位相连接。 她经常会看到有人在简历上详细写下他们暑期打零工的经历，以及他们因工作而产生的价值。然而，应聘者们并没有告诉招聘官他们可以在科技公司发展的能力。 这也不是说打零工的经历永远不该出现在码农岗的简历上。一个好的应聘者可以详细写下他们的零售体验，并将其与他们申请的职位相关联。 如果你认为你没有机会，因为你从来没有引用过这些技术，也不要绝望。你的经验并不是判定你否符合条件的唯一决定因素。你的爱好或兴趣也是有用的信号。 如果你喜欢熔补电子产品，把断裂的电子产品焊接修复，或完全表现出能熟练应对复杂的技术，那么无论如何要把这些列在简历上。 最终，招聘官想要知道的是你的背景与所求职位到底如何相关。每个人都是截然不同的，都会带来不同的东西。 向招聘官展示你的能力。充分使用这60秒，并给他们一个考虑你的理由：“嘿，这个人可能是一个不错的选择。” 工具推荐 链接：http://amzn.to/2Hj91OH 这是一本关于编码，以及一些简历撰写技巧的书，适用于初学者。我就是用它来准备我的简历初稿。 链接：http://amzn.to/2DsXTMO   此书尤其适用于新毕业生。主要讨论专业/辅修的选择，如何撰写简历，以及获得理想工作的分步指南。 祝大家顺利当上码农~ 原文链接： https://medium.freecodecamp.org/how-to-write-a-great-resume-for-software-engineers-75d514dd8322 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 
9,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658954&idx=1&sn=0908a267f949becbc201bb4976f26921&chksm=bd4c3d598a3bb44fc6b03359c62ceae6f4d4abbf8415cf4807aebd2e31ec4b250d60e7188e74&scene=27,快去注册！吴恩达新书《机器学习思维》免费预定开启,大数据文摘作品 作者： 魏子敏 “一些技术类的AI课程会给你一个锤子，而这本书会告诉你，如何使用机器学习这把锤子。” 国内清明假期第一天，也是美国很多高校春季学期的第一周，闲不住的吴恩达老师从斯坦福大学给广大机器学习的学习者，特别是AI团队领导者带来了一个不大不小的利好： 。 如果你是一位AI团队的技术领导者，你或许常苦于如何制定一个靠谱的AI决策：比如如何确定最有前途的人工智能方向，如何诊断机器学习系统中的错误。 这些决策一方面对公司和团队发展意义重大，另一方面又必须通过长期的实践试错才能逐渐积累 经验 。 吴恩达希望通过自己多年的从业经验帮你缩短这个过程。 他希望在这本新书中，总结自己多年从业经验，帮AI团队领导者解决这些战略难题，让更多项目更好地构建AI系统。 不过，这本书目前依然在撰写中，吴恩达在推特中称，他策划这本书已经有一段时间了，之前因为深度学习项目搁置了一段时间，现在准备重新开启。 点击相关网站注册后，可以免费收到最新完成的章节。 ﻿ 图：吴恩达通过twitter发布了这一消息﻿👆 先奉上注册地址，感兴趣的同学可以点击以下网址或者点击“ ”赶紧注册啦： mlyearning.org ﻿ ﻿ 点击注册网站后，你可以看到一封吴恩达写给大家的名为《 》的公开信，详细阐述了这本书将涵盖的内容以及他写这本书的目的。 大数据文摘对这封公开信编译如下： 人工智能、机器学习和深度学习正在改变众多行业。我一直在写一本书——机器学习思维（Machine Learning Yearning），教你如何构建机器学习项目。 本书的重点不在于教授机器学习算法，而在于如何使机器学习算法发挥作用。 一些技术类的AI课程会给你一个锤子；而这本书教你，如何使用机器学习这把锤子。如果你渴望成为AI的技术领导者并想学习如何为你的团队设定方向，这本书将会对你有帮助。 阅读Machine Learning Yearning后，您将获取以下内容： 如何了解到AI项目最有前途的方向； 如何诊断机器学习系统中的错误； 如何在复杂设置中构建ML，例如不匹配的训练/测试集； 如何建立一个ML项目来比较与人类的表现； 如何了解何时以及如何应用端到端学习、迁移学习和多任务学习。 从之前的经验看，学习如何制定这些“战略性”决策的唯一方法是，在研究生课程或公司中，通过多年积累的经验来培养。我正在写的这本机器学习思维，希望可以帮你快速获得这项技能，以便可以更好地构建AI系统。 这本书大约有100页，包含许多易于阅读的只有1-2页的章节。如果你希望在每章完成后收到草稿，请注册邮件列表。  ——Andrew Ng 【今日机器学习概念】 Have a Great Definition 
10,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658978&idx=1&sn=8f0b2ad1f55445dbbd1f482f082d898d&chksm=bd4c3d718a3bb4675466c4a3aaecbadcd9a76b0963852f64488226690beb381c271cfc652f1e&scene=27,除了A/B测试，你还需要搜集这些数据！,大数据文摘作品 编译：Apricock、笪洁琼、龙牧雪 本文作者Steve Blank是最早提出用户拓展的硅谷企业家，被誉为“精益创业之父”，他著有The Four Steps to the Epiphany《四步创业法》，同时担任斯坦福、加州伯克利、哥伦比亚大学的创业课导师。在这篇文章里，他将告诉你什么样的数据和信息才是对企业有价值的。 收集来自用户的真实反馈是用户拓展的核心概念，也是精益创业的核心思想。 但是应该收集什么样的信息呢？ 有个我以前的学生向我诉苦说，只有2%的早期测试人员回复了他们的在线调查。 这份调查问卷是这么开头的： 这份问卷包括57个问题，最后3题是开放性问题，仅需约20分钟即可完成。请注意，一旦开始作答则需全部完成，不可中途停止并保存答案。 仅需20分钟。哈！ 我给他打了个电话，告诉他甚至一些SAT（美国学术能力评估测验，相当于高考）的试卷都没有这么多问题。我接着问他，有没有亲自走出办公楼，和这些潜在顾客谈一谈？或是给他们打电话？ 他有点困惑地说：“我们是一家互联网公司，所有用户都通过互联网获得，为什么不能让他们通过网上问卷给我需要的答案呢？” 根据用户拓展理论，创始人要做到持续并及时地获取用户、渠道和市场的信息。他们需要以下三种类型的数据，或者是可视化数据图表，以真正了解业务该如何开展： 第一手市场信息 鸟瞰全局的数据 从用户和竞争者角度出发的思考 获取第一手市场信息就要“走出办公楼”，和潜在或是实际客户交流。用户拓展理论提出，获取用户数据最好的方式是个人观察和体验——从办公桌后面走出来，和用户、竞争者以及市场建立较为亲密、私人的关系。 科技公司的创始人经常将通过A/B测试和在线调查获取的数据与信息混淆成第一手市场信息，然而非也。 事实上，这种错误的认知甚至可能引致事业失败。 定量的度量标准能让你知其然，却无法知其所以然。 A/B测试可以告诉你一种方式优于另一种，但不能告知你是什么导致了这种差异。用户的在线调查可以给你一部分答案，但你无法获知调查过程他们的瞳孔是否扩大、也听不到他们说话的语调。没有这些可实际观察、体会的现象，我是不会将事业建立在这些调查结果上的。 收集一些定量的信息当然是必需的，但企业创始人若不“走出办公楼”，就会错失用户拓展的一个关键点——你收集的数据反而会使你盲目，意识不到自己很可能在优化错误的商业模型。用户需求是会变化的。 第二种创始人需要的信息，是综合了客户、市场和竞争环境的多角度“鸟瞰图”。整合出这种全方位的信息，需要从多种渠道收集信息： 网页 社交媒体（脸书、推特、博客等） 销售数据 盈亏信息 市场调研数据 竞争分析 A/B测试 客户调查数据 …… 根据鸟瞰全局的数据，创始人可以弄清楚市场的形态以及竞争和客户情况的整体模式。与此同时，他们可以衡量行业数据和实际销售情况与公司收入和市场份额预期的匹配程度。 不过别忘了，大多数市场研究公司擅长的是预测过去。如果它们善于预测未来的话，那些研究者早就自己去创业了。 我一般会这样测试一位创始人如何理解这种“竞争思路”：我会给他一支马克笔，让他走到白板前，画出市场中所有参与者的关系图，并说明每位参与者所处何处。 第三种角度来自于用户和竞争者。换位思考，把自己假想为用户和竞争者，以此推断竞争者可能采取的措施、预测用户需求。 对于已有的市场，你应这样问自己：“如果我正是自己的竞争对手，掌握他所拥有的资源，接下来会如何行动？” 对于新市场或是细分市场，应当自问：“为什么相当数量的早期使用者会选择这个应用、网页或产品？怎么能让我90岁的外婆了解并购买这个产品？” 从客户的角度考虑，应该这样自问：“为什么我非选这家公司不可呢？” 把这想成下棋的技巧，你应考虑到双方所有可能的对策。如果我们是自己的对手会做什么？会如何反应？会筹谋计划些什么？一段时间后，这种角色扮演会成为每个人思考、计划过程中的的一部分。 第一手市场信息显然是最详细、最重要的，但所提供的视角稍显片面。只关注这些信息的创始人或面临有失全局的风险。 “鸟瞰全局”的数据体现市场大势，用以深究细节却有所不足。只依赖于此的创办人，其决策的准确性或许有所欠缺。 从用户和竞争对手的角度考虑是一种假想推测的练习，然而实际中没有人能确切地知道用户和竞争者究竟会如何行动。 三种角度的信息相结合，可以帮助创始人对于其业务发展有更准确的认知，使他们更好地与产品或市场磨合。 即使有了上述三种角度的信息，创始人也应谨记：要想做出完美的抉择，现有的信息是永远不够的。 数据收集过程中最重要的步骤是，一旦得到了信息，将会如何处理。对于精益企业和敏捷企业来说，用户信息的传递是其立足之基石。不管信息是好是坏，都不应被当作珍宝一样保护起来。大公司的文化总是青睐保密能力（尤其是打压坏消息的能力）较好的人，但在我的公司里，这样的人不会存在。 所有的消息，尤其是坏消息，都应被传播、分析、理解，从而能够采取行动。 也就是说，理解寥寥无几的点击率、员工流失率和销售损失的意义，比理解销售收益更重要。弄清楚竞争者的产品在哪些方面更具优势，比理解你的产品在哪方面仍有优势更重要。成功的创业公司通常建立了一种创业文化，这种文化不会惩罚带来坏消息的人。 每位创始人都需要考虑三个数据要点：第一手市场信息、鸟瞰全局的数据和从用户、竞争对手的第三者角度来进行的考量。 创业公司经常陷入将度量标准、A/B测试和调查混淆为与现实客户互动的陷阱。 应当确立信息化的目标，以此帮助达成产品/市场的适应性。 原文链接： https://thinkgrowth.org/the-3-data-streams-that-every-founder-needs-2a883a310dfe 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 
11,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658957&idx=2&sn=baaaf9048615a83fbfd919790f24eef8&chksm=bd4c3d5e8a3bb448984d76d9e0ac585f592154309978c1f375298a6b003a7306e63446e4e6e0&scene=27,二条题目：Reading Club | 算法和人生选择：如何最高效地找到合适的那件衣服？,"大数据文摘作品 作者：段  少 主播：段天霖 三月倒春寒，天气的喜怒无常让你一会短袖，一会毛衣，忙碌了一天的你回到家里，因为穿了毛衣，所以满头大汗，想马上换身凉爽的衣服，但乱糟糟的衣柜又要花几个小时来整理，想想就不happy，如何一回到家就极速换上舒爽的衣服，开心的摊在沙发上，而且自己的其他衣物依然摆放整齐呢？ 有一个算法能够让你迅速找到要穿的衣服鞋子而其他衣物依然摆放整齐，它还能够使你迅速搜寻到研究资料的同时办公桌依然井井有条，而且它还可以让你在人际交往中游刃有余，杜绝无效社交，从而拥有高效率人生，这就是最近最少使用替换算法（Least Recently Used，LRU）。 本周，我们来聊一聊【 】。由来自杜克大学的美女主播段天霖与大家分享：“LRU算法”赋能你的高效人生。 点击收听👇 如果电脑的1024G内存装满时，就需要把一些视频，Vi源图等大文件忍痛割爱删除，才能让新的资料储存进来。这一so easy的方法，在计算机算法里被称为替换策略或剔除策略。 此算法由莱斯洛.贝雷迪创造，它的目的是最大化减少在缓存中不需要的数据，缓存装满时就替换或删除很长时间之后才会再次需要的资料， 这个未雨绸缪、能够预测未来并且执行已知最优策略的算法，被称为贝雷迪算法（Bélády’s Algorithm）。 这个理论尽管不能够做到完美，但却能够极大的提高我们的效率。 贝雷迪算法（Bélády’s Algorithm）有三种方式： 随机剔除算法（Random Eviction），把新获取的数据放进缓存，随机替换旧的数据资料； 先进先出算法（ First In, First Out，FIFO），删除或替换在缓存停留时间最长的资料； 最近最少使用替换算法（Least Recently Used，LRU），覆盖或删除未使用时间最长的数据资料。 对于这三种方法，贝雷迪在多种情况下的做过测试比较， 在用计算机办公的时候，你可能会在email、网页浏览器和OFFICE软件之间不断切换，你刚刚用过其中一个软件，就有可能再次使用到它。不出意外的话，上次使用时间离现在时间最长的软件，通常也会隔很久时间才会用到。 对于操作系统的内存管理，需要解决的最难的问题是你使用了如此多软件程序，如何最有效率利用内存容量有限的内存，让多种软件程序的切换使用更流畅。 最近最少使用替换算法是为内存的虚拟存储管理服务的，是目前最通用、最有效的方法。 简单说就是在内存有限的状态下，增加一部分外存作为虚拟内存，把进程所需空间划分为多个页面，内存中只存放当前所需页面，真正的内存只存储当前运行时所用得到信息，其余页面放入外存，这就扩充了内存的功能，极大地提高了计算机的能力。 最近最少使用替换算法（Least Recently Used，LRU）根据数据的历史访问记录来进行删除数据资料，其关键的原则是“如果数据最近被访问过，那么将来被访问的几率也更高”。顾名思义，此算法关心的因素为： 运用这一算法最成功的大概是一些零售巨头：盒马先生、京东和亚马逊等。 亚马逊不采用传统图书馆或百货公司的仓储方式，而是通过研究消费者历史订单、搜索记录、愿望清单、购物车清单、退货记录、鼠标在各种商品的停留时间等各种数据预测出消费者下一步可能购买的商品，把最近的某个区域非常热销的商品，配送到该地区的临时仓库。 仓库内部看起来非常混乱，玩具可能放在钢笔、尿不湿、键盘和小提琴旁边，但是需求购买量大的商品会排放在不同区域。商品距离顾客已经很近，当顾客下单时，产品能迅速配送。这种仓储方式就是亚马逊根据贝雷迪算法（Bélády’s Algorithm）发明的“预测式出货”专利。 简要总结一下，亚马逊通过划分临时仓库和中央仓库的不同功能，让临时仓库存放顾客购买需求量大的商品，由于距离非常近，很利于短时间内完成配送服务，提升了顾客满意度，从而带来稳定高效的现金流。 我们常看到的收纳建议，是把类似的物品归在一起。日本的东京大学的经济学家野口悠纪雄是反对此看法的，他出版过非常多办公室收纳和人生攻略的畅销书籍，刚开始研究经济学时，他常常被书籍和笔记等大量文件淹没，每天都要花很多时间整理。 一开始他只是把每份文件放进档案袋里，档案袋上标注文件标题和日期，然后把档案袋全部放进大箱子里，这种方法不需要思考每份文件的如何摆放，能节省很多时间。 到了1990年代初期，他一律把档案袋放在箱子的左手边。野口指出，不论新档案还是旧档案，都适用左边法，每次取出档案用过后，一定是放在箱子最左边，找档案也是从最左边开始，这样，他最先看到的就是最近使用过的档案。 野口一开始这样做，只是因为把档案塞到最左边比塞回原处要容易得多，但他后来发现，这种方式不只是简单，而且更有效率。然而这种方法有个问题，是否容易找到你需要的档案呢？ 虽然野口当时并不知道他的收纳方法其实就是最近最少使用替换算法的延伸。最近最少使用替换算法告诉我们，把新的资料放入缓存时，应该剔除最旧的内容。 但我们应该把新的资料放在哪里，才会提高下次搜寻的效率？1970和1980年代的计算机科学家，进行了一系列的研究，解答了这个问题。当时他们遇到的问题和野口归档的困境一样，在寻找档案时，你必须要从头开始逐一看过每个档案，但你找到所需的档案后，可以放在任何位置。此时你应该把这个档案放在哪里，才能更高提升下次的搜索效率？ Daniel Sleator和Robert Tarjan在1985年发表关于自组织列表的重要论文。通常，搜寻从最前端开始，所以我们排列顺序时，也希望把最可能用到的物品放在最前端，但最可能用到的物品又是什么呢？这又回到预测未来的问题了。 史利特和塔尔占的研究结果显示，如果我们遵循最近最少使用替换算法，每次把物品放回最前端，那搜索所花的时间，绝对不会超过我们能预知未来时的两倍，而且其他算法都没办法保证这一点。 史利特和塔尔占的研究结果还提出另一种变化，把野口的档案收纳方法旋转90度，一箱档案旋转90度就变成一摞档案，这样一来在找档案时，自然会从上到下，每次抽取文件后不放回原处，而放在最上面。在书桌上堆了一大摞文件，不但是不是混乱的象征，还是目前已知最有效率的资料摆放结构，没有必要产生罪恶感，由于我们无法预知未来，所以把用过的东西放在最上面是最好的办法。最近最少使用替换算法不只更有效率，而且就是最佳方法。 那如何利用此算法高效整理你家的衣服鞋子呢？ 首先，决定要保留和舍弃哪些衣物。如果你念大学时买的T恤有时还会穿，就不要丢掉；但很久没穿的格子长裤，就送到二手店，说不定要能遇到白富美。 其次，利用家里的不同空间。你经常在哪里穿西装，是卧室，还是书房，还是客厅，就把西装放在离那个地方最近的柜子里。这点经常被收纳专家提到，Julie Morgenstern的《收纳其实很容易》有这么一段话：我把跑步和运动用品放在前门衣柜的底部箱子里，我希望它尽量接近大门。 最后，多层次收纳。 例如你家的收纳空间，门口的鞋柜是第一个存储结构，卧室的衣柜是第二个，地下室是第三个，依据最近最少使用替换算法（Least Recently Used，LRU），拿到衣服鞋子的速度会随着层级而越来越慢，不同物品会从每个层级剔除到下一个层级，你可以再买一个比鞋柜更小，取用速度更快的收纳箱。 有人说，人的地位是由认识与交往陌生人的能力决定的。 陌生人与熟人只是一层窗户纸，你完全有能力让一个陌生人变成熟人，自己的人脉远不是按交换的名片数量决定的，关系的培养和维护才是最重要的。 使用最近最少使用替换算法，来弥补短时间内对彼此记忆的大幅度衰减，经过多次联系交往后，新的“熟人”才会形成和固化。 人的记忆的能力从生理上讲是十分惊人的，它可以储存10的15次方比特的信息， 1887年，雅各布斯通过实验发现，对于无序的数字，测试者者可以记起的最大数量大约为7个。发现遗忘曲线的艾宾浩斯也发现，人在阅读一次后，可记住约7个字母。 1956年，美国心理学家米勒教授发表了一篇重要的论文《神奇的数字7±2：我们信息加工能力的局限》，明确提出短时间记忆的容量为7±2，即一般为7，并在5到9之间波动，这就是神奇的7±2效应，它告诉我们一个规律： 但如何做到呢？借鉴最近最少使用替换算法。 首先，预测对方最想听的内容，删除对方最不想听的，把对方最想得到的信息放在最前面，虽然7±2法则表示人能记下7个左右的信息块，但在社交场合中有很多干扰因素存在，比如噪音干扰和对方的心情，所以最好讲述两三个信息块，这样才能够给对方留下深刻的印象。 其次，结构化组合不同的重要信息块，用生动的肢体语言和幽默有趣的话语，来打动陌生人，让他们更好的回忆起你热情洋溢的笑容。例如郭德纲的相声，大家都爱，为什么，大包袱和小包袱很有节奏感，你笑的也有节奏感，喜欢音乐的我们当然也最痴迷有节奏的谈话。 最后，呵护你的关系，第一次见面的一周后，选择对方最熟悉的话题，比如选择与对方行业、公司、产品、个人兴趣相关的话题，来请教一些自己感到苦闷与感到不解的问题，回答的质量不重要，你也不要太挑剔，彼此的肯定很重要，当来往超过五个来回就属于一般意义上的熟人了。 此后每月保持一个月一次左右的微信问候，忌讳在初期交往的时候提出太多的苛刻要求，每年保持在三到四个节假日送上自己编写的好玩的祝福微信。有机会的话，参加朋友的聚会或邀请朋友带上他们的朋友一起参加有趣味的活动，来扩大自己的交往圈，使关系发展的“星星之火”可以高效留存下来。 马上就要过莺啼燕语的四月了，是个让自己改变的好时间。只要有这个最近最少使用替换算法（Least Recently Used，LRU），不论你在公司冲业绩，还是在学校写论文，还是你在家里被逼着做家务，还是要提升自己的社交质量，你都可以比别人更有效率，更快升职加薪、更快得到奖学金、更快整理衣物、更高效找合伙人。 点击收听前三章内容： 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 "
12,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658936&idx=2&sn=5ed330f1a4e9ee09b01072cdd8cada97&chksm=bd4c3d2b8a3bb43d9a8b7ad89df62c5a757d6a9eaeccebf77c15585fedc3897f6de24ddcda4e&scene=27,前沿 | AI不用地图和GPS也能认路：DeepMind再放大招,﻿ 大数据文摘作品 作者：龙牧雪 是的，谷歌DeepMind又在搞事情。 这次，是用深度强化学习和神经网络来建立导航系统。无需标注好的地图指引，AI仅仅依靠街景照片的图像识别就能到达目的地。类似于AlphaGo Zero的没有棋谱，也能学会下棋。 注意，这无关乎驾驶，仅仅关乎导航——穿越真实城市，到达指定的经纬度坐标。整个过程不涉及交通数据（周围有没有车和人），也没有对车辆控制建模。 但这已经足够复杂了。在曼哈顿的5个区域、伦敦和巴黎市中心，AI能成功穿过复杂的交叉路口、人行道、隧道和各种拓扑结构。 3月31号，DeepMind在ArXiv上发布了相关论文：Learning to Navigate in Cities Without a Map。大数据文摘公众号后台回复 即可下载这篇论文。 ﻿ ﻿ DeepMind随后发表的一篇博客文章称，AI做的这件事类似于一个小孩如何记住周边的环境。小孩并不需要看一张地图，只需记住街道的视觉外观并沿途转向，就能前往朋友家、学校或杂货店。而且会越走越熟练。如果迷路了，他可以通过关键地标甚至太阳的朝向来认路。 这是人类的导航系统。 导航是一项重要的认知任务，有导航系统的人类和动物可以在复杂的世界中远距离穿行，而无需地图。同时，可以自我定位（“我在这里”）和表述目标（“我要去那里”）。 那么，AI如何学习在没有地图的城市中进行导航？ 一个利器是谷歌街景视图（Google Street View）。这些图像数据是现成的。这样，AI不用真的到某个城市里穿行，只要在街景里游荡就可以了。利用街景视图建模的优势在于，这些照片以人眼视角拍摄，也就是说，如果一个人站在相同的地理位置，他看到的图像就和模型看到的一样。 ﻿ 依靠街景图像而不是地图 研究人员建立了一个基于神经网络的人工智能体，学习使用视觉信息（来自街景图像的像素）在多个城市中导航。当AI到达目标目的地（例如，指定的经纬度坐标）时，该AI就会得到奖励。 好比一个7x24小时无限循环工作的快递员，要不断地到达指定地点，但是又没有地图可以看。 随着时间的推移，AI学习以这种方式跨越整个城市。经过在多个城市的训练和学习，在适应新的城市时AI的表现非常好。 AI在巴黎街景中训练。街景图像与城市地图叠加，显示目标位置（红色），代理位置和视野（绿色）。请注意，AI不会看到地图，只能看到目标位置的纬度/经度坐标。 与传统的依赖明确映射和探索的方法（例如试图本地化并同时绘制地图）相反，DeepMind让AI只使用视觉观察，而不使用地图、GPS定位或其他辅助工具。 用到的技术是，构建了一个神经网络代理，用于输入从环境中观察到的图像，并预测它应该在该环境中执行的下一个操作。使用深度强化学习进行端对端训练，类似于此前关于学习穿越复杂3D迷宫，以及用无监督辅助任务进行强化学习来玩游戏的研究， 神经网络由三部分组成 ： 可以处理图像并提取视觉特征的卷积网络 特定场所的循环神经网络，其隐含任务是记住环境，并学习“这里“（代理的当前位置）和”那里“（目标的位置） 产生关于代理行为的导航策略的场所不变循环网络。特定于语言环境的模块被设计为可互换，并且如其名称所示，对于代理导航的每个城市都是唯一的，而视觉模块和策略模块可以是语言环境不变的。 ﻿ ﻿ CityNav (a) MultiCityNav特定城市建模 (b) 训练和转移到新城市 (c) 就像在Google Street View界面中一样，AI代理可以在适当的位置旋转，或者在可能的情况下前进到下一个街景。与谷歌地图和街景环境不同，AI不会看到小箭头，本地或全球地图，或著名的Pegman：它需要学习区分开放道路和人行道。目标可能在真实世界中距离数公里，AI要通过数百个街景图才能到达。 ﻿ ﻿ Pegman，谷歌街景视图中的虚拟小人 值得注意的是，这是一个可以转移到新城市的模块化神经网络架构。与人类一样，当AI访问一个新的城市时，我们会期望它必须学习一组新的地标，但不必重新学习其视觉表现或其行为（例如，沿着街道向前走或在交叉路口处转向）。因此，使用MultiCity体系结构，DeepMind首先在许多城市进行训练，然后冻结策略网络和视觉卷积网络，并在一个新城市中只建立一个新的特定地区路径。这种方法使AI能够获得新的知识，而不会忘记它已经学到了什么，类似于渐进式神经网络架构。 导航系统是研究和开发人工智能的基础，也对了解人类的生物导航系统有帮助。 素材来源： https://deepmind.com/blog/learning-to-navigate-cities-without-a-map/ 【今日机器学习概念】 Have a Great Definition 
13,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658978&idx=2&sn=941f71e26c27514e7ec56b0e766bee3e&chksm=bd4c3d718a3bb467d85fe042357fc0a2d7569249840521b1a15303c37e9b1e6b0f08a25fc583&scene=27,重磅译制 | 更新：牛津大学xDeepMind自然语言处理 第8讲（中）注意力模型,大数据文摘重磅课程汉化《牛津大学xDeepMind自然语言处理》 本周更新至：Lecture 8 注意力模型（2） 马上观看👇 点击文末 ，即可免广告观看 牛津大学Deep NLP是一门关于自然语言处理（NLP）的高阶课程。课程由 和 （AlphaGo的开发机构）联合开设，是牛津大学计算机系2017年春季学期最新课程。由Phil Blunsom主讲，同时邀请到多位来自DeepMind和NVIDIA的业界讲师来做客座讲座。 大数据文摘已联系课程主讲人取得翻译授权，并联合北京邮电大学模式识别实验室 组织了视频汉化， 发布。 课程视频【中文字幕】学习地址： （连载中，请收藏！点击文末 ，可直接加入学习） http://study.163.com/course/introduction/1004336028.htm 牛津大学课程页面（所有资料汇总）： https://github.com/oxford-cs-deepnlp-2017/lectures 本课时PPT精华 后台对话框内回复“ NLP ”获取本课时PPT 后台对话框内回复“ NLP ”获取本课时PPT 课程 ，复制打开链接免费加入学习： http://study.163.com/course/introduction/1004938039.htm 《斯坦福CS231n深度学习与计算机视觉》课程已更新完毕，李飞飞与Andrej Karpathy（现任Tesla AI部门主管）主讲，已有9万+人参与学习，复制打开链接免费加入学习： http://study.163.com/course/introduction/1003223001.htm 本期工作人员 翻译 李楠  闵峰  乔一宁  张世平   刀哥  momo  无敌乔卡特 终校 IrisW  蒋宝尚 项目管理 龙牧雪  李楠 顾问 张闯  寒小阳  汪德诚 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 
14,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658936&idx=3&sn=e5d682149b49acaa70dec774f5648f01&chksm=bd4c3d2b8a3bb43d0e9e70566561b23227ef7dd730903a231c8efcf0a3ef5b7eec2d7891820b&scene=27,业界 | 剧情反转！原谷歌AI与搜索部门老大加入苹果,剧情再次反转！ 就在昨天，谷歌被曝出分拆搜索和人工智能部门，部门老大John Giannandrea引退，Jeff Dean和Ben Gomes各自负责AI和搜索业务。而一天后，苹果公司宣布雇佣John Giannandrea。 John Giannandrea将负责苹果公司的「机器学习与人工智能战略」，成为16个直接向库克汇报的高管之一。 苹果在人工智能领域被认为落后于同行，而此番抢先聘用原谷歌AI与搜索部门负责人，可以被认为是苹果公司在人工智能方面追赶竞争对手的一大举措。 在Facebook数据丑闻之下，苹果在人工智能研究推进过程中的数据隐私方面有自己的考虑。苹果公司表示正在开发一种方法，可以在不影响隐私的情况下训练人工智能算法。 根据纽约时报曝出的内部邮件内容，苹果公司CEO库克在周二已向其员工表态：“我们的技术必须受到我们的价值观引导，John支持我们在隐私方面的承诺，以及我们在使计算机更加智能、更加人性化过程中的周全做法。” 尽管苹果凭借手机产业崛起为全球最有价值的上市公司，但科技行业的许多人认为，苹果的语音助手Siri不如谷歌和亚马逊的同类产品更有竞争力。 Giannandrea的领英暂未更新 Giannandrea今年53岁，苏格兰人，被同事称为J.G.，曾经帮助谷歌整合所有人工智能产品条线，包括互联网搜索、Gmail和谷歌助手。 2010年，谷歌收购了初创公司Metaweb，作为首席技术官的Giannandrea在那时候加入谷歌。当时Metaweb正在建设“世界知识数据库”，收购之后，谷歌最终将其应用到搜索引擎中，为用户的查询提供直接答案。在Giannandrea的任期内，人工智能研究在谷歌内部变得越来越重要。谷歌的主要人工智能实验室，谷歌大脑(Google Brain)的员工 坐在谷歌首席执行官Sundar Pichai的旁边办公 。 苹果在人工智能领域曾经高调招聘，其中包括卡内基梅隆大学教授Russ Salakhutdinov。 Giannandrea在接受采访时曾表示，“人工智能技术的快速增长是对人类的威胁”这种担忧被夸大了。 “我们会加速进入某种超级智能系统，而人类在那个时代无能为力。”Giannandrea反对这种说法，他认为这种超级系统的技术基础得到实现还遥遥无期。 素材来源： https://www.nytimes.com/2018/04/03/business/apple-hires-googles-ai-chief.html https://techcrunch.com/2018/04/03/apple-steals-googles-ai-chief/ 【今日机器学习概念】 Have a Great Definition 
15,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658936&idx=4&sn=251c8d48cfcfa33a4aa05edb94b3beb9&chksm=bd4c3d2b8a3bb43da5047b21bbc54db36482e53891c019e29ac4d2aa5d0e1b60c9be6d9d132c&scene=27,突发 | Up主在YouTube加州总部开枪，至少3人受伤,当地时间4月3日下午，美国加州YouTube总部发生枪击事件，犯罪嫌疑人是一名女子。该名女子在作案后也开枪自杀。 目击者说，刚开始以为是地震，随即跑出会议室，但是还没有跑出大楼，就听到有人开枪的消息。还有人看见地上和楼梯上有血迹。 据外媒报道，枪击者伪装成YouTube工作人员进入大楼，在现场至少开了20枪，随后开枪自杀。事发时，有超过1100名YouTube员工在大楼里上班。 警方初步调查称，该名死亡女子在现场被发现，其似乎是用手枪自杀的。 目前，枪击者身份已被确认，名为Nasim Aghdam，是一个Up主，曾在2017年1月发视频抱怨YouTube的视频Filter机制。 现在确定的是枪击者至少认识其中一名受害者，但是犯罪动机尚未明确。 该女子曾经的视频画面 记者从接受伤员的医院了解到：共有三名受伤人员，其中，一名三十六岁男子情况危殆，一名三十二岁女子情况严重，一名二十七岁女子情况良好。三名伤者均有清醒的意识，无人进行手术治疗。 在接到报案两分钟内，警方立即赶到了事发现场，并进行现场控制：封锁了大楼附近的几条公路，并对现场人员进行挨个搜身检查。 案发后不久，美国总统特朗普针对此事件发推特表示刚了解到此事件的简要情况，他和现场的人员感同身受，并感谢行动如此迅速的警方。 美国 参议员 Dianne Feinstein发推特表示她正在为YouTube员工祈祷。此参议员一直主张控枪。 素材来源： https://www.google.com/amp/s/amp.cnn.com/cnn/2018/04/03/us/youtube-hq-shooting/index.html https://www.nbcbayarea.com/news/local/Suspect-in-You-Tube-Shooting-Posted-Rants-About-the-Company-Online--478711713.html 【今日机器学习概念】 Have a Great Definition 
16,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658904&idx=1&sn=3ff417c236c2b0867b72ebb2344887a4&chksm=bd4c3d0b8a3bb41dd47013bb634513fb06cbf6103122c34d367ae18b1b0c80a3f24b6a903690&scene=27,谷歌AI First战略性一步：分拆搜索和AI部门，Jeff Dean任AI总负责人,大数据文摘作品 编译：龙牧雪、蒋宝尚 刚刚，据海外媒体Bloomberg报道，谷歌公司已经确认，谷歌工程高级副总裁John Giannandrea将不再担任搜索和人工智能部门的负责人。 John Giannandrea 搜索和人工智能部门将一分为二，分拆成搜索部门和人工智能部门。人工智能单独成为一个部门，这一举措被认为将极大增强谷歌AI业务的影响，也是谷歌AI First战略的重要一步。 新的人工智能和搜索业务将由Jeff Dean和Ben Gomes这两位高管负责。 原谷歌大脑（谷歌人工智能研究的重要部门）负责人Jeff Dean将接管谷歌的所有AI相关业务。而谷歌搜索副总裁Ben Gomes将全面负责搜索业务。 Jeff Dean 被拆分的搜索和人工智能部门在谷歌存在了两年。 2016年2月，谷歌母公司Alphabet将谷歌的搜索和人工智能部门合二为一，聘请资深计算机科学家John Giannandrea掌舵。他为谷歌的“知识图谱”这项技术打下了坚实的基础。 谷歌的搜索和人工智能业务一直处在这两个领域的技术领导地位，但随着基于语音的搜索设备的出现，它正面临来自亚马逊和苹果等竞争对手的新威胁。 新任搜索部门负责人的Ben Gomes在谷歌的主要工作内容是遏制其平台上的虚假信息，确保谷歌搜索保持领先地位。 Ben Gomes 谷歌CEO Sundar Pichai越来越强调AI对整个公司的重要性。人工智能现在非常重要，足以组建自己的业务部门。这标志着谷歌将重点放在机器学习和人工智能方面。 据了解，John Giannandrea仍然在Google负责另外的业务。谷歌的一位发言人证实了上述举措，但拒绝进一步置评。 素材来源： https://www.bloomberg.com/news/articles/2018-04-02/google-shakes-up-management-at-top-of-powerful-search-ai-units https://www.cnbc.com/2018/04/02/google-exec-john-giannandrea-steps-down-jeff-dean-takes-over-ai.html 【今日机器学习概念】 Have a Great Definition 
17,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658904&idx=2&sn=3b9ebb2633f3da59a114c87f720b8f19&chksm=bd4c3d0b8a3bb41d5f40e5f257984eb258559ea60d978f76e9e0b72e1551d1607d0218f0ae2d&scene=27,FinTech崛起：算法将如何改变支付行业？分析数据集只是第一步,大数据文摘作品 编译：Yanruo、大茜、一针、Yawei Xia 不久之前，CEO们和大型银行还坚信，银行的地理位置是为客户提供所必须考虑的因素。但是，就在近10年，数字银行（Digital Banks）崛起。数字银行可能永远都不会有实体存在，但它仍然在继续扩大用户群并增加包括保险、抵押和贷款服务。下面我们就来看看数字化和算法化会给传统的支付模式带来的变化：在数据集之上进行分析只是第一步，要完成算法化流程，还需要使用机器学习与人工智能创建新的数据。 在支付行业，我们曾见证Chase和Fisrt Data等公司占据行业统治地位长达四十多年。然而，就像银行业的数字化迫使业内人士改变战略一样，我们注意到，数字化支付已经帮助了一些公司获得更多市场份额，比如说WorldPay、Vantiv，甚至是最近的Stripe、PayPal/Braintree和Adyen。 它们的成功并不立足于传统商业，而是大力发展科技创业项目，有些发展得好的项目抢了传统业务的风头、甚至把他们挤下历史舞台。这里可以联想一下诸如娱乐传媒大亨对Netfix、出租车对Uber或者传统商店对Amazon的竞争交锋。 2018与2006年亚马逊与传统零售公司市场价值对比 可是，随着越来越多的企业都认识到数字化是大势所趋，我经常会问： 就如同在70、80年代大胆采用计算机与数据库的公司，又或者是那些在90年代就已洞悉互联网将掀起巨变的公司，经历了新千年网络泡沫破裂的验证，我认为现如今深入理解算法化（Algorithmization）将带来的改变并积极投资于此的公司最有可能平稳度过竞争激烈的2010和2020年代。 数字化流程 要理解算法化是什么，我们首先需要回头看看传统商业的流程。数百年来，传统商业流程是由人们用劳动力创造产品或提供服务和与之相关的一系列周边业务活动组成。 例如，提供医疗服务的医生有坐诊时间，病人可以直接就医或提前预约。传统而言，登记患者信息、更新病历及开具处方等一系列流程都是通过纸笔完成的。随着这些流程的数字化，计算机进入了医生的办公室，从此病人档案可数字化存储，预约看病可使用数字日历，处方则可直接邮件给药剂师。 即使到今天，企业仍不断改进数字化流程：开发移动应用程序或者提供云服务来让用户更好访问和存储实际商业流程所产生的数据。 算法化 当我们讨论算法化时，我们讨论的是使用存储在数据库中的数字化标记数据和自动化程序分析用户并根据结果进一步反馈给用户有价值信息的过程。 大多数公司已经完成了上述的过程，但这只是进入算法化的第一步。当可以使用数据集（N）来分析用户信息并反馈时， （N=N+1）。 一个支付服务提供商的例子 为了更好地说明，现假设有一个每天处理数百万笔的交易的支付服务提供商。商户上传的每一笔交易都包含PAN（个人账号）、CVC（信用卡验证码）、有效期和顾客姓名以及电子邮件地址等与交易相关的信息。通过浏览器，PSP（支付服务提供商）还能收集额外数据如：时间和日期、设备ID、浏览器类型与版本、IP地址和其他数据点（N）。 当处理交易的过程中，交易数据会存储在数据库中。大多数PSP（支付服务提供商）会用这些数据为商户提供指定日期的标准交易报告。有些甚至能汇总数据来提供数据摘要。如果他们想更加吸引用户，他们会开发可视化图表来显示交易是如何随着时间的推移变化的。 随着计算能力、云计算和分布式存储技术的进步，包括PSP（支付服务提供商）在内的许多公司都在尝试各种改进现有流程的方法。例如，此前我们假设的这一PSP（支付服务提供商）决定研究海量历史数据是否能帮助公司防止未来传入交易数据中的欺诈性行为。通过使用机器学习和人工智能，数据科学家得以发明一种算法，它能使用一部分交易中多种变量来 。 基于卡的支付系统好处是，持卡人能够质疑特定时间段内的交易。每当一起欺诈性交易被举报时，发卡商都会发送一条消息来追回交易。只要接收到这些信息，PSP（支付服务提供商）就可以将其存储在数据库中。这使得PSP有能力验证初步欺诈预测的准确性。借助人工智能算法，他们可以通过增加或减少此前算法中各变量的权重来调整原有算法并提高其评分。这实际上是创建了算法化中的一个新流程（N=N+1）。 前文的例子只是一个关于如何使用算法化改进现有流程的案例。有趣的是案例中的方案确实是多年来处理欺诈交易问题的主要方案，可是欺诈者也越来越聪明，欺诈行为仍然时有发生。 但是支付所包含的内容不仅仅是防止欺诈。成本、货币兑换、连接性能、计费和支出是一些新的PSP能够使用算法化有所作为的领域。随着越来越多的公司逐渐习惯PSP的商品化，保持PSP成功的方法并不是减少欺诈或降低交易成本，而是展示PSP的价值，即为使用者带来更多的生意。 销售部门比财务部门更受欢迎的原因是创造更多的收入等于是增长，而降低成本可能会提高利润，但不会增加收入。 智能获取 路径 在性能、功能或定价的基础之上，同样的交易数据可以用于优化获取线路。实现一个多路径算法是很好的方法，这是一个更“智能”的或者说复杂版的A/B测试，它使用机器学习来动态分配流量给性能好的变量，同时分配更少的流量给表现不佳的变量。通过连接多个数据收集方，PSP可以给特定客户分配效果最好的预测变量，从而提供最好的预测结果、定价和功能。 因为发卡方设置的两步交易验证如Visa的Verified或是万事达（Mastercard）的3DSecure，许多PSP依然有较高的支付被拒率。采用决策树的机器学习方法，PSP们可以预测交易是否需要转到3DSecure页面进行额外的两步验证，或进行常规流程是否能完成交易。 不要被别人的想象限制 当然，还有许多其他使用交易数据的方式可以提高商业表现。如果说有人能够利用几十年来所积累的用户数据来创造一个能够改进现有流程的PSP，或者是能够满足甚至目前还不存在的商业模式对支付需求的PSP，我觉得完全有可能。 我们不可避免地要承认，这个世界正处于金融科技革命的掌控之中。 科技环境正在以指数的速度发生改变，使得金融部门的变化比以往更加复杂和多样化。 这一切是如何发生的？金融科技初创公司与传统金融行业相比有何优势？ 这个问题使我们思考技术落地的问题和金融科技成功的秘密，金融科技快速发展是由于大数据分析，区块链，机器学习或人工智能？ 金融科技正在试图对全部门进行数字化。通过使用大数据，机器学习和人工智能为新一代投资者提供最佳投资机会，机器人顾问很有可能会取代（人力）财务顾问。 人工智能 帮助你更准确快速地处理这些信息。机器学习可以识别特定的模式，并且能够随着它完成的的每一项任务而改进。因此，随着时间的推移，其处理信息的能力会变得更快。 区块链 可以改变沃尔玛等公司的供应链，并帮助像摩根大通这样的银行每年节省数十亿交易费用。区块链实际上使得整个系统不再需要中介来进行资产转移。付款交易通常通过一个中介，经过多个步骤对申请人进行身份验证和授权。 完成这些流程可能需要两到三天时间。而通过区块链能将所有步骤压缩成在几秒或几分钟内完成的一个步骤。因此，许多金融服务行业可以通过使用该技术提高交易速度和透明度来提高绩效。 在流程中运用AI，ML和区块链的另一个理由是提高安全性。虽然人工智能尚未先进到可以完全替代人类，但它可以验证和复查重复费用和其他常见错误。基于人工智能的工具可以十分准确地检测欺诈行为。 北欧地区最有前景的FinTech创业公司 北欧地区是欧洲第二大金融科技区。FinTech仍然是瑞典最大的独立产业。 他们正在寻找新的方式来提供金融服务，从而开发出新的发展客户和与客户进行交流的方式。过去几年里，他们已经引入了许多有前途的创业公司，这些公司正在“围剿”传统金融服务业。 我们都知道的公司比如iZettle，Klarna，Auka（mCash），Trustly，Meninga等，它们都在一步步进阶行业顶尖的位置。谁会成为下一个脱颖而出的公司？谁会在不久的将来取代上述公司的地位？您可以在下面找到一些北欧地区的金融科技初创公司的名单，这些公司很有意思，有的值得长期关注，甚至值得你去亲自尝试他们的服务。要不然，投资者怎么会投资巨款来孵化它们呢？ 1.Lendify 总部位于：瑞典斯德哥尔摩 成立时间：2014 已融资4200万欧元                  Lendify在瑞典建立了第一个真正的市场借贷平台。该公司经营一个在线信贷平台，人们可以相互借贷而无需银行参与。 2.LunarWay 总部位于：丹麦奥尔胡斯 成立时间：2015 已融资900万欧元 LunarWay是一家手机银行应用程序开发商，其目标用户是千禧一代。通过APP开设银行账户，可获得MasterCard®（万事达）支持的借记卡，查看实时交易消费的信息以及通过商品目录或零售商查看您的交易。用户还可以通过应用程序设置储蓄目标，以及支付账单。 3.Pleo 总部位于：丹麦哥本哈根 成立时间：2015 已融资630万欧元 Pleo——与应用程序联系的“智能”公司卡片。Pleo是管理公司开支的全新方式。提供即时和按需预付MasterCard®（万事达）虚拟卡用于在线购物和塑料卡片用于店内购买。Pleo允许员工购买他们工作所需的东西，同时使公司完全控制所有开支。借助突破性技术，Pleo降低了管理的复杂性，取消了费用报告并简化了簿记。 4.Anyfin 总部位于：瑞典斯德哥尔摩 成立时间：2016 已融资500万欧元 Anyfin——其目标是建立未来金融服务，杜绝不正当商业行为，并关注那批没有被传统金融服务关注到的人群。它降低借款人每月的高利率和隐性费用。利用技术跳过昂贵的中间商，并且不会收取过高的管理费用。 5.Capdesk 总部位于：丹麦哥本哈根 成立时间：2015 已融资100万欧元 Capdesk——是世界上第一个社会化股东管理工具。它旨在通过创建透明，协作和可访问的投资环境，让未上市的股票同样具有投资价值，从而提高私有公司股份持有人的体验。该平台使公司的所有权数字化并将所有投资者的一些相关动态更新集中收集呈现。 6.Hiveonline 总部位于：丹麦哥本哈根 成立时间：2016 已融资81.9万欧元 Hiveonline——小企业和可持续投资产品的金融信托平台，其在金融生态系统中建立信任机制。它有两个主要业务：帮助小型企业管理声誉，交易和协议，以及一系列可持续投资产品，让投资者相信他们的资金正用于正确的事务，同时根据他们的业绩对发行人进行评分。 7.BizBot 总部位于：挪威福内布 成立时间：2017 已融资21.3万欧元 Bizbot是投资者和企业所有者的股权工具。通过分析用户数据，BizBot可以自动完成那些费时的流程，从而提供宝贵的资源以提高生产力并减少工作量。 谁是他们的用户？他们如何影响和改变世界？ 通过这些技术，可以在B2B行业，B2C行业，独立客户和不同行业的客户之间简化所有有关金融和银行业务的手续。金融科技创新通过移动设备或较大型的权威机构，改变传统贸易、银行交易，金融产品和服务。 金融科技初创公司正在以多种方式影响金融市场：提供更快的贷款处理，可以在几小时内而不是几天或几周内申请和批准贷款。而且还可以通过数据分析提供定制保险服务。小企业和其他用户允许通过应用程序进行所有支付从而节省时间。提供全天候客户服务，向客户提供建议，同时保证最少账户和最低费用。客户只需要以前费用的一部分就可得到定制的、个性化服务。 北欧金融科技凭借出色的金融技术，卓越的支付平台和前卫的技术消费者在全球扩张方面拥有独特的地位。世界其他地方还有多久才能如此数字化？时间会证明。 原文链接： https://towardsdatascience.com/the-algorithmization-of-payments-how-algorithms-are-going-to-change-the-payments-industry-5dd3f266d4c3 https://altabel.wordpress.com/2018/02/28/fintech-startups-who-is-the-next-klarna-in-the-nordic-sky/ 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 
18,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658904&idx=3&sn=d529295c4bd5c6e84703ccbee74483b9&chksm=bd4c3d0b8a3bb41d58286c31a9be7ba5893cba4c094958958fece7aeaaa39c18e6c75647ff31&scene=27,AI大事件 | TensorFlow开发者峰会，DeepMind重回巴黎，谷歌云提供文字转语音服务,大数据文摘作品 呜啦啦啦啦啦小伙伴们大家好呀！过去的一周中AI圈都发生了什么？大佬们讨论了哪些问题？研究者们发布了哪些值得一读的论文？又有哪些开源的代码和数据库可以使用了？快快跟随文摘菌盘点过去一周AI大事件！ 新闻 来源：MEDIUM.COM Tensorflow开发者峰会于2018年3月30日举行。它包含数十个教程和几个重要公告，包括Tensorflow.js的发布和重新品牌化，Tensorflow的JavaScript端口，Tensorflow Hub的发布，Tensorflow模型代码的分享和Tensorflow对SWIFT的支持等等。 来源：DEEPMIND.COM 链接：https://deepmind.com/blog/a-return-to-paris/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI DeepMind 宣布在欧洲大陆开设第一个研究实验室DeepMind Paris，此实验室将由由Remi Munos领导，他是DeepMind的主要研究科学家之一，曾发表过150篇研究论文。 来源：CLOUDPLATFORM.GOOGLEBLOG.COM 链接：https://cloudplatform.googleblog.com/2018/03/introducing-Cloud-Text-to-Speech-powered-by-Deepmind-WaveNet-technology.html?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这一项新服务允许您使用高质量的文本到语音的合成功能，为您的应用程序生成自然的声音。价格竟然低至100万字16.00美元。 文章&教程 来源：WORLDMODELS.GITHUB.IO 链接：https://worldmodels.github.io/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 代理能够在自己的“幻觉”中学习吗？在这项研究中，一个代理是在一个学习的环境模型里面进行训练的，这是一种虚拟的环境。并且在学到策略然后转回到真实的环境中后，代理仍然表现出色。  来源：SIMONINITHOMAS.GITHUB.IO 链接：https://simoninithomas.github.io/Deep_reinforcement_learning_Course/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 关于Deep Reinforcement Learning的系列免费博文，您可以在这里了解主要算法以及如何在Tensorflow中实现它们。 来源：WWW.YOU TUBE.COM 此Youtube频道包含上周举行的Tensorflow开发者峰会的所有录音，是了解新的Tensorflow功能和用例的优秀资源。 代码、项目&数据 来源：GITHUB.COM 链接：https://github.com/minimaxir/person-blocker?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 使用在MS COCO数据集上预先训练过的Mask R-CNN自动“阻挡”图像中人物的脚本（如Black Mirror插图为White Christmas）。 来源：GITHUB.COM 链接：https://github.com/salesforce/matchbox?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI Matchbox使深度学习研究人员能够在各个示例级别编写PyTorch代码，然后在小型代码上实现高效运行。 爆款论文 来源：ARXIV.ORG 链接：https://arxiv.org/abs/1803.10760?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 当足够的信息被代理的传感器隐藏时，RL算法会变得无法解决简单任务，这是一种称为“局部可观察性”的特性。这篇文章的作者开发了一个模型，使用记忆，RL和推理网络（MERLIN），其中记忆形成由预测建模过程指导。MERLIN便于在三维虚拟现实环境中解决任务，其部分可观察性非常严格，并且记忆必须在很长的时间内保持不变。该模型演示了一个单一的学习代理体系结构，可以解决心理学和神经生物学中的经典行为任务，而不需要对感官输入的维度或经验持续时间进行简单的假设。 来源：ARXIV.ORG 链接：https://arxiv.org/abs/1803.09473?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 将代码片断表示为连续分布向量的神经模型。其主要思想是将代码表示为其抽象语法树中路径的集合，并将这些路径以智能且可扩展的方式聚合成单个固定长度的代码向量，该代码向量可用于预测片段的语义属性。作者通过使用它来从其身体的向量表示来预测方法的名称，从而证明了该方法的有效性。 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 
19,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658993&idx=1&sn=07074d52f93c7e9057a87ef0a418c6f3&chksm=bd4c3d628a3bb4740d22bf1da362ba78a8cd12b0cd8d27b8d79c3c234ecbc070747fd9a61aa5&scene=27,编程新手入门踩过的25个“坑”，你犯过其中哪些错误？,大数据文摘作品 编译：傅一洋、汪小七、张南星、GAO Ning、夏雅薇 高级的编程是逻辑思维的流露，会编程只代表你懂了这门语言的语法，但是会写清晰简洁易懂可迭代的代码才是程序员该追求的境界。编程入门已经不容易，但是如果能够在早期树立一些正确的“代码观”，或许可以让你的编程之路升级得更快。作者苦口婆心地给出了25条建议，句句真言。 首先我要声明的是：如果你是编程新手，本文并不是要让你对自己犯的错误感到愧疚，而是要你对这些错误有更好的认知，并避免在未来再犯。 当然，这些错误我也经历过，但是从每个错误中都学到了一些新东西。现在，我已经养成了一些好的编程习惯，我相信你也可以！ 下面是这些常见的错误，顺序不分先后。 一般来说，创作一篇高质量的文章不易，因为它需要反复推敲研究，而高质量的代码也不例外。 编写高质量代码是这样一个流程： 思考、调研、规划、编写、验证、修改 。（貌似没办法编成一个好记的顺口溜） 按照这样的思路走，你会逐渐形成良好的编程习惯。 新手最大的错误之一就是太急于写代码，而缺乏足够的规划和研究。虽然对于编写小程序而言是没多大问题的，但对于大项目的开发，这样做是很不利的。 为了防止代码写完之后发现重大问题，写之前的深思熟虑是必不可少的。代码只是你想法的流露。 生气的时候，在开口说话前先数到十。如果非常生气，就数到一百。 ——托马斯·杰斐逊 我把它改成针对写代码的版本： 审查代码时，重构每一行之前，先数到十。如果代码还没有测试，就数到一百。 ——Samer Buna 编程的过程主要是研读之前的代码，思考还需要修改什么，如何适应当前系统，并规划尽量小的改动量。而实际编写代码的过程只占整个过程时间花费的10％。 不要总认为编程就是写代码。编程是基于逻辑的创造，慢工出细活。 虽说写代码前充分规划是好，但凡事都有个度，还没开始做，就思考太多，也是不可取的。 不要期望世界上存在完美的规划，至少编程的世界中是不存在。好的规划可以作为起点，但实际情况是，规划是会随后续进行而改变的，规划的好处只是能让程序结构条理更清晰，而规划太多只会浪费时间。 瀑布式开发是一种系统线性规划的开发方法，它严格遵循预先计划的需求、分析、设计、编码、测试的步骤顺序进行，步骤成果作为进度的衡量标准。在这种方法中，规划是重中之重。如果只是编写小程序，也完全可以采用这种方法，但要对于大的项目，这种方法完全不可取。任何复杂的事情都需要根据实际情况随机应变。 编程是一个随时需要根据实际情况作出改变的工作。你后续可能会因为一些原因要添加或删除的某些功能，但这些情况瀑布计划中可能你永远也想不到。所以，你需要敏捷的开发模式。 但是，每一步之前是要有所规划的，只不过规划的过少或过多都会影响代码的质量，代码的质量非常重要。 如果你无法兼顾代码的多项质量指标，至少要保证它的可读性。凌乱的代码就相当于废品，而且不可回收。 永远不要低估代码质量的重要性。你要将代码看作沟通的一种方式，作为程序员，你的任务是交代清楚目前任务是如何实施的。 我最喜欢一句编程俚语是： 写代码的时候可以这样想，维护你代码的家伙是一个知道你住在哪里的暴力精神病患者。 ——John Woods 很形象是不是？ 即便是一些细节。例如，你的代码可能会因为排版问题或大小写不一致而不被认可。 还需要注意的是避免语句过长。任何超过80个字符的文本都是难以阅读的。你可能想在同一行放置长条件以便看到完整的if语句，这是不可取的，一行永远不要超过80个字符。 这种小问题可以通过linting工具或格式化工具轻松解决。比如在JavaScript中两个完美结合的优秀工具：ESLint和Prettier。多用它们，让工作更轻松。 还有一些与代码质量相关的错误： 任何超过10行的函数都太长了。 一定不要出现双重否定句。 使用简短的，通用的或基于类型的变量命名。尽量保证变量命名能清晰地表述变量。计算机科学领域只有两件难事：缓存失效和变量命名。 缺乏描述地插入一些字符串和数字。如果要使用固定的字符串或数值，应该将其定义为常量，并命名。 “对于简单的问题，担心花费时间而草率地处理”。不要在众多问题中进行跳跃式选择，按部就班地来。 认为代码越长越好。其实，大多数情况下，代码越短越好。只有在追求可读性的情况下可适当详细些。比如，不要为了缩短代码而使用很长的单行表达式或嵌套表达式，但也不要增加冗余的代码。最好的是，删去所有不必要的代码。 过多使用条件语句。大部分你认为需要条件语句的情况都可以不通过 它来解决。因此，考虑尽可能多的备选方案，根据可读性进行挑选。除非你知道如何测试代码性能，否则，不要试图优化。还有就是：避免Yoda条件或条件嵌套。 当我刚开始编程时，一旦遇到问题，我会立刻寻找解决方案并重新运行我的程序。而不是先考虑我的头号方案复杂性和潜在的失败原因。 虽然1号方案极具诱惑性，但在研究了所有解决方案后，通常能发现更好的。如果无法想出多种方案，说明你对问题了解不够。 作为专业程序员，你的工作不是找到办法，而是找到最简捷的办法。“简捷”的意思是方案必须正确，可执行，且足够简单，易读，又便于理解和维护。 软件设计有两种方法。一种是设计的足够简单，没有瑕疵，另一种是设计的足够复杂，没人看得出明显瑕疵。 ——C.A.R.霍尔 这是我常犯的错误，即便确定了我的头号方案并不是最简单的解决方案，仍然不放手。这可能与我的性格有关。大多数情况下这是一种很好的心态，但不适用于编程。事实上，正确的编程心态是，将早期失败和经常性失败看成一种常态。 当你开始怀疑某个方案的时候，你应该考虑放下它并重新思考，不管你之前在它这里投入了多少精力。学会利用像GIT这样的源代码管理工具，它可以帮助你实现代码分支，尝试多种方案。  不要认为你付出了精力的代码就是必须采用的。错误的代码要摒弃。 很多次，在解决问题需要查阅资料时，我却直接尝试解决问题，浪费了很多时间。 除非你正在使用的是某种尖端技术，否则，遇到问题时，谷歌一下吧，因为一定会有人也遇到了同样的问题，并找到了解决方法，这样，能节省很多时间。 有时候谷歌之后，你会发现你所认为的问题并不是问题，你需要做的不是修复而是接受。不要认为你了解一切，Google会让你大吃一惊的。 不过，要谨慎地使用谷歌。新手会犯的另一个错误是，在不理解代码的情况下，原样照搬。尽管这可能成功解决了你的问题，但还是不要使用自己不完全了解的代码。 如果想成为一名创造性的程序员，就永远不要认为，自己对在做的事情了如指掌。 作为一个有创造力的人，最危险的想法是认为自己知道自己在做什么。 ——布雷特·维克多 这一点不只是针对使用面向对象语言的例子，封装总是有用的，如果不使用封装，会给系统的维护带来很大的困难。 在应用程序中，每个功能要与用来处理它的对象一一对应。在构建对象时，除了保留被其他对象调用时必须传递的参数，其他内容都应该封装起来。  这不是出于保密，而是为减少应用程序不同部分之间的依赖。坚持这个原则，可以使你在对类，对象和函数的内部进行更改时，更加的安全，无需担心大规模的毁坏代码。 对每一个逻辑概念单元或者块都应该构建对应的类。通过类能够勾画出程序的蓝图。这里的类可以是一个实际对象或一个方法对象，你也可以将它称作模块或包。 在每个类中，其包含的每套任务要有对应的方法，方法只针对这一任务的执行，且能成功的完成。相似的类可共同使用一种方法。 作为新手，我无法本能地为每一个概念单元创建一个新类，而且经常无法确定哪些单元是独立的。因此，如果你看到一套代码中到处充斥着“Util”类，这套代码一定是新手编写的。或者，你做了个简单的修改，发现很多地方也要进行相应地修改，那么，这也是新手写的。 在类中添加方法或在方法中添加更多功能前，兼顾自己的直觉，花时间仔细思考。不要认为过后有机会重构而马虎跳过，要在第一次就做对。 总而言之，希望你的代码能具有高内聚性和低耦合性，这是一个特定术语。意思就是将相关的代码放在一起（在一个类中），减少不同类之间的依赖。 在目前项目还正在编写的时候，总是去想其他的解决方案，这是忌讳的。所有的谜团都会随着代码的一行行编写而逐一解开。如果，对于测试边缘案例进行假设，是件好事，但如果总想要满足潜在需求，是不可取的。 你要明确你的假设属于哪一类，避免编写目前并不需要的代码，也不要空想什么计划。 仅凭空想，就 认为未来会需要某种功能，因而尝试编写代码，是不可取的。 根据目前的项目，始终寻求最少的代码量。当然，边缘情况是要考虑的，但不要过早落实到代码中。 为了增长而增长是癌细胞的意识形态。 ——Edward Abbey 在准备面试的时候，新手往往太过于关注算法。掌握好的算法并在需要时使用它们固然不错，但记住，这与你的所谓“编程天赋资质”无关。 然而，掌握你所用语言中各种数据结构的优缺点，对你成为一名优秀的开发者大有裨益。 一旦你的代码中使用了错误的数据结构，那明摆着，你就是个新手。 尽管本文并不是要教你数据结构，但我还是要提几个错误示例： 使用list（数组）来替代map（对象） 最常见的数据结构错误是，在管理记录表时，使用了list而非map。其实，要管理记录表，是应该使用map的。 例如，在JavaScript中，最常见的列表结构是数组，最常见的map结构是对象（最新JavaScript版本中也包含图结构）。 因此，用list来表示map结构的数据是不可取的。虽然这种说法只是针对于大型数据集，但我认为，任何情况下都应如此，几乎没有什么情况，list能比map更好了，而且，这些极端情况在新版本的语言中也逐渐消失了。所以，只使用map就好。 这一点很重要。主要是由于访问map中的元素会比访问list中的元素快得多，访问元素又是常有的过程。 在以前，list结构是很重要的，因为它能保证元素的顺序，但现在，map结构同样能实现这个功能。 不使用栈 在编写任何需要递归的代码时，总是去使用递归函数。但是，这样的递归代码难以优化，特别在单线程环境下。 而且，优化递归代码还取决于递归函数返回的内容。比如，优化两个或多个返回的递归函数，就要比优化单个返回值的递归函数困难得多。 新手常常忽略了使用栈来替代递归函数的做法。其实，你可以运用栈，将递归函数的调用变为压栈过程，而回溯变为弹栈过程。   把目前的代码变得更糟 想象一下，给你这样一间凌乱的房间： 然后，要求你在房间里再增加一个物件。既然已经一团糟了，你可能会想，把它放在任何地方都可以吧。因此，很快就能完成任务。 但是，在编写代码时，这样做只会让代码越来越糟糕！你要做的是，保证代码随着开发的进行，变得越来越清晰。 所以，对于那间凌乱的房间，正确的做法是：做必要的清理，以便能将新增的物品放置在正确的位置。比如，你要在衣柜中添置一件衣服，那就需要先清理好地面，留出一条通向衣柜的路，这是必要的一步。 以下是一些错误的做法，通常会使代码变得更糟糕（只举了一部分例子）： 复制代码。 如果你贪图省事而复制代码，那么，只会让代码更加混乱。就好比，要在混乱的房间中，添加一把新椅子，而不是调整现有椅子的高度。因此，头脑中始终要有抽象的概念，并尽可能地去使用它。 不使用配置文件。 如果你的某个值在不同时间、不同环境下是不一样的，则该值应写入配置文件中。或者，你需要在代码中的多个位置使用某值，也应将它写入配置文件。这样的话，当你引入一个新的值时，只需要问自己：该值是否已经存在于配置文件？答案很可能是肯定的。 使用不必要的条件语句或临时变量。 每个if语句都包含逻辑上的分支，需要进行双重测试。因此，在不影响可读性的情况下，尽量避免使用条件语句。与之相关的一个错误就是，使用分支逻辑来扩展函数，而不去引入新函数。每当你认为你需要一个if语句或一个新的函数变量时，先问问自己：是否在将代码往正确的方向推进？有没有站在更高的层面去思考问题？ 关于不必要的if语句的问题，参考一段代码： 上面的isOdd函数是存在一些问题的，你能看出最明显问题吗？ 那就是，它使用了一个不必要的if语句。以下为其等效的代码： 我已经学会了，尽量不去写注释。因为大多数的注释可以通过对变量更好的命名来代替。 例如以下代码： 其实，也可以写成这样没有注释的，效果相同： 所以，每次写注释前，先思考一下：能否通过改善参数的命名来避免写注释呢？ 但有一些情况下，是必须写注释的。比如，当你用需要注释来表述代码的目的，而不是代码在做什么时。 如果你实在想写注释的话，那就不要描述那些过于明显的问题。以下是一些无用注释的例子，它们只会干扰代码的阅读： 所以，不要成为这样的程序员，也不要接受这样的代码。如果必须处理这些注释的话，那就删掉好了。要是碰巧你雇佣的程序员总是写出这样的代码的话，快点解雇他们。 我认同这一点：如果你自认为是专家，且有信心在不测试的情况下编写代码，那么在我看来，你就是个新手。 如果不编写测试代码，而用手动方式测试程序，比如你正在构建一个Web应用，在每写几行代码后就刷新并与应用程序交互的话，我也这样做过，这没什么问题。 但是，手动测试代码，是为了更明确如何在之后进行自动测试。如果成功测试了与应用的交互，那就应该返回到代码编辑页，编写自动测试代码，以便下次向项目添加更多代码时，自动执行完全相同的测试。 毕竟，作为人类，每次更改代码后，难免会有忘记去重新测试曾经成功过的代码，所以，还是把它交给计算机完成吧！ 如果可以，就在编写代码之前，先猜测或设计测试的过程。测试驱动开发（TDD）这种方法不仅仅是流行，它还能使你对功能的看法发生积极的变化，以及为它们提供更好的设计方案。 TDD并不适合每个人，每个项目，但是，至少要会用它。 看看这个实现了sumOddValues功能的函数，有什么问题吗？ 测试通过，一切顺利，但情况真是如此？ 上述代码问题在于，没有考虑到所有情况。尽管，它能正确地处理一部分的情况（测试时恰好命中这些情况之一）。来看看其中的几个问题：  问题＃1： 没有考虑输入为空的情况。在没有传递任何参数的情况下调用函数，会发生什么？会出现如下所示的错误： 这通常是个坏兆头，原因主要有二： 1.用户无法看到函数内部，不知其如何实现的。 2.异常提示对用户没有任何帮助，但你的函数又无法满足用户需求。倘若异常提示表述的更明确些，用户就能知道自己是如何错误地调用了函数。比如，可以在函数中，设计抛出一个异常，提示用户定义出错了，如下所示： 也可以不抛出异常，忽略空输入并返回0的总和。但是，无论如何，必须对这些情况有所处理。 问题#2： 没有处理无效输入的情况。如果传入的参数是字符串，整数或对象而不是数组，会发生什么情况？ 出现了下面的情况： 那么，很不幸，因为array.reduce确实是定义过的！ 我们命名了函数的参数数组，因此，在函数中，将所有调用该函数的对象（42）标记为数组。所以，就会抛出异常：42.reduce不是一个函数。 这个错误很令人困惑不是？也许，更值得注意的错误是： 问题＃1和＃2被称为边缘情况，他们都是常见的边缘案例。但通常，有一些不太明显的边缘案例也是需要考虑的。例如，我们传入负数，会发生什么？ -13是奇数，但结果是你想要的吗？或许它应该抛出异常？求和过程是否应该包括参数中的负数？还是应该忽略？也许你意识到，该函数应命名为sumPositiveOddNumbers。 这种情况处理起来很容易，但是，更重要的一点，如果不写一个测试文档来记录测试案例的话，后续的维护者也将对此毫无线索，甚至认为忽视负数是故意的或是出现了疏忽。 问题#3： 测试没有涵盖所有的一般情况。除了边缘情况，函数也有可能无法正确处理某个合理、有效的情况： 上例中，不应将2计入总和。 原因很简单：reduce函数是将第二个参数作为累加器的初始值的，如果该参数为空（如代码所示），reduce将使用数组中第一个值作为累加器的初始值。这就是为什么在上面测试用例中，第一个偶数值也包含在了总和中。 即便你在编写的过程中就发现了这个问题（并解决了），也是要编写相应的测试案例并记录的，测试记录还应包含其他测试用例，如全偶数的情况，列表中存在0的情况，列表为空的情况。 如果测试记录很少，又忽略了很多情况，忽视了边缘情况，那么，这一定是新手干的。 除非你是超级程序员，可以独当一面。否则，毫无疑问你会碰到许多愚蠢的代码。新手往往意识不到这些，他们会认为，既然作为代码库一部分，又用了很长时间的代码，一定是没有问题的。 更糟的是，如果这些代码中存在不妥，新手可能就会在其他地方重复这些不妥。因为他们认为，代码库中的代码是没有问题的，从中学到的方法也是没有问题的。 还有一些代码，看起来很糟糕，但是，它可能包含着某种特殊的情况，从而迫使开发人员必须这么写。这些地方，常常会有详细的注释，以将情况告知给新手，并说明，代码为何要这么写。 作为新手，你应该假设任何不明白或不正规的代码都是不好的。然后，去提问，去质疑，去查他的git blame记录！ 如果代码的作者无处可寻，那就仔细研究代码本身，理解其中的所有。只有当你完全理解后，才能形成自己的观点（不论好与坏）。在此之前，不要草率地对代码下结论。 我认为“最佳实践”这个词着实不好，它意味着无需再深入研究，这已经是最好的结果了，毋庸置疑！ 但编程中没有最好只有更好，只能说对某种程序而言，目前这已经是比较好的方案了。 甚至某些我们以前认为的最佳实践，现在已经不是最好的解决方案了。 只要你肯花时间去研究，总能发现更好的方案，所以不要再执着于最佳实践，尽你努力做到最好即可。 不要因为你在某个地方读到的一句名言，或是你看到别人这么做了，或是听人说这是最佳实践就去做某件事。   沉迷于性能优化 在编程中过早优化是万恶之源（至少大部分是）。 ——Donald Knuth （1974年） 自从Donald Knuth发表了以上观点之后，编程就发生了很大的变化，至今为止，我认为这个观点都是有价值的。 记住一条好的规则：如果你不能有效地量化代码中的问题，那就别试图去优化它。 如果在执行代码前已经在优化了，那么你很可能过早的进行了优化，这是完全没必要的，只是在浪费时间。 当然在你写新代码之前一些明显需要优化的内容还是要考虑优化的。例如，在Node.js中，你要确保你的代码中没有泛滥的使用循环或阻止调用堆栈，这些是非常重要的，这是你必须牢记要提前优化的一个例子。所以在编写过程中，可以时常问问自己：我准备写的代码会阻止调用堆栈吗？ 应该避免对任何不能量化的代码进行任何不明显的优化，否则反而会不利。可能你认为你这样做会带来性能上的提升，但事实上这会成为新的不可预料的bug来源。 因此，不要浪费时间去优化那些不能量化的性能问题。 在应用程序中添加特性最简单的方法是什么？从你自己的角度看，或许是看它如何适应当前的用户界面，对吧？如果这个功能是要捕获用户输入的，那么把它加到已有的那些表单中。如果这个功能是要添加一个页面链接，那就把它加到已有的嵌套链接菜单中。 不要自以为是。要站在终端用户角度来开发，这样才是真正的专业人员。这样的开发者才会去思考有这个功能诉求的用户需要什么，用户又会如何操作。而且他们会考虑如何能让用户更便捷地找到和使用这个功能，而不是只考虑如何在应用 程序中添加这个功能，而不考虑这个功能的可发现性和可用性。   工作时没有选对适合的工具 每个人在完成编程的相关活动中，都有一套自己喜欢使用的工具。其中有一些很好用，也有一些不好用，但是大多数工具只是对某一项特定任务很棒，而对其他任务来说都没有那么好。 如果要把钉子钉在墙上，锤子确实是把好工具，但如果要用锤子来旋螺丝钉，那就是很糟糕的工具了。不能只是因为你“喜欢”锤子，就用它来旋螺丝钉。也不能因为锤子是亚马逊中最受欢迎的工具，用户评价得分5.0，就用它来旋螺丝钉。 根据受欢迎程度来选择工具，而不是针对问题的适用性来选择工具是新手的一个标志。 对于新手而言，另一个问题是：你也许根本不知道对一项特定工作来说什么工具“更好”。在你当前的认知范围内，也许某一种工具就是你所知道的最好的工具。但是，跟其他工具相比时，它并不是首选。你需要熟悉所有可用的工具，并且对刚开始使用的新工具保持开放的心态。 一些程序员是拒绝使用新工具的，他们对于现有的工具很满意，而且他们可能也不想去学习任何新的工具。我明白，我也能理解，但是这显然是不对的。 工欲善其事，必先利其器。你可以用原始工具建造一个小屋，并享受你的甜蜜时光；你也可以投入时间和资金去获得好工具，这样你就可以更快地建造一座更好的房子。工具是不断更新的，而你也需要习惯去不断学习并使用它们。 一个程序非常重要的一方面就是某种格式数据的管理，该程序将是添加新记录、删除旧记录和修改其他记录的界面。 程序的代码即使有一点点的小问题，都会给其管理的数据带来不可预估的后果，尤其当你所有的数据验证都是通过那个漏洞程序完成时，则更是如此。 当涉及到代码和数据的关系时，初学者可能不会立即将这些点联系起来。他们可能觉得在生产中继续使用一些错误代码也是可以的，因为特征X是不用运行的，它没那么重要。但问题是错误代码可能会不断地导致数据完整性问题，虽然这些问题在一开始的时候并不明显。 更糟糕的是，在修复漏洞时，并没有修复漏洞所导致的细微的数据问题，就这样交付代码只会积累更多的数据问题，且这样的问题会被贴上“不可修复”的标签。 那么如何避免让自己发生这些问题呢？你可以简单地使用多层次的数据完整性验证，不只依赖于单个用户界面，应该在前端、后端、网络通信和数据库中都创建验证。如果你不想这么做，那么请至少使用数据库级别的约束。 要熟练掌握数据库约束，并学会在数据库中添加新列或新表时使用它们： NOT NULL是对列的空值约束，表示该列不允许使用空值。如果你的应用程序中设定某个字段必须有值，那么在数据库中它的源数据就应该定义为not null。 UNIQUE是对列的单一约束，表示在整个表中该列不允许有重复值。比如，用户信息表的用户姓名或者电子邮件字段，就适合使用这个约束。 CHECK约束是一个自定义表达式，对于满足条件的数据，计算结果为True。例如，如果有一列值必须是介于0到100之间的百分比，则可以使用CHECK约束来强制执行。 PRINARY KEY（主键）约束表示某一列的值必须不为空，且不重复。你可能一直在用这个约束，数据库中的每个表都必须有一个主键来识别不同的记录。 F OREIGN KEY（外键）约束表示某一列的值必须与另一个表的某一列值相匹配，通常来说外键约束也会是主键约束。 对于新手来说，另一个与数据完整性相关的问题是缺乏对事务处理（transactions）的思考。如果多个操作需要更改同一个数据源，且它们相互依赖时，则必须把它们包装在一个事务当中，这样当其中一个操作失败时就可以进行回滚。 这是一件很麻烦的事情。编程过程中，有时的确是需要推倒重来。编程不是一个界限分明的领域，变化层出不穷，新需求提出的速度远超于任何团队可以应对的能力范围。 打个比方，基于当前的速度，如果你需要不同种类的轮胎，除了改进我们都熟悉且喜爱的轮胎以外，也许我们需要换一种角度思考。然而，除非真的需要特殊设计的轮胎，否则没有必要推倒重来。就将就用用原来的轮胎吧。 不要浪费宝贵的时间在寻找所谓的最好的轮胎之上。快速搜索，然后使用所寻找到的内容。只有在这些轮胎真的没法像宣传的那样好好工作时，再进行更换。 编程最酷的一件事就是大多数轮胎都是透明的，你可以看到它内部的构造，能够非常容易地判断代码的质量高低。 所以尽量使用开源代码。开源包的缺陷更容易解决，更容易被替代，也更容易从内部支持。然而，当你需要一个轮子时，不要买一个全新的车，然后把你现在的车放在那辆新车上 。 也就是说，不要在代码里加载一整个包，然后只使用里面的一两个函数。最好的例子就是JavaScript中的lodash程序包。如果你只是想随机排列一个数组，只需要加载shuffle方法就好，不要加载一整个令人绝望的lodash程序包。 新程序员们的一个明显特征就是把代码审查当做批评，他们不喜欢、不珍惜，甚至是恐惧代码审查。 大错特错，如果你也有同样的感受，那么你需要立刻改变你的态度。把每次代码审查都看做是学习机会，用开放的心态欢迎、珍惜它们，并且从中学习。更为重要的是，要向给你提供了指导的审查员们表示感谢。 你需要接受一个事实——每个人都是终生代码学习者。大多数代码审查都能教给一些你以前可能不知道的知识，所以请将代码审查当做是一项学习资源吧。 有时，审查员也会犯错误，这时候就轮到你去教他们一些东西了。然而，如果审查出来的问题不仅仅是由于你的代码导致的错误，那么也许还是需要进行代码修改。如果无论如何你都需要教审查员一些东西的话，那么谨记：教授别人是你作为程序员最有收获的一件事。 新手们有时会低估一个好的源代码/版本控制系统，所谓好的系统，我指的是Git。 源代码控制并不仅仅是指把代码修改推送给别人，然后进行版本变更，这个行为的意义远不止如此。源代码控制的主要目的在于清晰的历史记录。 代码需要时常进行回顾，而代码的修改过程的记录将会极大助力于一些疑难杂症的解决，这也是为什么我们会很在意提交信息。代码控制同样也是一个沟通实施信息的渠道，使用这些零碎的提交历史，能够帮助未来的代码维护人员了解代码的发展情况以及现在所处的状态。 常常提交、尽早提交，并且出于对连贯性的尊重，请在提交标题中使用现在时态。信息最好尽量详尽，但谨记它们应该是经过提炼总结的。如果你需要好几行来阐述想表达的内容，也许意味着你的提交信息太长了。重来吧！ 不要在提交信息中不要放入任何不必要的信息。例如，不要列出被加载、被修改或者被删除的文件。 这些列表本身已经包含在提交的代码中了，并且能够通过一些Git命令参数实现，它们只会成为总结信息中的噪音。一些团队喜欢在每个文件改变中都做一次总结，我认为这是另一种提交信息太冗长的标志。 源代码控制和可发现性也有关系。当你遇到一个函数，需要开始了解它的需求或者设计，你可以寻找介绍它的提交信息，然后阅读函数相关内容。 提交信息甚至可以帮你找到程序中导致缺陷的代码是哪些。Git在提交中提供了一个二进制搜索（bisect命令）来精准定位导致缺陷的罪恶源头。 源代码控制也可以在代码变动正式生效之前发挥极大的作用。诸如阶段转换、选择性打补丁、重置、隐藏、修复、应用、区分、撤销以及其他许多对代码编辑有用的工具。所以好好理解、学习、使用并且珍惜他们吧。 你知道的Git特性越少，那么你离文章中所说的新手就越接近。 同样的，这一点并不是在比较函数式编程与其他算法的优劣区别，那是另外一篇文章要谈论的话题。 需要指出的是，共享状态往往是问题的源头，如果可能的话，尽量避免使用它。如果无法避免，那么需要把使用共享状态控制在最低限度。 当我还是编程初学者的时候，我没有意识到我们所定义的每一个变量都是一个共享状态。变量当中包含了数据，并且可以被该变量所处的域内所有元素改变。域的范围越大，那么这个共享状态的范围就越广。尽量把新变量声明维持在一个小范围内，并确保它们不会向上渗透。 情况比较严重的问题就是当共享状态生效、多个源头都会导致同一个事件循环标记发生改变时（在事件循环环境中），会发生争用条件。 事实是：新手有可能会采取计时器作为共享状态争用条件的曲线救国之道，特别是当他们需要处理数据锁定的问题时。 这是在立flag，别这样做。切记，处处留心，并且在代码审查时指出这个问题，绝对不要接受这种情况。 错误是一个好东西，它们的存在意味着进步，意味着你更容易获得成长。 编程大牛们对错误爱不释手，而新手则恨之入骨。 如果看着这些可爱的小小红色错误信息，会让你觉得心烦，那么你需要改变一下态度，把它们视为助手。你需要好好对待它们，并充分发挥它们的作用，促进自己的成长。 有些错误需要升级至异常情况。异常情况是需要你给出解决方法的用户自定义错误。有些错误需要单独进行处理，它们的存在将会让程序崩溃，并且强制退出。 程序员也是人类，你的大脑、你的身体都需要休息。常常，当你进入编程状态时，就忘记了休息。我把这一点也视为新手的一个标志。这不是你可以妥协的点。把一些能够强制你休息的内容整合到你的工作流中，然后短暂地休息一下。 离开椅子，在附近走走，同时想想下面需要做的事情。当你回到代码的世界时，就可以用全新的视角看待你的成果。 这 篇文章很长，现在你可以休息一下了。 你在学习编程的过程中踩过哪些坑呢？请给我们留言吧！感谢阅读！ 原文链接： https://medium.com/@samerbuna/the-mistakes-i-made-as-a-beginner-programmer-ac8b3e54c312 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 
20,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658936&idx=1&sn=f90d5cc14371fda9c974e88b4e286c73&chksm=bd4c3d2b8a3bb43ddd35bcdab0ef30e8c274e43a3fd0dfdb921ffbc53504b84739c2e81e8bd7&scene=27,手把手：用Python实现一个基于RSA算法的区块链客户端,"大数据文摘作品 编译：晚君、Molly、蒋宝尚 区块链作为比特币和其他加密货币的核心技术，在最近几年引起了全世界的注意，但是各国这一颠覆性的技术态度不一，因为其去中心化的分布式结构，可以使用户之间直接进行交流，无需中心节点参与的这种技术模式对银行、证券等机构带来了极大影响。 区块链的技术模式和各国对区块链的态度： G20各国对数字货币观点大盘点，整体友好 老矿工5000字区块链终极指南 而在本篇文章，抛开介绍区块链的技术特点和应用场景，文摘菌手把手的教大家 ，和一个区块链的客户端。 我们实现的区块链有如下几个特性： 可以向区块链中添加多个节点。 工作量证明（PoW）。 简单的节点间冲突解决机制。 使用RSA 加密进行交易。 我们的区块链客户端有如下几个功能： 使用公钥/私钥加密技术生成钱包。（基于RSA算法）。 使用RSA 加密算法生成交易。 我们还实现了2个展示界面： 挖矿者使用的“区块链前端” 用户生成钱包和发币的“区块链客户端” 我在原始代码的基础上进行了一些改动，向交易中加入了RSA加密，并实现了钱包生成和交易加密，两个界面使用HTML/CSS/JS 实现。 完整的项目代码： https://github.com/adilmoujahid/blockchain-python-tutorial 请注意，这个实现是用于教学目的，所以它不适用于生产环境。因为它保密性不够，且缺乏一些重要的特性。 你可以从终端启动区块链客户端。进入blockchain_client文件夹，并输入命令：python blockchain_client.py。 在浏览器中打开http://localhost:8080，接下来你会看到如下展示界面。 展示界面导航栏有3个标签: 钱包生成器:使用RSA加密算法生成钱包(公钥/私钥对)。 生成交易：生成交易并将其发送到区块链节点。 查看交易：查看区块链上的交易。 要想生成交易或查看交易，至少需要一个区块链节点在运行（将在下一节中介绍）。 blockchain_client.py文件代码中一些重要部分的说明： 我们定义了一个Python类，我们命名了4个属性字段：sender_address，sender_private_key，recipient_address，value。 这是发送方创建交易所需的4个信息。 to_dict()方法返回一个Python字典格式交易信息（没有发件人的私钥）。 sign_transaction()方法接收交易信息（没有发件人的私钥），然后使用发送者的私钥进行签名。 下面是初始化一个Python Flask应用的代码行, 我们将用它来创建不同的API来与区块链及其客户进行交互。 下面我们定义了3个返回HTML页面的Flask路径，其中每个标签都有一个html页面。 下面我们定义一个生成钱包（私有/公钥对）的API。 下面我们定义一个API，将sender_address, sender_private_key, recipient_address, value字段作为输入，并返回交易（没有私钥）和签名。 你可以从终端启动区块链节点，通过进入blockchain文件夹，并输入命令： python blockchain_client.py或python blockchain_client.py -p <PORT NUMBER> 。如果你未指定端口号，则会默认端口号为5000。在浏览器中打开http://localhost:<PORT NUMBER>可以看到区块链前端展示界面。 展示界面导航栏有两个标签： 挖掘：用于查看交易和区块链数据，以及挖掘新的交易区块。 配置：用于配置不同区块链节点之间的连接。 下面是blockchain.py文件代码中一些重要部分的说明。 我们首先定义一个具有以下属性的Blockchain类： transactions：将被添加到下一区块的交易列表。 chain:：实际的区块链，也就是一个区块数组。 nodes：一个包含节点URL的集合。区块链使用这些节点从其他节点中检索区块链数据并且在检查到它们没有同步时更新其区块链。 node_id：一个标识blockchain节点的随机字符串。 这个Blockchain类还实现了以下方法： register_node(node_url): 将新的区块链节点添加到节点列表中。 verify_transaction_signature(sender_address, signature, transaction): 检查提供的签名是否与通过公钥（sender_address）签署的交易相符。 submit_transaction(sender_address, recipient_address, value, signature): 如果签名通过验证，则将交易添加到交易列表中。 create_block(nonce, previous_hash):向区块链添加一个交易块。 hash(block): 创建一个区块的SHA-256散列。 proof_of_work()：工作算法的证明。寻找满足挖掘条件的随机数。 valid_proof(transactions, last_hash, nonce, difficulty=MINING_DIFFICULTY):检查散列值是否满足挖掘条件。该函数在proof_of_work函数中使用。 valid_chain(chain): 检查区块链是否有效。 resolve_conflicts():通过用网络中最长链代替链的方法解决区块链节点之间的冲突。 下面这一行，我们初始化了一个Python Flask 应用，用于创建和区块链交互的API。 下面，我们初始化一个区块链对象。 下面我们定义了2种返回我们区块链前端展示界面html页面的Flask路线。 下面我们定义了Flask API来管理交易和挖掘区块链。 此API将'sender_address', 'recipient_address', 'amount' 和 'signature' 作为输入，并且如果签名有效，则将交易添加到将添加到下一个块的交易列表中。 '/transactions/get':此API返回所有将会添加到下一个块的交易。 '/chain':此API返回所有区块链数据。 '/mine': 此API运行工作算法的证明，同时添加新的交易块到区块链。 下面我们定义Flask API来管理区块链节点。 '/nodes/register':此API将节点URL列表作为输入，同时添加URL到节点列表。 '/nodes/resolve':此API通过使用网络中最长的可用链替代本地链的方式解决区块链节点间的冲突。 '/nodes/get':此API返回节点列表。 在此篇文章中，我们介绍了涉及区块链背后一些核心概念，并且学习如何用Python实现一个区块链。为了简单起见，此文没有涉及一些技术细节，例如：钱包地址和Merkle树。如果你想了解有关该主题的更多信息，我建议阅读比特币白皮书原著，并跟着比特币维基和Andreas Antonopoulos的优秀书籍学习：掌握比特币:编程开放区块链。 原文链接： http://adilmoujahid.com/posts/2018/03/intro-blockchain-bitcoin-python/?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 "
21,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658832&idx=2&sn=11dd241abd33e86507b0e82150daf639&chksm=bd4c3dc38a3bb4d50edd71b56d73f857b84dcded99ce8875fbb02abf2b1ae6ca650051faf51d&scene=27,校招情报局 | 创新工场AI工程院招聘中，文摘菌专属通道直达BU邮箱,"大数据文摘作品 大数据文摘全新栏目 “ ” 来啦！ 校招阶段每期精心挑选 3~5家AI/DS公司校招信息 发布最新校招情报，提供专业可靠信息 直接联系招聘负责人，争取文摘菌专属锦囊 比别人更快直达HR和终面！ ：点击 使用 大数据文摘专属报名通道，简历可以BU邮箱哦！ 本期出镜企业 创新工场 创新工场由李开复博士创办于2009年，作为国内一流的创业投资机构，一直深耕于人工智能、消费升级、互联网金融等领域，致力于打造全方位生态投资服务平台。 2016创新工场成立人工智能工程院，是面向人工智能领域的科研转化实验室和人才培养基地。它由李开复博士亲任院长，王咏刚、王嘉平担任副院长，汇聚了世界顶级机构的著名工程师和顶尖科学家。创新工场人工智能工程院成立以来，在AI生态方面积极推动人才培训、数据开源两大基石建设，成功地举办了“AI Challenger全球人工智能挑战赛”、“DeeCamp深度学习训练营” 等一系列王牌计划。 创新工场人工智能工程院2018春季校园招聘正在进行中，本次招聘对象既包括了2018年毕业的应届生，又包括寻找日常实习的在校生，如果你想要与李开复博士以及AI工程院各位“重量级”的工程师近距离交流和共事，就快快加入我们吧~ 工作地点 北京 文摘菌专属投递福利 点击 ， 通过大数据文摘的报名通道可以简历直达创新工场人工智能工程院招聘的BU！同学们有没有心动呢？ 本次文摘菌专属通道由实习僧提供，通过专属通道投递的简历自带下列光环： 创 新工场人工智能工程院 对通过实习僧投递简历的同学给予高度的认可； 优秀简历直达BU邮箱（带标签的简历哦）！ 招聘岗位 应届生职位： 技术类： 算法工程师、后端工程师、前端工程师、移动端开发工程师、嵌入式开发工程师 产品类： 产品经理 实习生职位： 技术类： 算法实习生、后端实习生、前端实习生、嵌入开发实习生 产品类： AI产品实习生、教育运营产品实习生 市场类： 社区运营实习生，市场实习生 设计类： UI设计实习生、平面设计实习生 算法工程师 职位描述： 机器视觉、图形图像、自然语言处理、数据挖掘等AI相关的算法研发； 算法相关的代码库、工具库的封装和发布； AI相关算法的性能优化、工程环境部署； 参与搭建和实现分布式深度学习集群。 任职资格： 本科及以上学历，计算机/信息科学/软件/电子工程/应用数学等相关专业优先； 熟练掌握机器学习相关的理论知识和实践技能； 熟悉CNN、RNN、LSTM等典型深度学习模型的使用场景和使用方法； 在机器视觉、语音识别、自然语言处理、数据挖掘、量化交易中的一个或多个相关领域有实践经验； 熟悉TensorFlow、Caffe、MXNet等主流深度学习框架中的一种或多种； 拥有扎实的数学和编程功力。 嵌入式开发工程师 职位描述： 视觉等智能设备的系统设计、模型优化和软硬件整合工作； 计算机视觉相关的计算网络、弱电系统的设计与实施； 与相关的图像处理、计算机视觉软件的研发。 任职资格： 本科以上学历，自动化、计算机、电子工程或相关专业； 拥有下列一种或多种智能设备/嵌入式系统的开发经验：智能摄像头、智能家电、车载智能设备、无人机、机器人、自动驾驶系统； 有ARM系统或嵌入式Android系统的开发经验； 有计算机视觉或FPGA产品开发经验者优先。 移动端开发工程师 职位描述： 将机器学习算法在不同的移动平台上进行移植适配，性能优化； 将机器学习算法封装成对开发者友好的SDK， 推广算法商业化落地业务应用； 研发机器学习算法的移动端应用。 任职资格： 扎实的计算机基础，熟悉计算机网络相关知识； 熟悉 C / C++ / Kotlin/ Java / Swift / Objective-C等开发语言； 掌握Android 或 iOS 移动端应用开发； 对移动端应用开发有热情，关注移动端最新技术动向； 加分项：开源社区贡献者 / 参与过实际项目开发 / 有深度学习相关科研经历者； 前端工程师 职位描述： 负责AI工程院相关业务的前端开发工作，实现高性能的交互以及动画效果； 负责产品的需求以及后台程序的实现，提供合理的前端架构； 与产品、后端开发人员保持良好沟通，能快速理解、消化各方需求，并落实为具体的开发工作。 任职资格： 计算机基础知识扎实； 熟悉HTML5、CSS3、ES6, 熟悉Node.js； 了解前端自动化流程，熟悉常用的开源工具如Webpack / Gulp / Grunt等； 对前端性能和安全性有自己的心得； 熟悉一门后端语言，如Python / PHP / Java / Lua / Go等； 高效的团队协作能力，对各种前端新兴技术有敏锐的洞察力。 加分项：开源社区贡献者, 有React / Vue / Angular / RN / Electron使用经验。 后端工程师 职位描述： 负责AI工程院产品的后端开发和维护； 负责产品后端架构的改进和优化，确保后端服务稳定可靠； 参与后端前沿技术的探索； 任职资格： 计算机基础知识扎实，对数据结构及算法有较好的掌握； 掌握至少一种后端编程语言，包括但不限于C / C++ / Java / Python； 熟悉Linux操作系统； 有一定的系统设计能力； 有优秀的解决问题的能力，有很强的学习能力； 6、加分项：开源社区贡献者 / 参与过实际项目开发。 产品经理 职位描述： 通过市场调研、竞争者分析、客户调查、用户行为研究等制定产品方向； 与客户沟通产品需求，参与或指导产品功能设计和用户体验设计； 管理并组织项目，与技术团队和运营团队合作保证项目顺利实施； 持续监控并分析产品数据，发现可改进之处，提出并推动优化方案； 对外提供与产品相关的咨询服务。 任职资格： 计算机/信息科学/电子工程等相关专业优先，本科及以上学历； 有互联网行业，零售行业，或金融科技行业实习/工作经验者优先； 优秀的沟通协作能力、较强的理解分析能力、执行管理能力； 善于理解用户业务，对用户需求有敏锐的洞察力、正确的理解和判断； 有数据挖掘、机器学习等经验者优先。 更多职位详情 点击 查看哦！ 七险一金，带薪年假，有竞争力薪酬，有快速成长机会。最重要的是，创新工场人工智能工程院由李开复博士亲任院长，王咏刚、王嘉平担任副院长，还有来自世界顶级机构的著名工程师和顶尖科学家。能够和他们一起共同探索技术、数据、人才、商业价值的结合，推进人工智能在科学研究与商业领域的实践探索，听听就很心动呢！ 从文摘菌渠道报名简历还可以直达BU邮箱，还等什么？小伙伴们，简历投起来~ 简历投递 方式一： 点击 方式二： 将您的简历发送至hr@chuangxin.com。 温馨提醒： 如果选择邮箱发送，请将邮件标题注明“大数据文摘-应届生/实习生-职位-姓名”，如“大数据文摘-应届生-算法工程师-小明”，这样会方便我们的HR更快接收您的简历。 公司官网： www.chuangxin.com Have a Great Definition "
22,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658831&idx=2&sn=31269dfec3422640c0e28ad101527166&chksm=bd4c3ddc8a3bb4ca7ba1241fc5af2f081fdd4852b27e668c3788356bef2d04ee47170775642e&scene=27,重磅译制 | 更新：牛津大学xDeepMind自然语言处理 第8讲（上）注意力模型,大数据文摘重磅课程汉化《牛津大学xDeepMind自然语言处理》 本周更新至：Lecture 8 注意力模型（1） 马上观看👇 点击文末 ，即可免广告观看 牛津大学Deep NLP是一门关于自然语言处理（NLP）的高阶课程。课程由 和 （AlphaGo的开发机构）联合开设，是牛津大学计算机系2017年春季学期最新课程。由Phil Blunsom主讲，同时邀请到多位来自DeepMind和NVIDIA的业界讲师来做客座讲座。 大数据文摘已联系课程主讲人取得翻译授权，并联合北京邮电大学模式识别实验室 组织了视频汉化， 发布。 课程视频【中文字幕】学习地址： （连载中，请收藏！点击文末 ，可直接加入学习） http://study.163.com/course/introduction/1004336028.htm 牛津大学课程页面（所有资料汇总）： https://github.com/oxford-cs-deepnlp-2017/lectures 本课时PPT精华 后台对话框内回复“ NLP ”获取本课时PPT 后台对话框内回复“ NLP ”获取本课时PPT 课程 ，复制打开链接免费加入学习： http://study.163.com/course/introduction/1004938039.htm 《斯坦福CS231n深度学习与计算机视觉》课程已更新完毕，李飞飞与Andrej Karpathy（现任Tesla AI部门主管）主讲，已有9万+人参与学习，复制打开链接免费加入学习： http://study.163.com/course/introduction/1003223001.htm 本期工作人员 翻译 李楠  闵峰  乔一宁  张世平   刀哥  momo  无敌乔卡特 终校 IrisW  蒋宝尚 项目管理 龙牧雪  李楠 顾问 张闯  寒小阳  汪德诚 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 
23,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658831&idx=1&sn=61ef35b9e2a091b5ceff62917fb2aecb&chksm=bd4c3ddc8a3bb4ca17f8b2d70ab37db52a9ac9d414b43e122d49a9bde8ea089234a50df67413&scene=27,CBInsights详解阿里巴巴vs亚马逊全球战略，印度澳洲新加坡是主战场,"大数据文摘作品 编译：张南星、王梦泽、吴双、蒋宝尚 亚马逊和阿里巴巴是全球最大的电商巨头，两者市值总和超过1.1万亿美元。为了尽量避免彼此间的直接竞争，他们扩张的地域各不相同，但是随着国际化的不断推进，竞争显然不可避免。 “我们相信全球化就是未来。” 马云曾表示。 亚马逊目前主要占领了北美及欧洲市场，但正在极其努力地进入印度市场，同时在澳大利亚和新加坡采取了一些行动。阿里巴巴垄断着中国，并在东南亚完成了战略合作关系和投资关系布局。但是和亚马逊一样，阿里巴巴也在印度下了赌注，并正在进入澳大利亚市场。 电商巨头们充分利用了以下三个重要趋势： 全球金融体系正在变得数字化和移动化 全球财富不断增长 互联网渗透率不断上升 阿里巴巴和亚马逊正使用不同的战略以争取在潮流中分一杯羹： 在美国和中国之外，阿里巴巴所拥有的少数股权公司数量是亚马逊的两倍，而亚马逊购买的公司数量比阿里巴巴多了5倍。 阿里巴巴在美国和中国之外比亚马逊多拥有两倍公司的少数股权 亚马逊在美国与中国之外购买了更多的公司 虽然这两个公司采取了不同的扩张战略，他们的目标最终是一样的——把他们的电商与物流技术推广到全球。 亚马逊正集中精力将其广受好评的市场模式全球化，将在接下来十年内花费数十亿美元将其价格低、选择多、到货快的商业模式推广至全世界。 阿里巴巴则在全世界范围内扩张物流网络，并把分支机构连接起来，形成全球电商市场。 为什么选择现在进行全球扩张？ 这两个公司，特别是阿里巴巴，正在全球寻找扩大营业收入的方法。它们都想成为电商老大，并把一个国家带到线上零售的世界。 并且两个公司都能够负担它们激进的扩张计划，因为他们股价的飞速增长——亚马逊市场市值达到7200亿美元，阿里巴巴达到4830亿美元。 过去几年阿里巴巴与亚马逊的市值涨势不断 本文使用CB Insights的数据，研究绘制了亚马逊和阿里巴巴在全世界的扩张路线，并深入研究了它们是如何通过并购、投资、合作以及研发的方式在本国市场之外激进扩张的。 目录 1.阿里巴巴与亚马逊的首要国际化目标 2.印度    1) 亚马逊的市场先行方式    2) 亚马逊的生态效应    3) 阿里巴巴借Paytm突入印度    4) 两个战略的对比 3.澳大利亚    1) 亚马逊旨在消除“被距离主宰”的恐惧    2) 阿里巴巴瞄准了中国的澳大利亚旅游潮    3) 中国对澳大利亚产品的需求 4.东南亚    1) 阿里巴巴的Lazada推动收入增长    2) 亚马逊全力进入新加坡市场 5.欧洲 6.其他赌注    1) 中东    2) 香港    3) 以色列    4) 国际孵化 7.总结 亚马逊和阿里巴巴在新市场中的竞争越来越激烈。澳大利亚、新加坡以及印度已经准备好成为接下来几年之内最具爆发力的电商市场。 印度 是其中最具增长潜力的地区，这也是为什么亚马逊和阿里巴巴都把印度视为长期战略重点。投资银行摩根斯坦利的研究表明，2026年，印度的线上零售市场将从2016年的150亿美元增长到200亿美元。 这是基于2009年（39亿美元）已实现的指数级增长做出的预测。目前，Flipkart（印度本土电商平台）是继亚马逊和Snapdeals（印度本土电商平台）之后的市场领导者。 亚马逊在印度、欧洲、加拿大、以色列、阿联酋的投资与并购，其中在印度的投资、并购份额最大 澳大利亚 是一个成熟的金融经济体，88%的居民都是活跃互联网用户。这些用户在9月16日到9月17日间，共线上消费183.8亿美元，而这仅仅只是该国总零售销售额的7%，这个比例在美国是9.12%，在中国是19.6%。只要澳大利亚电商市场增长50bps（比特每秒）的流量，电商销售额的增长就可达到15亿美元。而且 这个国家的零售市场非常分散，不存在零售商垄断的现象，极大方便了这些虎视眈眈的巨头们在这里获得垄断地位。 新加坡 比其他东南亚国家现代化程度都要高，82%的人口在互联网上活跃。因此成为了两个巨头眼中的“香饽饽”。阿里巴巴和亚马逊已经在这里成为了主要玩家，它们正在布局线上转型，希望在激烈的竞争中保住现有的位置。阿里巴巴及其旗下Lazada的网页访问量在2017年8月达到98.8万，亚马逊以69.8万紧随其后。 阿里巴巴的全球投资地图 千禧年一代占印度人口的三分之一。从各方面而言，印度的人口结构与快速增长的互联网渗透率都意味着这个国家的巨大电商潜力。 印度线上消费增长 亚马逊和阿里巴巴在印度的增长经济中采取了不同的投资方式。亚马逊在已有的商业模式中投入了数十亿，并投资了其他额外的市场；同时阿里巴巴在支付解决方案以及现有电商市场上做了重要的战略性投资布局。 现在Flipkart和亚马逊正争夺在印度的市场垄断地位，截止目前，Flipkart已经通过股权投资筹集了将近75亿美元，并且即使面临着来自于亚马逊的有力竞争，Flipkart没有丝毫放弃的打算。 另一方面，阿里巴巴在印度则采取了一种和腾讯微信更像的战略——打造超级应用。 亚马逊在2013启动了amazon.in，不久之后，Jeff Bezos宣布亚马逊计划在印度投入20亿美元发展电商网络，并投资不断增长的创业中心。过去几年印度的股权并购数已增加了270%，从2013年的543笔增加到了2017年的2019笔。 在亚马逊发展早期，几乎有一半的亚马逊消费者都是用现金支付快递包裹，这给物流带来了不小的挑战，并且限制了亚马逊地区间的发展潜力。其他购买者则用电子钱包付款，这些钱包可以在实体店铺或者使用预付卡充值。 为了改善客户的支付体验，提供更多的支付选择以驱动市场增长，亚马逊在2014年第四季度投资了QwikCilver，一家礼品卡解决方案供应商，并在2016年进行了后续投资。 从此，礼品卡系统就整合到了亚马逊市场体系中，并可以通过邮件进行发送。 亚马逊礼品卡 亚马逊在2015年将更多的资金投资于其他行业的两个公司——BankBazaar，一个在线金融产品搜索工具，以及HouseJoy，一家按需式家庭服务公司。 2016年初，亚马逊并购了一家总部在印度的创业公司EMVANTAGE Payments，没有公布并购额。并购后，亚马逊宣布这家公司的员工将加入亚马逊支付团队，发展其在印度的电商支付平台。如今，印度市场上已经可以接受印度银行的信用卡作为支付方式了。 下面这些在印度发行的银行卡可以用于线上支付，信用卡：VISA, Master Card，American Express， Diners Club International；借记卡：VISA，Master Card，Maestro，RuPay 2016年末，Jeff Bezos在印度加注两倍，并且对增长市场承诺了另外30亿美元的投资。 一年以后，亚马逊进行了它最大的一笔少数股权投资——投给Shoppers Stop的2800万美元。这家电商初创公司是印度领先的时尚零售商之一，将一线品牌与消费者连接在了一起。这个软件在Google Play商店中有100万到500万的下载量。 Shoppers Stop软件截图  亚马逊生态效应 除了核心市场，亚马逊还在印度提供亚马逊金牌服务Amazon Prime和Amazon Now服务。 印度用户通过支付Prime会员费999卢比（15.32美元），就可以获得免费且迅速的快递服务以及Prime会员专享的视频服务（Amazon Prime Video） 。亚马逊在2017年初开始在印度开放Prime会员注册，第一年的会员增长就高于其他任何国家。 尽管亚马逊的视频服务（Amazon Prime Video）比Netflix晚一年进入印度市场，但是它已经比该流媒体服务商拥有更多的订阅者。 在印度，亚马逊Prime Video打败了Netflix（亚马逊Prime Video注册数有61万，Netflix有52万） Amazon Now应用的使用方法 截至目前，亚马逊已经在印度的13个州建立了56个运营中心，占据了1350万立方英尺的库存空间，其中包括了最近由于Amazon Now服务持续增长所新开的15个仓库。 截止到2017年3月31日，亚马逊在印度的年度销售额增长了105%。 分析一下亚马逊的季度财报，不难发现印度市场优先级极高，因为在2015年到2017年间，印度被提到了59次。 阿里巴巴借Paytm突入印度市场 自从亚马逊在印度完成了第一次外部投资之后，阿里巴巴迅速跟上了步伐。2015年1月，阿里巴巴及其旗下的蚂蚁金服给One97集团下的Patym投资了2亿美元。 Paytm是印度最大的移动支付公司，并且自从2010年成立以来，积累了超过2亿用户。在原始投资后8个月，阿里巴巴和蚂蚁金服又另给这个快速增长的公司投入了6.8亿美元。加起来，阿里巴巴和蚂蚁金服拥有Paytm40%的股权。 初尝Paytm胜利的果实之后，阿里巴巴投资了Paytm集团下的在线零售商Paytm Mall（A轮融资）。Paytm Mall在3月财年结束时，预计总市场价值将达到30亿美元，目标在2019年3月达到100亿美元。 刚进入2018年，阿里巴巴及子公司蚂蚁金服在印度已经动作频频。 进入2018才两天，阿里巴巴就投资了3500万美元给Xpressbees，一家电商物流公司。一个月之后，阿里巴巴投资了线上杂货商BigBasket’s（E轮融资）。2月，蚂蚁金服购入了线上视频及生活方式门户Zomato18%的股权，总价值2亿美元。 亚马逊与阿里巴巴集团在印度的投资情况，包括投资与并购 图源：CBINSIGHTS 除了阿里巴巴在印度的投资，一个中国的并购事件也可能改变印度的游戏规则。2014年，阿里巴巴购买了UCWeb，一家移动互联网科技及应用服务的提供商。 如今，UC是印度最受欢迎的浏览器，占据40%的市场份额。2018年1月，这个浏览器的月度活跃用户跃升到1.3亿，在印度地区应用下载排行榜中排名第六。 UC浏览器通过强调为用户提供根据喜好定制的内容，将自己与其他诸如Google之类的竞争者区分开。这个平台给阿里巴巴提供了收集大量印度人口数据的机会，并将数据分析结果应用于在其他商业领域的交叉销售。 阿里巴巴还通过2016年控股香港彩票公司AGTech，把触手伸向了数字化娱乐领域。 这个并购为AGTech与Paytm之后成立投资公司Gamepind铺平了道路，这家公司现在成为了移动游戏及电商平台。 根据AGTech和Paytm，Gamepind让用户通过参加各种各样的休闲游戏和比赛，得到购买商品和服务的折扣价格。这个平台能够通过独立的应用和Paytm应用内部两个渠道进行访问，让Gamepind能够接触到Paytm的3亿用户。 Gamepind界面 阿里巴巴表示，Gamepind是一个极好的商品市场营销及宣传平台，与移动购物者及休闲玩家形成了创新互动。 亚马逊在印度的计划非常清晰——尽量促进Amazon Now和Amazon Prime的增长；而阿里巴巴所追求的增长则难以归类。 看起来阿里巴巴似乎正在建立一个超级应用以集合它所有服务和商品。也许它会模仿腾讯微信应用的设计。 微信的“一站式”设计 通过Paytm控制了移动支付市场，阿里巴巴的投资变得多样化：娱乐、媒体、杂货 、物流、电商、游戏、网页服务以及按需快递，这些内容同样可以在腾讯微信应用中找到。 忽略印度作为电商市场的潜力， 市场领导者Flipkart在2017年3月，一个财政年度收入增长达到29%，但是同时损失同比也增加了68%。 获取市场份额并达到盈利，需要花费大量的精力与资本才有可能使之成为现实。当市场成熟后，赢家才可能获得应有的数十亿的收入。 阿里巴巴和亚马逊都似乎能成为澳大利亚零售市场的黑马，但是 。 亚马逊正扩张商家在国内的覆盖范围，而阿里巴巴则主要把澳大利亚的公司推向全球化。 亚马逊正在大洋洲区域内建立一个第三方商家售卖市场，通过推广其获得专利的FBA (Fulfillment By Amazon)模式，让商家们能够集中精力提供商品和服务，而B2C的物流问题则由亚马逊来解决，这在一个幅员辽阔的国家是个难题。 阿里巴巴则采取了两个扩张战略，都主要集中在 。阿里巴巴正在基于支付宝开发建立云服务，与当地商家达成合作关系，让中国人到澳大利亚的旅游实现无缝连接。同时阿里巴巴还在扩张澳大利亚与中国之间的物流网络，以促进两国之间商业与商业间的贸易。 根据阿里巴巴集团董事总经理周岚，阿里巴巴在澳大利亚的目标是通过云计算、在线支付以及物流来“建立完整的必要运营基础设施来让当地商业实现全球化扩张”。 另一方面，亚马逊则集中注意力于为全澳大利亚的消费者提供其一如往常的服务——一个商品价格低、种类选择多以及物流运送快的购物平台。 亚马逊旨在消除“被距离主宰”的恐惧 2 012年，亚马逊携AWS（亚马逊网络服务）首次进入澳大利亚，并于一年后在amazon.com.au网站上推出了Kindle商店。 2017年，这家美国电商巨头宣布计划在澳大利亚开设一个具有Amazon Prime和其他所有权益的市场。同年12月，亚马逊开始在澳大利亚进行扩张，在墨尔本丹德农南部设立了一个2.4万平方米的运营中心。 澳大利亚的市场实力已经由亚马逊证实了。根据摩根斯坦利的数据，亚马逊通过国际运输将商品运至澳大利亚，已实现了10亿美元的销售收入。 这家墨尔本运营中心的运作方式与美国的相似。从2月26日起，亚马逊将为第三方供应商提供亚马逊配送(FBA)服务，并在未来有可能配送亚马逊自有品牌Amazon Essentials。 亚马逊还与澳大利亚邮政合作推出了最后一英里配送服务。这项服务表示17年12月（亚马逊在澳运营的第一个月），是它迄今为止最忙的一个月。 然而， 。 FBA服务开展的第一个月，有报道称亚马逊有很多订单未能按承诺的时间送达。尽管澳大利亚邮政也有一定的责任，但如果亚马逊过度承诺了其配送时间却未能做到，它的名誉仍会受损。 在一个创造了“被距离主宰”的词语的国家，人们认为亚马逊会于近期在悉尼和佩斯设立其他的运营中心，使亚马逊的配送范围能覆盖大部分的区域，为了实现这一目标，亚马逊可能会收购该区域的物流公司。 亚马逊已经为澳大利亚消费者提供了Prime Video、Twitch Prime服务以及Alexa产品，Prime配送服务有望于2018年实现。 阿里巴巴瞄准了中国的澳大利亚旅游潮 阿里巴巴与澳大利亚政府合作，于2017年2月在澳大利亚开设了第一家总部。阿里巴巴寻求在中国与澳大利亚深厚的关系上进一步发展。中国是澳大利亚最大的贸易合作伙伴，2016年进口了价值超过550亿美元的澳大利亚商品。 2016年各国占澳大利亚出口比例（数据来自标准国际贸易分类） 阿里巴巴在澳大利亚有两个主要的商业机会： 中国人到澳大利亚旅游的热潮 中国对澳大利亚产品的需求 阿里巴巴在澳大利亚的主要业务是支付宝。 据澳大利亚统计局公布的数据显示，2017年，约有140万的中国大陆旅客前往澳大利亚，同比增长了13%。预计在2020年，中国游客将在澳大利亚消费将近130亿美元，其中包括教育费用。 支付宝与澳大利亚旅游出口委员会（ATEC）建立了合作关系，目标是将其移动支付平台扩展到全国的旅游业。 这项合作旨在培养企业主和员工，让他们做好准备，以便能够服务来此的支付宝用户，并从中获利。支付宝拥有5.2亿活跃的中国用户。 2016年底，阿里巴巴在澳大利亚推出云服务和支付宝，到今天，超过八千个商家接受支付宝付款。 阿里巴巴集团也和澳大利亚出租车公司Cabcharge开展合作，截止至2018年2月已有2.2万辆出租车支持支付宝付款。这会帮助中国旅客克服语言障碍，并使付款变得更加便捷。 中国对澳大利亚产品的需求 中国对澳大利亚商品有着巨大的需求量。澳中商务委员会的最新报道显示，有86%的中国旅客表示，旅行结束后他们购买的澳大利亚商品增多，几乎所有的受访者表示在旅行结束后都会在中国继续购买澳大利亚的商品。 去年双11当天阿里巴巴平台上，代理252个品牌的63个澳大利亚商家的24小时销量在所有国家中排名第三（仅次于美国和日本）。 在近三年的双十一中，澳大利亚的销量稳步提升，从2015年的销量排名第五，到去年的第四名，现在升至第三名。 新的总部成立后，已经有1300个澳大利亚和400个新西兰商家通过支付宝的在线零售平台，天猫和天猫国际上进行销售。随着阿里巴巴持续将澳大利亚的商品推向平台，这些数字应会显著增长。 为了促进和维系牢固的商业关系，阿里巴巴将在澳大利亚举办电子商务博览会，将澳大利亚和新西兰的品牌和小企业与中国日益增长的市场连接起来。 2018博览会的日期还未确定，去年有超过5100家买家和卖家参会，与会人数令人印象深刻，今年的人数预计会超过去年。 为了加快澳中贸易市场的发展，阿里巴巴已经建立了各种合作伙伴关系。 澳大利亚邮政： 2017年，阿里巴巴宣布与澳大利亚邮政合作。合作旨在通过在阿里巴巴的Lazada电子商务网络上开发首个澳大利亚市场，简化澳大利亚与东南亚之间的物流流程。（Lazada市场覆盖东南亚六国，详细信息见下文相关段落） 此外，阿里巴巴的支付宝已经被整合到AlphaCommerceHub (ACH)，这是一家澳大利亚邮政和金融科技公司Alpha Payments Cloud的合资企业。通过将所有的重要商业服务统一到单个云平台，包括通过支付宝进行支付，ACH为澳洲零售商创造了一个商业平台。 Chemist Warehouse： 该澳大利亚连锁药店企业与阿里巴巴的跨境电商网站天猫国际签署了独家合作协议。作为独家经营权的回报，阿里巴巴将在重大营销活动期间提供支持，帮助它更好的接触中国消费者。 Qantas:  阿里巴巴同样也与澳洲最大的航空公司Qantas建立了合作关系。协议协定中国旅客可以在阿里巴巴网站上直接购买Qantas的飞机票。Qantas会利用合作关系进一步扩大中国至澳大利亚航线的规模，目前航班数量为每周130班。 东南亚是阿里巴巴在中国以外最重要的市场。而亚马逊只聚焦于新加坡。 在新加坡，阿里巴巴和亚马逊在电子商务和按需购物业务的领域上直接竞争。这个东南亚国家似乎是两大巨头唯一直接正面竞争的市场。 根据Google和Temasek的数据，东南亚国家有6.2亿人口，到2025年电子商务市场规模有可能达到880亿美元。 阿里巴巴的Lazada推动收入增长 为了在东南亚电子商务市场占有一席之地，阿里巴巴在2016年以10亿美元获得了当时估值15亿美元的新加坡电商平台Lazada的控股权。一年后，阿里巴巴继续注资10亿美元将持股比例提升至83%，这一次对Lazada的估值为31.5亿美元。 Lazada的市场覆盖东南亚六国：印尼，马来西亚，菲律宾，新加坡，泰国和越南。 该区域市场呈现爆炸式增长。在阿里的两次投资期间，Lazada平台上的商户增长到10万以上，提供给消费者的库存量单位（SKU）超过了8000万个。 2016年11月，Lazada使用3000-4000万美元的投资资金，收购了新加坡网上超市Redmart，它将与亚马逊竞争市场。 阿里巴巴希望对Lazada的收购会成为将其50%的收入转移到海外这一计划的关键因素。 根据截止至2017年12月31日阿里巴巴的季度财报，其国际商务零售业务的收入已达7.27亿美元，同比增长93%。阿里巴巴将Lazada列为实现这一增长的主要原因。 为了继续在东南亚扩大其电子商务市场，阿里巴巴独家为Tokopedia在第F轮融资了11亿美元。Tokopedia是东南亚最大经济体印尼的一家电商公司。  “我们一致认为阿里巴巴是我们的老师和榜样，” Tokopedia的CEO兼联合创始人William Tanuwijaya在一份声明中表示，“今天我们十分激动地欢迎他们成为我们的股东，并且相信我们的合作在未来会加快Tokopedia的发展，使其实现通过技术实现大众商业化的使命。” 亚马逊全力进入新加坡市场 亚马逊于2017年7月进入新加坡并立即提供了Prime Now服务，此产品为消费者提供了数万件商品的两小时送达服务。  “这是我们第一次在全国范围内提供Prime Now服务。新加坡允许我们同时向整个国家推出服务，但当你观察新加坡时，它是一个城市、大都会，人们非常依赖科技，这与Prime Now的价值定位十分符合，”亚马逊亚太区Prime Now负责人Henry Low说道。 2017年12月，亚马逊在新加坡推出了完整的Prime会员项目。 完整的项目包括满30.2美元免国际运费，订阅Prime Video服务以及Prime Twitch。 阿里巴巴和亚马逊的竞争在新加坡愈演愈烈。早在亚马逊推出完整的Prime服务之前，Lazada与Netflix和Uber联合推出了一个名叫Liveup的会员项目。 亚马逊在欧洲运营着五个不同的在线零售市场，主导着欧洲的电商市场。 亚马逊的第二和第三大市场分别是德国和英国，仅次于美国。 从2010年起，亚马逊已经进行了三次投资来巩固欧洲市场并强化物流。 在2011年，亚马逊收购了CicekSepeti的少量股权，CicekSepeti是土耳其的一家在线鲜花礼品店运营商。三年后，亚马逊通过投资英国和法国的两家物流公司强化了其在欧洲的物流。 从那时起，亚马逊建立了各种合作关系来继续主导欧洲的电商市场。 2016年，全球物流地产领先企业Goodman，扩大了与亚马逊在欧洲的长期合作关系。从2006年起，Goodman已经为亚马逊在欧洲范围内提供了超过100万平方米的物流基地。作为新项目的一部分，Goodman将会在法国Amiens开发一个10.7万平方米的物流中心，并在法国Lauwin-Planque租用一处占地3万平方米的物业。 2017年3月，亚马逊与德国DHL物流公司展开合作，DHL将为亚马逊在德国的生鲜食品提供空运服务。 为了继续增加其内部服务，亚马逊近期在欧洲推出了Twitch并扩大了Prime Video的范围。 亚马逊预计Twitch会吸引一大批欧洲的追随者，并在不久的将来带来显著的广告收入。今年3月，亚马逊证实已收购了爱尔兰游戏平台GameSparks。该公司是一家“后端即服务”的公司，为游戏开发者提供云端平台来构建排行榜等多种功能。 亚马逊与德国的Discovery通信公司合作，转播体育网络Eurosport。双方的合作协议也包含了奥地利，将会为亚马逊Prime会员提供来自Eurosports的优质高清视频。 亚马逊在2017年以5.8亿美元收购了阿联酋的Souq.com。这笔交易使亚马逊在沙特、阿联酋和埃及的日益增长和竞争激烈的电商市场上站稳脚跟。收购时，Souq.com宣称拥有超过4500万的月访问量，其提供31个类别下的840万种产品。 根据麦肯锡数据，中东地区的几个国家共有5千万的消费者，但当前在线零售只占总零售比重的2%。 亚马逊和Souq计划整合商品和服务，以便扩大当地的业务规模和供给。 六个月后，亚马逊和Souq收购了Wing.ae。这家创业公司计划打造一个为多种电子商务平台提供类似Prime的当天送达服务的物流网络，同时也提供其他的如音乐和视频服务。 交易条款没有公开，在收购前，Souq.com一直是该公司的唯一投资人。 由于相邻的地理位置及当地活跃的创业环境，阿里巴巴已经成为香港电商市场的主力玩家。从2016年起，阿里巴巴在香港对以下行业进行了13项投资： 电子商务：8项 医疗设施和服务：1项 移动商务：2项 互联网软件和服务：2项 阿里巴巴在当地最大的下注是2017年末的WeLab。Welab是一款手机APP， 。随着阿里巴巴继续进军全球不发达的市场，此项技术在向没有传统信用评分的人提供信贷方面可能会极其重要。 从2015年起，阿里巴巴每年会在以色列的科技领域进行6笔投资。近期，阿里巴巴参与了Nexar的3000万美元的B轮投资。该创业公司使用手机创建一个由AI支持的“车到车”汽车网络，可以预测和预防交通事故。 阿里巴巴集团在2017年底宣布成立一家致力于创新和科技合作的全球研究院，其命名为达摩院，代表着“探索，冒险，动力和展望”。在接下来的三年，阿里巴巴将会投资150亿美元在全球各地建立7个研究实验室。 2018年2月，阿里巴巴在新加坡与当地大学共同设立了第一家实验研究室，该机构将会专注于开发医疗保健、智能家居和城市交通领域的人工智能应用。  “阿里巴巴达摩院处在开发下一代技术的最前沿，这也会推动阿里和我们的合作伙伴的发展。”阿里巴巴的CTO张建锋在新闻稿中提到。 除了美国和中国外，其他的研究院将会在俄罗斯的莫斯科和以色列的特拉维夫建立。 这符合中国的 ，该倡议旨在加强欧亚大陆之间的互联互通。 阿里巴巴和亚马逊都是全球势力，并在持续地扩大其在世界各地的影响力。在全球众多未开发在线零售的区域，亚马逊和阿里巴巴在中到短期内都有着巨大的机会，同时若一旦犯下重大失误也会损失惨重。 通过并购、投资、国际扩张和合作，亚马逊和阿里巴巴将会继续在像印度、澳大利亚、新加坡等这类高速发展的市场进行扩张，也会继续巩固在其他国家的市场领导地位。 市场规模仍旧十分庞大，双方的竞争必然也十分激烈。随着其他区域互联网普及率的提高，拉丁美洲和非洲有可能会成为这些电商巨头扩大疆土的下一个必争之地。 原文链接： https://www.cbinsights.com/research/amazon-alibaba-international-expansion/   【今日机器学习概念】 Have a Great Definition "
24,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658866&idx=1&sn=9f1ab552b90d21ac3adfa520923fc160&chksm=bd4c3de18a3bb4f7f0daebf85e511157aea9d3f3fdb2567131247bfe4322a2bae389cd7619eb&scene=27,我在谷歌大脑见习机器学习的一年：Node.js创始人的尝试笔记,大数据文摘作品 编译：王一丁、于乐源、Aileen 本文作者Ryan Daul是Node.js的创始人，应该算是软件工程领域当之无愧的大犇了。他和我们分享了自己在谷歌大脑见习项目一年中的工作，成果，失败和思考。 去年，在通过对TensorFlow的研究得出一点点心得之后，我申请并入选了谷歌大脑举办的的首届见习项目（Google Brain Residency Program）。该项目共邀请了24名在机器学习领域有着不同背景的人士，受邀者将在为期一年的时间里和Google的科学家及工程师们在位于山景城的Google深度学习研究实验室中共同探索最前沿的深度学习科技。 这个为期一年的项目已经结束了，在此我将就这一年的经历作一个总结与分享。 最初拟定的目标是“修正”老电影或电视剧的画面。想象一下，上世纪90年代电视剧的粗糙画面或60年代的黑白电影，在色彩华丽的4K屏幕上播放的情景。 这应该是完全可行的：把4K视频转换成满是颗粒感的、低分辨率的、甚至是只有黑白两色的视频并不难，之后再通过某个训练出的监督模型来反转这个过程就可以“修正”了。而且，有数不尽的数据训练集，很棒不是吗！ 先别急着兴奋——因为能做这事儿的技术还没有出现......不过我们确实离目标越来越近了。 为了更好地实现这个目标，以科技之名，我再一次搬离了布鲁克林来到了湾区。几天后我的日常生活就变成了与Google的机器学习专家进行讨论以及在庞大的软件架构中四处探索。 如果你想跳过技术细节，可以直接跳到总结部分。 本文作者Ryan Daul开发了Node.js，一个流行的前端框架 众所周知，在美剧《CSI犯罪现场》中使用的缩放技术在现实中并不存在，你无法将照片放大到任意倍数。但可行的是，在放大照片的同时将像素可能构成的合理图形进行推测并呈现，这也是实现我目标的第一步–逆向提高图片的分辨率。 在文献中，这一问题被称之为“超分辨率”问题，是一个科学家们尝试了很久都没有解决的难题。 根据以往的经验，我们认识到只是训练一个卷积模型最小化低分辨率图像与高分辨率图像的平均像素差值无法彻底地解决这一问题。因为这一类模型训练的目的是平均化输入图像和目标图像的整体差值，这就导致了生成的图片非常模糊。 对我们而言，理想模型应该针对不同区域做出一个最佳的选择，尽可能的对细节做出全方位的优化。比如说，输入一张模糊的树的图片，我们希望我们的模型能分别对树的躯干、树枝、树叶进行优化，哪怕原图中没有相应的细节也没有关系。 起初，我们打算用条件型生成对抗网络（conditional GAN）来解决这个问题，但经过几次失败的尝试后，我们换成了另一种有望解决该问题的新型生产式模型——PixelCNN。（换成PixelCNN不久，SRGAN就发布了，它用GAN来解决超分辨率问题并能输出相当不错的结果。） PixelCNN和传统的卷积神经网络十分不同，它将图像生成问题转化成了一个像素序列选择问题。核心思想借鉴与于LSTM（长短时记忆网络）这样的门控递归网络，尽管他们通常被应用于单词或字符序列的生成上，但无可否认效果是非常好的。PixelCNN巧妙地构建出一个卷积神经网络（CNN），它能基于先前的像素的概率分布来生成下一个像素，也就是说同时具备了序列模型和卷积神经网络的特点。                                                van den Oord 等人所绘 让我没想到的是，通过PixelCNN生成的图像看起来非常自然。与对抗网络试图在生成与鉴别中找到一个精确的平衡不同，PixelCNN的目标只有一个，所以面对超参数的变化，它有更好的稳健性，也更容易被优化。 对于用PixelCNN解决超分辨率问题的首次尝试，我试图用ImageNet提供的图片进行训练，但事实证明这个目标还是有些太高了。（相较于很多生成式模型使用的CIFAR-10、CelebA或LSUN数据集，ImageNet更加的复杂）我很快地就发现——像素来序列生成图像的过程极其缓慢。 当输出图像的尺寸大于64x64时，生成一张图片的耗时超过数个小时！但当我降低了输出图像的尺寸并使用脸部或卧室类的小型数据集后，就开始慢慢得到了一些振奋人心的结果了。 用名人脸部图像数据集训练出来的超分辨率像素递归模型所生成的高分辨率图像。 左侧为测试数据集所用的8x8低分辨率输入图像。中间为PixelCNN模型所输出的32x32高分辨率图像，右侧是原始的32x32分辨率图像。我们的模型优先整合脸部特征，而后去合成较为逼真的头发与皮肤方面的细节。 就计算资源而言，在Google不会因GPU或CPU的数量而受限，所以如何扩大训练的规模便成为该项目的另一个目标——因为即便采用这些小型的数据集，在单个GPU上完成训练也要花上数周的时间。 异步随机梯度下降（Asynchronous SGD）是最理想的分布式训练方法。使用这种方法，你可以用N台机器，每一台都独立训练同一模型，并在每个时间步长共享一次权重参数。 权重参数被托管在一台单独的“参数服务器”上，该服务器在每个时间步长内都进行“远程过程调用（RPC）”，以获得最新数值并发送梯度更新。 如果整个数据流非常顺畅，就可以通过增加线程的方式线性增加模型每秒内的训练次数。但因为每个线程都是独立训练的，随着线程数的增加会越来越容易导致在当前线程还没有完成一次训练或更新时，它所使用的权重就已经过期了 。 如果是为了解决分类问题，这对神经网络的影响不大，把训练的规模扩增到几十台机器不难。但PixelCNN却对过时的梯度极其敏感，这就导致了通过增加硬件的数量来使用异步随机梯度下降算法所带来收益微乎其微。 另一个方法，是用同步随机梯度下降算法（Synchronous SGD）。使用这一方法，所有线程在每个时间步长内进行同步，每次下降的梯度会被平均，这保证不会出现权重过期的问题。 从数学的角度看，它与随机梯度下降算法是一样的，既机器越多，批处理能力越强。但同步随机梯度下降算法（Sync SGD）的优势是，它允许各线程使用更小、更快的批尺寸，从而来增加每秒训练的次数。 但同步随机梯度下降算法也有自己的问题：首先，它需要大量的机器经常进行同步，这就无可避免的会导致停机时间的增加；其次，除非将每台机器的批尺寸设为1，否则它无法通过增加机器的数量来增加每秒训练的次数。最终，我发现对我而言最简单有效的设置是用一台8GPU的机器使用同步随机梯度下降算法进行训练，即便如此每次训练仍需花上数天的时间。 拥有大量计算能力的另一好处是可以对超参数的优化进行大规模的暴力搜索。不确定该使用什么样的批尺寸进行训练？挨个试一遍！在找到论文中所用的配置前，我曾尝试过数百种配置。 另一个难题是如何量化评估结果。如何才能证明我们的图像比基准模型更好？衡量超分辨率效果的传统方法，是对比输出图像与原始图像在对应像素点之间的距离（峰值信噪比，PSNR）。 虽说我们的模型输出的脸部图像在质量上明显更好，但在像素对比上，平均看来还不如基准模型所输出的模糊图像。我们还尝试用PixelCNN本身的相似度测量来证明我们的样本比基准版本有着更佳的像素分布，但同样失败了。最后，我们把这项任务交给了大众——询问参与调查的人哪些图像看上去更真实，这才证明了我们模型的价值。 超分辨率的像素递归论文： https://arxiv.org/abs/1702.00783 PixColor：着色问题的另一次尝试 PixColor输出的双色模式 Slim的创造者Sergio Guadarrama一直在研究图像着色问题，他曾和我描述过这样一个试验：获取一张224×224×3的图像，将其置于YPbPr色彩空间中（该空间图像的灰度、颜色相互分离），首先将颜色通道降至28×28×2的超低分辨率，再用双线性插值法再把颜色通道放大，所得图像与高色彩分辨率的原始图像相比几乎没有差别。 你需要的只是几种颜色。顶行是原始彩色图像；中间是降低并采样后的色度图像，尺寸缩小至28像素；底行是双线性提高中间行的采样率并结合原始灰度图像的结果。 这一现象表明，着色问题可以简化成低分辨率颜色预测问题。我原本已准备好彻底放弃PixelCNN了，因为显然它无法输出大尺寸的图像，但转念一想其用来生成28×28×2的图像还是很可行的，并最终通过使用4位颜色数值而非8位，进一步的简化了着色问题。 Sergio构建了一个“美化”神经网络，它能美化低分辨率颜色的图像，并将溢出边界的颜色推回至正确位置–构造仅仅是使用L2损失函数将图片与图片进行比较。我们还用一个预训练好的ResNet作为辅助神经网络，以避免需要额外添加一个新的损失函数的需求，这中做法我们在超分辨率项目中就使用过。 通过以上所有技巧，不论是通过大众评估还是颜色直方图交叉测量，我们能够在ImageNet的训练集上实现最佳的结果。事实证明，一个训练好的PixelCNN模型产生的图像具有良好的数据分布性，而且没有发生过任何模型崩溃的问题。 Lab颜色空间中的颜色通道的边缘统计数据。左：每种测试方法的直方图以蓝色显示，ImageNet的测试数据集直方图以黑色显示。右图：左图颜色通道的相交比例 由于模型为每个灰度输入的可能着色声明了一个概率分布，我们可以对该分布进行多次取样，以获取同一输入的不同着色。下图用结构相似度（SSIM）很好地展示了分布的多样性： 为证明我们的模型可生成不同的样本，我们用多尺度SSIM对比了同一输入的两种输出。上图显示了ImageNet测试数据集的SSIM距离直方图。图中在多个SSIM间距上分别显示了每对图像。SSIM值为1表示两张图像完全相同。 该模型还远称不上“完美”，因为ImageNet尽管庞大，但不能代表所有的图像。我们的模型在处理非ImageNet图像时并不理想。真实的黑白照片（不同于彩色照片转化出的黑白照片）会得出许多不同的分布数据，也会出现很多彩色照片中所没有的物体。比如，Model T汽车的彩色照片不多，ImageNet图像集中可能一张都没有。或许采用更大的数据集和更好的数据扩增方法可以改善这些问题。 如果想了解输出图像的质量，可以来看看这些图： 当我们模型处于训练中期时处理的一小组非常难处理的图像： http://tinyclouds.org/residency/step1326412_t100/index.html 用我们的模型处理ImageNet上的随机数据集:   http://tinyclouds.org/residency/rld_28px3_t100_500_center_crop_224/ 作为对比，下面是用其他算法来处理同一ImageNet测试数据集的结果： http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/en/ http://richzhang.github.io/colorization/ http://people.cs.uchicago.edu/~larsson/colorization/ 所有完整的细节都可以在我们的论文中找到:  https://arxiv.org/abs/1705.07208 失败与未报告的实验结果 这一年期间，我曾间歇性地投入过许多业余的小项目，尽管它们都没成功，但其中有几个值得一提的项目： 大数的素因数分解 素因数分解一向都是个难题，尽管近期在素数分布领域又有了突破，也依旧很有挑战性。我们的想法是，如果为神经网络提供足够多的训练样本，看看它能否找出一些新的东西？ Mohammad和我尝试过两种方法：他修改了Google机器翻译的seq2seq模型，该模型把一个半素大数的整数序列作为输入，并以预测其素因数中的一个做为输出；我则使用一个较为简单的模型，它将定长整数作为输入，并用几个全连接层来预测输入的分类：素数或合数。 但这两种方法最后都只学到了最为明显的规律（如果尾数为0，那它就不是素数！），最后我们只能抛弃这个想法。 对抗做梦 受Michael Gygli的项目启发，我想看看能否用一个鉴别器充当它自己的生成器。为此，我构建出一个简单的二元分类卷积神经网络来判断输入的真假。 Michael Gygli的项目： https://arxiv.org/abs/1703.04363 既给出一张噪点图片并让它使用梯度自我更新来生成图像（也称为deep dreaming），训练的目标是令该网络把“真实”类别的输出达到最大化。该模型通过交替生成“假”实例来进行训练，跟典型的GAN中的鉴别器一样，通过升级权重来区分真假实例。 起初我的想法是，因为这个模型不需要像GAN那么复杂的架构设计，所以应该会极大地降低训练的难度。而事实上，这个模型在MNIST数据集上的确输出了不错的结果，如下栏所示：每一纵列都是由噪音图片一步步推进成为红色的MNIST数值。 但我没法在CIFAR-10 数据集上达到同样的效果，并且它的实用性也极为有限。很遗憾，因为我觉得“对抗做梦（Adversarial Dreaming ）”将会是一个很酷的论文标题。 鉴于PixelCNN训练一次需要很长的时间，我便想试试能不能用一个训练好的PixelCNN模型训练出前馈式、图像对图像卷积神经网络生成器（8x8至32x32尺寸的LSUN卧室图片集）。我所设置的训练方法是：在前馈式网络的输出上进行自动回归，在PixelCNN下更新权重以便将两张图片的相似率最大化。但这个设计失败了，它生成了非常奇怪的图像： 探索“异步随机梯度下降”的改进方法 如前所述，很多模型都不适用于异步随机梯度下降算法。最近，一篇名为DCASGD的论文提出了一种解决过时梯度问题的可能方法——在每一个线程更新自己的权重时使用差分向量。如果可以实现，这种方法可以大大减少每次需要的训练时间。不幸的是，我没能在TensorFlow上复原他们的结果，也就无法尝试我基于此方法的几个设想，可能还是哪里有Bug。 DCASGD的论文： https://arxiv.org/abs/1609.08326 思考，结论 作为软件工程师，我在机器学习方面并没有什么经验。但基于过去一年对深度学习的研究，我想说一下对该领域的总体看法，以及与范围更广的软件领域之间的关系。 我坚信，机器学习将改变所有行业，并最终改善每个人的生活，许多行业都会因机器学习的发展而受益。我相信我在这个项目中尝试的超分辨率问题在不久的将来就会被解决，所有人都可以看到查理·卓别林这类老电影的4K版。 不过，我确实发现，这一模型的构建、训练和调试都相当困难。当然，大部分的困难是由于我缺乏经验，这也表明有效训练这些模型是需要相当丰富的经验的。我的工作集中在机器学习最为容易的分支上：监督式学习。但即便有着完美的标记数据，开发模型可能仍然十分困难。 一般情况就是预测的维度越大，构建模型所花的时间就越长（例如：花大把的时间进行编程、调试和训练）。基于我的经验，建议所有人在开始时都尽可能的简化和限制你的预测范围。 举一个我们在着色实验中的例子：我们在开始时试图让模型预测整个RGB图像，而非只去预测颜色通道。最开始的想法是，因为我们使用的是跳跃连接（skip connection），所以神经网络应该容易就能处理好灰度图并输出可观的结果。后来，我们通过只预测颜色通道这一做法极大的提高了模型的性能。 如果我用“工作”这一词的直观意义来描述软件的话，那么图像分类任务似乎“工作”的很稳健；生成式模型几乎很少能“工作”，人们也不太了解这种模型，GAN能输出高质量图像，但同时却极难构建起来。我的经验是，对GAN的架构作出任何小改动都有可能使它完全无法工作。我听说强化学习与其相比更加困难，但因经验不足，在此就不作评价了。 另一方面，随机梯度下降算法的性能十分强大，即使是严重的数学错误，可能也只是会使结果有一些失真，而不至于产生严重的偏差。 因为训练模型经常需要花费很多天，这是一个非常缓慢的修改—运行循环。 机器学习领域的测试文化尚未完全兴起。训练模型时我们需要更好的评断方法，例如网络的多个组成部分需要维持特定的均值和变量，不能过度摆动超出界定的范围。 机器学习的bug使heisenbugs一类的漏洞很轻松地通过了我写的测试。 并行化（Parallelization）能带来的好处很有限。增加计算机数量使大规模的超参数搜索会变得更加容易，但理想情况下，我们会设计不用特别仔细调试也能很好运转的模型。（实际上，我怀疑超参数搜索能力有限的研究人员将不得不设计出更好的模型，因此他们设计出的模型更加稳定）。 不好的是，对于很多模型而言，异步随机梯度下降算法并没有什么用处—— 更加精确的梯度通常用处不大。这就是为什么 DCASGD 的研究方向很重要的原因。 从软件维护的角度看，关于如何组织机器学习项目大家鲜有共识——就像是Rails出现之前的网站：一群随机PHP脚本，商业逻辑和标记符号乱写一气。在TensorFlow项目中，数据通道、数学和超参数等配置无组织地混为一团。 我认为精美的机器学习类项目的结构/组织还未被发现（或者说是还未被重新发现，就像DHH重新发现并普及 MVC那样）。我的项目结构一直在进步，但我现在还无法将它称之为“精美”。 机器学习的框架会继续快速迭代。我最初使用的是Caffe，后来又不得不称赞TensorFlow带来的好处，而PyTorch 和 Chainer之类的项目现在则使用动态计算图来形吸引客户。 但漫长的“修改 - 运行”循环是开发更好模型的主要阻碍，所以我认为能优先实现快速启动和快速评估的框架最终会取得成功。尽管拥有TensorBoard和iPython之类的有用工具，但是检查模型在训练期间的具体细节仍然很难。 论文中的信噪比很低。但是还有很大的改进空间。人们通常不会坦率承认他们模型的失败之处，因为学术会议更看重的是准确度而不是透明度。我希望学术会议能接受提交博客文章，并要求开源实现，Distill在这方面的努力值得称赞。 对机器学习而言，这是一个令人激动的时代。在各个层面上都有大量工作等待完成：从理论到框架，每一方面都有很多值得改进的空间。它几乎和互联网的诞生一样令人激动，加入这场技术革命吧！ 原文链接： http://tinyclouds.org/residency/ 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 
25,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658866&idx=2&sn=7ac229e3bb473cea32b12643fef05818&chksm=bd4c3de18a3bb4f76233ad47280616bf99a34ae1f44d445f951a9b5593d19c5afa9e1d238730&scene=27,手把手 | Apache MXNet助力数字营销，检测社交网络照片中的商标品牌,"大数据文摘授权转载自OReillyData 数字营销是指在数字平台上推广服务和产品。广告技术（通常简写为“ad tech”）是指供应商、品牌及其代理机构使用数字技术来定位潜在客户，提供个性化信息和产品，并分析线上花费带来的效果。 例如，赞助的故事在Facebook新闻传播里的传播；在Instagram里的故事量；在YouTube的视频内容开始前播放的广告；由Outbrain支持的美国有线电视新闻网文章末尾的建议链接，所有这些都是实际使用广告技术的案例。 在过去的一年里，深度学习在数字营销和广告技术中得到了显著地应用。 在这篇文章中，我们将深入探讨一个流行的应用场景的一部分：挖掘网络名人认可的商品。在此过程中，我们将能了解深度学习架构的相对价值，进行实验，理解数据量大小的影响，以及在缺乏足够数据时如何增强数据等内容。 应用场景概述 在本文中，我们将看到如何建立一个深度学习分类器，该分类器可以根据带有商标的图片来预测该商品所对应的公司。本节概述了可以使用此模型的场景。 名人会认可一些产品。通常，他们会在社交媒体上发布图片来炫耀他们认可的品牌。典型帖子会包含一张图片，其中有名人自己和他们写的一些文字。相对应的，品牌的拥有者也渴望了解这些帖子的里他们品牌的展现，并向可能受到影响的潜在客户展示它们。 因此，这一广告技术应用的工作流程如下：将大量的帖子输入处理程序以找出名人、品牌和文字内容。然后，对于每个潜在客户，机器学习模型会根据时间、地点、消息、品牌以及客户的偏好品牌和其他内容生成非常独特的广告。另外一个模型则进行目标客户群的检测。随后进行目标广告的发送。 下图显示了这一工作流程： 名人品牌认可机器人的工作流程。图片由Tuhin Sharma提供 如你所见，该系统由多个机器学习模型组成。 考虑一下上面所说的图像。这些照片可以是在任何情况下拍摄的。因此首要目标就是确定照片中的物体和名人。这可以通过物体检测模型完成。然后，下一步是识别品牌（如果有的话）。而识别品牌最简单的方法就是通过识别它的商标。 在本文中，我们将研究如何构建一个深度学习模型来通过图像中的商标识别品牌。后续的文章将讨论构建机器人的其他部分（物体检测、文本生成等）。 问题定义 本文中要解决的问题是：给定一张图片，通过标识图片里的商标来预测图片对应的公司（品牌）。 数据 要构建机器学习模型，获取高质量数据集是必须的。在现实业务中，数据科学家会与品牌经理和代理商合作来获得所有可能的商标。 为了本文的目的，我们将利用FlickrLogo数据集。该数据集有来自Flickr（一个流行的照片分享网站）的真实图片。FlickrLogo页面上有关于如何下载数据的说明。如果你想使用本文中的代码构建自己的模型，请自行下载数据。 模型 从商标标识别品牌是一个经典的计算机视觉问题。在过去的几年中，深度学习已成为解决计算机视觉问题的最新技术。因此我们将为我们的场景构建深度学习模型。 软件 在之前的文章中，我们谈到了Apache MXNet的优点。我们还谈到了Gluon这一基于MXNet的更简单的接口。两者都非常强大，并允许深度学习工程师快速尝试各种模型架构。 现在让我们来看看代码。 我们首先导入构建模型所需的库： 我们使用FlickrLogos数据集里的FlickrLogos-32数据集。变量<flickrlogos-url>是这个数据集的URL。 数据准备 接着是创建下述的数据集： Train （训练数据集） Validation （验证数据集） Test （测试数据集） FlickrLogos数据已经分好了训练、验证和测试数据集。下面是数据里图片的信息。 训练数据集包括32个类别，每个类别有10张图片。 验证数据集里有3960张图片，其中3000张没有包含商标。 测试数据有3960张图片。 所有的训练数据图片都包含有商标，但有些验证和测试数据里的图片没有包含商标。我们是希望构建一个有比较好泛化能力的模型。即我们的模型可以准确地预测它没有见过的图片（验证和测试的图片）。 为了让我们的训练更快速、准确，我们将把50％的没有商标的图片从验证数据集移到训练数据集。这样我们制作出大小为1820的训练数据集（在从验证数据集添加1500个无商标图像之后），并将验证数据集减少到2460张（在移出1500个无商标图像之后）。在现实生活中，我们应该尝试使用不同的模型架构来选择一个在实际验证和测试数据集上表现良好的模型架构。 下一步，我们定义存储数据的目录。 现在定义训练、测试和验证数据列表的路径。对于验证目录，我们定义两个路径：一个存放包含商标的图片，另外一个用于没有商标的图片。 让我们从上面定义的列表里面读入训练、测试和验证（带有商标和无商标的）数据文件名。 从FlickrLogo数据集读入的列表已经被按照训练、测试和验证（包含和未包含商标）进行了分类。 现在让我们把一些没有商标的验证图片移动到训练集里面去。这样就让训练数据里包含了原来所有的图片，外加上来自验证数据里50%的没有商标的图片。而验证数据集现在只包含原有的所有带有商标的图片和剩下50%没有商标的图片。 为了验证我们的数据准备结果是对的，让我们打印训练、测试和验证数据集里的图片数量。 数据准备过程的下一步是设置一种目录结构来让模型的训练过程更容易一些。 我们需要目录的结构和下图里的类似。 数据的目录结构。图片由Tuhin Sharma提供 下面这个函数能帮助我们创建这个目录结构。 使用这个函数来创建训练、验证和测试目录，并把图片按照它们的相应的类别放到目录里面。 接下来是定义模型所用的超参数。 我们将会有33个类别（32种商标和1个无商标）。这个数据量并不大，所以我们将只会使用一个GPU。我们将会训练20个周期，并使用40作为训练批次的大小。 数据预处理 在图片被导入后，我们需要确保图片的尺寸是一致的。我们会把图片重缩放成224*224像素大小。 我们有1820张训练图片，但并不算很多。有没有一个好的办法来获得更多的数据？确实是有的。一张图片在被翻转后依然是表示相同的事物，至少商标还是一样的。被随机剪裁的商标还依然是同一个商标。 因此，我们没有必要为训练来找更多的图片。而是把现有的图片通过翻转和剪切进行一定的变形来获得更多的数据。这同时这还能帮助让模型更加鲁棒。 让我们把50%的训练数据上下翻转，并把它们剪切成224*224像素大小。 对于验证和测试数据，让我们按中心点剪切图片成224*224像素大小。现在所有的训练、测试和验证数据集都是224*224像素大了。 为了实现对于图片的转换，我们定义了transform函数。这个函数按照输入的数据和增强的类型，对数据进行变换，以更新数据集。 Gluon库有一个工具函数可以从文件里导入图片： 这个函数需要数据按照图2所示的目录结构来存放。 这个函数接收如下的参数： 数据存储的根目录路径 一个是否需要把图片转换成灰度图或是彩色图（彩色是默认选项）的标记 一个函数来接收数据（图片）和它的标签，并将图片转换。 下面的代码展示了在导入数据后如何对其进行转换： 相同的，对于验证和测试数据集，在导入后也会进行相应的转换。 DataLoader是一个内建的工具函数来从数据集里导入数据，并返回迷你批次的数据。在上述步骤里，我们已经定义了训练、验证和测试数据集（train_imgs、val_imgs、test_imgs相应的）。 num_workers属性让我们可以指定为数据预处理所需的多进程工作器的个数。 现在数据已经导入了，来让我们看一看吧。让我们写一个叫show_images的工具函数来以网格形式显示图片。 现在，用4行8列的形式来展示前32张图片。 进行变形后的图片的网格化展示。图片由Tuhin Sharma提供 上面代码的运行结果如图3所示。一些图片看起来是含有商标的，不过也经常被切掉了一部分。 用于训练的工具函数 本节内，我们会定义如下一些函数： 在当前处理的批次里获取数据 评估模型的准确度 训练模型 给定URL，获取图片数据 对给定的图片，预测图片的标签 第一个函数_get_batch会返回指定批次的数据和标签。 函数evaluate_accuracy会返回模型的分类准确度。针对本文的目的，我们这里选择了一个简单的准确度指标。在实际项目里，准确度指标需要根据应用的需求来设定。 下一个定义的函数是train函数。这是到目前为止我们要创建的最大的函数。 根据给出的模型、训练、测试和验证数据集，模型被按照指定的周期数训练。在之前的一篇文章里，我们对这个函数如何运作进行了更详细的介绍。 一旦在验证数据集上获得了最佳的准确度，这个模型在此检查点的结果会被存下来。在每个周期里，在训练、验证和测试数据集上的准确度都会被打印出来。 == True: net.hybridize() loss = mx.gluon.loss.SoftmaxCrossEntropyLoss() trainer = mx.gluon.Trainer(net.collect_params(), ‘sgd’, { ‘learning_rate’: learning_rate, ‘wd’: wd}) best_epoch =  best_acc =   isinstance(ctx, mx.Context): ctx = [ctx]  epoch in range(num_epochs): train_loss, train_acc, n =  ,  ,  start = time()  i, batch in enumerate(train_data): data, label, batch_size = _get_batch(batch, ctx) losses = [] with mx.autograd.record(): outputs = [net(X)   X in data] losses = [loss(yhat, y)   yhat, y in zip(outputs, label)]  l in losses: l.backward() train_loss += sum([l.sum().asscalar()   l in losses]) trainer.step(batch_size) n += batch_size train_acc = evaluate_accuracy(train_data, net, ctx) val_acc = evaluate_accuracy(val_data, net, ctx) test_acc = evaluate_accuracy(test_data, net, ctx) print(“Epoch %d. Loss: % f, Train acc % f, Val acc % f, Test acc % f, Time % f sec” % ( epoch, train_loss/n, train_acc, val_acc, test_acc, time() – start ))  val_acc > best_acc: best_acc = val_acc  best_epoch!= : print(‘Deleting previous checkpoint…’) os.remove(model_prefix+’-%d.params’%(best_epoch)) best_epoch = epoch print(‘Best validation accuracy found. Checkpointing…’) net.collect_params().save(model_prefix+’-%d.params’%(epoch)) 函数get_image会根据给定的URL返回一个图片。这个函数可以用来测试模型的准确度。 最后一个工具函数是classify_logo。给定图片和模型，这个函数将会返回此图片的分类（在我们的场景里就是品牌的名字）和此分类相应的概率。 模型 理解模型的架构是非常重要的。在我们之前的那篇文章里，我们构建了一个多层感知机（MLP）。此架构如图4所示。 多层感知机。图片由Tuhin Sharma提供 此MLP模型的输入层应该是怎么样的？我的数据图片的尺寸是224 * 224像素。 构建输入层的最常见的方法就是把图片打平，构建一个50176个(224 * 224)神经元的输入层。这就形成了一个下图所示的简单的数据流。 扁平化输入。图片由Tuhin Sharma提供 但是当进行这样的扁平化处理后，图像数据里的很多空间信息被丢失了。同时另外一个挑战是相应的权重数量。如果第一个隐藏层有30个神经元，那么这个模型的参数将会有50176 * 30再加上30个偏置量。因此，这看来不像是一个好的为图像建模的方法。 现在让我们来讨论一下一个更合适的架构：用于图片分类的卷积神经网络（CNN）。 卷积神经网络（CNN） CNN和MLP类似，因为它也是构建神经网络并为神经元学习权重。CNN和MLP的关键的区别是输入数据是图片。CNN允许我们在架构里充分利用图片的特性。 CNN有一些卷积层。这个词汇“卷积”是来自图像处理领域，如图6所述。它工作于一个较小的窗口，叫做“感知域”，而不是处理来自前一层的所有输入。这种机制就可以让模型学习局部的特征。 每个卷积层用一个小矩阵（叫卷积核）在进入本层的图像上面的一部分上移动。卷积会对卷积矩阵内的每个像素进行修改，此运算可以帮助识别边缘。图6的左边展示了一个图片，中间是一个3×3的卷积核，而运用此卷积核对左边图片的左上角像素计算的结果显示在右边图里。我们还能定义多个卷积核，来表示不同的特征图。 卷积层。图片由Tuhin Sharma提供 在上图的例子里，输入的图片的尺寸是5×5，而卷积核的尺寸是3×3。卷积计算是两个矩阵的元素与元素的乘积之和。例子里卷积的输出尺寸也是5×5。 为了理解这些，我们需要理解卷积层里的两个重要参数：步长（stride）和填充方法（padding）。 步长控制卷积核（过滤器）如何在图片上移动。 下图表明了卷积核从第一个像素到第二个像素的移动过程。 卷积核的移动。图片由Tuhin Sharma提供 在上图中，步长是1。 当对一个5×5的图片进行3×3的卷积计算后，我们将得到一个3×3的图片。针对这一情况，我们会在图片的边缘进行填充。现在这个5×5的图片被0所围绕，如下图所示。 用0填充边缘。图片由Tuhin Sharma提供 这样，当我们用3×3卷积核计算时，将会获得一个5×5的输出。 因此对于上图所示的计算，它的步长是1，且填充的尺寸也是1。 CNN比相应的MLP能极大地减少权重的数量。假设我们使用30个卷积核，每个是3×3。每个卷积核的参数是3×3=9，外加1个偏置量。这样每个卷积核有10个权重，总共30个卷积核就是300个权重。而在前面的章节里，MLP则是有150000个权重。 下一层一般典型地是一个子抽样层。一旦我们识别了特征，这一子抽样层会简化这个信息。一个常用的方法是最大池化。它从卷积层输出的局部区域输出最大值（见下图）。这一层在保留了每个局部区域的最大激活特征的同时，降低了输出的尺寸。 最大池化。图片由Tuhin Sharma提供 可以看到最大池化在保留了每个局部区域的最大激活特征的同时，降低了输出的尺寸。 想了解关于CNN的更多的信息，一个好的资源是这本在线图书《神经网络和深度学习》。另外一个好的资源是斯坦福大学的CNN课程。 现在我们已经对什么是CNN有了基本的了解。为了这里的问题，让我们用gluon来实现它。 第一步是定义这个架构： 在模型架构被定义好之后，让我们初始化网络里的权重。我们将使用Xavier初始器。 权重初始化完后，我们可以训练模型了。我们会调用之前定义的相同的train函数，并传给它所需的参数。 我们让模型运行20个周期。典型的情况是，我们会训练非常多的周期，并选择验证准确度最高的那个模型。在上面运行了20个周期后，我们可以在日志里看到验证准确度最高的是在周期5。 在此周期之后，模型看起来并没有学到更多。有可能网络已经饱和，学习速度变慢了。我们下一节里会试一个更好的方法，但还是先让我们看看现在这个模型的表现如何。 让我们把最佳验证准确度的模型参数导入，然后分配给我们的模型： 现在让我们看看这个模型在新数据上的表现。我们会从网上获取一个容易识别的图片（见下图），并看看模型是否能准确地识别。 BMW的商标。图片由Tuhin Sharma提供 模型的预测结果很糟糕。它认为这个图片里没有包含商标的概率是8%。预测的结果是错的，且概率非常低。 让我们再试一张图片来看看准确率是否有改善。 Foster的商标。图片由Tuhin Sharma提供 又一次，模型的预测结果是错的，且概率很低。 我们没有太多的数据，而如上所见，模型训练得已经饱和。我们可以继续试验更多的模型架构，但是我们没法克服小数据集的问题，因为可训练的参数远远大于训练图片的数量。那我们如何克服这个问题？在没有太多数据的情况下不能使用深度学习吗？ 对此的答案就是迁移学习。下面接着讨论。 想想这个比喻。你想学一门新的外语，怎么进行哪？ 例如，你可以进行一个对话。导师：你好吗？你：我很好，你怎么样？ 你也能试着对新的外语做一样的事。 因为你的英语很熟练，你可以不用从零开始学一门新的语言（即使看起来你是这样做的）。你对一门语言已经有了心智图，你可以试着在新的语言里找到相应的词汇。因此在新的语言里，你的词汇表可能依然有限，但凭借你对于英语对话结构的知识，你依然能用新语言进行对话。 迁移学习的工作机制也是一样的。高准确度模型是在海量数据集上训练出来的。一个常见的数据集是ImageNet数据集。它有超过一百万张图片。全球的研究人员已经使用这个数据构建了很多不同的前沿的模型。这些模型（包括模型的架构和训练好的权重）都在网络上可以获得。 通过这些预先训练好的模型，我们将再次对于我们的问题来训练这个模型。事实上，这种情况是非常普通的。几乎总是这样的，大家首先构建的能解决计算机视觉问题的模型都是使用了一个预先训练好的模型。 在诸如我们的例子的很多场景里，如果受限于数据，这可能是所有人都能做的。 一个典型的方法是保持模型的前面层不变，只训练最后一层。如果数据量非常有限，只需要把分类层再训练就可以了。如果数据量相对充足，可以把最后的几层都再训练一下。 这是有效的，因为卷积神经网络在每个连续层学习更高层次的表示。它在许多早期阶段所做的学习在所有图像分类问题中都是共同的。 现在让我们使用一个预先训练的模型来做商标检测。 MXNet有一个模型库，里面有很多预先训练好的模型。 我们会使用一个流行的预先训练的模型，它叫resnet。这篇论文里提供了这个模型架构的很多细节内容。一个简单一些的解释可以在这篇文章里找到。 让我们先下载这个预训练过的模型： 因为我们的数据很少，所以我们将只训练最后的输出层。我们先随机初始化输出层的权重。 现在我们调用之前一样的训练函数： 现在这个模型马上就有了更好的准确度。典型的情况是，当数据比较少时，我们只训练几个周期，再选验证准确度最高的那个周期的模型。 现在，周期16有最好的验证准确度。因为训练数据有限，再继续训练的话，模型就开始出现过拟合。我们可以看到在周期16后，随着训练准确度的增加，验证准确度却开始下降了。 让我们导入周期16相应的检查点存储的参数，并用它们作为最后的模型。 评估预测的结果 对于我们之前用于评估的相同的图片，让我们看看新模型的预测结果。 图片由Tuhin Sharma提供 我们看到这个模型用98%的概率预测对了BMW这个商标。 现在让我们试一试另外一个之前测试的图片。 尽管预测的概率并不高，比50%略低。但Foster依然是所有商标里概率最高的那个。 进一步改进这个模型 为了改进模型，我们需要改正一下我们构建训练数据集的方式。每个商标都有10张训练图。但是，为了把一些验证图像从验证集里转到训练集，我们将1500张图像作为无商标的例子移动到训练集里。这导致了显著的数据偏差，这可不是一个好方法。以下是解决此问题的一些选项： 给交叉熵损失赋予一定的权重。 在训练数据里不包含无商标的图片。从而训练一个对不包含商标的测试和验证图片预测成所有商标都有很低的概率的模型。 但请记住，即使在用迁移学习和数据增强的情况下，我们也只有320个商标图片。这对于想建立高度精确的深度学习模型而言还是太少了。 总结 在本文中，我们学习了如何使用MXNet构建图像识别模型。Gluon是进行快速原型试验的理想选择。使用杂交和符号导出，把原型转变成生产系统也非常容易。通过使用MXNet上大量预先训练的模型，我们能够在相当快的时间内获得非常好的商标检测模型。一个很好的学习这背后的理论的资源是斯坦福大学的CS231n课程。 大数据文摘授权汉化的 斯坦福大学的CS231n课程： http://study.163.com/course/introduction/1003223001.htm 这篇博文是O’Reilly和Amazon的合作产物。请阅读我们的编辑独立声明。 Tuhin Sharma住在印度班加罗尔，目前在Ivanti担任高级数据科学家。 在 此之前，他曾在IBM Watson和RedHat担任数据科学家。他研究生毕业于印度理工学院计算机科学与工程专业。他喜欢在休闲时间打乒乓球和吉他。他最喜欢的一句话是“生活是美好的”。你可以在LinkedIn上找到他。 Bargava Subramanian是在印度班加罗尔的一名深度学习工程师。 他目前为一些公司进行数据科学实践提供指导。他拥有马里兰大学的硕士学位。他是一位热心的NBA球迷。你可以在http://bargava.com上找到更多关于他的消息，或通过@bargava在Twitter上联系他。 由O'Reilly和Intel共同举办的 即将开始，跑步入场还来得及，戳 马上抢票 👇 【今日机器学习概念】 Have a Great Definition "
26,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658768&idx=3&sn=d4be0ecf4b43544768ea6f853b852c0e&chksm=bd4c3d838a3bb4954bf7fdece7a8a94beddd5cd2572b9f88e0bf393f3a34e0044ff532af01c9&scene=27,大咖 | 法律领域的科技创新要配套司法制度改革：清华RONG论坛实录,大数据文摘作品 还记得我们报道过的“ ”吗？双方的比赛内容是审查保密协议（NDA），人类律师的平均准确率达到了85%，而AI律师则能达到95%，并且可以在26秒内完成任务。 素以“高智商”闻名的律师们，在处理流程化工作上已经被证明了可以被AI替代。 对法律界来说，这不是件坏事，因为律师的精力可以用来处理更需要人类专长的工作，比如承担法律责任、做出道德判断，从而带来整体效率的提高。 杭州首家互联网法院开庭 在法院，同样的剧情也在上演。从信息化范畴的电子笔录、视频远程开庭，到智能化范畴的语音翻译辅助审讯、AR物证，检查机关和法院都已从这些技术中受益。然而，司法相关的制度改革还跟不上科技创新的速度。比如，使用机器翻译做笔录会遇到一个关键问题：机器翻译能不能替代法律上的翻译人员？ 在此背景下，3月23日，在由清华大学数据科学研究院主办，清华大学法学院、社会科学学院、北京国双科技有限公司协办，清数大数据产业联盟承办的“清华RONG系列论坛之司法大数据专场”论坛中，来自国家信息化、法院信息化、司法及大数据领域一线的专家学者们分享了各自的观点。 大数据文摘为大家带来了论坛部分实录： 刘品新 ： 智慧法制的双轮驱动 众所周知这几年司法有很大的进步，按照习总书记的说法是做成了很多以前想做没有做成的事情。司法的进步可以从不同的角度去解读。从我个人的观察，司法这几年一方面在进行司法体制的改革，朝着深度、朝着内部进行改革，有人讲刀刃向内，对司法员进行改革。同时做信息化的建设，尤其是以大数据、人工智能加司法的建设，在法院检查系统都取得了很好的成绩。 以江苏检察院为代表，网上检察院、掌上检察院三位一体的检察院建设很有成效，去年9月份在江苏召开全国检察机关的智慧检务系统会议的时候，各地检察官、各级代表尤其是一些专家学者评价都很高。有些院士评价检察院的工作已经跟美国一样走到了世界的无人区，在智慧司法建设方面已经走到最前面。 江苏检察院的案管机器人，通过大数据人工智能对案件进行管理，考核大家的绩效，对大家的办案进行督导。包括检察机关的所有办案，案件从公安到检察院再到法院，全过程安管机器人都可以提供帮助，是一个令人惊讶的新型的检察官。 司法改革和司法建设双轮驱动 2016年5月中共中央国务院印发了国家创新驱动发展战略纲要，明确提出来，在今天国家的建设要施行创新驱动，要改变双轮驱动构建一个体系，推动六大转变进行布局，构建新的发展动力系统，关键词是双轮驱动，是指科技创新和体制机制创新两个轮子互相协调。它指的是国家整个层面，包括国家治理层面，更包括治理层面的司法治理、法制的层面。 法制领域里搞双轮驱动，因为它是国家治理的组成部分，是推动国家治理体系现代化、治理能力现代化的一部分。因此一方面要靠传统的武器——司法改革，改掉那些传统的顽疾；另一方面要科技创新，寻找新的动能，进行动能的转换。 习近平总书记在去年7月份对全国司法体制改革推进会上做了批示，要遵循司法规律，把深化司法体制改革和现代科技应用结合起来，不断完善和发展中国特色社会主义司法制度。 我们把深化司法体制改革和现代科技应用结合这个思路简称为双轮驱动。双轮驱动是国家治理体系现代化的需要，直接地说就是国家领导人的指示。 但是对于双轮驱动，很多人都是简单地理解。司法只要找两波人做事：一部分是法律人去做司法改革；一部分是借助社会力量找科技人员，成立自己的司法大数据研究院，进行科技创新。我觉得这是孤立地看待双轮驱动。 最近这两年推动相关工作的时候，我有一个新的体会。现在大家把双轮驱动理解为两个轮子是孤立的，是错误的。 因为从实践和理论来讲，双轮驱动是指并驾齐驱，是交错在一起。如果做一件事情不考虑第二件事情，一定达不到效果，而只有把这两股力量、两项工作结合起来，才能够达到我们预期的效果。 国内智慧法制建设的成绩 首先是杭州的互联网法院 ，它的成立是希望探索在网络时代中国如何通过司法解决网络纠纷，提供中国的治理网络纠纷的方案。互联网法院使用到很多科技的手段，它的很多案子是远程庭审，基本上没有面对面的审理。 远程开庭 这种审理可以把原告和被告在世界各个不同的角落集中在一起，法官借助网络进行裁判。这个成绩初步的取得，与科技支撑是有密切关系的，没有今天最起码的远程法庭或者起码的网上视频技术是不可能推出杭州互联网法院的。 之后是法院系统解决执行难的问题 ，这两三年以来，法院的执行难的问题有很大程度的解决。法院建立了一种非常庞大的数据库，它能够跟各个银行，跟一些房产公司、民航、火车、交通这些部门进行联网，共享他们的数据库，使得老赖的信息无可盾形。 接下来是北京检察院的同志最早的创造 ，第一次在全国使用VR技术在庭上进行物证的展示，法院同志对它评价很高，它可以让人非常好地把握证据。 这几年搞刑事审判中心的改革很难，做了很多事情，比如说非法证据的排除规则的建立，这些虽然都取得了小小的成效，但是用VR等现代技术来支撑庭审的时候，能够更直观的了解案件是怎么发生的。 再之后是我挖掘检察机关通过科技创新打击农村冒领困难补助金 ，中央特别关注扶贫工作中的腐败治理。腐败的现象表现的很多，其中有一种是中央支持的钱被一些地方村长和其他官员通过种种渠道落入自己或者亲戚的口袋里。我们就把田地辅助金等数据汇总，设立一个数据库，就可以发现这些腐败案件。 第二种是把村干部冒领困难补助金和农地补助金的数据进行登记，若发现这个村里面几乎所有的村干部家族里的钱都排在最前面，就说明有冒领的问题。我们在司法改革、探索的过程中，使用了科技创新，产生了奇效。 与科技手段结合，产生的效果不如预期 法院、检察机关都在进行智能语音的探索，检察机关试验的比法院广泛一些，特别是使用了双语。我们在新疆很多地方使用了维汉智能语音系统，包括审讯的时候进行辅助审讯、庭审的时候进行辅助开庭、产生判决书的时候进行自动的判决书翻译。 这些工作经过两年多的努力产生一些效果，但是今天看起来，它遇到的障碍是配套制度改革还没有跟上。 我们以庭审中使用智能语音为例，现在有的信息化做的好的法院，开庭是这种模式：法官一个人在法庭上，没有书记员，检察官在自己的办公室，他的办公室也没有书记员，被告是在看守所，只有一个法警。这种开庭的效果很好，节约了很大的成本。 现在这种模式遇到了很多问题，比如笔录是不是合法的，我们强调庭审记录是书记员记的。如果在维族地区使用双语翻译的话，这种机器翻译的东西能不能替代法律上的翻译人员？有的时候很多法院要求笔录必须是两个司法人员，而这样的庭上的只有一个人。这种配套制度跟不上的时候，就导致了科技创新的效果没有最大程度的彰显。 司法领域的科技创新一定要跟司法改革相结合 未来智慧司法的建设，一定得跟司法改革相结合，在任何法律领域的科技创新都一定要配套进行司法相关的制度改革。 我认为我们在今天需要做一些配套的改革：笔录的改革，应该建立电子笔录制度；诉讼参与人制度改革，确认以智能语音为代表的这些机器能够起到一个书记员或者翻译员，或者是代理人的身份；建立类案检索制度，它能不能跟西方国家的判例制度相对应；网上庭审程序的改革，今天的线上庭审是不是像线下的程序一样，能不能在庭下完成一部分工作，庭上只是做一些核心的工作。当然还有其他的。 最后拿国务院《关于新一代人工智能的发展规划战略》做一个补充，这个战略里面对智能司法的建设、人工智能的建设做了长远的部署，同时它对相关的法律配套制度建设也做了论述，2020年第一步应该初步建立部分领域的人工智能能力规划和政策法规，到2025年第二阶段应该初步建设人工智能的法律法规，到第三步2030年应该建成更加完善的人工智能法律法规。 它强调制定促进人工智能发展的法律法规，是今天中国实施人工智能或者智慧国家建设的一个重要的保障措施。但是这样的文件，这样的指示，许多人片面理解。我今天提醒大家把这两者真正的结合，就像是两只互动的手。希望我们法律人和技术人，司法改革工作和智慧法制工作携手共同走向未来。 中国社会科学院法学研究所胡昌明： 法治蓝皮书·法院信息化发展报告 首先我介绍一下这个报告的背景情况，我是来自中国社会科学院法学研究所，我们是在国家法制指数研究中心工作，我们这个指数中心主要研究和开发跟中国法律相关的一些指数。 其中法制信息化就是一个比较重要的指数之一，除了信息化之外，我们还对中国法制蓝皮书进行总结，每年我们都会发布法制的发展情况，其中包括大量的指数，包括法院的信息化，包括警务的透明度，政府公开信息等等一些报告都是在蓝皮书进行汇报。 我们刚发布了2018年最新的法制蓝皮书，在全国500多个蓝皮书中影响力方面，每年排名第一。此外我们也是做了一些地方蓝皮书，从16年开始，我们对中国法院的信息化进行一个评估，第一年做了第三方评估报告，17年做了第一份发展报告。 今年2月份发了中国法院信息化发展报告，其中最重要的一篇报告就是法院信息化第三方评估，这个评估也是首次对法院信息化状况进行量化的评估。 今天报告主要分以下五个方面，其中前两个方面更多的是理论。 法院信息化评估的意义 我们知道从1996年开始，法院已经开始信息化的建设。 到目前为止经过二十多年的发展，法院信息化取得了重大的成就，比如说中国裁判文书网，包括法院各种信息化的电子档案的生成等等。 这些成绩需要一个总结，同时在法院的信息化发展过程中，各地的发展也非常不平衡，投入了大量的人力物力，这些人力物力是不是值得投入，或者现在还存在什么问题，我们需要总结。这就是我们这个报告去评估的初衷。 法院信息化评估的原则 我们进行评估，主要是从以下四个方面。 ，我们根据法院信息化的建设蓝皮进行评估，同时采取客观的方面，包括第三方网络公司提供的数据，包括最高法院提供的一些数据。 重点突出 ，重点选取对法院信息化非常重要的几个指标进行重点评估，不是全面铺开。 ，第一年评一些主要的指标，今后几年会逐渐对指标进行深入的分析。 ，从智能审判，高效执行，优质服务和自动化管理进行评估。又分了16个二级指标和42个三级指标，我们对每个指标都进行评分，评估对象是全国34000多家法院，从高院到基层法院都包括在内。 法院信息化建设的成效 第一，在基础建设方面，法院信息化确实是发展的非常显著 。 技术公司提供门户网站链接的有效性，已经有91%的门户网站链接是有效的，不能访问或者链接无效的网站非常少。 门户网站更新非常及时，在有效的网站中95%的网站更新非常及时，只有4%多的法院不够及时。科技法庭遍地开花，经过统计全国36000多家法庭当中已经有24000多家法庭实现科技法庭，不只是架一个监视录像，通过语音识别自动把当事人的发言辅助笔录的生成，还包括一些高清的摄像头在不同角度切换。 第二，司法便民不断的创新，有70%的法院有网上立案功能，900多家法院已经实现网上缴费，大大减轻了当事人的精力。 在上海、河北、吉林网上缴费已经全面铺开。12368是法院提供的诉讼服务热线，这个热线在全国法院已经普及的非常高，从西部的甘肃，中部的安徽，东部的浙江以及上海全面铺开了。 上图是最高法院的领导跟远在重庆基层法院的信访人的视频接访情况，四级法院的法官都可以在同一个画面中出现，便利了当事人跟法院的交流。从法院的角度来说，也能够第一时间了解到基层当事人的心声。 第三，信息化能够助力审判绩效。 电子签章在人民法庭运用的特别广泛，以前盖人民法院的章需要到几十公里外专门盖章，一篇文书通常需要十个以上的盖章，各种人力成本和时间成本非常大，现在半数法院已经实现了电子签章的技术，在广东、青海等地80%以上的法院已经实现了。 然后是电子送达，送达难是在法院民事审判当中非常难的难题，40%的精力都在送达方面。目前我们看到电子送达功能已经覆盖了75%的法院，其中上海本地的法院已经实现了百分之百的电子送达，当然这是功能上的，不是说现在所有的案件都能够直接送达，接下来需要进一步的当事人的信息采集，才能完全实现电子送达，这是一个发展方向。 第四，推进法院精准管理。 一是智能统计和分析，统计数据需要大量的人力物力，例如原来每个月20日是统计报截日，每个法院都需要管理部门的两三个人工作两到三天才能把一个法院的数据统计完，而这种数据需要层层汇报到最高法院，时间大概是10天左右，动用的人力物力非常大。 现在从最高法院的大数据平台可以看到全国各法院，各个下面的基层法院收案量，结案量，对于司法统计又达到了精确化，又节约了大量的人力和物力。同时自动生成统计报表的时候，能够做一些类案的分析。 最早法院统计一个项目非常困难，包括政法委给法院一个指令，最近狗咬人的事件比较多，统计涉犬案件的纠纷，需要从侵权的、宠物狗的医疗美容案件当中寻找，人工寻找成本非常高，如果是通过大数据能够自动的生成一些统计报表。 在司法改革之后，法院的监督不能再像以前那样通过案件审批的方式进行监督，自动化的监管也是非常重要，是司法改革的配套制度。目前我们也看到已经有78%以上的法院实现对于案件超期进行警示。某些法院案件自动化监管水平已经达到100%。 信息化建设仍存在一些问题 ，电子卷宗是法院信息化进一步深化的关键，但是在深度应用方面，电子化仍然不太足。包括提取信息的回填，包括卷宗文字的智能识别方面，能够实现的法院比例比较低，不到40%。中西部的法院电子卷宗结案生成率也是不高。 第二，文书智能生成。 这项功能在全国法院都是非常重视，我们到全国各个法院调查的时候，很多法院都声称能够生成自动文书，或者他们都在研发这样的系统，但是我们看到真正的功能方面，文书智能生成能够生成一些简单的信息，对于最关键的事实理由和刑事案件的量刑分析方面，实现的不是很理想，还需要进一步探索。 第三，诉讼服务和引导。 杭州互联网法院已经能够实现网上庭审，面对面的跟当事人远程开庭，但是这项功能在全国法院实现的比例非常低。网上调解和网上开庭的评估中，大部分法院还是不能够实现这样的功能。 第四，审判信息有待进一步公开。 裁判文书网已经是世界上最大的文书网站，但是我们在评估中发现一些问题，包括不上网文书的数量、案号和理由公开的非常少，导致有些案子不公开，今后对裁判文书的利用和研究的产生不利的影响。 在裁判文书网查询的时候，经常需要验证码，非常低效，现在已经改进了。我们最新查看裁判文书网，已经不会出现验证，这个是值得肯定的。 法院信息化发展方向 第一，需要深层次运用。 法院信息化发展到现在，它的一些基本电子化和浅层次的运用已经发挥的非常好，但是对于辅助法官办案的深层次的功能应用，仍然不太够。因此需要在开发新系统的时候，多听取一线的审判人员，一线的法官意见，把法官的需求和技术人员的能力结合起来开发一些对于辅助审判更加有用的功能。 第二，需要对于现有的一些审判系统，一些应用加以总结。 各地在不同的功能方面有一些很好的开发，比如说上海的类案比较和识别方面。各个地方都在开发同一个功能，这些功能需要最高法院对于全国的法院更深入的调研，一些好的经验总结出来，而不是各地去开发类似的软件。 Have a Great Definition 
27,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658768&idx=2&sn=bafa3de48fd209aa22ccda3328b250d0&chksm=bd4c3d838a3bb495c3e6e8e3f7e7c265e73181270c643b17f8b93314fe66ff8bf786a81ff623&scene=27,业界 | Kaggle问卷主成分分析，16000万数据从业者面临这5类挑战,"大数据文摘作品 编译：李雷、元元、小鱼 数据科学的功能是在数据中寻找有用的观点并加以应用。然而，数据科学并非凭空而来。在向分析目标迈进的过程中，数据从业者可能面临阻碍其进展的各种挑战。 本文探讨了数据从业者在分析数据时遇到的挑战类型。为了研究这个问题， 调查报告 （Kaggle 2017 State of Data Science and Machine Learning）中的数据。这是一项针对16,000多名数据从业者展开的专项调查（数据收集于2017年8月）。 Kaggle的调查数据显示，数据科学家面临的最常见挑战包括脏数据（36%），缺乏数据科学人才（30%）和缺乏管理支持（27%）。 数据来源： https://www.kaggle.com/kaggle/kaggle-survey-2017 数据从业者过去一年所面临的挑战 在调查中10153名受访者被问到，“在过去的一年中，你工作中遇到了哪些障碍或挑战？（可多选）。”结果如上图所示，排名前十的挑战是： 脏数据（36%的受访者提及此项） 缺乏数据科学人才（30%） 公司政策（27%） 缺乏明确的研究问题（22%） 数据无法访问（22%） 结果未被决策者使用（18%） 向其他人解释数据科学（16%） 隐私问题（14%） 缺乏专业领域知识（14%） 小公司请不起数据科学团队（13%） 结果显示，平均每个数据从业者就会遇到上图中的三项挑战（3是中位值）。不同职位所遇到的挑战数量不同。自认为是数据科学家(Data Scientist)或预测建模师（Predictive Modeler）的数据从业者称遇到了其中的四项挑战。自认为是程序员的数据从业者称只遇到了其中的某一项挑战。 我想将这20项挑战进行分组，把通常一起出现的挑战归为一组，因此我对数据进行了主成分分析（0表示未经历此项挑战;1表示经历过此项挑战）。我发现了一个相当清晰的、由5个主要成分构成的分组方案，其中特定挑战往往会与其他相关挑战一起出现。 数据从业者遇到的挑战的主成分分析。 图中表格数据是方差极大正交旋转后的成分矩阵， 得分大于等于0.40的成分以粗体显示。 上图中五个主要成分（挑战分组）是： 分析结果未被用于决策：这组挑战还包括公司政策、无法将研究结果纳入决策过程以及缺乏管理支持。 数据隐私、真实性、无法访问：这组挑战围绕数据本身展开，包括数据清洗的复杂程度、可访问性以及隐私问题。 扩展/部署工具的局限性：这组挑战与用于提取结果、部署模型以及将解决方案扩展到完整数据库的工具相关。 缺乏资金：资金缺乏引起的挑战会影响组织机构在外部数据源、数据科学人才以及可能的领域专业知识方面的购买力。 提出的错误问题：这组挑战包括难以对数据科学项目的结果保持合理的期望，并且对数据分析没有明确目的或方向。 数据从业者在数据科学和机器学习工作方面会遇到一些挑战。一年中平均每个数据从业者可能会遇到其中三项挑战。最常见的数据科学和机器学习挑战包括脏数据，缺乏数据科学人才，缺乏管理支持以及缺乏数据分析明确的方向或目的。 原文链接： http://businessoverbroadway.com/top-10-challenges-to-practicing-data-science-at-work Have a Great Definition "
28,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658768&idx=1&sn=c974e5898da33872fcb4439bcaf2c353&chksm=bd4c3d838a3bb495a814206587a7247448ae82ebf5be9b29fdd31af2f04757a217ffa51d8166&scene=27,TED演讲：给你一个机器替身，会发生哪些有意思的事？,大数据文摘字幕组作品 翻译：Queen、Melody 监制：龙牧雪 有个机器替身， 大概是每个为《黑客帝国》而疯狂的人的梦想吧！但是，如果你仔细想想，你真的想要一个替身吗？ 想象一下：你在北京工作，公司总部在纽约。 你怎么跟纽约总部沟通？可能是发邮件、开电话会议甚至视频会议，对吗？ 这就是你在纽约总部的形象：一部越洋电话里的一个声音。没有表情、没有多余的动作，甚至如果你和总部的戏精在电话里吵起来了，他们可以随时关掉你的开关。 那么，如果给你的机器替身安上一个身子，会不会有所改善呢？就是下面这样的： 额……看起来好像有点简陋。这么一个带屏幕和轮子的家伙能做什么呢？ 有了它，你就能“滚”到你同事的办公桌前，如果他们不回复你的邮件，“你”就站着不走，直到他们觉得不好意思为止。是不是很棒！🌚 给你一个机器替身，你会有什么反应？又会给你周围的人和环境带来怎样的影响？这就是加州大学Santa Cruz分校心理学教授Leila Takayama和她的团队在做的研究。 TED演讲：如果你是个机器人会怎样？ 时长13分钟 带有中文字幕 ▼ 除了堵在你同事的办公室门口，你能做的事还有很多！ 比如，以某种身份列席公司大会： 有意思的是，加州的机器人学和心理学研究者发现， 。在会议进行过程中，同事们会围绕着你的机器替身，但是不会靠得太近，就好像你真的在会议室里一样。 机器和人之间形成了一种微妙的互动关系。不过，也会有不舒服的时候。 人们第一次看到这些机器人的时候，通常会有这样的反应：“哇，看这些部件，这里一定有一个相机”，然后开始戳你的脸。 有时，你的同事们还会直接说“你的声音太小了”，然后走过来把你替身的音量键调大一点。这样会不会使你感到有点不舒服？就好像有人走过来说“我要把你的脸按大一点”一样？ 所以， 。 还有，在机器代替你参加鸡尾酒派对的时候，另一个问题出现了。看下面这张图： 图中，试用机器替身的哥们发现“ ” 他原本身高有一米八，但是机器替身只有一米六高。这让他觉得非常不适应，因为他必须仰着头和人对话。“大家好像都不怎么看我！”，他抱怨。 研究发现，当同一个人使用同样的机器替身，表达同样的内容时，如果他们处在身高较高的机器人身体里，他们的话会被认为更有说服力、更有参考价值。 这个世界不仅看脸还看身高 瑟瑟发抖 当你认真思考机器人技术时，你会发现我们并不是在重新创造人类，而更多的是在探索如何拓展我们自身。 比如，这些替身机器人没有胳膊，所以用替身的同事没法玩台球，但是他们却能围观和起哄那些正在玩台球的人，这对增强团队凝聚力非常重要。 或者，你可以把办公室的垃圾桶当足球踢来踢去🌚 这波操作很6了 上面都是人类看机器的视角。如果我们转换视角，看看正在操作机器的人，他们见到的画面就是下面这样： 非常像一个电子游戏的场景。可能过于像了，以致于正在操作机器的人们没有意识到，画面的另一端也是一个真实的世界。 在一次让一帮小孩子操作机器替身的实验中，研究者发现，实验很快演变成了 然后小朋友们的机器替身就会在走廊里追逐这些人。 有没有让你想起《安德的游戏》？ 这也是人机交互的设计者应当承担的责任：去帮助人们认识到他们的行为会在现实世界里造成真实的后果，去建立一种责任感。 我们当然不想让机器替身具有如此的破坏性，所以 。这样一来，如果有人想冲向一把椅子就不成了，机器替身会重新规划一条路线。 但是也遇到了问题。研究人员发现，有些人需要花费更多的时间才能通过障碍测试课程。这是因为人类有一套重要的自我感知维度。有些人有强烈的自我控制倾向，他们必须是自我命运的主宰，无法接受将自我掌控权移交给自动化的系统，所以他们会强烈地反抗这些自动化的系统。 在这些人的思维里，“如果我想要撞击那把椅子，我就一定要撞到那把椅子。”所以这套自动化的辅助系统会让他们非常痛苦。 意识到这一点是非常重要的，因为我们正在建立越来越自动化的世界，从自动驾驶、无人机、智能家居，到扫地机器人、铲猫屎机器人。 是的，真的有铲猫屎机器人 不同人的自我维度会让他们有不同的反应，我们永远不能把人类都当做完全相同的均一体。我们的性格不同，文化背景不同，甚至在不同时刻我们的心情好坏也是不同的。 这些都是人类与机器人交互时需要考虑的问题。 机器人技术永远不仅仅是机械技术。 机器人技术创造的未来让我们能够扩展我们自身，同时还要学习通过机器表达人类共有的天性和我们自身的个性。在感受过变得更矮、更高、更快、更慢，甚至是没有双臂之后，我们学会和他人感同身受，也对机器人产生了同理心。 探索有机器人参与的未来，人类会更加了解自己。 原视频链接： https://www.ted.com/talks/leila_takayama_what_s_it_like_to_be_a_robot Have a Great Definition 
29,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658748&idx=4&sn=9180e9ac9fefb941119a3bdcb5fd1ba5&chksm=bd4c3e6f8a3bb779a1cf9c5553f9aa7c8e09e254f286221029b7e013517464794099dddb7715&scene=27,业界 | 阿里巴巴宣布全面进军IoT，五年要链接100亿设备,“过去20年的互联网是‘人联网’，未来20年的互联网是‘物联网’。”   3月28日，阿里巴巴集团资深副总裁、阿里云总裁胡晓明在2018云栖大会·深圳峰会上宣布：阿里巴巴将全面进军物联网领域，IoT是阿里巴巴集团继电商、金融、物流、云计算后新的主赛道。 胡晓明表示，互联网的上半场是将人类活动数字化，比如电商、社交、文化娱乐等，催生了今天蓬勃发展的互联网市场，背后是全球40亿网民。互联网的下半场是将整个物理世界数字化，道路、汽车、森林、河流、厂房……甚至一个垃圾桶都会被抽象到数字世界，连到互联网上，实现“物”“物”交流、“人”“物”交互，这会是一场更加深刻的技术变革，一场全新的生产力革命。   目前，阿里云支持2/3/4G、LoRa、NB-IoT、eMTC等95%的通信协议。 阿里云于2014年开始启动物联网研发，目前已经完成了城市、生活、制造、汽车四大物联网领域的核心技术布局。   据了解，目前阿里云在江苏与无锡试点了中国首个物联网之城——鸿山小镇，基本实现城市的智能管理：传感器提前发现火情，智能交通缩短消防准备时间；水管爆裂后快速定位，抢修时间缩短77%；路灯自动调节亮度，降低40%能耗；装有传感器的井盖和广告牌可动态感知位置状态，发现险情及时预警……1000多公里之外，雄安新区也正在积极拥抱物联网，阿里云将与雄安合力打造“世界物联网中心”，为数字中国打样。   此外，本次峰会上，阿里云还与高德地图联合发布“ET城市大脑智能交通公共服务版”，更多城市的交通部门可以免费使用城市大脑中的大量人工智能算法，优化信号灯配时间，缓解城市拥堵。该产品的前身其实是2016年阿里云与高德在广州试点的“互联网+信号灯”，这一次做了升级。 【今日机器学习概念】 Have a Great Definition 
30,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658748&idx=3&sn=09957d174abbf4c287f3a8ca4d79931c&chksm=bd4c3e6f8a3bb7791993cf44b948e1b4974484af93592bb6e7a2bd24766d8d272418fe3f2931&scene=27,学界 | 斯坦福数据科学Phd新课放出阅读清单，你读过哪些？,"大数据文摘作品 编译：蒋宝尚 不同于以往的授课式课堂风格，这次斯坦福大学的教授Hadley Wickham开设了一门论文讨论课。课程名为：Readings in Applied Data Science。要求学生每周阅读3~4篇论文，并给出反馈。 考虑到内向和不善表达的学生，课程采用Stephen D. Brookfield和Stephen Preskill的讨论手册中的技巧来确保每个人都有机会参与课堂讨论。课程成绩的评判也没有采用传统的结课考试，而是由课堂参与、讨论准备、课外阅读笔记三部分得分构成。 Hadley Wickham教授已在网上贴出了这门课程的阅读清单推荐，下面这些论文，你读过哪些？ 什么是数据科学 数据科学家大多只做算术,这是件好事—— Noah Lorang（2016） https://m.signalvnoise.com/data-scientists-mostly-just-do-arithmetic-and-that-s-a-good-thing-c6371885f7f6 企业数据分析和可视化：面试研究——Sean Kandel，Andreas Paepcke，Joseph Hellerstein，Jeffrey Heer（2012） https://idl.cs.washington.edu/papers/enterprise-analysis-interviews 50年的数据科学（OA预印本）——David Donoho（2017）（注：这是一份讨论文件，许多着名的统计人员对评论做出了贡献。） https://www.tandfonline.com/doi/abs/10.1080/10618600.2017.1384734 数据收集和协作 整洁的数据——Hadley Wickham（2013） https://www.jstatsoft.org/article/view/v059i10/ 电子表格中的数据结构——Karl W Broman，Kara Woo（2017） https://peerj.com/preprints/3183/ 在数据项目中使用Google表格的最佳做法——Matthew Lincoln (2018) https://matthewlincoln.net/2018/03/26/best-practices-for-using-google-sheets-in-your-data-project.html 软件工程 数据科学家的软件开发技能——Trey Causey（2015） http://treycausey.com/software_dev_skills.html 打扰一下，你有没有时间谈论版本控制？——Jennifer Bryan (2017) https://peerj.com/preprints/3159/ 足够好的科学计算实践——Greg Wilson，Jennifer Bryan，Karen Cranston，Justin Kitzes，Lex Nederbragt，Tracy K. Teal（2017） http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510  DevOps 介绍Docker进行可重复研究，并以R环境为例——Carl Boettiger（2014） https://arxiv.org/abs/1410.0846 机器学习:技术债务的高利息信用卡——D.Sculley，Gary Holt，Daniel Golovin，Eugene Davydov，Todd Phillips，Dietmar Ebner，Vinay Chaudhary，Michael Young（2015） https://research.google.com/pubs/pub43146.html 教学 统计学入门课程：托勒密体系？——George W Cobb (2013) https://escholarship.org/uc/item/6hb3k0nz 数据科学教育的民主化——Sean Kross，Roger D Peng，Brian S Caffo，Ira Gooding，Jeffrey T Leek（2017） https://peerj.com/preprints/3195/ 教授数据科学统计——Danny Kaplan (2017) https://peerj.com/preprints/3205/ 数据道德 伦理数据科学家——Cathy O'Neil (2016) http://www.slate.com/articles/technology/future_tense/2016/02/how_to_bring_better_ethics_to_data_science.html 大数据，机器学习和社会科学——Hannah Wallach（2014） https://medium.com/@hannawallach/big-data-machine-learning-and-the-social-sciences-927a8e20460d 数据科学道德准则——DJ Patil（2018） https://medium.com/@hannawallach/big-data-machine-learning-and-the-social-sciences-927a8e20460d 统计实践的道德准则——美国统计协会职业道德委员会（2016年） http://www.amstat.org/ASA/Your-Career/Ethical-Guidelines-for-Statistical-Practice.aspx 可复用性 计算科学最佳实践——Victoria Stodden, Sheila Miguez (2014) https://openresearchsoftware.metajnl.com/articles/10.5334/jors.ay/ OpenSci如何使用代码评审来促进可复用的科学——Noam Ross，Scott Chamberlain，Karthik Ram，MaëlleSalmon（2017） https://ropensci.org/blog/2017/09/01/nf-softwarereview/ 工作流程 平易近人的社会科学导论——Kieran Healy (2016) http://plain-text.co/ 打开笔记本历史——Caleb Daniels（2013） http://wcm1.web.rice.edu/open-notebook-history.html 如何成为现代科学家——Jeff Leek（2016） https://leanpub.com/modernscientist 业界 在Twitter上做数据科学——Robert Chang（2015） https://medium.com/@rchang/my-two-year-journey-as-a-data-scientist-at-twitter-f0c13298aee6 程师不应该写ETL构建一个高功能数据科学体系的指南——Jeff Magnusson(2016) https://multithreaded.stitchfix.com/blog/2016/03/16/engineers-shouldnt-write-etl/ 在Airbnb上使用R包和教育来发展数据科学——里卡多比昂（2016） https://medium.com/airbnb-engineering/using-r-packages-and-education-to-scale-data-science-at-airbnb-906faa58e12d Instacart的数据科学——Jeremy Stanley （2017） https://tech.instacart.com/data-science-at-instacart-dabbd2d3f279 .rprofile： ——Kelly O'Briant（2017） ﻿https://tech.instacart.com/data-science-at-instacart-dabbd2d3f279 营销数据科学——Erik Oberg （2018） https://medium.com/indeed-data-science/marketing-for-data-science-a-7-step-go-to-market-plan-for-your-next-data-product-60c034c34d55 职业发展 在数据科学就业市场上的感觉如何——Trey Causey（2016） http://treycausey.com/data_science_interviews.html 学术求职建议——Matt Might  http://treycausey.com/data_science_interviews.html 数据科学中的冒充者综合征——Caitlin Hudon（2018年） https://caitlinhudon.com/2018/01/19/imposter-syndrome-in-data-science/ 原文链接： https://github.com/hadley/stats337/blob/master/README.md Have a Great Definition "
31,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658832&idx=1&sn=2f99e33af77542bf85b28cefa6e6525e&chksm=bd4c3dc38a3bb4d5a35db00001e48f1f8e14b6ebd678f7b0a55c4970effcbc1223231a8ff5dc&scene=27,吴军北京来信：人工智能应该变成通识教育，区块链不是炒概念,大数据文摘作品 作者：魏子敏、龙牧雪 就像今天在每一所理工院校的图书馆，都能找到几台正在播放吴恩达深度学习课程的电脑，10年前，在每一栋理工院校的宿舍楼里，都能看到几本被放在枕边的《数学之美》。 提到人工智能领域的领路人，这两位都曾就职于谷歌的吴老师，影响了一代中国AI学习者。 2006年，当时的谷歌成立还不足10年。时任智能搜索部科学家的吴军，将其在谷歌黑板报发出的一批技术文章整理成集，并以《数学之美》的名字出版发布。无数正对技术世界懵懵懂懂的青年人因为这本书，走上了计算机、数据挖掘、甚至人工智能的道路。 今年3月初，大数据文摘有幸在北京见到了吴军老师，并就当前几个有趣的话题（人工智能的数学基础、区块链、信息焦虑等）和他聊了一小时。 之后，吴军老师也对大数据文摘的读者们说出了自己的寄语，点击视频查看👇 吴军：博士，知名自然语言处理和搜索专家，硅谷风险投资人。吴军博士曾经担任谷歌资深研究员，设计了谷歌中、日、韩文搜索算法以及谷歌的自然语言分析器。2010-2012年担任腾讯负责搜索和搜索广告等业务的副总裁，后回到谷歌负责计算机自动问答项目。他的著作《数学之美》荣获国家图书馆第八届文津图书奖、第五届中华优秀出版物奖，《文明之光》被评为2014年“中国好书”，《浪潮之巅》荣获“蓝狮子2011年十大极佳商业图书”奖，《智能时代》开启了2016智能时代元年。 可以上下滑动哦！ 以下为大数据文摘整理的采访实录： 关于深度学习与人工智能 吴军： 也不能说（深度学习）没有数学基础，从计算机来讲，它是有一整套完整的模型的。与其说它没有数学支撑，倒不如说是因为没法解释。从这个角度来讲，它确实是一个黑盒子，我只知道输入什么信号，然后输出优化结果。但是，这是不是瓶颈也不好说。 ‌ 当然（深度学习）还有几个不好解释的地方，比如到底多少层好，有人说在可计算的情况下，层数深的就是好，但是到底为什么？也没人能解释。 所以现在整体来讲，在工业界，在学术界比如说MIT，他们都试图做一些解释，但是我到现在没有看到太合理的解释。 吴军： 人工神经网络和生物神经网络没有半点关系，并不是简化了模型，因为我们还没有搞清楚人的神经网络是怎么回事。 ‌ 但是大家还是用了这个词。 因为从拓扑结构上，（人工神经网络）可能有点像人的脑细胞和神经这种关系。但人的脑细胞神经的连接和人工神经网络完全是两回事。 我曾经在斯坦福商学院听到真正研究生物神经元的一个诺贝尔奖获得者的一次讲座。老教授第一句话就说，人工智能跟我的研究半点关系没有？‌结果这商学院那些学员就马上跳起来说，那我们还来听你的课干什么。（笑） 但其实很多时候并不需要有那么多的关系，飞机的飞行和鸟类的飞行的原理是完全不一样的，火箭和飞机又是不一样的，马跑和汽车跑也是不一样的，只要最后能达到目就好，这是我的看法。 认知科学本身又是一个黑盒子，就是说大家搞不清楚是怎么回事。 最近认知科学的概念特别的火，包括人的一些语言能力、我们人的语法为什么构建出这样一种表达方式，都属于认知科学的范畴。比如说我在美国那时学自然语言处理，大部分时候你可能会把它放在计算机系，跟人工智能有点关系。而很多大学又把它放在认知科学系，这里头其实是有交叉的。 但从另一点来讲，认知科学还是一个交叉科学，涉及到很多领域。 到目前为止，我们今天理解和使用的人工智能和生物学，并没有太紧密的关系。 有人试图来做一些结合，但它并不是仿生借鉴，比如说利用人工智能技术对人脑的一些缺陷进行一些补充。 第一，我们知道有些帕金森综合症患者大脑中有一部分功能丧失了，使用人工智能的芯片有可能把这部分功能恢复，类似心脏起搏器。 第二，是大脑是没问题的，但是比如说脊椎断了，无法控制肌肉，这时候可以放置一个有发射功能的识别芯片。它能够采集到神经信号的变化，采集到人的意念。布朗大学有个研究，就是用大脑控制机械手臂打字。大概一分钟能打30个字符，没有人快，但是OK。这就是现在是可以做到的。 早期的芯片比较简单，几百个电极在接收人的信号，第二代大概能做到上万个。接下来有一些纳米技术可能做到上百万，就可以比较准确接收到信号了。 有一些机构比如布朗大学，已经在做这些事情，也有一些demo产生。 （点击查看）👆 我们看到的至少有四个方向。 第一个刷脸，这个肯定是就是人脸图像识别。 第二就是自然语言理解技术，如人机的对话、机器翻译、家庭助手。 因为如果一个设备太大或太小，用键盘都是不方便的。通过自然语言理解技术，能解决不少问题，如亚马逊的Alexa。 亚马逊智能语音硬件ALEXA👆 第三就是机器人技术。尤其一些危险的场合，人不适合去的。这种其实不需要是人形机器人，针对特定场合设计不同的形状，能解决问题就好。其实无人驾驶汽车也是一种特定的机器人。 ‌第四个是和IOT相结合的智慧城市。 ‌人工智能不是一个虚的话题，在商业上的收益其实是可以看得见的！ 关于 区块链技术 大数据文摘： ‌ 吴军： 区块链不是炒概念。 ‌这个名词起的很好，它反映了这个技术的本质。 区块是一个记录，链是一个过程，所以它很详细也很清楚地表示了这种技术的两个特点。 ‌它会不会是下一个趋势呢？ 首先它和大数据人工智能是不矛盾的，我想要强调这一点。但是它和前面这两者又有一个区别，在应用场景或者作用上的区别。 ‌例如，大数据和人工智能是生产力，使得我们的效率能够提高；而区块链是生产关系，它可以衡量我们每一个人的一个贡献。‌所以它和大数据人工智能应该是互补的，我不觉得是一个取代关系。 ‌ ‌第一代区块链就是比特币，但是你很难拿这个协议干别的事。基本上了解了它的设计思想，你得重新写一个。后来到第二代以太坊能够分出去做二次开发了，可以利用它发币了。这是区块链之所以起来很快的一个重要原因。‌大家发现这个圈钱圈得很快，而人工智能是不太能直接圈钱的。 物流是一个应用。像阿里巴巴也在尝试，我们投了一家公司，在这方面做的也还蛮好。 第二个就是智能合约，中国过去说的三角债、拖欠农民工工资等，都可以用区块链技术来解决。所以它的应用远比发币要大得多。 有些东西是可以用区块链解决，但它并不是必须的，比如医疗，现在有人在考虑个人隐私信息，比如病例的信息能不能用区块链技术，把所有权和查询权给分开。 ‌ 吴军： 不太一样。 互联网是一个很实在的东西，而且93、94年大家认识互联网以前，它已经存在了20多年了，也不会有什么太大的技术障碍，只差一个扩散的问题。 但是目前区块链还在一个探索阶段。 ‌ 吴军： 区块链是一个生产关系，它不完全是一个生产力。互联网是生产力，所以你用了它，效率比别人高，就赢了。区块链更是一个生产关系，是一个分配制度。你只能说新的公司，它的制度比另外一个公司好，但是制度再好，你总得做点实际的事才知道好在哪里。 关于 信息焦虑 大数据文摘： 吴军： 这种焦虑的主要原因是时代的变化快。 我在谷歌方法论里讲过这么一个现象。那一周的内容叫做“反对悲观主义”。什么意思呢？就是任何一个时代里，都有大量的悲观主义的人群，或者说是焦虑人群。 说世界现在是很好，一切都没问题，你就被人骂。如果天天说要塌了，大家都说你对。 过去有人说，人口爆炸，将来地球一定装不下，现在好像这事也没发生；70年代，大家说再过20年，全世界的石油就要用光了。现在都已经过去了40多年了，石油还不知道什么时候用光；80年代说酸雨不得了，所有所有的植物都要完蛋掉，也没发生；2000年前担心千年虫的影响；2000年后担心全球变暖；现在担心人工智能……反正总是在焦虑中。 除了最后两件事，现在还没有被证实是过度焦虑，其他以前的事好像都是有点过度焦虑。 ‌从某种角度上来讲，上帝好像特别照顾人类，到了时间点，问题自动就消失了。其实不是问题自动消失了，问题本来可能就没有你想象的这么大。这是第一点。 第二个点是，历朝历代都怀念“过去的好时光”。 这种看法其实自古有之。最早在雅典的黄金时代，他们会说再往早几百年前，那时代比我们现在好很多。包括柏拉图也是这么写，对未来有担忧，对以前的时代很欣赏；孔子也一样，说当时是礼崩乐坏。英国工业革命的时候，也怀念乡村过去生活有多么好，现在我们的城市多么糟。 这是人类的一个习惯，老怀念过去的好事，其实每个时代都有每个时代的焦虑！有些时候你可以心平气和地来看待，不必要过度担心。 关于“见识” 吴军： 找到自己真正擅长的领域。 见识首先是一个判断力，就是你该做什么，不该做什么。比如，面对一张数学考卷，你有些内容会，有些内容不会。考试时间两个小时，应该怎么办？ 根据我的观察，包括我在清华当老师的经历，很多考不好的同学，都是把大量的时间花费在分数占比相对较低，却很难的题目上，而没有重点关注分数占比高，却相对容易的题，这本身就是一个见识，捡了芝麻，丢了西瓜。 大部分人是喜欢获得，不喜欢失去。其实一个人最后成功，不在于他开始多少件事情，是在于他结束了多少件事。这些都是见识。写这个书的很重要目的就也就是希望让大家少走点弯路！ 之后的创作计划 吴军： 现在在写两本书，一个是《生活》，就是讲怎么能过一个比较好的生活。 还在写一本《科技简史》，从人类火的使用‌、衣裳的发明开始，讲到未来，包括讲到区块链上。 大数据文摘在朋友圈po出专访吴军老师的消息后，在留言区也收到了很多从业者的留言，尽数吴军老师对自己的深刻影响。 你对吴军老师还有什么话要说吗？在留言区告诉我们，我们会选出其中点赞数最高的2位同学转达给吴军老师，并送出吴军老师亲笔签名的最新著作《见识》。 Have a Great Definition 
32,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658689&idx=2&sn=432e520ce0bd83ca10d293f8d61193f0&chksm=bd4c3e528a3bb744fd2a249bd389f29bf4e5392f217bb56f3ec2d5b4a740247039ceb253397d&scene=27,BlockChange | 彭博社区块链就业市场调查：软件与金融行业机会最多,"大数据文摘作品 编译：王一丁、笪洁琼、Yawei Xia 区块链火了，随之而来的是对区块链人才的需求。这是一个刚刚兴起的行业，区块链技术开发人员还是稀缺资源，学校的教育也没有跟上。目前与区块链有关的系统教育资源还很有限，再加上区块链本身是一个跨学科以及知识与经验并重的行业，这对技术人才提出了更大的挑战。想要招聘区块链人才，不仅要打破传统的挖掘人才的方式，还要着重向他们展示工作未来可能的影响力，因为一般从事区块链开发的科技人员，都对改变世界有着美好的愿景。 HR要准备好迎接2018年区块链人才招聘的浪潮。 彭博社（Bloomberg）的数据分析表明， 。消息人士称，今年这类工作的数量预计也会增长。 区块链是新兴技术，所以有相关经验的工作人员供不应求，与此同时MOOC（大规模开放在线课程）和认证项目正在弥补学位教育课程的不足。为了聘到最好的区块链开发人员，HR们可能得采取与之前不同的招聘方式并灵活开展招聘人才等相关工作。 “许多公司已经意识到，世界流行风向标几乎被区块链占领，而他们则需要适应变化并在新世界中找到自己的位置”，不适应的话很可能就会被淘汰，Akshi Federici告诉彭博社。Federici领导着ConsenSys（ 一家区块链产品孵化器） 的学院以及教育部门。 据某专注于区块链人才团队的首席招聘官Kashyn Griffith Hill，2018年区块链开发的职位数增长很快。“人们迫切希望进入这个领域，因为这正是技术发展的方向，”Hill告诉彭博社。 区块链就业市场 Hill说，对区块链人才的需求增长主要来自初创公司。截至发稿，根据来自AngelList的数据，至少存在有1,520个区块链初创公司。 该公司发言人说，首席执行官（CEO），软件工程师，联合创始人，首席技术官（CTO）和创始人的职位在2017年LinkedIn名列前茅。Hill表示，持有更高职位的区块链专业人士的高比例，反映了区块链初创公司的数量。 Hill说，大公司也在招聘区块链人才，而往常这样的招聘只是作为初创公司的内部设置。据该公司数据，2017年，IBM开展了400多个区块链项目，并雇用了1,600多名员工，但当年10月份仍有超过150个与区块链相关的职位空缺。 技术软件行业 和 是在LinkedIn上发布区块链工作数量最大的两个领域。科技硬件和专业服务行业也出现大幅增长。 “区块链影响着全球所有行业。未来，无论人们是否知道这一消息，几乎所有的应用程序、界面、在线提供都可以在区块链上发挥作用。”Federici说。 Federici说，通过区块链创造的新商业模式也在推动一种新的技能类别。她说，例如，在设计令牌和检查智能合约的安全性方面需要技巧。智能合约是编纂合同，其中包括在满足预定条件时自行执行的条款。 技能与教育的断层 Federici说，创建Consensys Academy的缘由是区块链教育与实际需求方面的差距。Federici说，由于区块链是一门新兴技术，关于这个主题的传统四年制学位课程现在并不多。在创建学位课程时，相关知识和程序应用也发生了很大变化。由于区块链生态系统发展比较快，所以相应的资源和工具也较少。 此外，如Federici所言，很难提供区块链单独的课程。 将现实生活中的业务流程纳入法规要求对商业，法律和其他方面的理解。“因此，要学会这块内容，只学习是不够的，这也是一个需要实践加强练习的领域。” Consensys Academy，CryptoCurrency认证协会，B9实验室和Byte Academy都提供区块链认证计划。斯坦福大学，普林斯顿大学等学术机构以及各种MOOC平台也提供区块链和数字加密货币课程。塞浦路斯尼科西亚大学提供数字加密货币理学硕士学位，能够以在线形式在全球各地接受课程教育。 找到独角兽 Hill介绍道，尽管对于一个团队而言，经验高低都会有与之相匹配的职位，但有些职位是需要区块链框架的经验，甚至是从构建区块链开始。 Hill表示，有经验的区块链开发人员很难招，所以招聘经理必须灵活。她说，开发者往往已经投入于一个项目之中，这种情况下很难让其离开项目。 但她提供了一些建设性的意见。Hill建议，主动去找他们，而不是等他们来找你。寻找他们的工作成果，并在GitHub，Stackoverflow或Reddit上与他们联系；参加开发者大会以及访问Coind，Ethlance，Bitcointalk等 特定区块链平台 ，当然区块链聚会也是值得去参加的。“他们喜欢谈论区块链，因为他们对此充满激情，他们很乐意让人们了解这项技术的用途。” Hill还表示，他们还应该允许让他们远程工作，因为他们可能通常已经拥有自己的事业并在某地定居。他们通常也非常忙于其他项目的工作，并经常为工作之外的开源社区做一些贡献。 区块链开发人员表示，为了吸引最优秀的区块链开发人员，了解他们并向他们展示他们工作未来的影响也很重要，因为他们之所以投身于此业，很大程度上是想要改变世界。 原文链接： https://www.bna.com/blockchain-job-market-n73014474195/ Have a Great Definition "
33,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658748&idx=1&sn=573b386b7697e44ac88043dd34403818&chksm=bd4c3e6f8a3bb779184fcf1da9589e57707aefe39c863be2881b051e3405823f71ba0e71d69f&scene=27,涨姿势！用深度学习LSTM炒股：对冲基金案例分析,"大数据文摘作品 编译：王一丁、修竹、阮雪妮、 丁慧、钱天培 英伟达昨天一边发布“ ”，一边经历股价跳水20多美元，到今天发稿时间也没恢复过来。无数同学在后台问文摘菌，要不要抄一波底嘞？ 今天用深度学习的序列模型预测股价已经取得了不错的效果，尤其是在对冲基金中。股价数据是典型的 。 什么是序列数据呢？语音、文字等这些前后关联、存在内有顺序的数据都可以被视为序列数据。 将序列模型应用于语音和文字，深度学习在语音识别、阅读理解、机器翻译等任务上取得了惊人的成就。 具体怎么操作？效果又如何呢？来看文摘菌今天带来的这篇深度学习炒股指南。 对冲基金是深度学习应用中具有吸引力的领域之一，也是投资基金的一种形式。 不少金融组织从投资者那里筹集资金后对其进行管理，并通过分析时间序列数据来做出一些预测。在深度学习中，有一种适用于时间序列分析的架构是：递归神经网络（RNNs），更具体地说，是一种特殊类型的递归神经网络：长短期记忆网络（LSTM）。 RNNs维基解释： https://en.wikipedia.org/wiki/Recurrent_neural_network LSTM 维基解释： https://en.wikipedia.org/wiki/Long_short-term_memory LSTMs能够从时间序列数据中捕捉最重要的特征并进行关联建模。股票价格预测模型是关于对冲基金如何使用此类系统的典型案例，使用了Python编写的PyTorch框架进行训练，设计实验并绘制结果。 在介绍真实案例之前，我们先了解一下深度学习的基础： 首先，引入深度学习这个抽象概念。 其次，引入RNNs（或更具体地说是LSTMs）以及它们如何进行时间序列分析。 接着，让读者熟悉适合深度学习模型的金融数据。 接着，举一个实例来说明一支对冲基金如何使用深度学习预测股票价格。 最后，就如何使用深度学习来提高对现有或新购对冲基金的表现提供可操作的建议。 金融行业最具挑战性和令人兴奋的任务之一便是：预测未来股价是上涨还是下跌。据我们所知，深度学习算法非常擅长解决复杂的任务，因此深度学习系统是否能够成功地解决预测未来价格这个问题是值得尝试的。 股价预测： https://www.toptal.com/machine-learning/s-p-500-automated-trading 人工神经网络这个概念已经存在了很长一段时间，但由于硬件受限，一直无法进行深度学习方面的快速实验。十年前，Nvidia为其Tesla系列产品研发的高速计算的图形处理单元（GPUs）促进了深度学习网络的发展。除了在游戏和专业设计程序中提供更高质量的图形显示外，高度并行化的GPUs也可以计算其他数据，而且在很多情况下，它们的表现远优于CPUs。 Nvidia Tesla维基解释： https://en.wikipedia.org/wiki/Nvidia_Tesla 在金融领域应用深度学习的科学论文并不多，但是金融公司对深度学习专家却有很大的需求，显然，这些公司认识到了深度学习的应用前景。 本文将尝试说明： 为什么深度学习在用金融数据来构建深度学习系统时越来越受欢迎，同时也会介绍LSTMs这种特殊的递归神经网络。我们将概述如何使用递归神经网络解决金融相关问题。 本文还以对冲基金如何使用深度学习系统为例进行典型案例分析，并展示实验过程及结果。同时我们将分析如何提高深度学习系统性能，以及如何通过引进人才（如需要什么样背景的深度学习人才）来搭建应用于对冲基金的深度学习系统。 在我们进入这个问题的技术层面之前，我们需要解释的是什么使对冲基金与众不同。首先要明白的是，什么是对冲基金？ 对冲基金是一种投资基金，金融组织从投资者筹集资金并将其投入短期和长期投资项目或者不同金融产品。它的形式一般是有限合伙企业或有限责任公司。 对冲基金的目标是最大化回报，回报是其在特定时间段内净值的收益或损失。普遍认为，投资风险越大，相应的回报或损失也越大。 为了获得良好的回报，对冲基金依赖各种投资策略，试图通过利用市场低效率来赚钱。由于对冲基金有普通投资基金所不允许的各种投资策略，其并未被认定为一般基金，也不像其他基金那样由国家监管。  因此他们不需要公布他们的投资策略和业务结果，这可能会使相关经营活动充满风险。虽然一些对冲基金产生的收益超过市场平均水平，但也有一些损失了资金。其中一些的损失无法挽回，也有一些对冲基金的结果是可逆的。 通过投资对冲基金，投资者可以增加基金的净值。不过，并不是所有人都可以投资于对冲基金，它只适用于少数富有的投资者。通常，想要参与对冲基金投资的人需要获得认证。 这意味着他们必须在金融监管法律方面拥有特殊地位。不同国家对于“特殊地位”的认定有所不同。通常，投资者的净资产需要非常高——不仅是个人，而且银行和大公司也可以在对冲基金中运作。该认证旨在让那些有必要投资知识的个人才能参与其中，从而保护经验不足的小型投资者免受风险。 美国是全球金融市场最发达的国家，因此本文主要参考美国的监管体系。在美利坚合众国，美国证券交易委员会（SEC）的D规则501规定了“认可投资者”一词。   根据这一规定，认可的投资者可以是： 银行 私营企业 组织机构 提供或出售证券的发行机构的董事，执行官和普通合伙人 个人净资产或与该人配偶合资净值超过1,000,000美元的自然人 自然人在最近两年每个年度的个人收入超过20万美元，或与该人的配偶每年在该年度的共同收入超过30万美元，并且当年的预期收入也达到相同的水平。 信托资产总额超过5,000,000美元 所有股权拥有者均为认可投资者的实体 对冲基金管理者管理对冲基金时必须要找到一种方法形成竞争优势从而取得成功，即需比竞争对手更具创造力，带来更大价值。这是一个非常有吸引力的职业选择，因为如果一个人擅长管理基金，就可能从中获利许多。 另一方面，如果很多对冲基金管理者的决定很糟糕，他们不仅不会获得收益，还会造成负面影响。最好的对冲基金管理者可以获得行业中薪酬最高的职位。  除了管理费外，对冲基金管理者还可以从资金获利中抽成。这种补偿方式使对冲基金管理者更积极地投资以获得更高的回报，但与此同时，这也会使投资者承担更多风险。 第一支对冲基金出现于1949年，由作家和社会学家Alfred Winslow Jones创立。1948，Alfred就当时的投资趋势发表了一篇文章。 他在资金管理方面获得了巨大的成功。利用他的投资创新筹集资金，这种投资创新现在被广泛称为多/空投股票。该策略目前在对冲基金中仍非常受欢迎。股票可以被买入（买入：买多）或卖出（卖出：卖空）。 当股价低但预计股价将会走高时，买入股票（多头），一旦达到高价时并卖出（空头），这正是Alfred所创理论的核心——对预计将升值的股票中持仓多头，对预计将下跌的股票持仓空头。 金融数据属于时间序列数据。 通常，时间序列是连续、等间隔的时间序列：即离散时间序列数据。举例来说，海洋潮汐的高度，太阳黑子的数量以及道琼斯工业平均指数的每日收盘价都是时间序列。 这里的历史数据是指过去的时间序列数据。这是预测未来价格走向最重要和最有价值的部分。 网上有一些公开可用的数据集，但通常情况下，数据缺少很多特征——如间隔1天的数据，间隔1小时的数据或间隔1分钟的数据。 具有更丰富特征和更小时间间隔的数据集通常不公开，并且需要高价购买。 更小的间隔意味着更多的时间序列数据在一个固定的时间段内——一年内有365（或366）天，所以最多有365个（或366个）天数据点可用。 每天有24小时，所以在一年内有8,760（或8,784）小时数据点，每天有86,400分钟，所以在一年内有525,600（或527,040）分钟的数据点可用。 越多的数据意味着越多的可用信息，也意味着可以更好地判断下一刻会发生什么——当然，如果数据包含足够的特征也可以泛化的很好。  在全球金融危机高峰时期，2007年至2008年的股价数据由于存在偏差，所以可能无法预测近期价格趋势。越小的时间间隔，在固定的时间间隔内就会有更多数据点，从而更容易地预测接下来会发生什么。  如果我们拥有n年内每一纳秒的数据，那么很容易预测下一纳秒会发生什么，同理在股市中， 当然，这也并不意味通过一系列数据后，只有所作的短期预测才是正确的，长期预测也可以是正确的。  每个短期预测都会产生误差，因此通过链接多个预测，长期预测最终将产生更大的误差而导致预测无效。以下是雅虎财经在线提供的间隔为1天的Google股票数据示例。 数据集中只有日期，开盘价，最高价，最低价和平仓价等五列数据，分别表示交易开放时证券首先交易的价格，即证券在给定交易日上达到的最高价格，给定交易日的最低价格以及当天交易证券的最终价格。 通常，此类数据集中还有两列——“调整后收盘价”和“成交量”，但它们在这里并不相关。 可以看到数据中缺失了部分日期。这些是证券交易所休市的日子（一般是在周末和假日）。 为了演示深度学习算法，休市的日子使用之前的交易日价格。例如，2010-01-16，2010-01-17，2010-01-18的收盘价格将全部为288.126007，因为这就是2010-01-15。对于我们的算法来说，数据没有间隙是非常重要的，所以我们不会混淆它。  深度学习算法可以通过周末和节假日的数据学习——比如说，了解到在五个工作日后，从最后一个工作日起，会有两天的平价。 这是一张自2010-01-04以来谷歌股价变动的图表。要注意的是，图表中只显示了交易日的变化趋势。 深度学习基于数据表示学习，属于机器学习的一个分支。机器学习不是通过编程，而是从数据中学习得到的算法。它本质上是人工智能的一种方法。 深度学习已经应用到了多个领域：计算机视觉，语音识别，自然语言处理，机器翻译，而且在某些任务中，它的表现甚至超过人类。 深度神经网络 是深度学习的核心，它最简单、最基本的例子就是前馈神经网络，如下图所示，一个基本的前馈神经网络包括输入层、输出层和隐藏层。 隐藏层是输入层和输出层之间的多个单独层。我们通常说如果一个神经网络隐藏层的个数大于1，那么这个网络就是深度的。 每一层都由不同数量的神经元组成。这个基本前馈神经网络中的层称之为线性层，线性层中的神经元仅仅将1-D（或者2-D，如果数据是分批输入网络的）的输入和合适的权重相乘并求和，作为1-D或2-D输出的最终结果。 前馈网络中通常引入激活函数(activation function)表示非线性关系，进而对更复杂的非线性问题建模。 在前馈神经网络中，数据从输入层流向输出层，并不会反向传播。 神经元之间的连接是加权的。这些权重需要调整以便神经网络对于给定输入返回准确的输出。前馈网络将数据从输入空间映射到输出空间。隐藏层从前一层的特征中提取重要的和更抽象的特征。 通用深度学习管道和机器学习管道一样，都包含以下步骤： 数据采集。数据被分成3部分：训练集、验证集和测试集。 使用训练集进行多轮（每一轮包含多个迭代过程）训练DNN模型，并在每轮训练后使用验证集进行验证。 在不断训练和验证后，测试模型（一个带有固定参数的神经网络实例）。 训练神经网络实际上是通过反向传播算法结合随机梯度下降法来最小化损失函数，以此来不断调整神经元之间的权重。 除了通过学习过程确定的权重，深度学习算法通常还需要设置超参数——一类无法从学习过程获得，但需要在学习过程前确定的参数。如网络层数、网络层中的神经元数、网络层的类型、神经元的类型和初始权重都属于超参数。 在超参数设置中，第一存在硬件限制，目前，在一个GPU上设置一万亿个神经元是不可能的。第二超参数搜索问题属于组合爆炸；彻底搜索所有可能的超参数组合是不可能的，因为这个过程需要无限长的时间。 由于上述原因，超参数的设置通常是随机的，或者采用一些启发式方法和一些论文中提供的知名方法——本文稍后展示一个用于金融数据分析的循环神经网络的超参数设置实例，许多科学家和工程师已经证明循环神经网络在时间序列数据处理方面表现突出。 通常，验证一个超参数对于指定问题的效果是好是坏的最好方法就是做实验。 训练的目的是使得神经网络很好地拟合训练数据。 每个训练步骤之后的模型验证和整个训练过程结束后的模型测试都是为了确定模型是否具有良好的泛化能力 。 泛化能力强意味着神经网络模型对于新数据也能做出准确的预测。 关于模型选择有两个重要的术语：过拟合和欠拟合。 如果一个神经网络对于它所训练的数据太复杂——如果它有太多的参数（网络层数太多，以及/或者网络层中有太多的神经元）——这个神经网络很有可能过拟合。 因为它有足够的能力去拟合所有数据，所以它能很好的适应训练数据，但是这个模型在验证集和测试集上的性能会很差。如果一个神经网络对于它所训练的数据太过简单，这个模型会欠拟合。 此时神经网络在训练集、验证集和测试集中性能都很差，因为它的能力不足以拟合训练数据并且进行泛化。在下图中我们用图形来解释这几个术语。 蓝色的线表示神经网络模型。第一张图表示当神经网络参数较少时，不能拟合训练数据和泛化的情况。第二张图表示在有最优参数数量时，神经网络对新的数据有较好的泛化能力。第三张图表示当神经网络参数太多时，这个模型过拟合训练数据，但是在验证集和测试集中表现不佳。 神经网络中一个更复杂的版本是循环神经网络(Recurrent neural network)。与前馈神经网络不同，循环神经网络中的数据可以向任意方向流动。RNN可以更好的表示时间序列的相关性。一般循环神经网络的结构如下图所示。 一个循环神经元的表示如下图所示。在t时刻以X_{t}作为输入，返回t时的隐藏状态h_{t}作为输出，隐藏层输出反向传播回神经元。循环神经元展开后的表示如下图右侧部分。X_{t_0}表示t_{0}时刻的点，X_{t_1}表示t_{1}时刻的点,X_{t}表示t时刻的点。通过t_{0},t_{1},…,t_{n}时刻的输入X_{t_0},X_{t_1},…,X_{t_n}获得的输出就叫做隐藏输出，即h_{t_0},h_{t_1},…,h_{t_n}。 最有效的一个循环神经网络架构是LSTM结构。表示如下： LSTMs与一般的循环神经网络结构一样，但是不同的是循环神经元的结构更为复杂。 从上图可以看出，在一个LSTM单元内存在大量的计算。 在这篇文中，LSTM单元可以视为一个黑盒子，但是对于好奇的读者来说，可以看一篇阐述LSTMs内的计算以及其他一些内容的博客。 博客链接： http://colah.github.io/posts/2015-08-Understanding-LSTMs/ 我们把神经网络的输入称为“特征向量”。这是一个n维向量，其元素是特征：f_{0},f_{1},f_{2}…,f_{n}。 现在，我们来解释循环神经网络是如何应用到与金融相关的任务上的。循环神经网络的输入是[X_{t_0}，X_{t_1}，X_{t_2}，…，X_{t_n}]。这里让n=5。 我们采用Google连续5天（见上面开盘/高/低/收盘数据表）的股票收盘价，选择时间段为2010-01-04到2010-01-08，也就是[[311.35]，[309.98]，[302.16]，[295.13]，[299.06]]。这个例子中的特征向量是一维的。时间序列包含5个这样的特征向量。循环神经网络的输出是隐藏特征[h_{t_0}，h_{t_1}，h_{t_2}，…，h_{t_n}]。 这些特征比输入特征[X_{t_0}，X_{t_1}，X_{t_2}，…，X_{t_n}]更加抽象——LSTM需要学习到输入特征的重要部分并将它们映射到隐藏特征空间。 这些隐藏的抽象特征在下一个LSTM单元中传播并提供一组隐藏、更加抽象的特征，这些特征又可以在下一个LSTM单元中传播，以此类推。 在LSTMs连接序列之后，神经网络的最后一个组成部分是线性层（前一节介绍的简单前馈网络的构建部分），线性层将最后的LSTM的隐藏向量映射到一维空间的某个点上，这个点就是该网络的最终输出——时间周期X_{t+1}中预测的收盘价。在这个例子中应该是298.61。 注意： 也有少量的LSTM将LSTMs的数量作为一个超参数，该参数通常由经验获得，当然也可以使用一些启发式的方法。如果数据不是很复杂，我们可以使用一些不那么复杂的结构来避免过拟合。如果数据比较复杂，我们使用一个复杂些的模型来防止欠拟合。 在训练过程中，预测的收盘价会跟实际价格比较，其差值采用反向传播算法和梯度下降优化算法（或者其他形式——具体来讲在这篇文章中将使用梯度下降优化算法的“Adam”版本），通过改变神经网络权重来最小化。 模型经过训练和测试之后，在以后的使用中，用户只需要给模型输入数据，模型将会返回预测价值（理想情况下，价格会非常接近未来的真实价格）。 还有一件事要需注意，通常来讲，在训练和测试部分，数据分批次通过网络，对于网络来讲只需要一次就可以计算出多个输出。 下图是这篇文章中使用的架构，包括2个LSTMs栈和一个线性层。 试着用一个简单的交易策略实现算法，描述如下：如果算法预测明天股价会上升，就买入n（在这个例子里n=1股该公司的股票（做多），否则就卖掉所持有的该公司的所有股票（做空）。 投资组合的初始价值（现金和股票的总价值）设定为100,000美元。每次交易行为将买入n股该公司（以Google为例）的股票或卖出所持有的该公司的所有股票。在初始时刻，系统对该给定公司股票的持有量为0。 需要时刻牢记的是这只是一个非常基础和简单的例子， 。若是想使这个模型在实际中很好地应用，仍需要进行很多的研发工作来调整模型。 有些在本例中被忽略的因素，在应用于实际场景时，都应当被纳入考虑中：比如，交易费用没有被考虑在模型之中。另外假设系统可以在每天的同一时间交易并且认为每一天，即使是周末或假期，都是交易日。 对于模型测试，我们使用回溯测试法。该方法利用历史数据，基于开发策略所定义的规则重建过去本该发生的交易。我们将数据集划分为两部分——第一部分作为训练集（作为历史交易数据），第二部分作为测试集（作为未来交易数据）。 模型在训练集上进行训练，训练完成后，我们在第二部分测试集上预测未来交易，从而检验训练得到的模型在不属于训练集的“未来交易”数据上的表现。 用于评价交易策略的指标是夏普比率（Sharpe ratio，年化值，假设一年中的每一天都是交易日，一年有365天：sqrt(365)*mean(returns)/std(returns))），其中收益率定义为p_{t}/p_{t-1} - 1, p_{t}是t时刻的价格。 夏普比率反映了投资组合的收益率与额外的风险之间的比率，所以 一般地，对投资者来说，夏普比率大于1是令人满意的，大于2是非常不错的，而大于3则是极好的。 本例中，只选用来自雅虎的金融数据库（Yahoo Finance dataset）的谷歌历史价格的每日收盘价作为特征。虽然其他特征也有用，但是讨论该数据集中的其他特征（开盘价、最高价、最低价）是否起作用并不在本文讨论的范围之内。 其他一些不在该数据表中的特征可能也有用——例如某一特定分钟的新闻观点或某一天发生的重要事件。 然而，有时候很难将这些特征表示成对神经网络有用的输入并将其与现有特征结合起来。比如，对每一个给定时期，扩充特征向量并加入一个代表新闻观点或特朗普（Trump）在Tweet发表的观点是容易的（-1表示赞同，0表示中立，+1表示不赞同）。 但是，将特定的事件驱动的时刻（苏伊士运河的海盗事件，德克萨斯州炼油厂发现炸弹）加入特征向量并不容易，因为对于每一个这样的特定时刻，我们需要向特征向量中加入一个额外的元素，当该事件发生时令其为1，否则为0。 这样以来，为了考虑所有可能的特定时刻，我们需要向特征向量中加入无穷多个元素。 对那些更加复杂的数据，我们可以定义一些类别，对每一个特定时刻，确定它属于哪一个类别。我们也可以在系统中加入其他公司的股票特征，让模型学习不同公司股票价格之间的相关性。 此外，我们可以将循环层与另一种专门用于计算机视觉的神经网络——卷积神经网络（convolutional neural networks）结合起来以探究视觉特征是如何与某些公司股价相关联的，这也是一种很有趣的做法。 也许我们可以将使用相机拍摄的一张拥挤的火车站的照片作为一个特征，并将其加入神经网络，从而探究神经网络所“看”到的是否与某些公司的股价相关——或许在这个平庸且荒唐的例子中也存在着某些隐藏的信息。 下图展示了平均训练损失随时间逐渐减少的过程，这表明 必须强调的是需要将数据进行标准化处理以保证深度学习算法能够收敛。 下图展示了平均测试损失随时间逐渐减少的过程，这表明神经网络对新数据有一定的泛化能力。 该算法具有贪心性质 ：如果它预测明天股价将上升，那么算法将会立即买入n=1份该公司的股票（如果投资组合中有足够的现金），否则它将会卖出所持有的该公司所有的股票（如果有的话）。 投资的时间段固定为300天。在300天以后，卖出所有股票。训练后的模型在新的数据上的模拟结果如下图所示。下图展现了随着每天做多/做空的交易（或不做交易），投资组合的价值随时间变化的过程。 上述投资模拟的夏普比率为1.48。300天后最终的投资组合的价值为100,263.79美元。如果我们只在第一天买入股票，并在300天后卖出，组合价值为99,988.41美元。 下图展示的是由于神经网络训练得不好而在300天的固定投资时期后亏损的情况。 这一模拟的夏普比率为-0.94。300天后投资组合的最终价值为99,868.36美元。 下面是一个有趣的例子：上述算法具有贪心性质并且仅仅估计了第二天的股价，并且仅仅基于这一预测值作出决策。但仍有可能需要连接多个预测值并且预测未来多期的价格。 比如，有了第一组输入[X_ground_truth_{t0}，X_ground_truth_{t1}，X_ground_truth_{t2}，X_ground_truth_{t3}，X_ground_truth_{t4}]和第一个输出[X_ground_truth_{t5}]，我们可以把这一预测值输给神经网路来继续预测，即下一组输入为[X_ground_truth_{t1}，X_ground_truth_{t2}，X_ground_truth_{t3}，X_ground_truth_{t4}，X_ground_truth_{t5}]，此时输出为[X_predicted_{t6}。 类似的，接着下一组输入为X_ground_truth_{t2}，X_ground_truth_{t3}，X_ground_truth_{t4}，X_predicted_{t5}，X_predicted_{t6}]，由此可以得到[X_predicted_{t7}]等。 这里存在的问题是我们引入了一个预测误差，并且这一误差随着每一步新的预测而不断增加，最终导致了一个很差的长期的预测结果，如下图所示。最开始模型预测值有真实值具有相同的下降趋势，随后停滞，并且随着时间的推移变得越来越差。 对谷歌股票价格进行了简单的深度学习的分析，只要数据量足够大且质量足够好，这一模型几乎可以包含任何金融数据集。但是数据必须是可判别的，并且能够很好地描述和表示问题。 如果模型对于大量的测试都表现得很好并有很强的泛化能力，那么它便可以使对冲基金管理者使用深度学习和算法交易策略来预测未来某一公司的股票价格。 对冲基金管理者可以向系统输入资金金额使其每天完成自动化交易。但是，让自动化交易算法在完全没有任何监督的情况下进行交易绝对不是一个好的选择。 因此对冲基金管理者应当有一些深度学习知识或者是雇佣一个懂得一些必要的深度学习技能的人来监管并判断这一系统是否是去了泛化能力而不适合用于交易了。 一旦系统失去了泛化能力，那么就有必要从 头开始训练模型并重新进行测试（可以通过引入更多具有判别性的特征或新的信息——使用模型在上一次训练时没有用到的新的历史数据）。 有时候，数据质量差会导致深度学习模型不能够很好地训练和泛化。在这种情况下，一个经验丰富的深度学习工程师应当能够发现并扭转这种局面。 建立一个深度学习交易系统，你需要对冲基金数据科学家，机器学习/深度学习专家（包括科学家和工程师），熟悉机器学习/深度学习的研发工程师等等。 无论他们熟悉机器学习哪个领域的应用，不管是计算机视觉还是语音识别，老练的专家都能够将他们的经验很好地应用于金融领域。 归根结底，不管是哪方面的应用或产业，深度学习都有相同的基础，因此对有经验的人来说从一个主题切换到另一个都应该是简单的。 我们这里所描述的系统是最基本的，要应用于现实世界，需要进行更多的研发工作来增加收益。可能的系统改进方法包括开发更好的交易策略。 同时收集更多的数据来训练模型也是有帮助的，但是这样的数据一般都很贵。 缩短时间节点间的间隔也能够改善模型。使用更多的特征（如数据集中每一时点对应的新闻观点或重要的事件，尽管难以表示为适用于神经网络的形式）、大量的超参数的格点搜索优化以及循环神经网络结构的探索也能给模型带来改善。 此外，在做大量并行实验和处理大量数据（如果收集到了大量的数据）时，我们还需要更多的计算能力（更强的GPU是必需的）。 原文链接： https://www.toptal.com/deep-learning/deep-learning-trading-hedge-funds Have a Great Definition "
34,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658748&idx=2&sn=8e4f84398fd28844adb1679bc32a21df&chksm=bd4c3e6f8a3bb7796567f06431d4d68148df40d39dacdc33777946338c0e40f71d26c9a8673a&scene=27,论文Express | 谷歌DeepMind最新动作：使用强化对抗学习，理解绘画笔触,﻿大数据文摘作品 作者：龙牧雪 深度学习合成图像并不是什么新鲜事。谷歌自己就做过SketchRNN，能识别8条腿的猪有异常，输出4条腿的猪（ ）。 不过这些都依赖于人类输入数据的指导。人类需要告诉模型，哪些输入图片是猪，模型才能从中总结规律。 昨天，谷歌DeepMind发出了一篇博文，介绍了其最新论文Synthesizing Programs for Images using Reinforced Adversarial Learning（大数据文摘公众号后台回复 “图像” 即可下载）。 谷歌使用一种名叫SPIRAL的对抗性学习方法，先用一个强化学习代理（Agent）随机画画，再将成果输入另一个神经网络鉴别器（Discriminator）。鉴别器能判断某图形是由Agent生成的，还是从真实照片的数据集中采样而来。 如果代理生成的图像成功地骗过了鉴别器，就会获得奖励。也就是说，奖励函数本身也是由代理学习得来，人类并没有设置奖励函数。这样经过持续训练，强化学习得到的图像就会越来越接近真实照片。 该方法与生成对抗网络（GANs）的区别是，GANs中的生成器通常是直接输出像素值的神经网络。但是强化学习代理通过编写图形程序与绘图环境交互来生成图像，也就是说，可以将生成的图像中绘画的笔触通过一个机械臂画笔实现出来。 根据谷歌放出的一个绘画视频，该方法在数字、人物肖像的生成上，均取得了不错的效果。 谷歌绘画的视频 ▼ 在MNIST手写数字图像生成的实验中，输入数据包括手写数字的图像，但没有明确指出它们是如何绘制的。强化学习代理需要通过自学数字书写的笔画（图案、笔触强弱、笔顺），控制画笔，重现特定的图像。接下来，鉴别器将作出预测，该图像是目标图像的副本，还是由代理生成的。图像越难鉴别，代理得到的回报越多。 重要的是，这一切是可以解释的，因为它产生了一系列控制模拟画笔的动作。同时值得注意的是，这里对绘画的笔顺并没有强调，只要画得像，就不管是怎么画出来的了。 在人脸的真实数据集上，强化对抗式学习也取得了不错的效果。绘制人脸时，代理能够捕捉到脸部的主要特征，例如脸型、肤色和发型，就像街头艺术家用寥寥几笔描绘肖像时一样： 谷歌称，教会人工智能从对世界的观察中获得结构关系并表达出来，这是人工智能建立人类认知、概括和沟通能力的必由之路。 大数据文摘公众号后台回复 “图像” ，即可获取这篇论文。 谷歌DeepMind博文链接： https://deepmind.com/blog/learning-to-generate-images/ 【今日机器学习概念】 Have a Great Definition 
35,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658689&idx=3&sn=20b228545dbfb40781763983ef631711&chksm=bd4c3e528a3bb7446c02278eb030c037a381d349b9b9f55c36e3b5baa6ba3a18732fa491b0d6&scene=27,业界 | 小扎包下9家报纸整版，为FB数据丑闻道歉,大数据文摘作品 编译：蒋宝尚 Facebook数据隐私丑闻事件依然在持续发酵。 就在周日，Facebook在七家英国报纸和三家美国报纸上承包了一整页的版面，为剑桥分析数据隐私丑闻进行道歉。 报纸上有小扎的签名以及Facebook的logo 在道歉的整版报纸上，Facebook首席执行官马克·扎克伯格称，他很抱歉辜负了大家对他的信任，并表示： ” Facebook CEO扎克伯格以致歉信的形式发布的全版广告，澄清了脸书近况，再次重申公司早已阻止第三方软件“获取过多信息”，并且“当用户登录时，Facebook会限制数据软件获取用户数据。”扎克伯格写道，“这是背信的行为，很抱歉我们没有及时补救，但我保证我们将会做得更好。 据CNN报道，小扎共包下了9家影响力颇大的报纸，整版发布道歉信，包括《观察者》、《星期日泰晤士报》、《星期日邮报》、《星期日镜报》、《星期日快报》和《星期日电讯报》，以及《纽约时报》、《华盛顿邮报》和《华尔街日报》。 值得注意的是，扎克伯格在上周发表的文章中子并没有说他或公司对此感到抱歉。直到他在接受CNN的电视直播采访时，扎克伯格才口头表达道歉。 据我们所知，总部位于伦敦的数据挖掘和分析公司，由于2014年Facebook 开发者的慷慨数据共享政策，获得了多达5000万facebook用户资料的数据访问权。这些数据在Facebook条款的允许下流向了剑桥分析公司。 据报道，这些数据直接帮助川普胜选（详情点击阅读大数据文摘作品《 》）。当然，这也给Facebook带来了非常严重的后果。无数诉讼、政府调查、用户抵制运动包围着Facebook，导致其蒸发500多亿美元的市值。 原文链接： https://www.theverge.com/platform/amp/2018/3/25/17161398/facebook-mark-zuckerberg-apology-cambridge-analytica-full-page-newspapers-ads Have a Great Definition 
36,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658673&idx=3&sn=c81ed31858a06317d420a3c58212e7dd&chksm=bd4c3e228a3bb73485bc6e9b58484379ba34d770e77070c14ddbe82f560813d102afed45fc35&scene=27,AI大事件 | 斯坦福初创公司发力AI硬件，DeepMind删除神经元了解深度学习,呜啦啦啦啦啦小伙伴们大家好呀！过去的一周中AI圈都发生了什么？大佬们讨论了哪些问题？研究者们发布了哪些值得一读的论文？又有哪些开源的代码和数据库可以使用了？快快跟随文摘菌盘点过去一周AI大事件！ 来源： WWW.THEGUARDIAN.COM  链接： https://www.theguardian.com/technology/2018/mar/19/uber-self-driving-car-kills-woman-arizona -tempe ?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 坦佩警方表示，Uber自动驾驶汽车在车祸发生时处于自动驾驶模式，被撞到的行人后来在医院死亡。此次事件是第一起致命的自动驾驶汽车交通事故。 点击查看大数据文摘相关报道： 来源： TECHCRUNCH.COM 链接： https://techcrunch.com/2018/03/15/the-red-hot-ai-chip-space-gets-even-hotter-with-56m-for-a-startup-called-sambanova/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这家初创公司由两位斯坦福大学教授Kunle Olukotun和ChrisRé共同创立，并由前Oracle开发高级副总裁Rodrigo Liang领导。Olukotun和Liang不会涉及架构的细节，但他们正在试图重新构建操作硬件，用来优化在图像和语音识别等领域越来越流行的以AI为中心的框架。 来源： GITHUB.COM 链接： https://github.com/tensorflow/tensorflow/releases/tag/v1.7.0-rc1?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI Eager Execution现在从contrib包移出到了Tensorflow的核心。其他更改包括更容易计算的自定义渐变，Tensorflow图形调试器和SQLite数据集。 来源： TECHCRUNCH.COM 链接： https://techcrunch.com/2018/03/22/skyline-ai-raises-3m-from-sequoia-capital-to-help-real-estate-investors-make-better-decisions/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI Skyline AI是一家以色列的初创公司，使用机器学习帮助房地产投资者识别有潜力的房产。它日前宣布已经从红杉资本筹集了300万美元的种子资金。 来源： WWW.ARGMIN.NET  链接： http://www.argmin.net/2018/03/20/mujocoloco/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 简单随机搜索可以在MuJoCo等基准问题上超越强化学习算法吗？ 答案是肯定的。 相应论文： https://arxiv.org/abs/1803.07055 来源： INT8.IO 链接： https://int8.io/monte-carlo-tree-search-beginners-guide/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20A I 蒙特卡洛树搜索（MCTS）的深入介绍，许多棋盘游戏代理都使用这个算法，包括国际象棋引擎和AlphaGo。其主要目的是在当前游戏状态下选择下一个最优的行为。 来源： PETEWARDEN.COM 链接： https://petewarden.com/2018/03/19/the-machine-learning-reproducibility-crisis/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 在机器学习领域，重现往往很难。当涉及到跟踪变化和重建模型时，整个领域仍处于黑暗时代。这篇文章列出了一些挑战以及我们如何接近它们。 来源 ：DEEPMIND.COM 链接： https://deepmind.com/blog/understanding-deep-learning-through-neuron-deletion/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI DeepMind的一组研究人员通过删除单个神经元以及神经元组来观测这种操作对网络的性能影响。他们发现可解释的神经元并不比难解释活动的混淆神经元更重要，并且相比仅能对它们之前看到的图像进行分类的网络，能够正确分类看不见的图像的网络对神经元删除更具适应性。 来源： GITHUB.COM 链接： https://github.com/higgsfield/RL-Adventure?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这个教程在PyTorch和Jupyter中实现了一系列深度Q学习算法，其代码清晰易读。这个代码库是了解各种算法之间差异的良好开始。 来源： MEDIUM.COM 链接： https://medium.com/huggingface/how-to-train-a-neural-coreference-model-neuralcoref-2-7bb30c1abdfe?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这篇文章将指导您了解Coherence解决方案系统的工作原理以及如何使用CoNLL 2012数据集进行训练。完整的代码在Github上可用。 来源： GITHUB.COM 链接： https://github.com/timgaripov/swa?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 该文档库包含PyTorch实现的随机加权平均（SWA）训练方法，适用于DNN的训练方法，包括平均权重导向Wider Optima和Better Generalization。 来源： GITHUB.COM 链接： https://github.com/henripal/labnotebook?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI LabNotebook是一个纯Python工具，允许使用者监控，记录，保存和查询所有的机器学习实验。这个库看起来很有潜力，但目前仍处于alpha版本状态。 来源： ARXIV.ORG 链接： https://arxiv.org/abs/1803.07055?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 作者介绍了一种随机搜索方法，用于训练连续控制问题的静态线性策略，使基准MuJoCo运动任务的最新样本效率相匹配。搜索算法的效率至少比这些基准测试中最快的免竞争模型方法高15倍。 来源： ARXIV.ORG 链接： https://arxiv.org/abs/1803.08240?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 语言建模中的许多先进方法都引入了新颖，复杂和专业的体系结构。作者采用基于LSTM和QRNN的现有最先进的词级语言模型，并将它们扩展到更大的词汇表和字符级粒度。经过适当调整后，LSTM和QRNN分别在字符级别（Penn Treebank，enwik8）和单词级别（WikiText-103）数据集上获得了最新结果。使用单个现代GPU仅需12小时（WikiText-103）至2天（enwik8）即可获得结果。 来源： ARXIV.ORG 链接： https://arxiv.org/abs/1803.03835?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 作者使用以前训练过的'教师'代理训练新的'学生'代理。作者表示，在计算密集型多任务基准测试（DMLab-30）中，kickstarted训练可提高新代理的数据效率，从而实现更快的迭代。同样的启动管道可以让一个学生代理利用专门从事个人任务的多位“专家”教师。在这种情况下，kickstarted代理可以把从头开始培训的“学生”代理与几乎减少10倍的步骤相匹配，并将其最终性能提升42％。 Have a Great Definition 
37,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658689&idx=1&sn=745ccd42599e0df5cb7add8b9dc1f33a&chksm=bd4c3e528a3bb7444eb2afe23fbfec345bf1a712f8e9179e9940955d2034eb66b0cecb065bba&scene=27,英伟达黄仁勋发布全球最大GPU，超300斤，汽车后备箱大小 | GTC2018,"大数据文摘作品 这一次的GTC大会可能让不少矿工略微失望，英伟达并没有如传言所说发布一款“挖矿”专用芯片，但这并不影响这场持续三小时的英伟达2018GTC大会的精彩。 当地时间3月28日上午9点，英伟达创始人兼首席执行官黄仁勋在San Jose McEnery 会议中心，开启了第九届年度 GPU 技术大会 （GTC）。 按照惯例，黄教主依然一身皮衣登场，激情满满完成了本次大会的keynote演讲，并发布了一系列英伟达的新产品。 发布全球首个基于Volta架构的GPU——GV100，并与医疗影像行业结合； DGX2——世界最大GPU诞生！重达350磅，有汽车后备箱那么大； TensorRT 4发布，为超大规模数据中心提速100倍； ﻿发布针对自动驾驶场景的解决方案。 本次大会的四大主题 图像、科学、AI、机器人 👆 “今天，我们将讨论令人惊讶的图像，令人惊讶的科学，令人惊讶的人工智能和令人惊讶的机器人。”刚一上场，黄教主就带着他一贯的激情脱口而出了四个“令人惊讶的”。 黄教主首先回忆了第一部电影的诞生，以及电影工业的发展。而这一切离不开GPU的支持。 ﻿ ﻿ 发布全球首个基于Volta架构的GPU——Quadro GV100 “15年来计算机图形学最重要的进步” ﻿ 今天发布的第一款产品是Quadro GV100——世界上第一款基于Volta架构的GPU工作站。它的创新之处是带有一个名为NVLink 2 的全新连接点，这一连接将编程和内存模型从一个GPU扩展到第二个，从而链接起来，使它们像一整个GPU那样工作。这两个GPU共有10,000个CUDA内核，236个teraflops的Tensor Cores和64GB内存。 “现在每年产生10亿张图片，而且可以再增加10倍，因为Quadro可以把实时渲染降低到现有成本的1/5，现有空间的1/7，和现有功耗的1/17”，黄教主接着说道。 这一产品的主要使用场景是计算机图像，例如电影和游戏产业。黄仁勋接下来展示了目前已经有的三十多个主要合作伙伴，涉及游戏、设计、电影、 建筑等行业。他非常激动地称，这项技术是15年来计算机图形学最重要的进步。 与医疗影像结合，推出虚拟化数据中心 这一芯片产品的另一个可广泛应用的领域是医疗行业。 黄教主展示了一张15年前的超声波图像并将其与一张现在的超声波图像比较。可以明显看到前者模糊的灰色像素，而后者甚至可以看到胎儿的准确肤色。 正是因为基于GPU的计算技术发展，现在可以比以前更好地重建图像，通过渲染来释放更多洞察力并迅速可视化图像。为了确保这一技术更好更快地应用到医疗行业的硬件设备上，英伟达还为此推出了Clara项目——远程、多模式、多用户的虚拟化数据中心，可以为每个系统进行虚拟更新。 黄教主说，英伟达在现代医学成像方面所做的工作是他最感到自豪的事情之一。 DGX-2——世界最大GPU诞生！ 这个庞然大物包含20亿个晶体管，其中每个GPU都通过光纤交换机通信，所以它的工作原理更类似一个交换机而不是一个网络。 这款GPU重达350磅（超过300斤），有汽车后备箱那么大，“没有人能把它举起来”，黄教主调侃道。 DGX-2的处理能力是去年9月发布的DGX-1的10倍以上。 DGX2示意图 👆 这款全球最强大的电脑售价为39.9万美元（约250万人民币）。 黄教主称，它可以取代300台消耗为180千瓦的双CPU服务器，而这三百台计算机总价值为3百万美元，使用DGX-2可以将成本降为之前的八分之一，并将占地空间降到之前的六十分之一。 5年前，在2个GTX 580上训练Alexnet神经网络需要花费6天，但现在使用DGX-2只需要训练18分钟。时间单位从“天”降低到“分钟”，产生巨大对比。 发布NVIDIA GPU Cloud（NGC） 黄教主接着说道：“在数据和计算量的‘双重指数级’增长的背景下，出于为越来越复杂的系统和软件提供支持的目的，我们发布了NVIDIA GPU Cloud（NGC）。” 不论使用什么云，都可以在NGC上使用相同的堆栈，现在的NGC已经有了两万注册用户，而这仅仅是去年发布后的一小部分。NGC已经通过了AWS、Google Cloud、Oracle Cloud和阿里云的认证。它是一个能在任何云上运行的唯一体系结构。 TensorRT 4发布，超大规模数据中心提速100倍 黄教主用一张幻灯片展示了超大规模数据中心需要考虑的7个重要因素，并强调，超大规模数据中心是有史以来最复杂的计算机。 目前世界上大概有3千万台超大规模服务器。英伟达在2016年9月推出TensorRT，这是专门用来服务超大规模数据中心的芯片。 2017年4月推出TensorRT 2；2017年9月推出Tensor RT 3。今天英伟达发布了TensorRT 4——它可以处理循环神经网络，与TensorFlow深度融合。完成网络训练后，它可以直接在设备上运行。 Tensorflow官方推特也同期发布了这一消息 👆 黄教主称，这一更新可以让图像加速190倍，自然语言处理加速50倍，推荐引擎提速45倍，语音提速36倍，语音识别率提高60倍。“总体而言，我们将超大规模数据中心的速度提高了100倍。 ” 黄教主接下来发布了Kubernetes，用来协调数据中心服务器海洋中的工作负载——目前已经可以被GPU识别。 ﻿ ﻿ 发布针对自动驾驶场景的解决方案——Perception基础架构 让自动驾驶技术的发展被推到了风口浪尖。本次发布会上，黄教主也着重强调了自动驾驶场景。 “安全是最重要的一件事。这是最难的计算问题。发生致命事故后，我们提醒自己，这项工作非常重要。我们需要一步一步地解决这个问题，因为这么多事情都处于危险之中。如果我们做得对，我们有非常大的机会挽救生命。” 而对于无人车的安全性，高效可用的芯片被摆上了举足轻重的地位。英伟达称已经花了五到七年的时间来了解这个系统。“我们正试图从头到尾思考这个问题，这里的四个支柱是：收集数据，训练模型，模拟，驾驶。” 黄教主接下来推出并详细介绍NVIDIA应用于自动驾驶场景的Perception基础架构： 每辆汽车都在收集PB级的数据，我们将其标记为数据因子 - 每月有1500人来标注100万件物品； 我们在NVIDIA DGX系统上进行训练，然后我们进行验证； 最终创建网络，我们现在在车上有10个网络。每个网络有10个DGX分配 这10个网络涵盖感知、自由空间距离感知、天气，激光雷达感知、基于相机的映射、相机定位到高清地图、激光雷达定位到高清地图、路径感知和场景感知。 “我们正在试图创建一个自动驾驶汽车流量和基础设施，这样整个行业就可以利用这一点，并创造出自动驾驶汽车的未来。” 不过，据海外媒体TechCrunch报道，在Uber事故后，英伟达已 。不知是否受此影响，英伟达股价今天持续走低，累计下跌超9%。 Have a Great Definition "
38,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658673&idx=2&sn=6c3d7729793cdf3ec82b37d46b44ad83&chksm=bd4c3e228a3bb73461915394b83982f2e4901254f2cab8648abacf54b1d42c54fe56178d660c&scene=27,业界 | 李彦宏：中国人愿意用隐私交换便利性；无人车事故是“人咬狗”新闻,"激起了全世界关于数据隐私讨论的 的余波之下，昨天，李彦宏 在中国发展高层论坛上谈到了数据使用问题 。 原话是这样的： 麦肯锡公司董事长、全球总裁 鲍达民： 很多医疗服务或者创新都需要用到人们的数据，我们应该如何使用数据？ 李彦宏 ： 当你把各领域的数据汇集到一起，力量就会变得更强。同时我们也非常了解隐私问题或者说如何保护数据。在过去的几年里，中国越来越注意这个问题，执法力度也加强了很多。但是同时我也认为， 中国人更开放，对隐私问题没那么敏感。如果他们可以用隐私交换便捷性，很多情况下他们是愿意的。 英文原文：Chinese people are more open or less sensitive about privacy issue. If they are able to trade privacy for convenience, for safety, for efficiency, in a lot of cases they are willing to do that. 问答环节的视频 ▼ 李彦宏还提到， 用户信息安全保障是所有互联网公司的生命线。 用户的一些个人数据实际上能够帮助互联网企业为之提供更好的服务或产品。 比如，用户在电商、购物网站上的习惯、关注的品类等等信息，有助于网站为用户提供更贴心、更高效的服务。 因此，需要在保障用户信息安全和运用用户数据为之提供更好服务之间，找到更好的平衡点。当然，这一切都要遵循一定原则， 。 李彦宏也非常重视AI人才。他透露百度在 研发上投入累积超过100亿人民币，在AI上还会持续投入，给愿意来北京工作的硅谷人才加薪15%：“人才很贵，但我们愿意花这个钱。” 此外，在论坛的演讲中， 李彦宏还表达了对中国人工智能发展前景的展望： 未来中国经济的成长可能要更多依赖人工智能技术。 未来3到5年无人车会进入开放道路运行状态。 自动驾驶在中国会更快普及开来。 中国发展AI有得天独厚的条件。 中国刚刚开完两会，在工作报告里总理提到互联网+和人工智能，前者是过去五年中国经济高速增长的一个动力，而后者更是未来的发展布局，我们要加强对人工智能的研发投入。 互联网本身的成长在中国已是瓶颈期，人口红利慢慢在消失，每人每天上网时间就那么长，这时互联网成长的动力匮乏，如今线上推广成本和线下差不多，甚至成本更高，这时需要新的动力引擎，就是人工智能。 中国非常乐意利用新技术，无人车无论研究还是制造，中国已经处在还比较领先的地位。4个月后，百度和厦门金龙合作的无人驾驶小巴就会量产出现。这是一辆完全的无人车，一开始会现在相对封闭的区域首先尝试起来，比如景区，码头公园等地方。自动驾驶技术目前在开放道路上还没有成长到摆脱司机，但是技术成熟很快，我相信未来3~5年时间就会进入开放道路状态。 如今自动驾驶出一个事故大家就引起大家的注意， 每天有500多人因为汽车事故死掉，没人报道，但Uber出一次事故，全世界都非常关注。（ ） 整个无人驾驶有很长的产业链，也不仅仅涉及中国，全球都会参与，所以我们认为一个开放的态度会更受益。 中国人现在怀着开放的态度接受新事物的，在这个角度看，自动驾驶会在中国更快的普及开。中国制造方面，会有新的事物出现，原来是音箱，一个小的电器，现在是智能音箱，原来是电视，现在是语音可以直接操控的电视。 中国制造现在正在发展为中国智造，任何一个设备，都应该有一个接口，是能理解人的语言的。以后机器能理解人的语言，人就不需要学习工具了，工具学会理解人。 政策方面，中国也非常开放，最近北京开放了105公里的道路供无人驾驶车进行测试。这个意义很大，北京是一个大国之首都，政治性是非常强的城市，现在对这项技术也开放，这非常不容易。 其实除了这个政策方面，我觉得中国还有两个非常有优势的地方， ，中国是全球最大的人力资源国家，同时中国人我觉得也比较勤奋，大家都觉得就是加班多工作几个小时没什么。所以就是我觉得对于未来中国AI的发展会有很好的帮助。 第二个就是数据 ，中国已经有7亿多的网民，这么多人每天的上网产生非常多的数据，而且这些人说的都是同一个语言。喜欢的是同一个文化，遵守的是同样一套法律，那么它们产生的数据用来作为训练各种各样机器学习的模型会有非常好的效果，所以中国发展AI是有非常得天独厚的条件的。 【今日机器学习概念】 Have a Great Definition "
39,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658673&idx=1&sn=4670c34b49e6022fcfa5b85f5c6001d6&chksm=bd4c3e228a3bb7346874484abddface0174bdc157cbfa52dc018a616a218ba8fd14eaec02a3c&scene=27,没资源？下一秒就可以加入的10个数据科学项目！,"数据资源十分难得，分析过程更是困难重重。挖掘数据背后的意义能够帮助更多的研究者点燃数据研究的热情，也会帮助其他人入门数据分析，以下就是我们找到的十个典范。 这是一个关于数据新闻工作的案例：在2016年美国总统大选期间，有团队从Facebook挖掘了外界影响的数据，并据此与一些社会上大型的社交媒体展开了正面交锋。这场调查被包括华盛顿邮报和纽约时代周刊在内的知名媒体所收录。 这份数据是由数据新闻研究中心的Jonathan Albright为Digital Journalism提供的，是由5个宣称具有外在影响力的网页中的每一个页面上自然发言读者的帖子所构成的目录册。 它不仅保存了每篇帖子的完整文档，也揭示了除购买广告外，使用Facebook平台所能带来的其他潜在影响力。 具体来说，这五个网页的内容传播力度更大。此外，这个数据集的讨论区是今年data.world里面最为火爆的。 Jonathan鼓励大家使用这个数据集来开展自己的研究和分析。这个集成数据集也展示了data.world上的其他新闻数据工作。 集成数据集 https://data.world/gswider/data-journalism-on-data-world?utm_campaign=distinct_values&utm_source=blog&utm_medium=medium&utm_content=171229 Jonathan制作的互动性可视化界面 数字货币的每日行情@scuttlemonkey 如果你在去年的这个时候投资了比特币，你现在可能已经赚得盆丰钵满了。但如果你没有投资，也可以在这个数据集里使用比特币后悔计算器，来得出你错过的收益。 这个项目在IFTTT使用data.world的同步程序，从Coin Metrics（一个提供可视化服务的数据聚合器）提取每日最新数字货币的数据。在此数据集的讨论区中，你可以查看十多种加密货币的价格走势及多种视觉效果图。 数据集讨论 区： https://data.world/scuttlemonkey/coin-metrics/discuss/visualizations/64263?utm_campaign=dataquest&utm_source=blog&utm_content=180122 Patrick制作的数据可视化效果 在美国，由于类鸦片类药物滥用而导致的服药过量率上升趋势令人担忧，它影响着全美成千上万的家庭。来自USAspending.gov的最新数据是由经财政部发布在data.world上的，里面包含详细的项目介绍和机构信息，你可以通过它了解联邦政府为解决这一问题所做的工作。 haotianxu91对此数据集进行了深入挖掘，并探究了能否把联邦政府提供的数据和对鸦片类药物滥用的治疗以及预防项目联系到一起。 项目详情： https://data.world/search?q=org%3Atreasury&utm_campaign=dataquest&utm_source=blog&utm_content=180122 Data.world上公开且容易获取的数据使得美国许多州及联邦政府机构都在努力提高财政支出的责任感和透明度。输入data.world组织名称来搜索代理机构，就可能在data.world找到更多的政府数据。 data.world链接： https://data.world/search?q=org%3Atreasury&utm_campaign=dataquest&utm_source=blog&utm_content=180122 由Haotian Xu提供 在data.world，我们认为数据在（不久的）未来是有关联的，我们十分期待看到更多的社区成员解锁关联数据的真正潜力，并且使用SPARQL—一种数据库的语义查询语言（以data.world的猫头鹰吉祥物命名）。 使用SPARQL对这组数据集进行查询再现了著名的“Kevin Bacon的六度空间”理论（“Six Degrees of Kevin Bacon” ）——对于数据集中的任意两位演员，通过查询他们以前合作的搭档，你会发现他们之间所间隔的人（如果存在）不会超过六个。 只需在查询语句的第7和第8行中替换你想要查询的演员名字，然后点击“运行查询”，就可以开启“SPARQL的六度空间”了。（提示：结果十分有趣，可以多试几次。） SPARQL的六度空间： https://data.world/login?next=%2Flinked-data%2Flinkedmdb%2Fworkspace%2Fquery%3Fqueryid%3Db671cc87-2078-4057-b1eb-366e9c5f48e1%26utm_campaign%3Ddataquest%26utm_content%3D180122%26utm_source%3Dblog 有39个地区被列入了Harvey总统宣布的飓风多发重灾区（PDD），虽然大多数遭受到财产损失的地区都需要修复和重建的援助，但资源有限的地区在获得联邦灾难恢复项目关注后会受益更多。 SP小组识别出了那些受财产损失影响最大的社区，并将数据发布在data.world。这个项目也同样被其他一些研究者推进，在data.world搜索“Hurricane Harvey”，会出现由许多个小组成员和组织创建的几十个数据集，他们希望通过给需要的人提供容易获取的重要数据，能够为灾后重建出一份力。 Hurricane Harvey的搜索结果： https://data.world/search?q=hurricane+harvey&type=dataset&utm_campaign=dataquest&utm_source=blog&utm_content=180122 由Alyssa制作的数据可视化效果 根据柯林字典，2017年“假新闻”一词的使用量增加了365%。尽管人们对于媒体越来越不信任，但由于数据成为了全球顶级新闻机构公信度的基石，我们终于在今年看到了新闻领域的重大转变。 这组数据来自新泽西的州法医办公室，在历经数月对记录的争论后，数据发布的24小时内，新上任的州长Phil Murphy承诺将在即将到来的立法会议上会对系统进行“全面改革”。 这个例子说明了数据新闻是如何帮助社区，甚至影响公共政策的。了解更多新泽西先锋媒体的这场耗时18个月的调查请戳—死亡与功能障碍： 。 文章链接： http://death.nj.com/？utm_campaign=dataquest&utm_source=blog&utm_content=180122 由 NJ Advance Media报道 民主数据始于2016年12月，当时全球各地的人们开始在数据相关的问题上展开合作，使用Slack进行策划，GitHub编程以及data.world共享数据。没有成文的规定也没有正式的组织，他们的目标是用最短的时间来完成真正的有效的工作。 这个数据集来自最早的一批项目，当前在全球已有2000多名电子志愿者。通过使用这个数据集和data.world R包，小组成员Jennifer Thompson可以收集一个dashboard所需的数据，创建并推出派生的数据集，并构建从站点提取实时数据的Shiny dashboard。在R Views（由RStudio编辑的R社区博客）中了解Jennifer所做的工作。 Jennifer工作内容链接： https://rviews.rstudio.com/2017/05/26/civic-data-wrangling-in-r-and-on-data.world/?utm_campaign=dataquest&utm_source=blog&utm_content=180122 由 Jennifer Thompson开发 想知道Grenada, Guyana和Gambia这三个国家的共同之处吗？它们都在全球足迹网（Global Footprint Network）的最小生态足迹名单之上。 全球足迹网（Global Footprint Network）的国家足迹账户 (NFAs) 记录了自1961年起生态资源使用情况以及各国的资源承载力。该组织在data.world上发布了2017年版的数据，对其进行分析后，可以帮助我们更好的了解经济发展与自然资源消耗之间的联系。 加入全球足迹网减少我们2018年的生态足迹，从计算自己的生态足迹来开始你的第一步吧！ 全球足迹网： http://www.footprintcalculator.org/?utm_campaign=dataquest&utm_source=blog&utm_content=180122 TableauHelp的教程能够帮助人们学习使用Tableau。数据项目包括指南、教程和练习，通过一个模拟练习来学习有关商业数据分析和可视化的基础知识。 学习在Tableau创建各种视图来研究数据链接： https://data.world/login?next=%2Ftableauhelp%2Ftableau-desktop-101-step-into-the-shoes-of-a-data-analyst%2Fworkspace%2Ffile%3Ffilename%3D01_lets_get_started.md%3Futm_campaign%3Ddataquest%26utm_content%3D180122%26utm_source%3Dblog TableauHelp提供的教程 社会数据项目周一大改造（Makeover Monday）的成员每周一会发布一条图表和其数据的链接，图表可以经由社区重新绘制。无论是简单的条形图还是复杂的信息图，他们都鼓励每个人参与进来。 链接： http://www.makeovermonday.co.uk/ 原文链接： https://www.dataquest.io/blog/10-data-science-projects-join/ Have a Great Definition "
40,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658629&idx=2&sn=8406e2a63ce9e6bde1324964a7677fb7&chksm=bd4c3e168a3bb700ddf72327c1199aa819c661a0a41b9fa09e366a8fa7ea52f1ca61e3f8543d&scene=27,业界 | 如果技术从业者上岗前也要宣誓，一份给程序员的希波克拉底誓言,大数据文摘作品 编译： “我们的生活状况依赖于陌生人的道德规范，而我们绝大多数也总是其他人眼中的陌生人。” ——比尔·莫耶斯，前白宫新闻发言人 让我们先来想象以下两个场景： 你是一名数据分析师，参与构建了近乎完美的针对性广告平台。这个平台推动了数十亿美元的业务，但随后被外国黑客用以影响总统竞选，并攻击民主制度。 你写了一个机器学习拼写检测算法，这个算法是全世界最优的，在全球范围内广为应用。但有一天，它将一些处方药的名称自动更正为其他名称，给无辜的人造成了伤害。 不可否认，如今技术人员手中的权利和能力比任何一个时代都要强大。 这两个例子也并非完全出于想象。 引发了技术人员是否该对技术结果负责的巨大争议。 而面对自己开发的算法可遭受到的道德指责，哈佛大学的一位论文作者这样公开回应道：“我只是个工程师。” 工程师的职责真的仅限于开发吗？ 通过设计产品、区分优先级、将其投入生产，技术研发者实际上正在影响着越来越多未曾谋面的人。 这些被开发完成的产品存在于人们的手腕上、笔记本电脑里、口袋中，因此也存在于人们的头脑中。 但是，不同于医生、警察、教师这些有着明确道德准则的职业， 给技术开发者的道德准则却时而如白纸黑字般分明，时而却含糊不清。 Visual Basic之父、资深程序员Alan Cooper在Interaction 18上就这一话题发表了演讲，并提出，不仅医生、教师，技术人员在就职时也该遵循自己的一套“希波克拉底誓言”。 点击查看其演讲完整内容： https://interaction18.ixda.org/program/keynote--alan-cooper/ 因为我们不仅要修补现有技术中的漏洞，更要在未来技术中预防这类滥用行为。 每个人都有不同的评判标准。谈及如何合理使用影响深远的产品时，人们也会有不同的意见。正因如此，技术人员们更应寻求深入理解所使用的模式和方法，以此了解它们带来的心理影响，以及与设计初衷相异的用户体验。不仅如此，当我们认为事已越界时，应该不惧权威、直言不讳。 纵然作为工程师、设计师、产品经理、数据科学家等的技术人员已在人们的日常生活中举重若轻，行业道德体系的教育和监督还有待完善。 领悟这一发现的过程使我们更深入理解了那些将道德准则纳入职业宣言的行业，Alan Cooper也因此将医生的希波克拉底誓言改编为技术人员 ff0000 的版本。 他说，“虽然这不是科技从业者的第一份誓言，也不会是最后一份，但却是新世界的一部分。在这个新世界中，我们不能再忽视我们所作所为应负的责任和潜在的影响。” 我们将这份宣誓誓言摘录如下： 我宣誓，尽我之能力及判断力实现此誓言： 我谨记，不论个人用户或集体用户，皆非数字或目标，而是应被尊重的人。 我将尊重前人来之不易的创造性成果，并甘于将自己所知授予后人。 我将应用自己的能力于终端用户的利益与价值，若相悖于产品目标，则坚决拥护前者。 我将谨记，技术之中不但包含科学，也包含艺术，同情心、技巧和对所做决定带来后果的警惕之心比技术知识、经济利益、地位提升更有价值。 我将不畏承认“我不知晓”，亦不会在需要深入的评价或多角度的思维时，不向同事求援。 我将尊重客户的需求，以保持与技术的健康关系。试图解决问题时，我将力求与对应受众建立直接联系。 我必会谨慎前行，在生活的平衡操作中，若面对伦理或道德争议，我将选择终止所为。 我将力求为受我技术影响的人们来带裨益，但我承认我的技术或将带来严重的不良后果。我将以谦虚的态度和对自己极限的清醒认知，面对并承担前述重大责任。 我将谨记，我的工作不仅是构建平台、应用或网站，最终更将影响人类，而人们应用我成果的水平可能影响到其家庭、经济稳定性或精神健康。如果我坚信我的成果符合道德标准，我应承担其直接后果的责任。 我将竭力防患对用户的剥削，因为预防胜于补救。 我将谨记我是社会的一员，我对社会负有特定的责任。我知晓其他人类同胞可能因我而身心健康，或失之强健。 重中之重是，我明白我是守卫者，我应格外关注我的技术产生的影响，甚于服从权威。若我不违背誓言，则可享受生活，并因自己的成果而喜悦，现世和身后受人尊敬 。 愿我能够严守最高使命，并能恒久经历为世人提供帮助之欢欣。 原文链接： https://builttoadapt.io/technologists-hippocratic-oath-94b88d3fe480 Have a Great Definition 
41,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658629&idx=1&sn=813b7f4c31f9cba92586e725323e5082&chksm=bd4c3e168a3bb700683bed2fb9fe0069946d242e2fb226da946936626cdcb8e628d8019ee44d&scene=27,手把手：扫描图片又大又不清晰？这个Python小程序帮你搞定！,"大数据文摘作品 编译：HAPPEN、于乐源、小鱼 一位乐于分享学生精彩笔记的大学教授对于扫描版的文件非常不满意——颜色不清晰并且文件巨大。他因此用python自己写了一个小程序来解决这个问题。 这个程序可以用来整理手写笔记的扫描件哦，输出的图片不仅很清晰，而且文件大小只有100多KB！ 先来看一个例子： 左：输入扫描件（300 DPI，7.2MB PNG/790KB JPG.）右：输出图片（300 DPI，121KB PNG）。 如果你急于上手操作，可以直接查看Github repo中的代码，或跳到本文结果部分，看看炫酷的颜色簇交互式三维图。 在大数据文摘后台回复 下载本文代码哦~ 免责声明： 上述过程或许可以用Office Lens应用程序实现，或者其他工具也可以实现。本文只是一个实用方法分享，不是什么发明创造。 一些我任课的班级没有指定的教材，这是因为我更喜欢每周指定一个“学生记录员”，与班里其他同学分享他们的讲义。这样可以为学生提供一些书面资源，以便他们需要时可以进行对照。笔记以PDF的格式发布在课程网站。 在学校，我们有一台能够将笔记扫描成PDF文件的“智能”复印机，但是它生成的文件不够招人喜欢。下图是手写笔记的输出示例： 复印机好像随意地决定是否将每个数学符号进行二值化，或者转换后的JPG很不理想（如上图中的平方根符号）。因此我决定对上述问题进行优化。 我们从某位同学一页漂亮的笔记开始处理，笔记扫描件如下： 以300 DPI精度扫描的原始PNG图像大小约为7.2MB；转换为图像品质较高的JPG格式后，文件大小约为790KB。由于PDF扫描件通常采用PNG或JPG作为容器格式，我们当然不希望在转换为PDF时损失文件信息。 但是考虑到网页加载时间，每页笔记800KB已经相当大了，我希望获得文件大小更接近100KB/页的图像。 虽然这位学生的笔记很整洁，但笔记的扫描件看起来有点乱。原因是复印机将这页笔记的反面内容也进行了扫描，这会分散读者的注意力，而对于JPG或PNG编码器来说，这种情况比纯色背景的图片更难压缩。  下图是我写的noteshrink.py程序的输出结果： 输出结果是一个相对较小的PNG文件，大小只有121KB。不仅图像内存变小，而且看起来更清晰！这才是我想要的！ 处理过程和彩色图像基础 以下是生成小内存且清晰的图像所需的步骤： 1.识别原始扫描图像的背景色。 2.根据背景色的不同阈值分离出前景色。 3.从前景色中选择几种“代表性颜色”，作为生成PNG过程中需要的索引色。 在深入研究这些步骤之前，先来了解下彩色图像是如何以数字形式进行存储的。由于人类眼睛中有三种不同类型的感色细胞，因此我们可以通过组合不同强度的红色、绿色和蓝色来重建任何颜色。重构过程就是将每种颜色与RGB颜色空间中的三维点一一对应，如下所示： 尽管真正的向量空间允许无限数量的像素亮度连续变化，但为了将颜色以数字形式存储在计算机上，我们需要对上述像素范围进行离散处理——通常红色、绿色和蓝色分别用8位通道色表示。这种将像素类比成三维色彩空间坐标的分析方法将为我们接下来的理解与重建提供巨大的帮助。 由于页面的大部分地方没有墨迹或线条，也许有人会认为纸张本身的颜色将会是扫描图像中出现频率最高的一种颜色——即复印机会将白纸的每个像素表示为相同的RGB值。 如果结果真是这样，那么分离背景色将不会有任何问题。遗憾的是，情况并非总是如此，由于复印机玻璃板上的灰尘和污迹、页面本身的颜色变化、传感器噪声等不同的因素，像素的RGB值会发生随机的变化，页面的“实际颜色”其实可能涵盖数千个不同的RGB值。 扫描图像的原件大小为2081×2531，共5267011个像素点。虽然我们可以逐一处理每个像素点，但是处理输入图像的代表性像素点会更快。 noteshrink.py程序默认采集输入图像5%的像素点（在扫描精度为300 DPI的情况下）。接下来，我们先选择一个10000点的小像素集，结果如下图所示： 虽然结果与笔记扫描件的页面差异很大（没有手写墨迹）——但两幅图像的颜色分布几乎完全相同。两张图片中大多像素点呈灰白色，也有少量红色、蓝色和深灰色的像素点。然后我们对10000个像素点按亮度进行了排序（例如将每个像素点的R、G和B进行求和），结果如下： 从远处看，图像底部80-90％的区域看上去是同一种颜色；然而仔细观察后，你会发现很多不一致的细节。事实上，上图中主要颜色（RGB值为（240,240,242））的像素个数仅为226——占比还不到总像素数10000的3％。 由于上述方法中主要颜色占总像素的比例很小，能否将它作为代表性颜色来描述图像的颜色分布就值得怀疑。如果在寻找方法之前先减小图像的位深度，我们将更好地识别页面的主要颜色。 因此我们把每个色彩通道四个最低有效位置零，将原来每个8位通道色简化成4位通道色，结果如下所示： 现在主要颜色的RGB值为（224,224,224），并且其像素点数为3623，占总像素的36％。通过减少位深度，实际上我们将相似的像素分到更大的“组”，这将更容易在数据中找到一个强峰。 可靠性和精确度之间存在一个折衷方案：小像素集可以更好地区分颜色，但大像素集处理起来更可靠。最后，我决定用6位通道色表示来识别背景色，这似乎是两个极端之间的一个最佳选择。 一旦识别出背景色，就可以根据图像中每个像素与背景色的相似程度来进行阈值计算。通常来说，通过计算两个像素坐标的欧几里得距离，再与预设的阀值进行比较就能得到他们之间的相似性。可这个最常用的方法却无法正确区分下面的几个颜色： 下表展示了每种颜色与背景色的欧几里德距离： 从表中可以看出，笔记反面渗过来的深灰色应该被分为背景色，但它与白色背景的差值要比粉红色的差值更大，而粉红色应该是前景色。如果使用这种方法，就无法有效分离出粉红色的前景色，因为总会包含渗过来的深灰色。 为了解决这个问题，我们可以将图片从RGB空间移动到色相-饱和度-亮度（Hue-Saturation-Value，HSV）空间，HSV将RGB的立方体转变为圆柱体，其剖面图如下： HSV圆柱体上表面边缘呈现圆形分布的彩虹色，色度（hue）是指围绕圆柱体的中心轴旋转的角度（红色为0°）。圆柱体的中心轴从底部的黑色、中间的灰色渐变到顶部的白色——整个轴的饱和度（saturation）为0，外圆周上鲜艳的颜色饱和度都为1。 最后，亮度（value）是指颜色的整体亮度，其变化范围从底部的暗色调到顶部的亮色调。 现在让我们用HSV重新区分一下之前的颜色： 从表中可以看出，白色、黑色和灰色的亮度差别很大，但它们的饱和度都很接近且数值较低——远低于红色或粉红色。通过分析图像的HSV值，我们可以利用下面的标准来标记属于前景色的像素，只需要满足其中一条就可以： 该像素的亮度与背景色的差值大于0.3； 该像素的饱和度与背景色的差值大于0.2； 第一条标准可以分离出笔记中的黑色墨迹，第二条标准则可以分离出红色墨迹和粉色线条，且这两个标准在选取前景色时排除了笔记反面渗透过来的灰色。但不同的图像可能需要不同的饱和度或亮度阈值，详情请参阅结果部分。 当我们将前景色分离后，会得到与页面上笔记的颜色相对应的一组颜色。将得到的像素点重新放进RGB空间并计算每个像素对应的坐标，可以看到新的散点图呈现簇状，每一个颜色会形成自己的色块： 由three.js提供支持的交互式三维图 现在我们的目标是将原始的图像（24位/像素）中的所有颜色用8种“索引色”进行替换（8并非固定的数字）。这样做有两种好处：首先，它缩小了文件的大小，因为现在只需要3位就可以指定一种颜色（因为8 = 2^3）；此外，它使得生成的图像在视觉上更美观，因为在最终输出的图像中，相似颜色的笔记都会只用一种颜色替代。 为了实现这个目标，我们通过数据驱动的方式，也就是利用上图中的“簇状”特性，选择每个色簇的中心坐标来表示这一组颜色。用术语说，我们将通过聚类分析来解决一个色彩量化问题（其实是向量量化）。 具体的做法是，通过k-means算法在一个颜色簇中找到一个点，这个点到其他每个点的平均距离之和最小。对上述数据集使用这个方法，得到7个不同的颜色簇： 由three.js提供支持的交互式三维图 在这张图中，黑色轮廓彩色实心的点表示前景色像素的颜色坐标，通过彩色的线将它们连接到RGB色彩空间中最近的中心点。当图像转换为索引颜色时，每个前景色像素的颜色将被替换为距其最近的中心点的颜色。最后，包围每个颜色簇的圆表示每个中心点距相关像素的最远距离。 除了能够设置亮度和饱和度的阈值之外，noteshrink.py还具有几个其他值得一提的功能。默认情况下，它通过将亮度的最小和最大值重新调整为0和255来增加最终调色板的鲜艳度和对比度。如果不进行调整，上述扫描件的8色调色板将如下所示： 调整后的调色板色彩更鲜明： 在完成前景色分离后，还有一个选项可以强制将背景色变为白色。通过转换为索引颜色的图像可以进一步压缩PNG文件，noteshrink.py还可以运行如optipng、pngcrush或pngquant等图像优化工具。 该程序最终会将多个压缩后的图像合并为一个PDF文件，就像使用ImageMagick的转换工具一样。此外，noteshrink.py会自动对输入文件名进行数字排序（而不是像shell globbing 那样按字母顺序排列）。当复印机输出的文件名是scan 9.png和scan 10.png时是非常有帮助的，上述排序功能保证了压缩后的页面在PDF中也保持同样的顺序。 以下是一些程序输出的例子。第一个输出的PDF使用默认的阈值设置，看起来很棒： 不同颜色簇的可视化： 由three.js提供支持的交互式三维图 第二个PDF需要将饱和度阈值降低到0.045，因为蓝灰色的线条颜色太深不便于阅读： 对应的颜色簇： 由three.js提供支持的交互式三维图 最后这个PDF来自于工程师的方格纸，在这个过程中我将亮度阈值设置为0.05，因为背景和线条之间的对比度非常低： 对应的颜色簇： 由three.js提供支持的交互式三维图 综上，这四份PDF文件大小约788KB，平均每页130KB大小。 如果再次启动这个项目，我想尝试一下其他的量化方案，就在前几天还在想用光谱簇结合最近邻图的方式去尝试一下，当时十分兴奋认为这是一个绝佳的方案，然后就发现已经有一篇2012年的论文提出了完全一样的构思，哎… 你也可以尝试使用最大期望算法来生成描述颜色分布的高斯混合模型——不确定之前是否有人做过类似的实现。当然感兴趣的同学也可以试试其他有趣的想法，如使用Lab这类视觉上均匀的色彩空间进行颜色聚类，并尝试自动给出指定图像的“最佳”聚类数量。 在大数据文摘后台回复 “压缩” 下载noteshrink.py哦~ 原文链接： https://mzucker.github.io/2016/09/20/noteshrink.html Have a Great Definition "
42,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658597&idx=2&sn=083703e511d34c8b20aeb97e3282dd8e&chksm=bd4c3ef68a3bb7e02d1d51099a22b6ef33880d760b17f4dc6bce2ed48ff7ae72522d6e739f86&scene=27,校招情报局 | 阿里巴巴2018实习生招聘进行中，文摘菌专属通道直达面试！,"大数据文摘作品 大数据文摘全新栏目“ ”来啦！ 校招阶段每期精心挑选 3~5家AI/DS公司校招信息 发布最新校招情报，提供专业可靠信息 直接联系招聘负责人，争取文摘菌专属锦囊 比别人更快直达HR和终面！ ： 点击 使用 大数据 文摘专属报名通道，简历可以跳过笔试，直达面试阶段哦！xiu～xiu～xiu～ 本期出镜企业 阿里巴巴 阿里巴巴集团经营多项业务，另外也从关联公司的业务和服务中取得经营商业生态系统上的支援。业务和关联公司的业务包括：淘宝网、天猫、聚划算、全球速卖通、阿里巴巴国际交易市场、1688、阿里妈妈、阿里云、蚂蚁金服、菜鸟网络等。 招聘概要 阿里巴巴2018实习生招聘正在进行中，本次招聘规模庞大，集合了阿里所有事业部的招聘信息，并派出阿里“重量级”工程师进行直播招聘，与同学们近距离互动哦。 工作地点 上海  北京  厦门  广州 杭州  成都  深圳  南京 美国西雅图（Seattle） 森尼韦尔（Sunnyvale）等 文摘菌专属投递福利 点击 ，通过大数据文摘的报名通道可以简历直达阿里集团招聘的BU，免笔试！ 为什么要推荐同学们使用文摘菌专属通道进行简历投递呢？看图你就知道了！👇 阿里巴巴官网投递简历后审核步骤 使用文摘菌专属通道审核步骤 同学们有没有心动呢？ 本次文摘菌专属通道由天池平台提供，通过专属通道投递的简历自带下列光环： 阿里对通过天池平台投递简历的同学给予高度的认可； 通过观看录播，大家对阿里校招岗位会有更清晰的了解，能帮助大家选择更合适的岗位； 优秀简历直达BU邮箱（带标签的简历哦）！ 如果在专属通道投递简历遇到问题时，可参考文摘菌吐血整理的教程： 通过登录天池进行投递，简历直达BU邮箱！ 简历投递完成后请在文章留言区签到哦， 由阿里集团校园招聘团队官方出版、为求职大型互联网企业的学生量身打造的官方指导书籍——《技术之瞳：阿里巴巴技术笔试心得》！（留言请注明姓名-与简历保持一致，留言后请添加小助手微信，微信号：AI_Learner） 招聘岗位 本次招聘包含阿里所有事业部的职位信息，鉴于篇幅有限，文摘菌先给大家提供部分诱人技术岗位的详情，更多内容请点击“ ”进行了解~ 岗位描述 跨平台Native中间件开发；  跨平台网络中间件、H5容器、Native容器的开发；  语音识别、图像识别、地理围栏、虚拟试妆、3D建模、AR/VR等领域的开发；  无线电商的首页、交易主链路、登陆、店铺等基础组件维护与开发；  iOS、Android等系统平台整体架构设计、运行期性能优化、设计动态化可扩展的组件、框架、容器,提升整体研发质量和效率。 岗位要求 熟悉iOS/Android平台原理机制,具备客户端性能优化的经验有一定软件架构设计能力，熟悉常见的异步、同步、多线程、跨进程、组件、容器的设计方法； 具备扎实的数据结构和计算机系统基础，编码功底扎实； 具备C++跨平台开发经验，熟悉NDK开发优先； 具备创新业务技术攻关和落地能力者优先（不限于算法、生物识别、图形图像、3D建模、AR、多媒体等领域）； 具有优秀的分析和解决实际问题的能力和态度，有创业的激情； 重视用户体验积极尝试各种新技术选择最佳实现与我们的产品有效结合，从中获取喜悦和成就感 。 岗位描述 大数据的采集、存储、处理，通过分布式大数据平台加工数据，支持业务管理决策； 大数据体系的设计、开发、维护，通过数据仓库、元数据、质量体系有效的管理和组织几百P的数据； 大数据产品的研发，通过对数据的理解，发挥你的商业sense，发掘数据价值，探索大数据商业化 。 岗位要求 所学专业是计算机、数学、统计等相关专业； 有较强的动手能力和学习能力，熟悉一门数据处理语言，如SQL、JAVA、Python、Perl等，熟悉unix或者linux操作； 具备扎实的专业基础，良好的沟通能力和团队合作，主动积极、乐于面对挑战； 有参与数据处理、分析、挖掘等相关项目更好； 对Hadoop、Hive、Hbase等分布式平台有一定的理解更好。 岗位描述 通过需求分析、设计评审，制定测试计划，设计测试用例，搭建测试环境，执行各级别和类型的测试，缺陷跟踪，来参与到互联网软件产品测试的全流程；  能站在研发过程的全局，借助最前沿的研发技术和理念，通过测试流程、方法和工具创新，努力提升研发的质量和效率;  能够站在用户的角度，不断完善产品的用户体验，影响到我们亿万的用户和消费者，让他们受益。 岗位要求 熟悉C/C++/Java等至少一种编程语言，有Shell或Ruby/PHP/Perl/Python等使用经验者优先；  熟悉Linux或Unix操作系统;  熟悉软件的开发测试流程，掌握常用测试用例设计方法，具备设计和开发测试工具和自动化测试框架能力；  广泛的技术视野，具备很强的学习能力、分析能力和解决问题的能力；  喜欢钻研技术，工作积极主动，不断追求产品的完善；  具备奉献精神，善于沟通，善于团队合作。 更多岗位信息请访问： https://campus.alibaba.com/position.htm?refno=11805 阿里巴巴的竞争力文摘菌就不多言了，实习生转正几率高，再加上极具竞争力的薪酬、五险一金。从文摘菌渠道报名还并且可以跳过笔试阶段，还等什么？小伙伴们，简历投起来~ 公司官网： https://www.alibaba.com/ 简历投递： https://tianchi.aliyun.com/markets/tianchi/campuslive?spm= a2c41.11326275.0.0 Have a Great Definition "
43,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658597&idx=1&sn=131c074c76a952a69af132ba962ffc41&chksm=bd4c3ef68a3bb7e060e1f66eebb79773dfc3b043ed09b0c48b5b3201f1139c2f58dccc8b5106&scene=27,日本老爷爷坚持17年用Excel作画，我可能用了假的Excel,大数据文摘授权转载自背包旅行 说起办公软件Excel， 不少人可能同小编一样， 谈及色变。 想想公式、表格头都大了， 今天要介绍的这个人竟然可以用其作画， 简直是大写的“丧心病狂”！ 这位传奇人物就是堀内辰男， 今年已经77岁了， 在日本长野生活。 大爷可以说是大器晚成， 做了几十年工程师， 60岁退休后闲在家里， 这可憋坏了停不下来的爷爷。 并没有向其他老年人一样， 觉得自己年纪大了， 不适合接受学习新鲜事物。 他一直想找一份自己喜欢的事情来做。 于是，想起自己热爱了一辈子， 却从未有过交集的画画。 满腔热血的找到了 一家学习日本传统画的培训班， 但是学习需要投入的资金， 难倒了生活并不算宽裕的他。 画纸，画板，颜料，画笔， 所有材料都是消耗品， 把这个当做爱好是一件很花钱的事情， 最后只得放弃了。 他不死心的问年轻人： “有没有什么不花钱的地方可以画画呢？” 年轻人想了想说， “要不您在电脑上试试吧， Word和Excel都能画画。” 回家就迫不及待打开电脑， Word和Excel都尝试过之后， 他发现Excel有表格、工具多， 更适合作画。 从那天起， 他开始刻苦学习之前从没用过的Excel。 摸清楚每一个功能键之后， 他开始研究起如何作画。 一点一点描绘，一次一次修改， 单元格越细密，轮廓线就越精准， 这比他想的难得多， 但是好在老人家觉得乐在其中。 从这些早年的作品中， 可以看到他一点一滴的进步， 学来学精细。 抱着重在参与的心情， 他参加了艺术展览。 可是大家只是惊讶于退休老人 和Excel作画这两点， 并没有人被作品惊艳到。 日本想来是一个追求精益求精的民族， 这下也勾起他必须要把这件事做精的绝心。 他开始挑战更有难度的画， 加图层，调整透明度...... 再用喷墨机打印出来， 更直观的发现问题， 再重新在电脑上调整。 他描绘心中的风景， 细腻柔和，情感丰富。 密密麻麻的线段， 没有一条是复制的。 放大看来不难发现， 它们都有自己的灵性。 要完成这样一幅画， 短则几个月，多则半年之久。 他说：“画画，就是用笔创造出一个世界。” 如今，他的作品一经亮相， 就会迎来一群人惊叹， 用Excel还能画的如此惊艳。 后来他参加了 “Excel自动图形艺术大赛”， 不出所料老人家一举夺冠。 作品被“群马美术馆”收藏。 为了供人学习绘画， 老人家还把自己的 Excel 画法， 上传网络，免费学习。 之后，为了带动更多在家无聊的老人， 他开了一所美术班， 教退休老人用Excel作画。 这个77岁的老人， 用17年的坚持， 让原本平淡的一生， 变得更加灿烂。 俗话说，活到老学到老， 这句话不是空谈。 每一天都是新鲜又独一无二的， 为什么要把生活过得千篇一律呢？ 知道自己要做什么， 就要去做， 而不是顶着一个幌子， 看起来很努力。 别把困难看的太难， 更别把低估自己当作理所应当。 Have a Great Definition 
44,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658591&idx=2&sn=24b8ff721a216efcf81406562aa620ad&chksm=bd4c3ecc8a3bb7dade4373f3fc88c01ff29ab28a03848e0927f29b7bcbc85ec3c45f29a540dd&scene=27,业界 | 3D打印汽车实现量产：3天就能造辆车，冲击传统汽车制造商,大数据文摘作品 汽车产业正处于一个变革的时代，以电力为主的新能源车正在逐步成为汽车领域的主角。新款电动车层出不穷，但是，到目前真正让人感到兴奋的产品还是并不多见。 制造商XEV称，这辆车制造时间仅花费3天。整个汽车除了底盘、座椅和玻璃之外，其他所有的组件都是3D打印的。车的定位为城市用途，面向 共享汽车、物流、外卖送餐等领域 （其实还是可以理解为代步车），速度并不快——最高速度被控制在每小时70公里以内。 XEV电动车公司创始人在接受采访时说：“3D打印技术制造汽车的优势在于，没有了模具生产的限制，汽车造型功能将会不断升级完善，且成本极低。因此我们的产品将没有分代，随时根据市场变化和反馈更新升级，自然容错率会很高。” 据透露，使用3D打印技术后一款车的整个研发周期可以控制在12个月左右，研发费用也较为低廉，相比传统车需要数年、花费上亿的研发成本来说，3D打印技术在汽车研发和制造上确实具备一定的优势。 Local Motors的3D打印车 此前，Local Motors、本田等公司都推出过类似的概念车或实车，但XEV这辆车是首个宣布量产的。该公司计划先在欧洲市场投放，售价为7500美元，2019年有望实现国产。 3D打印技术冲击汽车行业 使产品定制更加个性化 通过采用3D打印技术，消费者能够直接参与车辆的设计过程，从汽车的配色纹理，到个性化的车辆外观，甚至于汽车的功能模块都能够自主选择，或是从网络平台选择自己喜欢的样式，从而满足消费者的个性化和定制化的需求。也能够按照不同的业务，量身定制车辆，如酒店租车，物流车，配送车等。 使生产更加节约化 3D打印技术不需要使用模具或夹具，3D打印汽车的部件总数相比传统汽车大大减少。与此同时，3D打印大量减少了生产资料的浪费，这不仅节省了商业资金，而且更加保护环境。此外XEV电动车也使用了Polymaker研发的PLA材料，这是一种来源于玉米的可再生、完全可生物降解的塑料，真正实现了“全生命周期”内对环境的友善，比现今道路上任何行驶车辆更环保。此外还采用了尼龙、TPU等高分子材料，不但可以减轻车身重量，实现轻量化生产，而且可以有效降低成本，实现了去工具、去浪费化生产。 加速汽车行业的调整 3D打印技术带来的优势，会对传统企业带来一定的冲击，因为如此高度的定制化、个性化一定会加速汽车行业的调整。我们可以想象，汽车将按照市场反馈和出现的新技术进行升级。除了这些技术改进之外，还可以提供各种造型样式，这意味着更多样化的产品，能够做到以最短的时间和最低的开发成本设计出针对特定用户群的产品。 素材来源： https://item.btime.com/m_977384ff14caf5d13 https://www.cnbc.com/amp/2018/03/17/lsev-is-a-7500-3-d-printed-electric-car-from-xev.html?from=timeline&isappinstalled=0 Have a Great Definition 
45,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658559&idx=3&sn=88871ef20bb98a1862619ca45d41bd3f&chksm=bd4c3eac8a3bb7baebc05f30c3435eea4f0c16cb8fa6ee8205eb06aec71ae69567d64d3dad80&scene=27,快讯 | 小扎首发长文回应FB数据丑闻，谷歌云强调用户隐私保护,"大数据文摘作品 编译：蒋宝尚、小鱼、魏子敏 上周五，特朗普（Donald Trump）聘用的一家政治AI公司剑桥分析（Cambridge Analytica），被曝非法将大约5千万Facebook用户的信息用于大数据分析，从而精准刻画这些Facebook用户的心理特征，并向他们推送定制广告，甚至假新闻。（详情查看大数据文摘作品 ） 这一事件把Facebook推上了风口浪尖，昨天，事件有了两个不大不小的新进展： Facebook创始人扎克伯克就此事首次发长文公开回应，并且接受CNN独家专访，称I'm really sorry； 针对数据泄露事件，谷歌云在博客发文《确保企业云上数据安全》，阐述了如何保护用户在谷歌云的隐私数据，针对的目标群体是企业级客户。 当地时间3月21日，扎克伯格终于打破了沉默，回应了前几天Facebook遭遇的数据丑闻。其在个人Facebook页面上发表了一篇文章，阐述了公司为更好地保护用户数据而采取的一系列措施。 这位Facebook首席执行官在周三承诺将采取一系列措施保护数据，并着手解决社交网络与用户之间的“信任违约”。 “我们有责任保护你们的数据，如果我们没能做到，我们就不应该为你们服务。”扎克伯格在Facebook的一篇文章中写道。“我一直在努力了解到底发生了什么,以及如何确保这类事情不再发生。” 本周爆出的消息称，剑桥分析公司与特朗普“勾结”，助其赢得总统竞选，据称他们在Facebook用户不知情的情况下访问了大约5千万用户的信息。 据Facebook称，这些数据最初是由一名叫做亚历山大·科根（Aleksandr Kogan）剑桥大学讲师通过一个性格测试应用收集来的。收集行为完全合法，但是这些信息后来被转移到第三方，包括剑桥分析，这就违反了Facebook的政策。 此外，CNN也对扎克伯格进行了独家采访，视频中，小扎真诚表示：“我非常抱歉。” CNN采访视频链接： http://money.cnn.com/2018/03/21/technology/mark-zuckerberg-cambridge-analytica-response/index.html 这场争议使得Facebook市值蒸发了近500亿美元，大西洋两岸的政客们都呼吁扎克伯格应该在立法机构面前作证。 来自明尼苏达州的民主党参议员艾米·克罗布查(Amy Klobuchar)在推特上写道：“Facebook为保护用户而采取的措施是一个开始，但扎克伯格仍需要出庭作证。” Facebook现在面临投资者和用户的诉讼以及“删除Facebook”运动带来的巨大压力。 扎克伯格在周三表示,Facebook将采取措施进一步限制开发者访问用户数据，包括自动删除用户在三个月内从未打开的应用程序。 Facebook还将推出一款工具，使得用户可以限制应用程序访问他们的数据，该工具将在下个月出现在新闻页面的顶部。 扎克伯格表示，Facebook正在与监管机构合作对剑桥分析公司进行调查。 “是我一手创建的Facebook，我有责任对该平台上出现的任何问题负责，”扎克伯格说。“我们会从这件事情中积极吸取教训，并着手进行改进，使得我们的社区更加安全。” 在Facebook数据泄露之后，为了安定人心，谷歌云动作迅速，立即发布了一系列保护用户数据的措施。 Google技术基础架构高级副总裁Urs Holzle在谷歌I/O开发人员大会上谈论Google云平台 当地时间3月21日，Google Cloud官方博客发文，称谷歌云非常重视保护用户在谷歌云的隐私数据，以及阐述了具体的措施。 官方链接如下： https://www.blog.google/topics/google-cloud/new-ways-secure-businesses-cloud/ 其表示，个体消费者有时会从企业级云端的良好隐私决策中获得保护，就像涓滴效应一样，并且普通老用户也会从本公告中的一些细节条款中受惠——尤其是当他们使用托管在谷歌云的产品或服务器。而且据谷歌云端消费者的数据统计，像Spotify，Walgreens甚至苹果公司等平台，它们所拥有的客户数据远远超过你的想象。 谷歌的所有公告都在说一件事：希望获得客户的信任。当然，任何云平台提供商都需要客户的充分信任才能把数据交付给他们托管。但谷歌的方法有点不同——它试图建立最值得信赖的云平台，但是如果客户对谷歌没有足够的信任，谷歌也正在给客户提供方法来验证其后果。 例如，谷歌通过为客户提供谷歌自己的工程师和支持人员访问其数据的实时日志以及访问的理由来扩展访问透明度。采用这种做法，Google为企业客户提供一种保护其数据的方法，确保客户的数据不会因为谷歌员工的访问而泄露。 “我们希望尽可能公开和透明化谷歌内部人员对客户数据的访问，让客户看到都有哪些人访问了他们的数据。”云产品安全和隐私管理总监Jennifer Lin说。 谷歌通过让客户使用和保护自己产品相同的工具，让消费者能更清楚的了解数据安全威胁。谷歌云安全指挥中心将利用Google Security团队的工具，以及Cloudflare，CrowdStrike，Dome9，RedLock，Palo Alto Networks和Qualys等安全公司提供的数据，来对付僵尸网络，加密货币挖掘和其他威胁。 素材来源： http://money.cnn.com/2018/03/21/technology/mark-zuckerberg-cambridge-analytica-response/index.html http://money.cnn.com/2018/03/21/technology/mark-zuckerberg-cnn-interview/index.html https://gizmodo.com/google-opens-up-about-how-its-cloud-stores-your-secrets-1823934803 https://www.blog.google/topics/google-cloud/new-ways-secure-businesses-cloud/ Have a Great Definition "
46,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658954&idx=2&sn=f482d13e9721c33606571395200bb0ef&chksm=bd4c3d598a3bb44fe4addc73b5471e49c1fb847976599d8f138c0f2a8ec8a083e13cf0f9be16&scene=27,Python程序员最常犯的10个错误，你中招了吗？,"大数据文摘作品 编译： 什锦甜、 Gao Ning、 小鱼 Python简介 Python是一种具有动态语义的、面向对象的解释型高级编程语言。因其内置了高级数据结构，并支持动态类型和动态绑定，使用Python进行快速应用程序开发十分便利。同时作为一门脚本语言，它兼容部分现有的组件和服务。Python还支持模块和各种库的扩展，有助于实现模块化编程和提高代码复用率。 刚接触这门语言的新手可能会对Python简洁灵活的语法有些不适应，或是低估了Python强大的性能。鉴于此，本文列出了Python开发人员常犯的10个小错误，资深程序猿也难免会中招哦。 本文供Python高级开发人员参考，Python小白可以参考下面这篇文章： http://www.onlamp.com/pub/a/python/2004/02/05/learn_python.html Python允许开发者指定函数参数的默认值，这也是Python的一大特色，但当默认值可变时，可能会给开发者带来一些困扰。例如下面定义的函数： 看出bug了吗？那就是在每次调用函数前没有对可变参数进行赋值，而认为该参数就是默认值。比如上面的代码，有人可能期望在反复调用foo()时返回'baz'，以为每次调用foo()时，bar的值都为[]，即一个空列表。 但是，让我们来看看代码运行结果： 嗯？为什么每次调用foo()后会不断把""baz""添加到已有的列表，而不是新建一个新列表呢？答案就是，函数参数的默认值仅在定义函数时执行一次。因此，仅在第一次定义foo()时，bar初始化为默认值（即空列表），此后，每次调用foo()函数时，参数bar都是第一次初始化时生成的列表。 常见的解决方案： 代码示例： 运行结果没问题。 结果也正确。 什么鬼？我们只改变了A.x.，为什么C.x 也变了？ 在Python中，类变量是以字典形式进行内部处理，遵循方法解析顺序（Method Resolution Order ，MRO）。因此，在上述代码中，因为在类C中没有找到属性x，它就会从父类中查找x的值（尽管Python支持多重继承，但上述代码只存在一个父类A）。换句话说，C没有独立于类A的属于自己的x。因此，C.x实际上指的是A.x。除非处理得当，否则就会导致Python出现错误。 如果想更深入了解Python的类特性，请戳： https://www.toptal.com/python/python-class-attributes-an-overly-thorough-guide 假设你有如下代码： 这里的问题是except语句不接受以这种方式指定的异常列表。在Python2.x中，except Exception语句中变量e可用来把异常信息绑定到第二个可选参数上，以便进一步查看异常的情况。因此，在上述代码中，except语句并没有捕捉到IndexError异常；而是将出现的异常绑定到了参数IndexError中。 想在一个except语句同时捕捉到多个异常的正确方式是，将第一个参数指定为元组，并将要捕捉的异常类型都写入该元组中。为了方便起见，可以使用as关键字，Python 2 和Python 3都支持这种语法格式： Python变量作用域遵循LEGB规则，LEGB是Local，Enclosing，Global，Builtin的缩写，分别代表本地作用域、封闭作用域、全局作用域和内置作用域，这个规则看起来一目了然。事实上，Python的这种工作方式较为独特，会导致一些编程错误，例如： 问题出在哪？ 上面的错误是因为在作用域内对变量赋值时，Python自动将该变量视为该作用域的本地变量，并对外部定义的同名变量进行了屏蔽。因此，原本正确的代码，在某个函数内部添加了一个赋值语句后，却意外收到了UnboundLocalError的报错信息。 关于UnboundLocalError更多内容请戳： https://docs.python.org/2/faq/programming.html#why-am-i-getting-an-unboundlocalerror-when-the-variable-has-a-value 在使用列表时，Python程序员更容易掉入此类陷阱，例如： 奇怪，为什么foo1正常运行，而foo2崩溃了呢？ 原因和上一个案例中出现的问题相似，但这里的错误更加细微。函数foo1没有对变量lst进行赋值操作，而函数foo2有赋值操作。 首先， lst += [5]是lst = lst + [5]的缩写形式，在函数foo2中试图对变量lst进行赋值操作（Python将变量lst默认为本地作用域的变量）。但是，lst += [5]语句是对lst变量自身进行的赋值操作（此时变量lst的作用域是函数foo2），但是在函数foo2中还未声明该变量，所以就报错啦！ 下面代码中的错误很明显： 有经验的程序员都知道，在Python中遍历列表或数组时不应该删除该列表（数组）中的元素。虽然上面代码的错误很明显，但是在编写复杂代码时，资深程序员也难免会犯此类错误。 幸好Python集成了大量经典的编程范式，如果运用得当，可以大大简化代码并提高编程效率。简单的代码会降低出现上述bug的几率。列表解析式（list comprehensions）就是利器之一，它将完美避开上述bug，解决方案如下： 更多有关列表解析式的详细内容，请戳： https://docs.python.org/2/tutorial/datastructures.html#tut-listcomps 代码示例： 你以为运行结果会是： 但实际输出结果是： 8 惊不惊喜！ 这种情况是由于Python延迟绑定（late binding）机制造成的，也就是说只有在内部函数被调用时才会搜索闭包中变量的值。所以在上述代码中，每次调用create_multipliers()函数中的return函数时，会在附近作用域中查询变量i的值。（此时，return中循环已结束，所以i值为4）。 常见解决方案： 没错！我们利用了匿名函数lambda的默认参数来生成结果序列。有人觉得这种用法很简洁，有人会说它很巧妙，还有人会觉得晦涩难懂。如果你是Python开发人员，那么深刻理解上述语法对你而言非常重要。 假设你有两个文件，分别是a.py和b.py，两者相互导入，如下所示： a.py模块中的代码： b.py模块中的代码： 首先，我们尝试导入a.py： 运行结果正确！这似乎有点出人意料，因为我们在这里进行循环导入，应该会报错呀！ 答案是，在Python中如果仅存在一个循环导入，程序不会报错。如果一个模块已经被导入，Python会自动识别而不会再次导入。但是如果每个模块试图访问其他模块不同位置的函数或变量时，那么Error又双叒叕出现了。 回到上面的示例中，当导入a.py模块时，程序可以正常导入b.py模块，因为此时b.py模块未访问a.py中定义任何的变量或函数。b.py模块仅引用了a.py模中的a.f()函数。调用的a.f()函数隶属于g()函数，而a.py或b.py模块中并没有调用g()函数。所以程序没有报错。 但是，如果我们在未导入a.py模块之前先导入b.py模块，结果会怎样？ 报错了！问题在于，在导入b.py的过程中，它试图导入a.py模块，而a.py模块会调用f()函数，f()函数又试图访问b.x变量。但此时，还未对变量b.x进行定义，所以出现了AttributeError异常。 稍微修改下b.py，即在g()函数内部导入a.py就可以解决上述问题。 修改后的b.py： 现在我们再导入b.py模块，就不会报错啦！ Python的优势之一就是其集成了丰富的标准库。正因为如此，稍不留神就会在为自己的文件命名时与Python自带标准库模块重名。例如，如果你的代码中有一个名为email.py的模块，恰好就和Python标准库中email.py模块重名了。） 上述问题比较复杂。举个例子，在导入模块A的时候，假如该模块A试图导入Python标准库中的模块B，但你已经定义了一个同名模块B，模块A会错误导入你自定义的模块B，而不是Python标准库中的模块B。这种错误很糟糕，因为程序员很难察觉到是因为命名冲突而导致的。 因此，Python程序员要注意避免与Python标准库模块的命名冲突。毕竟，修改自己模块的名称比修改标准库的名称要容易的多！当然你也可以写一份Python改善建议书（Python Enhancement Proposal，PEP）提议修改标准库的名称。 先来看看foo.py文件中的代码： 在Python 2中，上述代码运行正常 但是在Python 3中运行时： 什么情况？原来，在Python 3中，在except代码块作用域外无法访问异常对象。（原因是，Python 3会将内存堆栈中的循环引用进行保留，直到垃圾回收器运行后在内存中对其进行清理。） 更多内容请戳： https://docs.python.org/3/reference/compound_stmts.html#except 解决方法之一是，在except代码块的作用域之外，加一句异常对象的引用就可以正常访问异常对象了。下面是处理后的代码，在Python2和Python3中的运行结果一致： 再次在Python3中运行代码： 问题解决了！ 更多有关Python2和Python3之间的区别，请戳： https://www.toptal.com/python#hiring-guide 假设名为mod.py的文件中有如下代码： 然后，你想在another_mod.py文件中进行如下操作： 如果你试图运行another_mod.py，将会出现AttributeError异常。 为什么呢？因为当Python解释器关闭时，该模块的全局变量的值都会被置为None。因此，在上述示例中，在调用__del__函数时，foo的值已经为None。 关于Python解释器的更多内容，请戳： https://mail.python.org/pipermail/python-bugs-list/2009-January/069209.html 调用atexit.register()函数可以解决上述的Python高阶编程问题。在调用atexit.register()函数后，当你的代码运行结束后（即正常退出程序的情况下），注册处理程序会在解释器关闭之前运行。 应用上述方法，修改后的mod.py文件如下： 当程序正常终止时，这种方法可以很方便的调用程序的清理功能。上述示例中，foo.cleanup函数会决定如何处理self.myhandle所绑定的对象，但是调用atexit.register（）函数就可以由你决定何时执行清理功能。 Python是一种强大且灵活的编程语言，提供了很多编程机制和范式，它可以极大地提高我们的工作效率。但不论使用何种软件工具或编程语言，开发人员都应该彻底理解Python的语法规则和编程规范，否则将会陷入“一知半解，害已误人”的状态。 不断学习Python的语法规则，尤其文中提到这些问题，有助于降低代码的出错概率，也会提升Python编程的效率。 如果想了解更多Python面试时会遇到的问题和相关建议，请戳： https://www.toptal.com/python#hiring-guide 希望你在阅读本文后能够有所收获，欢迎在留言区讨论~ 原文链接： https://www.toptal.com/python/top-10-mistakes-that-python-programmers-make 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 "
47,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658591&idx=1&sn=151adda5337f55af90270901eabeb330&chksm=bd4c3ecc8a3bb7da707552cc89c8e2da48e9d1c70b89325021f227d742b6ed29e92557925431&scene=27,换个角度看AI：追溯人工智能研究的历史和哲学逻辑,编译： Zoe Zuo 、 HAPPEN 、 丁慧、小鱼 正如题图所示，仿生人会梦见电子羊吗？ （译者注：Do Androids Dream of Electric Sheep?是Philip K. Dick所著的一本科幻小说，讲述人类在一个崩坏的环境中复制自己并奴役这些仿生人的故事。） 人工智能发展迅速且应用广泛。现实生活中AI技术的发展听起来像科幻电影，而科幻电影则更像是另一种画面感十足的现实场景。经过几十年的探索，AI技术可以说已趋于成熟，然而人们依旧固执己见，业内人士乃至全世界都对其可行性仍持怀疑态度。 类似的情形出现在玛丽•雪莱（Mary Shelley）创作的哥特式小说《弗兰肯斯坦》（Frankenstein）中。小说探讨了将人造生命创造出来并引入社会所产生的一系列后果。令我们困惑的是，书中的怪人一方面做出毫无人性的暴行，另一方面又展现出同人类一样的弱点，对友情的需求以及对于自我存在的危机感。 有人说我们应该关注新发现的前景与后果。但是，如果把机器人大军引入到像当今社会这样复杂的系统后产生混乱呢？也有人说我们要关注取得的成就，以及那些将此类想法落地的成功案例。然而，在偶然的成功和理论支撑的结果之间我们又该如何抉择？ 不妨集中注意力，一起理智地来追溯AI的历史渊源吧！ 不管你感兴趣的是古希腊哲学家逻辑思考的规则，还是阿拉伯数学家的公式推导，亦或是19世纪欧洲知识分子对数学的狂热。一个不争的事实是：问题远远比你想象的更为深刻（即便考虑摩尔定律）。 “我们日后成为什么样的人主要取决于父辈们在不经意间的教导，除此之外，我们由零零碎碎的智慧所塑造。” ——Umberto Eco 本文接下来的内容将讨论AI的发展史，包括一些重要人物所提出的相关问题、论证和看法。其中涉及的事件大部分都发生在20世纪60年代左右，同时期，也逐渐形成了AI的正式定义、发展目标、科研群体与反对者等。 1950年，艾伦·图灵（Alan Turing）试图在他具有开创性意义的论文《计算机器与智能》中回答这个刻意简化的问题。论文部分内容的含义并不明确，而且限定了人们对人工智能的理解。为此图灵设计了一个思维实验，这就是著名的 ： 参与者A是男性，参与者B是女性，参与者C的性别未知。C扮演询问者的角色，虽然无法看到A和B，但可以用客观的语句和两人进行交流。通过向A和B提问，C要试着确定A和B的性别。A的任务是迷惑C，让C做出错误的决定，而B则要协助C做正确的决定。 将问题重新设计，如下： 如果由一台机器来扮演A的角色，会发生什么？这种情况下，询问者做出错误决定的频率会与角色A、B由两个真人扮演时一样吗？ 图灵的方法似乎遵从了鸭子测试（duck test）的原理：如果它看起来像只鸭子，像鸭子一样游泳，像鸭子一样嘎嘎叫，那它大概就是只鸭子。 当谈及人类相关的智能，例如意识，图灵的观点是，不能因为某人（或某物）不具备尚未定义的特征而对其否定。因此，意识与我们对AI的探索无关。 哥德尔不完备定理 （Gödel’s incompleteness theorems）是我们试图谈论AI时面临的一大障碍。根据这一系列定理，数学逻辑无法具备完备性和相容性。因此，以数学逻辑进行学习的机器往往无法触及到一些真理。图灵对此的回应倒让人长舒一口气：你怎么知道人类智力就不存在局限性呢？ 小贴士： 哥德尔不完备定理是库尔特·哥德尔于1931年证明并发表的两条定理。 简单地说，第一条定理指出：任何相容的形式系统，只要蕴涵皮亚诺算术公理，就可以在其中构造在体系中不能被证明的真命题，因此通过推演不能得到所有真命题（即体系是不完备的）。 把第一条定理的证明过程在体系内部形式化后，哥德尔证明了他的第二条定理。该定理指出：任何相容的形式系统，只要蕴涵皮亚诺算术公理，它就不能用于证明它本身的相容性。 图灵的这篇论文论证充分，具有清晰的辩证结构，然而，因为论文推测的技术尚未被发现，图灵的论述也被搁置。 马文·明斯基（Marvin Minsky）是人工智能研究领域的先驱之一。翻开人工智能家族尘封的相册，明斯基就是给家庭聚餐添上些许不安的老人：“明斯基老叔，他迷人，与众不同，讲话总是很有趣。” 明斯基是1956年达特茅斯会议（the Dartmouth Conference）的组织者之一。在这次会议上，Artificial Intelligence作为术语首次被提出，同时也作为一个领域而诞生。明斯基对AI的切实可行充满信心，但他不看好用错误的探索方式，他也因此被人们所铭记。 1961年，明斯基被问及AI领域所取得的进展。让我们看看他说了什么： 我们应该先问问什么是“真正的”智能？我觉得这更像是一个美学问题，或者关乎一种尊严感，而不是一个科技问题！对我来说，“智能”不过意味着各种性能的综合，我们关注这些性能但无法理解。所以，这个问题通常和数学上“深度”问题相伴相随。一个定理的证明一旦被真正理解，它的内容就变得无关紧要了。 定义AI固然困难，明斯基承认这一点，因此他将继续探索。他的着手点是为AI确定几大发展支柱，即搜索、模式识别、学习、规划和归纳。 项目的终极目的是通过探索获得AI的解决方案。通过模式识别可以确定适合AI的工具，通过学习以往的经验可以对现有的算法进行改善，通过规划可以更高效地研究AI。至于机器能否获得归纳与推理能力，明斯基说道： 目前根据哥德尔不完备定理，还没有一个归纳推理系统能有效适用于所有体系。但是，给定一个体系（例如我们的世界）或者一些体系的集合，以及一套成功的标准，实现机器的认知就是技术性问题，而非空想。 明斯基在接下来的回答中多次重申，要实现AI应该通过各种复杂的分层架构。基于这一点，他质疑感知机算法，因为这一算法连中等难度的问题都解决不了，何况实际问题更加复杂。 明斯基的论断挫败了大众研究感知机的信心，从而耽误了深度学习的发展。通过进行深度架构，即使利用简单的构件也可以解决复杂的问题似乎在为明斯基开脱。不管怎样，明斯基的确具备独特的洞察力。 然而，因为帮助业界发现了各种原始方法的缺陷，明斯基的言论具有建设性意义。此外，深度学习或许是目前为止我们所探索到的最佳算法（还催生了各种很棒的应用），但绝不是AI的终极算法。 1980年，约翰·希尔勒（John Searle）对于AI的发展很不满。尽管早些时候他强烈反对强人工智能的概念，但这次他决定公开反驳。事实上，即使标题听起来有些讽刺。但我仍感觉希尔勒在揪着我的衣领，大力挥舞他的手，指着我说：“年轻的小伙子，让我帮你从根本上区分一下吧。” “你可能会有这样的印象：AI领域中写有关强人工智能的人认为他们可以避重就轻，因为他们没有认真研究过这个理论，并认为其他人也一样。至少我会发声质疑，并认真研究。” 希尔勒只攻击强人工智能这个概念，他认为这是一种计算机能够模仿任何人类行为的能力。而所谓计算机拥有认知能力的观点，亦可通过类比被推翻。由他提出的著名的思想实验“ ”论证了这一观点，实验过程如下： 假定某人被关在一个只有中文字符的房间里，而他只懂英文，对中文则一窍不通，甚至说不出中文字符与日文字符的区别。他在屋内完全是通过英文规则手册操作着屋外递进来的中文纸片（问题），这些字符需要通过英文形式的句法来确认，之后通过摆弄这些字符再将信息递送出去（回答）。恭喜！通过这个程序你就学会了中文。 这就是希尔勒于1980年提出的中文房间实验。思想实验本身并不是一个实验，因为它无法实际操作，而是探索一个想法的潜在结果。最古老也最有名的思想实验，可能是伽利略的比萨斜塔实验（你是否也认为伽利略真的从塔上往下扔苹果？）。 希尔勒的观点是，能够给出中文问题答案并不意味着懂中文，而这种能力也并非取决于由哪种语言书写规则。因此，给予适当算法后产生预期输出的计算机，不是一个“会思考的”个体。 就某些功能推理而言，希尔勒质疑的是一个程序的思考能力。他指责当今的AI研究人员存在行为主义和操作主义，试图将程序与头脑等同（事实也如此），而忽略了大脑的重要性。 希尔勒认为，认知只源于生物行为；而程序可以完全独立运行（因为它不受硬件平台的限制），因此程序并不具备认知能力。 当阅读他的原文时，你会感觉到希尔勒正在攻击一个尚未成熟的计算机科学家社区，而这个社区关于什么是智能并没有达成共识，只是试图通过技术手段和推测来模拟机器智能。 如同一般哲学方法中的虚无主义一样，明斯基回应希尔勒：“应该忽视希尔勒的误解。” 即使大象不会下象棋，你也没有理由责备它们。“ ”（ Elephants Don't Play Chess）是罗德尼·布鲁克斯（Rodney A. Brooks）在1990年发表的一篇论文，试图采用论据和他的机器人队伍来支持AI。罗德尼·布鲁克对AI的发展做出了卓越的贡献，经典的AI理论中应该有他的一席之地。 在那个时代，人工智能正经历着第二个寒冬。企业和政府也意识到不能对AI抱有过高期望而削减了资金。 所以是时候反省了。当一件事情从根本上失败时，有两种方式来理解：要么是这件事情不可能完成，要么采用了错误的方法。 布鲁克斯认为AI停滞不前是因为研究人员过于关注函数表达式。符号系统假设就是关于机器智能如何运作存在已久的观点。根据这个假设，世界上的人、汽车和情感等众多实体，可以很自然地将它们与符号相匹配，并输入给计算机。如果该假设成立，那么只要提供必要的信息便能使计算机拥有智能。 尽管这个假设看起来没有问题，但它在某种程度上误导了AI的发展： 符号系统不足以描述整个世界。根据框架问题，定义任何尚未明确存在的事物是一种逻辑错误。因此，布鲁克斯建议：为什么不把整个世界作为它自己的模型？ 简单计算无法衍生机器智能。启发式算法的大量使用是训练智能算法的必经之路，但这与我们尝试创造知识的初衷背道而驰。（网格搜索是对人类智力的侮辱。） 当AI的发展目标是寻求一种通用人工智能模型时，就出现了布鲁克斯称之为混淆的现象：大量的研究表明智能算法的适用场景并不明确。机器智能确实具有吸引力，正因为如此，人类对知识的探索才永无止境。 布鲁克斯并不支持物理根据假设（physical grounding hypothesis）。也就是说，让人工智能直接与世界交互，并将其用作自己的表示。上述假设与AI现在的发展之间还有很大的差距：从学习需要巨大的计算资源、专家的指导到总不够用的训练数据；布鲁克斯还设想，为AI配备物理实体和廉价硬件并将其销售到世界各地。要解决这个问题并不容易。 布鲁克斯认为机器智能是集群行为而不是复杂行为。或许他实验中最深刻的见解是，“目标导向行为源自于简单的无目标导向的交互行为。”无需预设协同模式，因为智能计算机可以制定出自己与世界交互的最佳策略。 布鲁克斯关于AI发展的讨论为我们证明了物理根据假设的重要性：人类是我们最常见和最亲近的智能体。因此，当我们试图重新创造这种智能特征时，就需要观察人类文明缓慢的形成过程。如果考虑到人类学习智能行为所需的时间，如交互、繁衍和生存，与我们尚未成熟的下棋程序相比，便可以得出结论：学习行为或许是最难开发的技能，也是我们应该要关注的重点。 布鲁克斯虽然对自己提出的实用方法很满意，但也承认其理论局限性，但他归因于学术界尚未提出让大家透彻理解人群动态交互行为理论。 再一次，工程师漠视了哲学界的异议： “如果我们的策略不能说服高高在上的哲学家，至少我们的技术将彻底改变我们生活的世界。” 尽管涌现出大量问题，但是我们不能质疑AI的进步。不管怎样，目前得益于技术的进步出现了很多不错的AI应用。如果忽略它们的存在去衡量当前研究质量是没有意义的。 深度学习是否能成为实现机器智能的有效工具？还是说，这是AI进入寒冬之前另一个间冰期？ 更重要的是，人们关注的角度已经开始从纯粹的哲学问题转向社会层面，而AI对日常生活的需求已远比理解概念、哲学和智能本身更加明显和迫切。不过，这种转变可能是一个更难以回答的问题，进而促使我们深入研究。 当维特根斯坦（Wittgenstein）撰写《逻辑哲学论》的时候，他面临着为难的选择：他的论点与他的学说相悖。也就是说，如果他的学说是正确的话，那么他的论点就是不合逻辑的，因此他的学说应该是错误的。但是维特根斯坦对此有不同的看法： “我的论点可以这样解释：当人们从开始学习到彻底理解后，便会认为它毫无意义。” 因此，我们需要用发展的眼光去理解隐含在复杂概念背后的真理。我们要坚定地迈出前进的步伐，也要做好随时放弃的准备。因为并不是每一步探索的结果都是正确的，但是我们需要理解每一步探索的过程。所以后来，当维特根斯坦谈到这个论点时，他说自己不需要梯子就能够直达真理。 或许在AI的发展过程中，我们仍然需要参考维特根斯坦的论点。 原文链接： https://medium.freecodecamp.org/deeper-ai-a104cf1bd04a Have a Great Definition 
48,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658559&idx=4&sn=12e26670f921365cf8e1c6757739b4f0&chksm=bd4c3eac8a3bb7ba257399bf4d23be2e7e94a336701feff63ca54d4ab59d2e5312323fca54a5&scene=27,AI角 | AI challenger零样本学习算法大赛报名开启，数据集开放,"大数据文摘作品 去年，AI Challenger（以下简称AIC）全球挑战赛吸引了来自65个国家近万团队参赛。 今年的AIC预热赛零样本学习（zero-shot learning）竞赛即日起开始。 零样本学习竞赛同样发布大规模图像属性数据集，包含78017张图片、230个类别、359种属性。 与目前主流的用于zero-shot learning的数据集相比，图片量更大、属性更丰富、类别与ImageNet重合度更低。 创新工场AI工程院运营副总裁吴卓浩表示，因为在很多情况下人们难以获得足够的有标注的数据来训练识别或预测模型。 受人类学习能力的启发，零样本学习（zero-shot learning）希望借助辅助知识（如属性、词向量、文本描述等），在没有任何训练样本的情况下学会从未见过的新概念。 这具有重要的研究意义和广泛的应用场景，被认为是实现大规模物体识别的一个重要方式。 最经典的零样本学习方法是Lampert 提出的直接属性预测模型(DAP)。 如下图所示，模型中属性训练是在传统特征提取的基础上的进行的，首先使用颜色直方图、局部自相似直方图、SIFT和PHOG等6种方法来提取样本图像的底层特征，这几种特征包含了图像的颜色、形状和纹理等方面，所以通过这种特征提取方法得到的特征可以良好的表达图像中的信息。这几种图像特征不仅适用与线性分类器，而且在非线性分类器中也能达到良好的表现。 在DAP方法中，通过上述的特征提取方法得到样本的图像特征后，将特征用于属性分类器的训练，然后将训练得出的模型用于属性的预测，最后采用贝叶斯方法推算测试样本的类别。近年来深度特征的使用大幅提高了零样本识别的准确率。 最具挑战的AI识别方法 零样本学习是当前最具挑战的AI识别方法之一。简单来说就是识别从未见过的数据类别，即训练的分类器不仅仅能够识别出训练集中已有的数据类别，还可以对于来自未见过的类别的数据进行区分。 这是一个很有用的功能，使得计算机能够具有知识迁移的能力，并无需任何训练数据，很符合现实生活中海量类别的存在形式。 传统的“零样本学习”方法首先是让智能体（Agent）对类别进行语义理解。将类别标签利用辅助知识（如属性）嵌入到语义空间中，再利用训练集中的数据学习这种从图像到语义的映射关系。 此后，即使遇到新的类别，只要提供了该类别的语义知识，模型即可识别该类别，这就是零样本学习。 例如识别一张斑马的图片，但在训练时没有训练过斑马的图片。那么我们可以通过比较这张斑马图片中包含的属性和各个类别的属性定义，进而在属性空间中找到与该测试图片相近标签，即为该图片的标签。 而零样本学习的意义也显而易见：在传统图像识别任务中，训练阶段和测试阶段的类别是相同的，但每次为了识别新类别的样本需要在训练集中加入这种类别的数据。 一些类别的样本收集代价大，即使收集到足够的训练样本，也需要对整个模型进行重新训练。这都会加大识别系统的成本，零样本学习方法便能很好的解决这个问题。 将来未知语言也能翻译 早期的零样本学习研究可以追溯到2008 年，Larochelle 等人针对字符分类问题提出了零样本学习（zero shot learning）方法，并且识别准确率达到了60%。 2009年Lampert 等人提出了Animals with Attributes数据集和经典的基于属性学习的算法，才真正打开零样本学习的关注度。 北大硕士赵波表示，在一些场景下，如细粒度物体识别、任意语言之间的翻译等，难以获得足够的有标注的数据来训练识别或预测模型。 因此，零样本学习具有重要的研究意义和广泛的应用场景。受人类学习能力的启发，零样本学习希望借助辅助知识（如属性、词向量、文本描述等）学习从未见过的新概念。目前零样本学习被认为是实现大规模物体识别的一个重要方式。 未知物体识别 例如，模型在“马”、“牛”等类别上训练过，因此模型能够准确地识别“马”、“牛”的图片。当模型遇到“象”这个新类别，由于从未见过，模型无法作出判断。 传统解决方案是收集大量“象”的图片，与原数据集一起重新训练。这种解决方案的代价高、速度慢。然而，人类能够从描述性知识中快速学习一个新概念。 例如，一个儿童即使没有见过“象”，当提供他文本描述“象是一种的大型食草类动物，有长鼻和长牙”。 儿童能够根据描述快速学会“象”这一新类别，并能在第一次见到“象”时识别出来。 零样本学习与之类似，在没有任何训练样本的情况下，借助辅助知识（如属性、词向量、文本描述等）学习一些从未见过的新概念（类别）。 比如说要进行三种语言之间的翻译，按照传统的方法需要分别训练六个网络，在日语和韩语之间没有那么多样本的情况下，训练英语→特征空间→日语，韩语→特征空间→英语这两个网络，那么就可以自动学会韩语→特征空间→日语这个翻译过程。 近年来，对抗网络GAN被用于图像合成，取得了以假乱真的效果。但传统图像合成仅能合成见过的类别的图像。零样本图像合成希望模型能够合成从未见过的类别的图像。目前已有一些算法通过条件GAN网络实现了零样本图像合成。 传统图像哈希算法利用一些训练样本来学习针对某些类别的哈希算法。但这些学习到的哈希算法无法用于新类别。零样本图像哈希，希望在已知类别上学到哈希算法能够运用到新的未知类别上。一些基于属性的零样本哈希算法已经被提出。 冠军：30,000人民币，颁发获奖证书 亚军：10,000人民币，颁发获奖证书 季军：3,000人民币，颁发获奖证书 双周冠军：3,000人民币 双周亚军：2,000人民币 双周季军：1,000人民币 以上提及金额为税前金额，详细规则请参考《竞赛选手报名协议》 注：数据集下载地址： https://challenger.ai/datasets   (1) 报名时间：即日起至4月23日。竞赛报名以及组队队员变更截止时间为4月23日23:59:59。 (2) 参赛队伍可1-3人组队参赛，确保报名信息准确有效。每名选手在大赛平台只能拥有一个账号，否则会被取消参赛资格及激励。 (3) 实名认证：为保证大赛公平性，所有选手必须完成个人信息实名认证。认证过程在个人中心的实名认证区域完成。 (4) 报名方式：登入AI Challenger官网，完成个人信息注册，即可报名参赛。 (5) 参赛队员必须遵守并签署《竞赛选手报名协议》。 Have a Great Definition "
49,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658559&idx=2&sn=8d5ac8dcd0c2d5d35a7c5b03c0af26d8&chksm=bd4c3eac8a3bb7ba3e2b791212454c36e464909eaf1e31ed03d89947dc5f43287be363cd4e92&scene=27,业界 | Uber自动驾驶撞死行人视频公布：无人车环境感知解决方案该如何优化？,大数据文摘投稿作品 投稿作者 ｜ 
50,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658516&idx=1&sn=cf11b5f15d56780382000197fc528b86&chksm=bd4c3e878a3bb791f01e28abe688672890a1091cac1293401b5aa40a62865b95bd042dbb1340&scene=27,日本科学家的AI读心术，解码脑电波，还原人眼所见,大数据文摘作品 编译：惊蛰、一针、龙牧雪 想象一下，如果电脑可以把你心中所想表现出来会怎样。 听起来感觉太遥远？然而最近，四位来自日本京都大学的科学家的研究成果，让这样的想象离落地更进一步。Shen Guohua、Tomoyasu Horikawa、Kei Majima 和Yukiyasu Kamitani在BioRxiv上发表了他们利用AI来解码人类思维的研究成果。 机器学习以前就曾被用来研究脑部扫描（MRI，即核磁共振）。给人类看一些简单的图像，比如黑白字母、简单的几何图形，AI能根据脑部活动的信号图还原人眼所见的图像。这一研究成果曾发表在著名刊物Neurons上。 大数据文摘公众号后台对话框内回复“ ”即可下载以上两篇论文。 还原效果还不错 不过这次，京都的这些科学家们开发了一种新技术，利用人工智能中的深度神经网络（deep neural networks） 来“解码”思想。 （比如一只鸟，或一个戴着牛仔帽的人）。看一下动图。左边是人眼看到的图像，右边是机器还原的图像。 有点恐怖= = “我们一直在研究通过观察人类大脑活动来重建或重现图像的方法。”其中一位科学家Kamitani表示，“以前我们假设图像是由像素或简单的形状组成的，但众所周知，大脑处理视觉信息时会分层次地提取不同层次上复杂度各不相同的的特征或其他信息。” 新的AI研究成果可以让计算机检测物体，而不仅仅是二进制像素。Kamitani说：“这些神经网络构成的AI模型可以用来表示人脑的层次性结构。” 在这项持续10个月的研究中，研究人员给三位受试人员分别展示一段时间的自然图像（比如鸟或人的照片）、抽象几何形状或字母。 第一排是受试者所见到的图片， 后面几排是AI根据3位受试者 对这些图片的不同印象生成的还原图。 在一部分测试中，当正在观看25张图像中的一张时，研究人员会测量记录受试人员的大脑活动。在另一部分的测试中，对大脑活动的记录是在之后受试人员回想图像时进行的。 测量完大脑活动之后，计算机把收集到的信息逆向解码（reverse-engineering）并生成受试人员心中所想的图像。 下面展示的流程图由京都大学Kamitani实验室的研究小组制作，并一步一步分解了这种可视化图像是如何被解码生成的。 下面两张图显示了受试者观看自然图像或者字母的图像时大脑活动的计算机重建结果。 用DGN技术生成的其他一些自然景观图像的重建结果。 黑框和灰框的图像分别是原图 和用DNN网络基于VC活动数据重建之后的图像， 三张重建的图片分别来自三位受试人员。 字母序列的所有重建结果 在另一组受试者观看图片后的回想过程中进行的脑电波测量实验上，科学家们又有了新的突破。 Kamitani说：“和以前不一样的是，采用我们的方法可以重建人类在逐渐回忆过程中脑海里出现的那些模糊的影像。” 如下面的图表所示，当试图解码人们回想图像过程中产生的脑信号时，AI系统重建出的结果就没那么好。那是因为，比起自然图像或字母，人类更难完全确切地记住猎豹或鱼的形象。 一些含复杂形象的图片的重建结果。 右下角的图片作为空白对照， 是根据测试过程中未 被展示图片时受试产生的脑信号重建的。 “出现这样的结果是因为，那个时候大脑的被激活的程度变弱了。”Kamitani解释道。 他还提到，随着技术的精确度正在不断提高，这一研究成果潜在的应用前景无可限量。 人们可以简单地通过想象来绘制图片或进行艺术创作；你的梦想可以被计算机画出来；可以通过形象化精神病患者的幻觉帮助改善对他们的照顾；而脑机接口可能有一天会实现人与人之间进行想法或脑海中的图像的直接交流，而不再限于语言。 虽然电脑读心这种事现在听起来可能来自使用脑电波交流的三体星人，但这些日本研究人员在这一联系大脑与计算设备的前沿研究中并不是孤军奋战。 比如，前GoogleX员工 Mary Lou Jepsen致力于在十年内打造一顶可以实现心灵感应的帽子，而企业家Bryan Johnson正在尝试构建可以植入大脑以改善神经功能的计算机芯片。更不用说Elon Musk的脑机接口公司 。 原文地址： https://www.newscientist.com/article/2162862-ai-reconstructs-whatever-you-see-just-by-reading-a-brain-scan/amp/?__twitter_impression=true Have a Great Definition 
51,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658516&idx=3&sn=c4d2fb3dfb7fd3ed1a069dbfe8d47367&chksm=bd4c3e878a3bb791633439e9a0c47f84d4a7a21c701b563206dfda76c1cbc3b5730125cf388f&scene=27,BlockChange | G20各国对数字货币观点大盘点，整体友好,大数据文摘作品 编译：小鱼、蒋宝尚 2018年3月19日至20日二十国集团(G20)财长和央行行长会议在布宜诺斯艾利斯举行加，这次会议引起了加密货币投资者的注目。 在会议到来的前一周，20国集团(G20)各国政府在媒体上发表的了一些声明。 据报道，日本计划在G20会议呼吁联合监管，以打击使用加密货币进行非法洗钱活动。与此同时，据知情人士透露，韩国当局正准备制定一项计划，允许国内投资者提供初始代币发行(ICO)， 以促进区块链技术的发展。 在G20这一重要会议上，区块链和加密技术以及如何对其进行监管是会议的讨论重点。这也表明该行业正在成为主流。由于会议结果可能会震荡“币圈”，所以我们认为这将是审查G20成员国现行监管情况的良机： 阿根廷是此处会议的主办方，也是采用比特币的最快国家之一。目前，阿根廷监管机构已采取鼓励创新的措施。事实上，阿根廷计划在期货市场提供比特币期货。 现状： 政府暂未进行监管。 澳大利亚没有具体的规定，但正在研究合适可行的方法。然而，澳大利亚交易与分析中心（AUSTRAC）最近更新了反洗钱法，要求提高加密货币的透明度。通过实施一个新的数字货币交易互换平台，数字货币的交易记录的具体细节将被要求披露在其平台上。 现状： 政府暂未进行监管，但着重于反洗钱和数字货币交易的透明度。 巴西似乎已经采取了最强硬措施，禁止投资加密货币，同时试图制定全面的监管措施。 现状： 禁止直接投资，未确认金融资产。 加拿大将自己定位为区块链技术创新的领导者。大量“矿工”涌入加拿大，加拿大中央银行甚至正在考虑为加密货币背书。但是，他们仍然对非法的交易活动保持警惕。 现状： 对加密货币的收入纳税。 中国对区块链和加密货币的态度非常有趣。一方面鼓励创新，另一方面采取最严格管制和控制。  现状： 禁止首次代币发行众筹（ICO），向各家地区交易所下发通知，叫停加密数字货币交易，出台相应措施打击比特币挖矿行为。政府希望下架那些提供用户登录入口的加密数字货币在线平台，或具有类似交易所服务功能的手机应用程序。 欧盟的各个成员国正在讨论如何协调整个欧盟的监管工作。 现状： 欧洲银行管理局此前向公众就虚拟货币相关风险发布警告，并于近期表示将采用反洗钱和反恐融资相关规定对虚拟货币进行监管。 法国、德国财长呼吁对加密货币加强全球监管。他们还成立了一个加密货币监管工作小组，特别关注打击逃税行为。 现状： 目前为止政府暂未进行监管，但是强调防止加密货币破坏全球金融稳定、给投资者带来风险。 德国（与法国一起）是在G20会议上支持应该对加密货币加强监管关键成员之一。他们似乎渴望帮助欧洲成为区块链和加密技术发展的主要枢纽，但各国应该合力监管。 现状： 承认加密货币是一种合法的金融工具，需要额外的许可证的同时也必须纳税。 印度认为应该对加密货币进行严密的监管，甚至暗示禁止加密货币的存在，因为认为它们简直无法监管。然而，印度在这个领域有很多创新，最近Zebi成功筹资，以及他们与邦政府建立的合作关系表明，目前存在回旋余地。 现状： 禁止使用加密货币进行支付，对洗钱和非法活动进行严格监管 印尼央行发布了一份新的声明警告投资者，比特币等加密货币的交易可能会给公众造成损失，甚至可能威胁到金融体系的稳定。但是虽然有强硬的态度，但是没有明确的立法。 现状： 政府暂未进行监管，但禁止金融科技公司使用加密货币进行交易 意大利正在制定立法草案，旨在对该国加密货币的使用进行分类，并列出与数字货币相关的服务提供商。不过，他们也注意到一些央行正在考虑鼓励加密技术的创新。 现状： 政府暂未进行监管。 2017年日本承认了比特币支付的合法地位，日本在对区块链、加密技术和监管的发展中处于领先地位。与此同时，日本政府对利用加密货币进行违法交易（如洗钱）和犯罪活动保持了高度警惕。 现状： 承认加密货币是一种支付工具并对其进行税收。 墨西哥立法机构通过了加密货币的监管法案。该法案指出，加密货币不是法定货币，加密货币如比特币应被视为商品，而不是货币。此外，该法案还试图将加密货币交易所的操作置于本国中央银行的监督之下。 现状： 法案通过，声明加密货币不是法定货币，应作为商品和并进行相关税收处理。墨西哥中央银行对加密货币交易所进行监督。 俄罗斯正在制定关于加密货币和ICO的联邦法律，并认为监管才是完善加密货币交易的方法，而不是彻底禁止。该法案涵盖了加密货币的创建，发行，存储和流通管理等过程的监管条例。 现状： 通过了加密货币和ICO监管立法，对ICO投资和广告进行了限制，对交易所的监管较为宽松。 沙特阿拉伯对加密货币监管的相当宽松，政府正在制定加密货币的监管规定，但彻底禁止不太可能。事实上，沙特阿拉伯和迪拜正在开展一项试点计划，测试如何使用新的数字货币来实现跨境支付，此举表明沙特阿拉伯对区块链和加密货币的潜力持积极态度。与此同时，一家由迪拜皇室成员创办的公司刚刚与Jibrel Network建立了合作关系，jCash加密货币显示了波斯湾地区有自顶向下支持的迹象。 现状： 可能引入一些监管加密货币的通用法案，禁止加密货币的交易不太可能。 南非政府正在实施对加密货币的监管，而且南非央行早在2014年就发布了数字货币白皮书。目前，南非政府正在研究加密货币的监管法案，在南非使用加密货币“不违法”，并且其价格会受税法的影响。 现状： 政府暂未进行监管，但有监管计划。 韩国是加密货币的主要市场，2018年1月份比特币交易的占比高达15％。由于韩国民众对加密货币的大力支持，政府不得不采取行动，并在一开始就取缔了加密货币的匿名交易。匿名交易现已被彻底禁止，但韩国政府正在放开对KYC交易的监管，正如之前指出的那样，他们正在考虑在新的监管条件下重新引入ICO。 现状： 不支持匿名账户交易（实名制），正在制定加密货币的税务法案，有可能引入ICO监管。 目前土耳其政府对加密货币暂未进行监管。事实上，据报道，土耳其的政治家正在寻求推出一种全国通用的加密货币。土耳其民族主义运动党副主席，前工业部长Ahmet Kenan Tanrikulu已起草了一份报告，提出一种由国家支持的名为“Turkcoin”的加密货币。 现状： 政府暂未进行监管。 到目前为止，英国对加密货币的监管采取了观望态度。但是最近，英格兰银行行长Mark Carney呼吁应该对加密货币采取严厉的监管措施。他指出，加密货币对当前金融体系尚未构成风险，但希望“将加密资产生态系统与其他金融体系执行统一标准”，以保护企业和个人的利益，防范非法活动。 现状： 政府暂未进行监管。 美国商品期货交易委员会（CFTC）和美国证券交易委员会（SEC）于2018年2月7日举行的听证会，受到了CFTC主席Christopher Giancarlo的大力支持，他本人也因此在Twitter币圈中受到了热捧。市场仍在消化美国众议院资本市场，证券和投资小组委员会当天的听证会的内容，虽然感觉听证会的辩论并未取得任何重大进展。 现状： 颁布了禁止ICO、洗钱和违法行为等相关法案，加密货币交易许可证计划生效。 区块链和加密货币的飞速发展不可避免地会引起政府和监管机构的注意。这些监管机构的态度将对这个行业未来的走向产生重要影响。但是，我们认为，对监管的关注是该行业演进和发展过程中非常重要的一步。 监管机构对于管理快速发展的科技市场越来越得心应手，并且从过去的管理案例中不断学习。 似乎大多数监管机构正在采取明智的做法，试图在与行业合作促进发展的同时放宽政策，制定一套最合适的法案来保护企业和个人的利益，并让市场蓬勃发展。 原文链接： https://medium.com/@Torquecapital/a-snapshot-of-current-crypto-regulations-of-all-g20-member-states-3b5f80ffac81 Have a Great Definition 
52,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658559&idx=1&sn=2205552572ca955fae8e23008dbba90b&chksm=bd4c3eac8a3bb7ba2a1e110772453a8b2f5532d5d61d3b204b9ebcc1dc9862f7ac23940962a9&scene=27,AI不仅能画画，还能编和弦了：谷歌这几年取得了哪些艺术成就？,本文经O'Reilly授权发布 大数据文摘字幕组作品 翻译：菜菜Tom、阿达、晓莉 监制：龙牧雪 在很多人的印象中，AI冰冷、生硬，和艺术无缘。但谷歌偏偏就不信。 谷歌大脑（Google Brain）有个Magenta项目，专门研究用TensorFlow和生成式模型来创造艺术作品，包括音乐、绘画作品等。他们的目的不是取代艺术家，而是为艺术家提供某些自动化协助，比如，编曲家可以用机器智能生成一段和弦。 项目代码已开源，请复制以下链接获取： https://github.com/tensorflow/magenta 感觉有点酷！让我们来看看Magenta项目负责人Douglas Eck是怎样介绍他们的成果的。 视频来自O'Reilly和Intel AI Conference 时长15分钟 带有中文字幕 ▼ 内含一段AI演奏的肖邦钢琴练习曲 不要错过欣赏机会 🎧 Magenta最近更新的博客文章里，详细介绍了MusicVAE音乐生成的相关技术细节。 博文链接： https://magenta.tensorflow.org/music-vae 最重要的是对潜在空间（Latent Space）的利用，即将高维数据转换成低维。 如果将一段音乐表示为时序数据，那么一定是高维的。比如，就单音钢琴来说，在任何时候，都可以按下或松开88个键中的一个。我们可以将其表示为90种类型的事件（88次按键，1次松开，1次休息）。 如果我们忽略速度并用一个16分音符作为时间单位，则两个4/4排的小节将具有9032种可能的序列（旋律）。如果扩展到16个小节，将会是90256个可能的序列，它比宇宙中的原子数量多很多倍！ 可视化来看的话，就是下面这样。这里是两小节随机的音符。纵轴代表钢琴上的音符，横轴代表时间。 但在潜在空间中，这些音符的表示是下面这样： 潜在空间能够表示低维空间中真实数据的变化。这意味着也可以通过潜在空间高精度地重建真实的数据。一种常见的模型是自动编码器（Auto Encoder）。 要生成一段音乐，需要模型学习较长的时间序列中的结构。在这里用到了一种分层解码器。 效果是，可以将一段旋律A和另一段旋律B相结合，生成一段“平均旋律”： 也可以用来给乐曲选择配器。 下面请欣赏AI配乐👇 听起来像是古典和摇滚乐的组合 对艺术创作者来说比较有价值的，是基于这些成果开发的一些小工具，比如下面这个工具，可以自动生成一些旋律，供编曲人员使用： 这个项目组内还诞生了一些有趣的交互作品，比如被写进“ ”的SketchRNN。 上面这张图说的是，基于谷歌开发的一个小游戏“QuickDraw”，研究人员收集了一批简笔画的数据，并用它们训练了一个模型，可以输出简笔画的图案。 有趣之处在于，人类的输入通常是脑洞大开的。 比如看上面的图片，左侧从上往下数第三组图案，人类输入了一只有5根胡须的猫。但是，机器认为一只“正常”的猫应该有6根胡须，左右各有3根，所以在输出图案的时候，就给这只猫多加了一根胡须。 同理，右上角的“8腿猪”显然也是超现实的，于是机器给我们画了一只正常的，2只眼睛4条腿的猪。 右侧第二组，人类给一个“猪”模型画了一辆卡车。以为机器会懵逼？没有。机器输出了一辆“猪猪卡车🚚”，或者说是，“卡车形猪猪🐽”？ 至于右下角输入牙刷那位，实在是爱莫能助了。不过还是能看出来机器给牙刷加的猫耳朵和胡子。 SketchRNN介绍页面： https://magenta.tensorflow.org/sketch-rnn-demo 你可以通过这个页面看其他人画过的一些样本，也可以点击Try Demo自己玩玩。首先你需要选择一个模型，模型加载完毕后，你就可以开始你的表演了，AI会根据你的笔画输出一个相应的图案。 文摘菌粗略看了一下，有100多个模型可以选择，什么蝴蝶、火烈鸟、手之类的都能画。随机试了一个“菠萝”模型，效果是这样的： 黑色的线条是文摘菌画的，绿色的线条是AI帮忙补全的。 生成简笔画和简单的和弦，AI能实现的这些功能对于艺术家来说还比较基础，但是在文摘菌看来还是挺神奇的！你觉得呢？ 正如Doug在演讲视频中所言，“我可画不出这么好的猪猪卡车！” 还没看够？参加今年北京4月10-13号的 跑步入场还 不晚哦。（ 报名咨询电话：010-88097476） 扫码使用大数据文摘专属8折优惠码WENZHAI报名，围观大咖👇 【今日机器学习概念】 Have a Great Definition 
53,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658496&idx=3&sn=dae1e684497b6861b42f3a8330a58c86&chksm=bd4c3e938a3bb78521218103e783b33b6d6fee66aa2155f048be4505311dfea390a02766ed08&scene=27,论文Express | 美图云+中科院AAAI2018：视频语义理解的类脑智能,"大数据文摘作品 近日，美图云视觉技术部门与中科院自动化所共同合作研发，提出一种基于类脑智能的无监督的视频特征学习和行为识别的方法NOASSOM (Nonlinear Orthogonal Adaptive-Subspace Self-Organizing Map)，该方法不依赖于标签信息，可以自适应地、无监督地学到视频的特征表示，相关成果已发表在AAAI2018。 大数据文摘就NOASSOM算法对美图云相关负责人进行了采访，针对NOASSOM效率问题，美图云告诉大数据文摘，NOASSOM由于引入核函数，在模型训练时的计算复杂度比ASSOM（Adaptive-Subspace Self-Organizing Map)）略高，但在提取特征时NOASSOM与ASSOM并无速度差异。 除了论文中提及NOASSOM可以提升识别率之外， NOASSOM是无监督特征提取方法，训练数据不需要标签信息。 而ASSOM是有监督学习，训练数据需要标签信息。 此外，美图云表示，该成果 计划被应用到美拍短视频相关业务场景中。 大数据文摘后台回复 “特征” 下 载论文PDF~ 以下是论文部分内容： 摘要 视频语义理解一直是学术界的研究热点之一。近两年随着短视频领域的火爆发展，围绕短视频的业务场景应用也在增长，工业界应用场景都对视频内容理解提出了迫切的落地需求。 与学术界用的确定性数据集不同，工业界业务产生的视频数据具有如下特点：首先，数据量大，每天都会有成千上百万的视频被上传；其次，内容未知，现实生活中的场景是很复杂的，尤其对于UGC内容，无法确定用户上传的视频中的主体和场景，行为更是无法预测；再次，时效性， ，它可能会随着时间发生变化进行转移。 因此，在这样的数据集上人工建立标签体系非常困难。NOASSOM算法的提出有效解决了算法模型在训练过程中无标签输入的问题。 NOASSOM算法原理 NOASSOM是通过模拟视觉皮层中表面区域的结构来构建的，以数据驱动自组织更新，恢复基本视觉皮层中的神经元对输入刺激的反应。 NOASSOM是对ASSOM方法的改进。 ASSOM是一种特征提取方法，它可以从输入数据中学习统计模式，并对学到的模式进行自组织排列，从而进行特征表示。但是ASSOM只能处理有标签的数据，并且只对线性化的数据有效，无法胜任其他复杂情形。 NOASSOM的提出解决了ASSOM对数据的限制问题。首先，NOASSOM通过引入一个非线性正交映射层，处理非线性的输入数据，并使用核函数来避免定义该映射的具体形式。其次，通过修改ASSOM的损失函数，使输入数据的每个样本可以独立地贡献于损失函数，而不需要标签信息。下图示意了NOASSOM与ASSOM的网络结构区别。 NOASSOM与ASSOM网络结构 NOASSOM算法模型 ASSOM由输入层、子空间层、输出层组成。NOASSOM比ASSOM增加一个非线性正交映射层，用于实现输入层和子空间层的非线性正交映射。为保证映射后的子空间基向量仍然保持正交性，NOASSOM采用正交约束的核函数： 输出层使用输入在子空间的投影表示： 使用投影残差构建损失函数： 原始的ASSOM的损失函数表示如下： 通过修改损失函数使每个样本独立地贡献于损失函数，而不必使用Class-specific 的数据进行有监督训练。NOASSOM使用随机梯度下降法对网络进行训练。 在每次迭代之后，重新对基向量进行正交化处理。算法流程图如下： 本文还提出一个层级的NOASSOM来提取高层的抽象特征，有效地描述视频中行为轨迹的表观和运动信息，构建了一个层级的NOASSOM结构提取视频中的局部行为特征，并使用FISHER VECTOR进行聚合编码，采用SVM进行分类，如下图所示： 层级NOASSOM 特征提取框架 实验及结果 NOASSOM在国际公开大型数据集UCF101, HMDB51和小型数据集KTH上进行了评测，识别获得了93.8%，69.3%和98.2%的识别率。不同算法识别率如下表所示： 在UCF101数据集上，与手工特征（iDt）+HSV基准方法和iDt+CNN方法相比，NOASSOM的识别率分别高出5.9%和2.3%；在HMDB51数据上，NOASSOM的识别率分别高出8.2%和3.4%。公开数据集上的实验结果表明， NOASSOM中训练得到的基向量的可视化结果如下图所示，左边是表观信息滤波器，右边是运动信息滤波器。表观信息滤波器通过学习可以检测到图像一些边缘信息，进而利用其对图像的水平边沿和垂直边沿进行检测，从而提取良好的轮廓纹理信息。右边的运动信息滤波器学到了一些类似Gabor滤波器学到的信息，这样的滤波器对运动信息更加敏感，实现对运动信息地鲁棒性提取。 NOASSOM中基向量的可视化结果 结论 NOASSOM方法的独特优势在于，可以从大量没有标签的数据进行更加快速的训练，并且获得和其他基于有标签数据方法性能相当甚至更加优越的性能。 基于这项技术的输出将被应用于美拍短视频多个业务场景中，如相似视频的推荐和大规模视频检索，基于短视频内容的用户聚类和画像，以及基于短视频内容的运营标签挖掘等等。 大数据文摘后台回复 “特征” 下载论文PDF~ Have a Great Definition "
54,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658516&idx=2&sn=26b11419359d8087156e182899bb3666&chksm=bd4c3e878a3bb7914be44e9911e9e96127c902623de9e6c89ca663a3be5d54d4c9f884ee7b78&scene=27,教育部最新：283所高校获批数据科学与大数据专业（附完整名单+公益计划）,大数据文摘作品 我国高校开设大数据本科专业，今年已经是第三年了。 3月21日下午，历时近一年时间，教育部公布了2017年度普通高等学校本科专业备案和审批结果的最新通知，第三批大数据本科专业院校获批。 教育部通知链接自取： http://www.moe.gov.cn/srcsite/A08/moe_1034/s4930/201803/t20180321_330874.html 2016年2月，北京大学、对外经济贸易大学、中南大学首次成功申请到“数据科学与大数据技术”本科新专业。2017年3月，第二批32所高校获批。至此，共有35所高校正在筹备“数据科学与大数据技术”专业，该专业学制为四年，授予工学学位或理学学位。有不少传言称，正在申报该专业的高校有不下几百所。 此次教育部最新公布的高校新增专业名单中，有248所学校获批，是过去两次审批通过额度近8倍。 第1、2、3批共283所获批高校完整名单： 图片可以上下滑动哟 据大数据文摘统计，在之前获批的所有高校名单中，河南省获批高校数量最多，达22所，北京次之，19所。安徽、广东、山西、河北次之。 看一下详细分布情况： 其中，985及211高校共36所，占比13%。 当被问及团队发展最大的挑战时，猎聘的首席数据官单艺对大数据文摘脱口而出：“首先是人才，高素质的数据人才太稀缺了”。 这似乎是个颇尴尬的场面：猎聘，这家致力于中高端人才招聘多年的互联网人力资源服务公司一直引以为傲的数据团队，竟然也面临着人才招聘的“老大难”问题。 而这个招人难的局面不止在猎聘存在，清华数据科学研究院执行副院长韩亦舜称，目前国内数据人才缺口是百万级的。 不止中国，全球的数据人才都处于极其稀缺状态，全球最大的人才社区领英LinkedIn也向大数据文摘透露过同样的招人难题（点击查看大数据文摘相关报道 ）。它们正无比真实的折射出一个数据团队建设的巨大难点：数据人才的奇缺。 教育部和各大高校显然也意识到了这个巨大的缺口，数据科学人才培养与学科建设自2016年2月，已经被提上了日程。 那么为什么要把大数据人才单独提出来说，它和之前的人才培养差别在哪里？大数据文摘曾经就此问题采访了清华数据科学研究院执行副院长韩亦舜。 “一方面，过去的各种学科建设成熟后都有自己的一定范围，‘自己给自己挖井’，边界清楚；但是另一方面也陷入了很深很狭隘的范围。”韩亦舜提到。 2014年4月26日，清华大学成立了“数据科学研究院”。作为国内首批培养数据科学人才为主要工作任务的研究院，清华希望培养更多有跨界意识和跨界实践的人才。 清华数据科学研究院主页👆 好的大数据应用型人才应该既懂得大数据，又懂得相应的产业知识（industry domain）。基于此，清华一方面希望各专业学生都对大数据知识有所了解，另一方面在课程实践上，希望文理同学组队在一起，在触碰实际问题的时候，也在产业界比较有经验的指导老师指导下进行课题研究，丰富自己的知识结构。 谈到数据科学人才培养，韩亦舜在这些年的实践中也总结了不少思考：“之前说要T字人才，一专多能，现在一专已经不够了，可能要两专甚至三专，这是社会发展的需求。类比当年发明显微镜的时候，其实给点时间，人类还是会找到如何和这么大量的数据相处的方式。” 尽管各方都意识到了人才培养的重要性，到底如何培养好的数据科学人才，还是个悬而未决的大问题。 目前全国各类高校、高职院校已陆续开始围绕大数据专业建设展开研究并申报大数据专业。但是即使获批专业，优秀的师资队伍和课程体系也不容易建成：作为交叉型学科，大数据的相关课程涉及数学、统计和计算机等学科知识。 “数据科学与大数据技术”专业强调培养具有多学科交叉能力的大数据人才。该专业重点培养具有以下三方面素质的人才： 理论性人才，主要是对数据科学中模型的理解和运用； 实践性人才，主要是处理实际数据的能力； 应用性人才，主要是利用大数据的方法解决具体行业应用问题的能力。 那么，主要的数据科学人才和师资来源于哪里呢？ 数据科学专业在高招时主要划分在这两个院系下：计算机派和数学统计派。此外，一些应用学科，比如金融专业、经贸等也会在自己的专业下设置相关课程。 中国人民大学统计学院赵彦云院长曾就数据科学本科专业设置思路，发表过自己的看法：“谈论大数据是时代话题，拥有大数据是时代特征、解读大数据是时代任务、应用大数据是时代机遇。” 在此背景下，开展基于数据分析、计算科学与计算机科学充分融合（即数据科学）的科学研究和人才培养工作已经十分必要和迫切。 虽然已经有高校开始进行大数据学科建设，但是在全国范围内还有很多大学无法开设大数据相关课程，培养大数据分析人才。这当中存在很多阻挠因素： 1.学习门槛高 数据科学是一门交叉学科，除了计算机相关知识，还需要有统计学、数学基础，以及一定业务知识，这无疑增加了学生学习的难度。 2、投入资金高 众所周知，大数据相关技术需要的资源配置比较高，这也妨碍了许多高校大数据专业落地实施。 3、可借鉴经验不足 数据科学是新兴学科，今年是数据科学与大数据技术本科专业获批的第三年，即便在高校中，专门研究此领域的老师也比较少，许多高校对于完整的数据科学人才培养体系还没有一套成熟的规划方案，而可以借鉴的经验也很少。 4、动手机会少 要进行大数据分析，首先必须有充足的高质量数据。然而，多数高校缺少企业项目实战案例和可以用于研究的商业数据，使得学生难以做到学以致用。 要解决数据科学动手难的问题，不同高校也在做自己的探索。 为助力我国大数据和人工智能人才培养，加快建设大数据和人工智能一流学科，北京清数教育科技公司联合清数大数据产业联盟，中关村大数据产业联盟、北京大数据协会、清华数据创新基地共同推出“数据科学与大数据技术”清数2018公益计划。 清数2018公益计划将向100所高校免费提供： 1.师资培训服务（包括15门mooc平台在线课程） 2.大数据实训平台使用权限一年（配套人工智能实验和科研平台资源） 3.数据科学与大数据技术专业建设咨询及论证。 申请加入计划，请点击文末 【今日机器学习概念】 Have a Great Definition 
55,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658496&idx=2&sn=1cfb5dcf08c18a3079c131fcaf6f2c2b&chksm=bd4c3e938a3bb785fd3ea51c322e254ef1d6929690d3f4a550a17abf355bd34f1095aeb04ae4&scene=27,业界 | 成为CTO之前，我希望有人告诉我这些,"如何成为一位合格的CTO，在成为CTO之前又需要哪些职业素养，即将离职的 SketchDeck CTO讲述他在过去四年担任此职位的经验。 这是一段刺激又美妙的体验，在创业公司工作与传统的任职大不相同：一开始，你完全不知道公司是否会成功，也不知道它会不会变成一份全职工作，之后，随着公司的发展，你体验着新的各不相同的职位。总的来说，你会经常做着你曾经从未做过的工作。在你还未充分利用手中的权力之前，新的责任已经来到了你的面前。 创业公司像大海中小船，能够灵活处理突发事件，但是你在第一天做出的决定会随着时间的推移不断往外产生涟漪。我现在知道的是，你选择的基础建设、框架结构和语言都将在未来的很长一段时间里伴你左右。 随着公司的成长，构建更多功能和子系统的重压会不断增大，每一个都将进一步锁住你的选择。伴随你获得更多动力的，是压力的持续增加，这时你再想停下来重新修改这些已经不可能了。 我对我们的选择非常满意：Amazon Web Services, Elastic Beanstalk, Firebase, AngularJS, Coffeescript, Kafka, Simple Queue System, SocketStream, Docker, SemaphoreCI, MySQL。列表中，仅有 AngularJS和MySQL在规模方面存在问题。我们的整个AngularJS代码包太大了，下载需要相当长的一段时间，应用程序也有点太慢了。随着BI查询复杂性的增加，（RDS中的）MySQL会崩溃并重新启动，这个问题很难解决。 众所周知，一项技术的生命周期惊人的短。CoffeeScript和AngularJS是已经过时的组件（我们计划迁移至TypeScript和最新的Angular）。当我们采用这些技术的时候，他们都相当的先进，真是庆幸，我对前沿科技的偏爱并没有引起任何严重的问题。我极其欣赏CoffeeScript ，因为其简洁的功能性语法，这些年里它极大地帮我大大提高了生产效率。 基于以上，你得明白你需要准确计算预算时间，并为技术的更替制定策略。你在采用任何技术时都得接受长期的“技术债务”。 同样，你编写的组件和库将长期存在，不管你写得好不好，他们的状态一直都会这样——所以，为将来的维护人员着想，你最好多花一点时间在上面。 我们试图在我们所处理的代码领域进行小幅改进。有时，考虑到代码库的（总是不完美）的总体状态，可能会有压力，此时，我就会进行不断的小改进。 最后，是关于测试的简短说明：我发现让我们的团队编写测试代码真的很困难。我为我们系统中的很多部分都编写了测试用例，并配置好了测试服务器，在每次有代码提交的时候会自动运行。 我总是希望团队里能够重视测试，但是不尽如人意。以下是我解决这个问题的想法： 开设有关如何编写测试的复习课程； 要求重要功能包括至少一个测试； 优化我们的测试服务器，使之在10秒钟内完成而不是10分钟（哎！），让程序员及时看到测试结果。 除了纯粹的技术决策之外，一名CTO还应兼顾人员管理。每天的大部分工作将是管理，领导，招聘和解雇人员。我不得不将学习这些贯穿始终。当然随着实践的进行，对这些流程会越来越熟练。 虽然员工是公司最宝贵的资产，但招聘员工的过程同样让人精疲力尽。相比收获了新入职的人，你可能需要花更多的时间来考虑雇用和拒绝更多的人。你可能需要更严格地过滤。我从未想到完美的创业团队成员是多么难得，也没想到会花如此多的时间和精力来寻找他们。 明确何时招人也是一个棘手的问题： 这些问题在你得到投资之后会尤其突出，因为你觉得你有义务让这些资金发挥最大价值。幸运的是，我们从Michael Siebel和YC那儿收获了一些具有帮助性的建议： 当你感觉某个职位需求非常迫切的时候才开始招聘（比如快赶不上合同进度了的时候）： 招人是为了满足业务发展的需要，不能本末倒置（这条主要适用于还没有形成规模化的早期公司）； 不要招人来做一些你都还没想明白的事情（一些优秀的候选人也许能给公司带来新的动力，但通常的做法还是靠“有魔力”的创始人配置公司资源来适应新的发展）。 综上所述，如果你不确定是否需要为某个岗位招聘员工，可能做这个决定为时过早。我们也曾试图雇人来给公司实现我们自己也没有计划好的增长方案，但大部分时候都失败了。 员工管理一直相对比较顺利 —— 定期开诚布公的检查，明确什么是该做的，什么是不该做的，这些措施让我和我的员工保持着良好的关系。 管理人员一直相对比较顺利—— 我发现解雇员工是工作中很棘手的问题。你能从其他地方找到很多有用的建议，我在这儿简单地重申一下，早在你理性地决定和正式解雇一个人之前，你的直觉就已经做出判断了，但是解聘员工的这个过程非常痛苦。 良好的定期交流有助于双方接受最坏的结果。最后，基于一份个人发展计划，有一部分人真的能够应付自如，成为高效的团队成员；每个人都应该有这样的机会去展示自己。 伴随公司发展的一大乐趣就是看到一些优秀的人才在各自的领域能够独挡一面。在此，我要向我的整个团队致以诚挚的敬意和祝贺。 原文链接： https://medium.com/sketchdeck-developer-blog/what-i-wish-i-knew-when-i-became-cto-fdc934b790e3 Have a Great Definition "
56,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658496&idx=1&sn=6cf3709d31ba2576b66455436ea092ab&chksm=bd4c3e938a3bb785b358ca381fa2ad4748a619bf34901400459501afc8281eda5e9a9fbf71f9&scene=27,助特朗普胜选、英国脱欧，深扒FB丑闻背后的神秘数据公司如何玩转人心,"大数据文摘作品 作者：钱天培、邱猛、龙牧雪、魏子敏 美国时间 3月19日，星期一，Facebook股价暴跌7%，一天内市值蒸发近400亿美元。在“数据泄露丑闻”发酵之下，这一暴跌并不意外。 上周五，特朗普（Donald Trump）聘用的一家政治AI公司剑桥分析（Cambridge Analytica），被曝非法将大约5千万Facebook用户的信息用于大数据分析，从而精准刻画这些Facebook用户的心理特征，并向他们推送定制广告，甚至假新闻。 这些用户信息由剑桥大学心理学系讲师Aleksandr Kogan通过App“thisisyourdigitallife”以学术研究为目的收集，但数据却被转移至第三方，即剑桥分析公司。 令人不解的是，Facebook在2年前就已得知Kogan的不当行为，并曾要求其销毁所有数据，但并未采取进一步行动，直到被媒体大规模曝光。 这起丑闻持续发酵，甚至被称作是“Facebook、谷歌等科技巨头结束垄断的转折点”。 而据海外媒体VICE一年前的一篇调查报道，这家政治AI公司或许还曾用同样的手段助推了“英国脱欧”事件。 要了解这家公司的“数据魔术”，让我们先来了解其涉及到的一门有趣的学科——“心理测量学”。 大数据营销和个性化推荐早已不是什么新鲜事，但这家在当时尚不知名英国公司的分析方法的确有所不同。 基于人口统计学的选举拉票活动基于非常有限的数据信息：所有的女人因为她们的性别收到同样的信息，或者所有的非裔美国人因为他们的种族收到同样的信息。而当其他的选举活动还依赖于人口统计学的信息时，剑桥分析已经采用了心理测量学分析了。 “基于性别或种族来拉票的想法是荒谬的。我们的预测基于大五类人格（OCEAN）模型。” 剑桥分析将美国的人口分为32类性格特征，并集中关注17个州。基于一个App应用，每一位特朗普竞选团队的游说者都可以精准了解到每栋房子中的住户的性格、喜好，总之，他们对你会不会投票了如指掌。 早在2016年9月，剑桥分析公司的CEO Alexander Nix就曾在Concordia Summit（迷你版的世界经济论坛）上公开分享大数据和心理测量学助力选举的秘诀，演讲题目是：The Power of Big Data and Psychographics in the Electoral Process。 戳这里看演讲视频👇 这些都发生在剑桥分析被曝光非法使用Facebook用户数据之前。 丑闻发生后，被曝帮助剑桥分析公司搜集数据的Aleksandr Kogan的简历已被迅速从剑桥大学官网撤下，只剩网页快照。 谷歌搜索“Aleksandr Kogan”结果，剑桥大学官网介绍页无法打开 网页快照显示Aleksandr Kogan任职于剑桥大学心理学系，研究领域涉及多种情感和心理健康，研究方法包括利用大规模数据集。 心理学和大数据，就这样被联系到了一起。 而早有人嗅到了可疑气息。 2017年1月，海外媒体Vice曾发出一篇原载于Das Magazin的德语文章，作者Hannes Grassegger和Mikael Krogerus。 文章详细报道了剑桥大学心理测量中心的另一位研究员Michal Kosinski如何开发基于Facebook点赞信息的大五类人格测试模型，而和剑桥分析有业务往来的Kogan被认为从Konsinski处获得了该研究方法，Konsinski亦表示了对Kogan及其与政治分析公司之间联系的担忧。 文章链接如下，感兴趣的读者可以自行查阅： https://motherboard.vice.com/en_us/article/how-our-likes-helped-trump-win Michal Kosinski现任斯坦福大学教授 本质上，“大数据”意味着我们在线上和线下的一切活动都会留下数字痕迹。我们的每一笔刷卡消费，每一次谷歌搜索，揣着手机时我们的每一个移动，每一次在社交媒体上点赞，都会被记录下来，并可能被用于针对性的营销。 举个例子，在我们刚搜索完“降血压”后，屏幕上就可能弹出降压药物的广告。 特朗普总统竞选活动的幕后推手，剑桥分析（Cambridge Analytica），正是这样一家“大数据”公司。而随着层层剖析，多家媒体也指出，它可能也曾参与英国脱欧。 让我们从2014年的剑桥大学心理测量中心开始说起。 心理测量学是一个由数据驱动的心理学分支，有时也被叫做心理图像学，主要致力于研究心理上的特征，比如人格。上世纪80年代，心理学家发展出了一种基于五种人格特征来评估人类的模型，就是著名的“大五类人格测试”。 “五类”人格分别是： 开放性（你对新的体验有多开放？） 严谨性（你有多追求尽善尽美？） 外向性（你有多爱好社交？） 宜人性（你有多体贴，多容易合作？） 神经质（你很容易沮丧吗？） 它们也被简称为OCEAN，即英语单词（Openness, Conscientiousness, Extroversion, Agreeableness, Neuroticism）的首字母缩写。基于这些维度，科学家可以对人格类型做一个相对精准的评估。这些预估包括一个人的需求和恐惧，以及未来行动。 “大五类人格测试”已经成为心理测量的标准技术。但是，在很长一段时间里， 这是因为它涉及一份复杂的、高度私人性质的问卷的填写。 然后，网络出现了。接着是Facebook。再接着是Kosinski。 Michal Kosinski2008年进入剑桥大学心理测量中心攻读博士，这是该领域在世界范围内最古老的研究中心之一。入学后，Kosinski加入了他同窗David Stillwell（现在是剑桥Judge商学院的讲师）的项目组。那时Facebook还没有如今的规模。 Kosinski项目组“我的人格（MyPersonality）”App能让用户参与填写不同的心理测量问卷，包括大量来自“大五类人格测试”问卷上的心理测试题（如“我容易惊慌”，“我爱反驳其他人”）。基于这项评估，用户会收到一份“人格侧写”报告，内容包括用户的“大五类人格”数值，用户可以自行决定是否授权将他们的Facebook个人简介分享给研究人员。 一开始Kosinski以为只会有几十个大学朋友来填问卷，没想到不久之后，几百、上千，甚至几百万的人参与了进来，展现了他们的内心世界。 通过问卷，心理测量学家计算出答题人的“大五类人格”数值。然后，Kosinski的团队将计算结果和测试对象的其他网络数据进行对比，比如他们赞了什么，在Facebook上分享了或发了什么，或他们填的性别、年龄和住址。这种方法使研究人员能够把信息串联起来，使其相关。 基于简单的网上行为，他们就能得出相当可靠的推演。 举几个例子，“赞”了化妆品牌MAC的男性有较高的可能性是同性恋；同性恋最好的指标之一是是否喜欢Wu-Tang Clan（美国Hip-pop组合）。Lady Gaga追随者们极有可能是性格外向的人，而那些“赞”了哲学相关内容的人则更可能偏内向。 Lady Gaga演唱会，图片来自网络 虽然，任何一个单独的此类信息都不足以让他们得到可靠的预测， 2012年，平均凭借一个Facebook用户的68个“赞”，Kosinski模型就能够估计出他们的肤色（准确率为95%）、性取向（准确率为88%）和党派（民主党或共和党，准确率为85%）。 除此之外，他们的智力、宗教信仰，以及酒精、烟草和毒品的使用情况，全都可以被预测出。从这些数据入手，这一模型甚至有可能推测出某人的父母是否离异。 点“赞”数超过300个时，Kosinski甚至能比实验对象更了解他们自己。 就在Kosinski发表了这些发现的当天，他收到了两通电话：一个诉讼威胁和一个工作邀请。这两个都来自Facebook。 仅仅数周之后，Facebook的“赞”的功能就被默认为仅自己可见。而在那之前，默认设置是点“赞”对所有人可见。不过，这样的变化不会对数据采集者造成什么困难：很多的App和网上的测验都会要求用户关联Facebook账户，并允许其访问用户私人数据，以此作为进行人格测试的前提条件。 更令人担忧的是，Kosinski和他的团队现在已经能够单纯地从一个人在Facebook上的头像或联系人的数量（外向性的一个很好的指标）推算出五类人格数值。 同时在线下，我们也留下了不少痕迹。举个例子，我们手机内置的运动传感器透露了我们的移动速度和移动距离（和情绪的不稳定性相关）。Kosinski总结道：我们的智能手机是一份我们一直在填写的巨大问卷，不管是有意识地还是无意识地。 最重要，同时也是最关键的是，这种方法反过来也奏效。 可以找到所有焦虑的父亲、愤怒的内向的人，抑或甚至是摇摆的民主党员。本质上，Kosinski发明的是某种类似于人类搜索引擎的东西。他开始认识到他的“作品”的潜能，但同时也看到其内在的危险。 大约在2014年年初，一个名叫Aleksandr Kogan的心理学助理教授找到Kosinski，说他代表一家对Kosinski的方法感兴趣的公司来询问，想要访问MyPersonality数据库。一开始，Kosinski和他的团队考虑了这个提议，因为这意味着能给研究中心带来一笔可观的收入。可是之后他犹豫了，因为Kogan透露了公司的名字：SCL，Strategic Communication Laboratories。 “（我们是）最佳的选举管理机构”，公司的网站上这样写着。SCL依靠心理建模提供销售（服务）。公司一个核心特色是：影响选举。 这到底是一家什么公司？这些人又在计划些什么？ 在那时，Kosinski不知道的是：SCL是一组公司的母公司。到底谁拥有SCL？SCL有哪些分支？因为其复杂的公司结构，这些都不得而知。 2013年，SCL分拆出一家新公司用以参与美国大选，名为剑桥分析（Cambridge Analytica）。 进一步调查后，Kosinski发现Aleksandr Kogan已经秘密地注册了一家公司，并和SCL有生意往来。从一份2015年12月刊登在卫报（The Guardian）的报告来看，SCL已经从Kogan那里掌握了Kosinski的方法。 Kosinski怀疑，Kogan的公司可能已经仿制了基于Facebook点赞数据的大五项类人格测量工具，并将它卖给这家选举影响公司（SCL）。他立刻与Kogan中断联系，并向中心主任报告了此事。此后，Aleksandr Kogan搬去了新加坡，结婚，并将自己的姓改成了Spectre。 约一年后， 剑桥分析的核心优势是新的政治营销，即微瞄准（micro-targeting），依靠五项人格（OCEAN）模型从用户的电子足迹中测量出他们的人格。 英国脱欧，图片来自网络 “英国退出欧盟”的公投结果宣布后，Kosinski不得不解释说他和剑桥分析公司没有任何联系，尽管这家公司名字中有“剑桥”二字。到底剑桥分析和英国脱欧运动有多深的牵连，我们不得而知。剑桥分析自己也不会去谈论这样的问题。 过了几个月，2016年9月，仅仅在美国总统大选的前一个月，在纽约Concordia Summit（世界经济峰会的迷你版）会议上，剑桥分析首席执行官Alexander Nix被邀请做了个演讲（演讲视频见这篇文章开头）。多数出席者都知道这就是特朗普新任的数字战略家。 与此同时，希拉里·克林顿则严重依赖于历史上首位“社交媒体总统”奥巴马的经验方法。她不仅拥有所有民主党人士的邮件列表，任用了来自BlueLabs的最前沿大数据分析师，而且得到了Google和DreamWorks的支持。 在2016年6月，当特朗普宣布聘请剑桥分析参与他的选举活动时，华盛顿的当权者们都嗤之以鼻。这家公司主要由美国的软件亿万富翁Robert Mercer（同时是2014年自然语言处理顶会ACL终身成就奖获得者）秘密赞助。而他女儿Rebekah也在后来被报道为剑桥分析的最大股东。 在演讲中，Nix解释说，到目前为止，选举拉票活动的策划都是基于人口分布的、而不是基于心理学特征。剑桥分析的大数据营销技术是基于三个要素：利用大五类OCEAN模型的行为科学，大数据分析和广告定位。广告定位即个性化广告，它通过尽可能找准消费者的个性，采取相应的广告策略。 “在剑桥，我们能够用一个模型来预测每一个美国成年人的人格。”Nix透露。 Nix坦率地描述了整个分析过程。首先，剑桥分析公司从各种不同的渠道（数据经纪公司Acxiom和Experian等）购买了人口数据，如土地登记、汽车数据、购物数据、奖励卡、俱乐部会员、杂志购买、教会活动数据。假如你想知道犹太妇女们住在哪里，以及她们的电话号码，你可以简单地购买这些信息。 剑桥分析将这些数据和共和党选民名册以及网上数据结合起来，并且计算出五大人格特征轮廓。数字踪迹在处理器中变成了为现实的人，这些人具有真实的恐惧、需求、兴趣和住所。 这个方法看起来和Michal Kosinski曾经研发的方法非常相似。剑桥分析也运用了社交媒体的调查和Facebook的数据。“我们描绘了共2.2亿人的性格特征。”Nix说道。 “这是我们为Ted Cruz选举活动准备的数据表。”  左边是图表；右边是爱荷华州地图，Ted Cruz在爱荷华州赢得了大量的选票。在地图上，有成千上万的小红点和蓝点。Nix缩小了条件范围：“共和党”，然后蓝点消失；“仍未被说服的”，更多的点消失了；“男性”，等等等。最后，只有一个名字还保留着，包括了年龄、住址、兴趣、个性和政治倾向。 那么，剑桥分析是如何为这个人定制他所看到的政治消息的呢？ Nix展示了如何用心理特征给选民进行分类以区别对待。例如，同样是关于美国第2次修正案持枪权利的报道，会被配以不同图片。“对于一个高度神经质和谨慎的人，我们会展示入室盗窃以及持枪的保险政策威胁。”Nix左边的一个图像显示了入侵者砸窗的手。 “相反，对于一个传统并和蔼可亲的观众——那些关心传统、习惯和家庭的人，我们则会展示这张图。”Nix右边的图像是一个男人和一个孩子站在夕阳下，手里拿着枪，正在射击野鸭。  据Alexander Nix回忆，在特朗普和克林顿的第三次总统辩论之日，特朗普的团队为他的论点测试了175000种不同的广告语，以便通过Facebook分析找到最合适的版本。 不同信息的区别其实是很微小的。为了用最佳的心理学方式定位到接受人，他们采用了不同的标题、颜色、字幕，附带了一张照片或视频。这种微调的方式可以触及到最小的群体，Nix在采访中说，“我们可以为某一个村庄、公寓、甚至个人定制消息。” 例如，在迈阿密的某个小区，特朗普的竞选活动为居民提供了克林顿基金会在海地地震后赈灾失败的消息，以阻止他们投票支持希拉里。这是特朗普竞选的一个目标：让潜在的选民，包括摇摆不定的左翼选民、非裔美国人和年轻女性，远离投票箱，也就是“抑制”他们的投票。 一位高级竞选官员说，这些以Facebook付费广告形式传播的“黑帖”只能由特定的用户看到。这些帖子包括针对非裔美国人的视频，比如某一条视频指出希拉里称黑人为猎食者。 Nix在Concordia峰会上做演讲时指出，传统的地毯式广告已死。在演讲结束前，他宣布：在Ted Cruz退出竞选后，公司正在帮助另一位总统候选人竞选。 特朗普， 图片来自网络 特朗普的数字化部队非常精准地瞄准了美国民众。但这是看不见的，因为他们的信息较少通过主流电视传播，更多的则是在社交媒体或数字电视上出现的个性化的信息。 彭博社记者Sasha Issenberg在访问圣安东尼奥的时候，惊奇地注意到这里是特朗普的数字竞选的基地。 入驻特朗普竞选团队的剑桥分析只由十几个人构成，他们7月从特朗普手中收到100000美元，8月收到250000美元，而9月收到了500万美元。据Nix透露，公司总共赚了1500万美元。（该公司在美国成立，其中有关个人资料发布的法律比欧盟国家更宽松。欧洲的隐私法要求只有经过个人“选择同意”后才能泄露个人信息，而在美国则允许个人信息泄露，除非个人“提出反对”。） 这些数字手段是前所未有的：2016年7月起，特朗普竞选团队的每个游说人都被提供了一个App，他们可以确定任意一幢房子里的居民的政治观点和性格类型。 这一程序提供商和“英国退欧”人士使用的程序是相同的。特朗普的工作人员只选择访问那些App预测会接受他们游说的人。拉票准备是根据居民的人格类型进行的。反过来，游说团队会把他们游说过的人的反应反馈到那个App中，而新的数据由此流入了特朗普竞选团队的数据库中。 而这并不是什么新鲜事。 民主党也做了类似的事情，不同的是，他们并没有依赖心理学分析。剑桥分析的厉害之处在于，他们将美国的人口分为32类性格特征，并集中关注17个州。正如Kosinski所发现的，喜欢MAC化妆品的男人更可能是同性恋者。该公司发现，偏好于美国制造的汽车的人，是特朗普的潜在选民。这些研究结果表明特朗普的讯息在那里发挥了最好的效果。在数据分析的基础上，他们决定在竞选的最后几周里关注密歇根和威斯康星州。而特朗普就此成为了实施大数据模型的媒介。 但心理测量方法在何种程度上影响了选举的结果？ 美国大选后，相关研究者也进行了研究来回答这一问题：初步结果是惊人的，研究表明人格定位十分有效。将不同的消息对应到不同性格特征人群的方法，使得营销人员可以为Facebook上的广告活动吸引最多63%的点击率，并促成1400次以上人们的决策转变。他们进一步展示了个性化营销的可扩展性——他们发现大多数的Facebook页面推广产品或品牌都受个性的影响，大量的消费者可以通过一个单独的Facebook页面被准确定位 。 和希拉里·克林顿相比，特朗普在数字竞选的投入远高于电视竞选。Facebook最终被证明是最好的竞选武器和最好的竞选支持者。 不管答案如何，无法避免的结果是，世界已被翻转。 大不列颠离开了欧盟，特朗普当选了美利坚合众国总统。而在斯坦福，反对把心理学定位运用到政治领域的Kosinski持续收到了指责他的邮件 。 他只能摇头说：“这不是我的错，我没有制造出炸弹。我只是证明了它的存在。” 【今日机器学习概念】 Have a Great Definition "
57,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658457&idx=3&sn=47f5a566ce9315eedbc043aca4c8d8e3&chksm=bd4c3f4a8a3bb65c53a6530aa4382a813f8d3c6dcacbaeca2babd049637a76c31795b9125975&scene=27,快讯 | 周志华获聘为南京大学人工智能学院院长,大数据文摘作品 据澎湃新闻报道，长江学者，南京大学计算机系教授周志华已于2018年3月13日起，获聘任为南京大学人工智能学院院长（兼）。 3月6日，南京大学新闻网正式宣布成立南京大学人工智能学院。 据南京大学新闻网消息：“近年来，随着全球人工智能技术飞速发展，人工智能已成为各国彰显创新实力的必争之地。2017 年国务院印发《新一代人工智能发展规划》，从国家层面对我国人工智能的发展道路进行了战略部署。 2018 年 3 月 5 日李克强总理的政府工作报告中四次提及智能，并特别指出要 、 。成立人工智能学院，是南京大学顺应国际科技发展趋势、打造学科发展生态体系、更好地服务国家与地方建设的又一重大举措。” 周志华教授从事人工智能研究20多年，是国内人工智能研究的代表人物。周志华主要专注于人工智能、机器学习与数据挖掘领域的研究，著有《Ensemble Methods: Foundations and Algorithms》、《机器学习》等，并在重要国际学术期刊和会议发表论文80余篇，获得发明专利11项。 2017年8月，周志华在国际人工智能联合会议（IJCAI）上当选IJCAI2021的程序委员会主席。 2017年9月，欧洲科学院公布2017年院士增选人员，周志华当选欧洲科学院外籍院士。 周志华表示，人工智能方面的人才需要掌握庞大的知识体系，包括坚实的数学基础、计算和程序基础，人工智能的专业知识，分析建模能力，这已经超出目前计算机专业的培养内容。“ 具体的课程设置必须考虑到核心类课程如机器学习、知识表示与处理、技术支撑类如模式识别与计算机视觉、自然语言处理、自动规划、多智能体系统、 计算智能等，平台类如机器学习系统平台、机器人、智能系统等。” 关于人工智能的就业前景，周志华教授称，目前，人工智能领域，人才稀缺：“以现在团队培养的学生来说。我们的学生在就业的时候，基本不需要走正常的校招， 所以到现在，供不应求。所以也正是因为有这么大的人才缺口，我们才觉得，我们现在有必要做一个更大规模的人才培养。”    南京大学教授回应建人工智能学院，目前培养模式不能满足需求。 根据2018年的一项调查显示，人工智能方向的硕博毕业生，最高年薪为50万元—70万元。在南京大学人工智能学院成立消息传出后，已经有国内的一线企业纷纷与学院寻求合作，希望能和南京大学合作开发课程，建立实验室和实习基地。 但是南京大学校长表示，人工智能学院初定本科生招生规模不会太大，为60-100人，如果今年可以完成程序就在今年招生，否则就推迟到明年。并希望完成程序后在部分本科生中打通本硕连读，此外还将招收硕士和博士生。 素材链接： http://m.thepaper.cn/newsDetail_forward_2033512 http://www.zhiyuantong.com/zhi/news/article/id/3308.html Have a Great Definition 
58,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658457&idx=2&sn=8a700f89439e300cc90d61ed4f218351&chksm=bd4c3f4a8a3bb65c1d2295731689b60f7dca74de292e14bc6e19f7182021c4d8ba8235118036&scene=27,Facebook数据被滥用？8个视频案例教你用好Facebook Graph API,"大数据文摘作品 编译：Aileen 过去的一个周末，社交网络Facebook因为用户数据被第三方API滥用帮助美国大选的事情上了热搜。直到现在，Facebook CEO小扎也没有发出任何官方回应，以及未来该如何更好的保护私人数据。有人认为作为坐拥海量用户数据的网站在获得巨大收益的同时，理应预想到数据被滥用的可能并作出防范措施，在事情发生之后也应该更积极的面对而不是回避。也有人提出犯法的是第三方API, 原罪不在Facebook。 先把这件事情放一边，可以确定的是Facebook拥有大量可供人们浏览的数据，人们可以使用此数据做很多事情。今天我们来了解一下如何使用Facebook Graph API用Python进行数据抓取和分析。 Facebook拥有大量数据供您探索，您可以使用以下数据做很多事情：分析Facebook页面或Facebook群组，将这些数据用于社交网络分析（SNA），为数字营销做数据分析， 甚至收集和保存自己个人项目的数据。 这些视频将向你展示如何做基本的分析 ，例如： 从Facebook下载数据 从json转换为更方便的数据结构 处理Graph API中的日期变量和其他数据 第1课：介绍和了解Graph API 在本视频中，我将向您介绍GRAPH API，我将使用GRAPH API Explorer并向您展示一些示例请求。 第2课：下载并保存Facebook数据   在本视频中，我将向您展示如何从Facebook页面或Facebook群组下载并保存所有数据，并记住某些要点。 第3课：设置和清理数据   在第三课中，我将使用notebook来清理和审计从Facebook获得的数据，并为分析做好准备。 第4课：评论最多的帖子   在第四课中，我将向您展示一种简单的方式，以获得评论最多的帖子。 https://v.qq.com/x/page/s06098fb92o.html 第5课：点赞最多帖子   在这个课程中发生了一些有趣的事情，因为我发现我可以使用API访问了一些已删除的帖子。 https://v.qq.com/x/page/r0609s6vt80.html 第6课：计算词频 在这个视频中，我将向您展示如何数一个组或一个页面中的所有帖子词频。 您也可以在评论中使用相同的功能。 https://v.qq.com/x/page/j0609g7vvhp.html 第7课：按关键字对帖子进行分组 在这个视频中，我会将在页面中具有关键字“free”的帖子进行分组，并计算有多少人拥有这个关键字，以及有多少人没有这个关键字。 分组方式非常有用，我们将在未来的视频中更频繁地使用更多变量。 https://v.qq.com/x/page/f06099j7ats.html 第8课：按日期分组 在本视频中，我们将探索“创建时间”变量，以按照年份，月份或星期几对帖子进行分组。 这可以用来查找发布模式等等。 https://v.qq.com/x/page/e0609puvw9j.html 原文作者： Nour  Galaby 原文地址：https://www.kdnuggets.com/2017/06/6-interesting-things-facebook-python.html Have a Great Definition "
59,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658427&idx=2&sn=73f8e454c4b1f69d1b5e60eb9ff84216&chksm=bd4c3f288a3bb63ebde5208681c881cd932ff65473a00b57793fedb2d48b60cb85bbe7157d07&scene=27,业界 | 特朗普大选曾利用大数据营销，违规使用5000万Facebook用户数据，扎克伯格仍未回应,作者：龙牧雪、魏子敏 可能左右了2016年美国总统大选的Facebook数据泄露丑闻还在持续发酵。 剑桥分析公司（Cambridge Analytica），一家与特朗普（Donald Trump）总统竞选团队有密切关联的数据公司，被曝获得了大约5千万Facebook用户的信息。 其中，有27万Facebook用户将自己的信息授权一个用于学术研究的App使用，其余受影响的用户则是这些授权用户的好友——他们的信息在不知情的情况下被特朗普竞选团队用于向他们针对性地推送广告。 这个名为“thisisyourdigitallife”的App由剑桥大学心理学教授Aleksandr Kogan开发，为学术目的收集数据，这是符合Facebook规则的。但随后这些信息被转移给了第三方，包括剑桥分析公司。数据转移违反了Facebook政策。 2016年9月，Cambridge Analytica的CEO Alexander Nix就大数据在选举中发挥的作用做演讲。 Facebook周五晚间表示，已经禁止剑桥分析公司使用其平台。 这一事件在Twitter上掀起了轩然大波，许多人批评Facebook在过去两年中已经得知此事，但并未就此采取行动。此前，Facebook曾要求剑桥分析销毁其获取的数据，但并未落实，数据仍然被剑桥分析持有。 最新进展是，曝光此事的Christopher Wylie（他自称是剑桥分析的技术架构师），表示自己的Facebook账号已被禁用。 Wylie表示，剑桥分析的目标是将社交媒体的影响力与大数据分析工具结合起来，创建心理学特征文件，然后操纵美国选民。这一操作也被剑桥分析的投资人Robert Mercer称为“军事风格心理运营活动”。Robert Mercer曾获得2014年ACL （自然语言处理与计算语言学领域最高级别的学术会议）终身成就奖。 周日，Facebook对此回应说：“我们正在努力确定Facebook数据是否已被销毁，我们正在进行全面的内部和外部审查。这是我们关注的焦点所在，因为我们一直致力于保护用户信息。” 这也引发了关于社交媒体公司是否足以保护其用户的讨论。 马萨诸塞州检察长Maura Healey周六宣布，她的办公室正在对Facebook和剑桥分析公司进行调查。 来自明尼苏达州的民主党参议员Amy Klobuchar周六在Twitter上写道，“扎克伯格需要在参议院司法部门作证。” “很明显这些平台不能自我监控，”她说。 “而他们说'相信我们'。” 来自马萨诸塞州的民主党参议员埃德马基呼吁，Facebook和剑桥分析公司分别列席参议院商务委员会作证。 Facebook对此的回应是，副总法律顾问Paul Grewal周五发表了一篇博客文章，称2015年，Facebook了解到非法数据传输和“要求认证”，“信息已被销毁”。 Grewal也补充说，几天前Facebook“收到报告”，并非所有数据都已被删除，而Facebook在调查时禁用了所有相关方的平台。Grewal还表示，Facebook致力于“大力执行保密政策，保护用户信息。” 但这个帖子完全没有抵消Facebook数据泄露事件的负面影响。 美国众议院情报委员会成员、加利福尼亚州民主党人Adam Schiff呼吁，要求Facebook解释为什么它在最初一直称自己是向教授提供有关数据，并称信息已被销毁。 “Facebook还必须回答，他们如何通知用户这一透露他们个人数据隐私的问题，”他在一份声明中说。 Schiff补充说，他认为Facebook通过禁用相关各方平台实现了“正确的举动”，但他表示他希望Facebook解释为什么在2015年公司获悉数据传输时没有停止与剑桥分析公司的合作。 在周日的一份声明中，Facebook承诺做出“全面的内部和外部评估”， 而Facebook CEO马克·扎克伯格和COO雪莉·桑德伯格仍未出面做出回应。 素材来源： http://money.cnn.com/2018/03/18/technology/business/mark-zuckerberg-facebook-politicians-data/index.html?sr=twCNN031918business0156AMStory https://techcrunch.com/2018/03/18/facebook-has-suspended-the-account-of-the-whistleblower-who-exposed-cambridge-analytica/?utm_source=tctwreshare&utm_medium=feed&utm_campaign=Feed%3A+Techcrunch+%28TechCrunch%29&sr_share=twitter Have a Great Definition 
60,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658457&idx=1&sn=e25cedcad28b14d724fa5e925fdfe027&chksm=bd4c3f4a8a3bb65c2778c8c73013a8bcf02bc383919ee501029cca33aad235ac29df0f3635fa&scene=27,Uber无人车发生全球首例行人致死事件，自动驾驶技术信度或倒退10年？,"自动驾驶技术再一次被推至了风口浪尖。 当地时间3月18日晚10点，49岁的Elaine Herzberg被Uber无人驾驶测试车撞倒，抢救无效身亡。 这是全球首例无人车致行人死亡事件，其处理结果必然会对全球无人车进程及相关规范制定产生不可估量的影响。悲观声音甚至称， 让我们先来重现一下悲剧发生的现场： 美国西部时间3月18日晚10点，亚利桑那州坦佩市，49岁的Elaine Herzberg在人行横道外横穿马路，随即被正在往北行驶的Uber无人驾驶测试车撞倒。 这名女子被送往医院，但因伤势严重而身亡。 坦佩警方证实，事故发生时，汽车确实处于自动驾驶模式，车后座还坐着一位安全驾驶员。 这是一辆沃尔沃XC90 SUV，被Uber改装，车顶配备有激光雷达和摄像头等设备。Uber发言人证实了这件事的发生：“我们正在与地方当局进行全面合作，调查这起事件。” 此次发生事故的汽车来自Uber亚利桑那州技术测试中心。事故发生后，Uber已暂了在坦佩、匹兹堡、旧金山和多伦多等城市进行的无人车测试。 再来更新两个最新进展： 进展1：Uber CEO Dara Khosrowshahi 发推特评论了这一“巨大悲剧（incredibly sad news）”。 亚利桑那州刚刚发生了一件令人难以置信的悲剧。 我们正在与当地执法部门配合以了解事情经过，同时也会认真考虑受害者的家人的安置。 - dara khosrowshahi（@dkhos）2018年3月19日 Uber_Comms发推向受害人家属表达慰问： 我们的心与受害者的家人同在。 我们正在与@TempePolice和地方当局充分合作调查此事件。 - Uber通讯（@Uber_Comms）2018年3月19日 进展2：华盛顿公路与汽车安全倡导机构（Advocates for Highway and Auto Safety）负责监管事务的主管Peter Kurdock称，亚利桑那州的交通事故是悲剧性的。 事故发生前一周，该组织致函运输局局长Elaine Chao，表示担心无人驾驶车的开发过程缺乏该部门行动和监督。  Kurdock说，这起致命的事故应该给国会议员一个“令人震惊的提醒”，即他们需要“思考所有问题，把最好的法案放在一起，希望能够防止更多这类悲剧发生。” 首例无人车辆造成的行人死亡事件引发了有关技术安全的问题的巨大讨论。 谷歌母公司Alphabet、通用汽车、Uber和百度等公司正在投资数十亿美元开发无人车技术，因为它有可能改变汽车行业，整体交通和城市运作方式。一位分析师估计，目前Alphabet的Waymo市值高达700亿美元。  这样的测试已经扩展到复杂的城市地区。亚利桑那和德克萨斯这些州采取了相对友好的监管方式，也吸引了不少希望将无人驾驶技术商业化的公司。 凤凰城地区是自动驾驶技术实验的沃土。Uber一直在有人类安全驾驶员在方向盘后的情况下测试自动驾驶技术。  去年年底，经过在凤凰城的多年测试，Alphabet旗下Waymo公司开始取消人类安全驾驶员，用无人车运送少数居民 （Waymo员工坐在后排座位上）。通用汽车公司也在凤凰城地区进行测试。 通用汽车发言人拒绝发表评论，Waymo的代表没有回复多个评论请求。 坦佩的死亡事件可能会减缓测试，推迟商业化并破坏这种乐观情绪。 位于华盛顿的倡导组织汽车安全中心执行主任Jason Levine说，  事故发生也引起了研究界的哗然讨论。 斯坦福大学教授李飞飞发推评论说：这是一起致命的无人车事故。斯坦福的研究者一直呼吁考虑机器学习的道德问题：这就是AI，AI对人类生活有着深刻影响。我们所有人都需要共同努力，让AI更安全、公平和仁慈。 纽约大学商学院教授Arun Sundararajan表示：“我们正处于自动驾驶技术的初级阶段，我们仍然在不断学习提升这项技术。每当你发布新技术时，都会遇到一系列意想不到的情况。 尽管人类也容易出错，但作为一个社会，数十年来我们已经能够理解这些错误，而机器的错误则不同”。 对事故调查过程中，监管部门也必然加强对无人驾驶车辆法规的监管。 美国国家运输安全委员会（NTSB）正在对死亡事件展开调查，并派遣了一小队调查人员前往凤凰城以东10英里处的坦佩。交通部国家公路交通安全管理局也派出了专门的调查组。 NTSB每年开展的公路事故调查相对较少，但一直在密切关注涉及全部或部分自动驾驶汽车的事故。去年，它曾对在佛罗里达州造成致命事故的Autopilot系统（来自特斯拉公司）进行调查并进行了批评。 NTSB对自动驾驶技术所持的警惕态度与交通部门恰好相反，该部门去年修改了自动驾驶汽车的政策，试图消除测试这些车辆的障碍。 消费者监督机构的隐私和技术项目总监John M Simpson表示，这次车祸强调了对新兴技术进行更严格监管的必要性。 Simpson表示：“机器人汽车无法准确预测人类行为，真正的问题出现在人与机器人车辆之间的交互作用中。”他说， 在最近发生的一起事件中，加利福尼亚警察发现一辆特斯拉停在五车道高速公路中间，一名司机在方向盘后面睡着了。该名男子称该车处于“自动驾驶”状态，这是特斯拉的半自动驾驶辅助系统，他因涉嫌酒后驾车而被捕。 研究自动驾驶的亚利桑那州立大学副教授Michael G Bennett说，自动驾驶汽车在坦佩的校园和街道上无处不在。一般情况下，有人类安全驾驶员坐在方向盘后面，但有时候车里面并没有人。 他说，这场致命的事故将引发业界严肃的改革和反思。 “对于这个行业来说，这可能是个问题，因为他们关于这项技术价值的核心论点之一是它比人类驾驶更优越，”Bennett说道，并补充道，自动驾驶汽车应该能够检测到行人并避免撞到他们，即使他们不在人行横道内：“每天，世界各地的行人都会走出人行横道的。” 这次事故提出了许多严重的问题。 让无人驾驶汽车在公共道路上进行测试足够安全吗，人群中有多少人并不同意成为实验里的小白鼠？ 同时，没有人能够量化这些无人车避免了多少车祸，避免了多少因为人们因为边开车边发短信、打电话或者酒驾造成的惨剧。 人类记录并不佳：去年有近4万人在美国的公路上死亡。 其中将近6,000人是行人——每天超过16人。然而，平均来看，人类驾驶员每驾驶1亿英里会杀死1.16人。 Waymo和Uber以及其他所有无人车合并在一起至今驾驶的距离远不及这些距离，他们已经杀死了一个。 这些公司是否需要增加技术的透明度？今天，开发人员不愿意将太多的数据提交给公共部门，因为担心政府可能会向竞争对手泄露一些非常昂贵的商业秘密。但是也许这些公司需要更加透明地了解他们的技术如何运作——以及它的缺点。 不过，即使公司交出了更多详细的信息，地方，州或联邦当局是否有专业知识来了解它并创建正确的保护措施？ “许多政府正在对开发该技术的公司报以大量的信任或信心，”南卡罗来纳大学法学院自主车辆监管研究的律师Bryant Walker Smith说。也许是时候让他们自己研究无人车并出台相应的法规了。 素材来源： https://www.theguardian.com/technology/2018/mar/19/uber-self-driving-car-kills-woman-arizona-tempe https://www.wired.com/story/uber-self-driving-car-crash-arizona-pedestrian/ Have a Great Definition "
61,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658427&idx=3&sn=ac13faa8e779434f41d7df0375f8ce11&chksm=bd4c3f288a3bb63ee59c5810d945e49f6a040b20537d74e6128ef6fab514595c9246593eab40&scene=27,AI角 | 把吴恩达深度学习系列课程画出来，这有份诚意满满的笔记求查收,大数据文摘作品 在吴恩达机器学习系列课程完结后不久，一位名叫Tess Ferrandez的小姐姐在推特上分享了一套自己的课程笔记，瞬间收获了3k+赞和1k+转发。 不同于满屏公式代码的黑白笔记，这套信息图不仅知识点满满，且行文构图都像插画一样颜值颇高。吴恩达自己也在推特上转发称赞了这一位有诚意的学习者，毕竟他一直倡导学习是一件简单快乐的事情。 大数据文摘将这份有趣的学习笔记呈现在此，请各位查收。 点击链接可查看下载这份笔记的完整版： https://www.slideshare.net/TessFerrandez/notes-from-coursera-deep-learning-courses-by-andrew-ng 【今日机器学习概念】 Have a Great Definition 
62,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658387&idx=2&sn=7add5b40fb3bd9efc263aebe9abe83c2&chksm=bd4c3f008a3bb616dec815db9685b3a6d1a012059fdc963e290865daab2a86a66ddc89766552&scene=27,重磅译制 | 更新：MIT 6.S094自动驾驶课程第2讲（2）深度Q学习,大数据文摘重磅译制：最In的无人车课程视频+中文字幕！ 本周更新至：第二讲（2） 深度强化学习-运动规划之深度Q学习 Deep Reinforcement Learning for Motion Planning-Deep Q Learning 时长30分钟 带有中文字幕 点击文末 ，即可免广告观看 这门【深度学习与自动驾驶】课程由麻省理工MIT开设，话题前沿且实践性质很强。课程首先引导大家了解深度学习，之后大家可以自己“造”一辆无人车（的算法🌚）！ 课程面向机器学习 ，但已经有大量经验的研究人员也能从课程提供的从实践出发的深度学习方法和应用中受益。 课程主讲Lex Fridman与TA团队 大数据文摘已取得课程翻译授权，并联合北京邮电大学模式识别实验室组织了视频汉化， 发布。 课程视频【中文字幕】学习地址： （连载中，请收藏！点击文末 ，可直接加入学习） http://study.163.com/course/introduction/1004938039.htm MIT深度学习与自动驾驶课程页面（所有资料汇总）： https://selfdrivingcars.mit.edu/ 本课时PPT精华 ▼ 《牛津大学xDeepMind深度学习与自然语言处理》课程 ，复制打开链接免费加入学习： http://study.163.com/course/introduction/1004336028.htm 《斯坦福CS231n深度学习与计算机视觉》课程已更新完毕，李飞飞与Andrej Karpathy（现任Tesla AI部门主管）主讲，已有9万+人参与学习，复制打开链接免费加入学习： http://study.163.com/course/introduction/1003223001.htm 北京邮电大学模式识别实验室 李琦、李子凡、刘冠群 刘家铭、慕宗奇、祁星群 吴灵境、肖思瑶、杨紫都、张文源 （按拼音排序） 寒小阳、龙牧雪 刘家铭、龙牧雪 张闯、汪德诚 Have a Great Definition 戳 ▼▼▼ 
63,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658427&idx=1&sn=f4649f886fcdd7158f22707ac46006e9&chksm=bd4c3f288a3bb63e601934306c8ef58ea1fccefc4f9d4770222e998e86b83daa4b87e68b5aa6&scene=27,用Python入门不明觉厉的马尔可夫链蒙特卡罗（附案例代码）,"大数据文摘作品 编译：Niki、张南星、Shan LIU、Aileen 这篇文章让小白也能读懂什么是人们常说的Markov Chain Monte Carlo。 在过去几个月里，我在数据科学的世界里反复遇到一个词：马尔可夫链蒙特卡洛（Markov Chain Monte Carlo , MCMC）。在我的研究室、podcast和文章里，每每遇到这个词我都会“不明觉厉”地点点头，觉得这个算法听起来很酷，但每次听人提起也只是有个模模糊糊的概念。 我屡次尝试学习MCMC和贝叶斯推论，而一拿起书，又很快就放弃了。无奈之下，我选择了学习任何新东西最佳的方法：应用到一个实际问题中。 通过使用一些我曾试图分析的睡眠数据和一本实操类的、基于应用教学的书（《写给开发者的贝叶斯方法》，我最终通过一个实际项目搞明白了MCMC。 《写给开发者的贝叶斯方法》 https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers 和学习其他东西一样，当我把这些技术性的概念应用于一个实际问题中而不是单纯地通过看书去了解这些抽象概念，我更容易理解这些知识，并且更享受学习的过程。 这篇文章介绍了马尔可夫链蒙特卡洛在Python中入门级的应用操作，这个实际应用最终也使我学会使用这个强大的建模分析工具。 此项目全部的代码和数据： https://github.com/WillKoehrsen/ai-projects/blob/master/bayesian/bayesian_inference.ipynb 这篇文章侧重于应用和结果，因此很多知识点只会粗浅的介绍，但对于那些想了解更多知识的读者，在文章也尝试提供了一些学习链接。 我的智能手环在我入睡和起床时会根据心率和运动进行记录。它不是100%准确的，但现实世界中的数据永远不可能是完美的，不过我们依然可以运用正确的模型从这些噪声数据提取出有价值的信息。 典型睡眠数据 这个项目的目的在于运用睡眠数据建立一个能够确立睡眠相对于时间的后验分布模型。 由于时间是个连续变量，我们无法知道后验分布的具体表达式，因此我们转向能够近似后验分布的算法，比如马尔可夫链蒙特卡洛（MCMC）。 在我们开始MCMC之前，我们需要为睡眠的后验分布模型选择一个合适的函数。一种简单的做法是观察数据所呈现的图像。下图呈现了当我入睡时时间函数的数据分布。 睡眠数据 每个数据点用一个点来表示，点的密度展现了在固定时刻的观测个数。我的智能手表只记录我入睡的那个时刻，因此为了扩展数据，我在每分钟的两端添加了数据点。如果我的手表记录我在晚上10：05入睡，那么所有在此之前的时间点被记为0（醒着），所有在此之后的时间点记为1（睡着）。 这样一来，原本大约60夜的观察量被扩展成11340个数据点。 可以看到我趋向于在10：00后几分钟入睡，但我们希望建立一个把从醒到入睡的转变用概率进行表达的模型。我们可以用一个简单的阶梯函数作为模型，在一个精确时间点从醒着（0）变到入睡（1），但这不能代表数据中的不确定性。 我不会每天在同一时间入睡，因此我们需要一个能够模拟出这个个渐变过程的函数来展现变化当中的差异性。在现有数据下最好的选择是logistic函数，在0到1之前平滑地移动。下面这个公式是睡眠状态相对时间的概率分布，也是一个logistic公式。 在这里，β (beta) 和 α (alpha) 是模型的参数，我们只能通过MCMC去模拟它们的值。下面展示了一个参数变化的logistic函数。 一个logistic函数能够很好的拟合数据，因为在logistic函数中入睡的概率在逐渐改变，捕捉了我睡眠模式的变化性。我们希望能够带入一个具体的时间t到函数中，从而得到一个在0到1之间的睡眠状态的概率分布。我们并不会直接得到我是否在10：00睡着了的准确答案，而是一个概率。创建这个模型，我们通过数据和马尔可夫链蒙特卡洛去寻找最优的alpha和beta系数估计。 马尔可夫链蒙特卡罗是一组从概率分布中抽样，从而建立最近似原分布的函数的方法。因为我们不能直接去计算logistic分布，所以我们为系数(alpha 和 beta)生成成千上万的数值-被称为样本-去建立分布的一个模拟。MCMC背后的基本思想就是当我们生成越多的样本，我们的模拟就更近似于真实的分布。 马尔可夫链蒙特卡洛由两部分组成。蒙特卡洛代表运用重复随机的样本来获取一个准确答案的一种模拟方法。蒙特卡洛可以被看做大量重复性的实验，每次更改变量的值并观察结果。通过选择随机的数值，我们可以在系数的范围空间，也就是变量可取值的范围，更大比例地探索。下图展示了在我们的问题中，一个使用高斯分布作为先验的系数空间。 能够清楚地看到我们不能在这些图中一一找出单个的点，但通过在更高概率的区域（红色）进行随机抽样，我们就能够建立最近似的模型。 马尔可夫链是一个“下个状态值只取决于当前状态”的过程。 （在这里，一个状态指代当前时间系数的数值分配）。一个马尔可夫链是“健忘”的，因为如何到达当前状态并不要紧，只有当前的状态值是关键。如果这有些难以理解的话，让我们来设想一个每天都会经历的情景--天气。 如果我们希望预测明天的天气，那么仅仅使用今天的天气状况我们就能够得到一个较为合理的预测。如果今天下雪，我们可以观测有关下雪后第二天天气的历史数据去预测明天各种天气状况的可能性。马尔可夫链的定义就是我们不需要知道一个过程中的全部历史状态去预测下一节点的状态，这种近似在许多现实问题中都很有用。 把马尔可夫链（Markov Chain）和蒙特卡洛（Monte Carlo），两者放到一起，就有了MCMC。 MCMC是一种基于当前值，重复为概率分布系数抽取随机数值的方法。每个样本都是随机的，但是数值的选择也受当前值和系数先验分布的影响。MCMC可以被看做是一个最终趋于真实分布的随机游走。 为了能够抽取alpha 和 beta的随机值，我们需要为每个系数假设一个先验分布。因为我们没有对于这两个系数的任何假设，我们可以使用正太分布作为先验。正太分布，也称高斯分布，是由均值（展示数据分布），和方差（展示离散性）来定义的。下图展示了多个不同均值和离散型的正态分布。 具体的MCMC算法被称作Metropolis Hastings。为了连接我们的观察数据到模型中，每次一组随机值被抽取，算法将把它们与数据进行比较。一旦它们与数据不吻合（在这里我简化了一部分内容），这些值就会被舍弃，模型将停留在当前的状态值。 如果这些随机值与数据吻合，那么这些值就被接纳为各个系数新的值，成为当前的状态值。这个过程会有一个提前设置好的迭代次数，次数越多，模型的精确度也就越高。 把上面介绍的整合到一起，就能得到在我们的问题中所需进行的最基本的MCMC步骤： 为logistic函数的系数alpha 和beta选择初始值。 基于当前状态值随机分配给alpha 和beta新的值。 检查新的随机值是否与观察数据吻合。如果不是，舍弃掉这个值，并回到上一状态值。如果吻合，接受这个新的值作为当前状态值。 重复步骤2和3（重复次数提前设置好）。 这个算法会给出所有它所生成的alpha 和beta值。我们可以用这些值的平均数作为alpha 和beta在logistic函数中可能性最大的终值。MCMC不会返回“真实”的数值，而是函数分布的近似值。睡眠状态概率分布的最终模型将会是以alph和beta均值作为系数的logistic函数。 我再三思考模拟上面提到的细节，最终我开始用Python将它们变成现实。观察一手的结果会比阅读别人的经验贴有帮助得多。 它省略了很多细节，方便我们创建模型，避免迷失在理论之中。 通过下面的这些代码可以创建完整的模型，其中包含了参数alpha 、beta、概率p以及观测值observed，step变量是指特定的算法，sleep_trace包含了模型创建的所有参数值。 为了更直观地展现代码运行的效果，我们可以看一下模型运行时alpha和beta生成的值。 这些图叫做轨迹图，可以看到每个状态都与其历史状态相关，即马尔可夫链；同时每个值剧烈波动，即蒙特卡洛抽样。 使用MCMC时，常常需要放弃轨迹图中90%的值。这个算法并不能立即展现真实的分布情况，最初生成的值往往是不准确的。随着算法的运行，后产生的参数值才是我们真正需要用来建模的值。我使用了一万个样本，放弃了前50%的值，但真正在行业中应用时，样本量可达成千上万个、甚至上百万个。 通过足够多的迭代，MCMC逐渐趋近于真实的值，但是估算收敛性并不容易。这篇文章中并不会涉及到具体的估算方法（方法之一就是计算轨迹的自我相关性），但是这是得到最准确结果的必要条件。PyMC3的函数能够评估模型的质量，包括对轨迹、自相关图的评估。 轨迹图（左）和自相关性图（右） 建模、模型运行完成后，该最终结果上场了。我们将使用最终的5000个alpha和beta值作为参数的可能值，最终创建了一个单曲线来展现事后睡眠概率： 基于5000个样本的睡眠概率分布 这个模型能够很好的代表样本数据，并且展现了我睡眠模式的内在变异性。 ，而是给我们一个概率。举个例子，我们可以通过这个模型找出我在特定时间点睡觉的概率，或是找出我睡觉概率超过50%的时间点： 虽然我希望在晚上10点入睡，但很明显大多时候并不是这样。我们可以看到，平均来看，我的就寝时刻是在晚上10:14。 这些值是基于样本数据的最有可能值，但这些概率值都有一定的不确定性，因为模型本身就是近似的。为了展现这种不确定性，我们可以使用所有的alpha、beta值来估计某个时间点的睡觉概率，而不是使用平均值，并且把这些概率值展现在图中。 晚上10:00睡觉的概率分布 这些结果能够更好地展现MCMC模型真正在做的事情，即它并不是在寻找单一的答案，而是一系列可能值。 贝叶斯推论在现实世界中非常有用，因为它是对概率进行了预测。我们可以说存在一个最可能的答案，但其实更准确的回复应当是：每个预测都有一系列的可能值。 同样我可以用我的起床数据创建类似的模型。我希望能够在闹钟的帮助下总能在早上6:00起床，但实际上并不如此。下面这张图展现了基于观测值我起床的最终模型： 基于5000个样本的起床事后概率 可以通过模型得出我在某个特定时间起床的概率，以及我最有可能起床的时间： 看来我需要一个更生猛的闹钟了…. 出于好奇以及实践需求，最后我想创建的模型是我的睡眠时间模型。首先，我们需要寻找到一个描述数据分布的函数。事先， 睡眠时间长短分布 正态分布的确能够解释大部分数据，但是图中右侧的异常值却无法得到解释（当我睡懒觉的时候）。 偏态分布有三个参数：平均值、偏离值，以及alpha倾斜值。这三个参数的值都需要从MCMC算法中得到。下面的代码创建了模型，并且使用了Metropolis Hastings抽样。 现在，我们可以使用三个参数的平均值来建立最有可能的分布模型了。下图为基于数据的最终偏态分布模型。 时长模型 模型看上去很完美！ 我想再次强调，完成这个项目让我体会到解决问题的重要性，尤其是有现实应用意义的项目！在我尝试使用马尔可夫链蒙特卡洛来端到端建立贝叶斯推论的时候，我重新熟悉了许多基础知识，并且非常享受这个过程。 我不仅了解到自身需要改进的习惯，而且当别人在谈论MCMC和贝叶斯推论时，我终于真的明白他们在谈论什么了！数据科学正是关于持续不断地在你自己的知识库中输入新的工具，而这最有效的办法就是发现一个问题，然后应用你所学的去解决问题！ 原文链接： https://towardsdatascience.com/markov-chain-monte-carlo-in-python-44f7e609be98 【今日机器学习概念】 Have a Great Definition "
64,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658283&idx=3&sn=a779e9c49f1c57975294cdb7e01d2dd8&chksm=bd4c3fb88a3bb6ae1a56f743c0853f06691074ebd87a088ae58a0ea23ef0c5204ed259bd57e6&scene=27,报名 | 清华RONG系列论坛之司法大数据专场,“电脑会取代人脑判案吗？”英国《卫报》曾经报道，上个世纪60年代，有科学家畅想：“随着人工智能的发展，电脑有望代替人脑，轻松预测司法裁判的结果。” 就在前段时间， 法律AI平台LawGeex与斯坦福大学、杜克大学法学院和南加州大学的法学教授合作进行了一项新的研究，让20名有经验的律师与训练好的法律AI程序相互比赛。结果是人类的顶尖律师输掉了比赛。（ ） 清华大学就此召开清华RONG系列论坛之司法大数据专场， 此次司法大数据专场将 会议背景 RONG系列大数据论坛由数据科学研究院发起。每场论坛针对某一个领域的大数据相关研究方向，联合清华大学相关院系和清数大数据产业联盟的成员共同参与。目前已成功举办“大数据与新闻传播”、“大数据与医疗健康”、“大数据与未来人居”、“大数据与诚信社会”、“大数据重构制造业”、“大数据与政府治理”、“大数据与可持续发展”等专场。 会议时间及地点 时间： 2018年3月23日 地点： 清华大学Fit楼 大会嘉宾与议程 支持单位 【主办单位】 清华大学数据科学研究院 清华大学法学院 清华大学社会科学学院 北京国双科技有限公司 清数大数据产业联盟 报名方式 1.扫描 报名申请： 2.点击文末 ，通过大会的首席活动报名平台进行报名。 
65,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658283&idx=1&sn=af34ea6168d1c27a02469c3a81bf8e6b&chksm=bd4c3fb88a3bb6ae1e65303cd425cbd7cb78abb354263a0ca79775c802d304aa7ca6b22d7f08&scene=27,七宗罪：我们是如何错误预估人工智能的,"大数据文摘作品 编译：惊蛰、新知之路、王一丁、张南星、于乐源、蒋宝尚 荒谬的预估往往会导致对未来的恐惧。而 为什么有人会对AI和机器人的技术前景如此恐慌？下文中，这 很多人对人工智能和机器人行业的快速发展感到十分焦虑，一部分人担心他们很快会变得过于强大，也有一部分人担心他们会对人类现在的工作体系产生冲击。 Market Watch上有人宣扬机器人将在十到二十年内占据现今大部分工作，甚至还发布了一张满是数据的图片当作论据。 机器人将在十到二十年内占据现今大部分工作 这份声明并不客观，比如，如图中显示美国100万地面维修人员在在十到二十年之后只会剩下5万，因为以后这些工作都会由机器人完成。实际上，目前有多少台机器人正在做地面维修呢？一个也没有。 类似的例子也适用于上图中其他所有行业，所谓在体力劳动者中将会出现90％甚至97％的大幅就业下滑，然而实际上却并非如此。 在许多对AI未来的预测中，都有相同的问题。首先列出ABCD四个有关导致错误预测的大方向，并简要评估他们的立场。 A.泛用人工智能（AGI）- AGI旨在从当今AI技术（如机器学习）中分离出一个思维实体，目的在于创造能像人类一样能够自主思考和行动的个体。 但最近AI领域的成功却并非都与AGI相关。 有些人认为所有的人工智能都是泛用人工智能（AGI），但正如“General”一词所指，AGI要求远远高于目前AI。如果将现有的AI都理解为是AGI，那就明显有些名不副实了。 目前，“泛用人工智能”的研究并不是十分理想，既没有做到特别通用，也没能形成一个独立存在的个体。50年前遇到的问题，如在推理能力和常识上的不足，现在仍是制约其发展的主要原因。在其他领域中，比如在人工生命(Artificial Life)和适应行为模拟（Simulation of Adaptive Behavior）方面，人们已经取得了一些进展，但这些研究现在已经停滞了。 理论上说，“泛用人工智能”是可以实现的。然而或许人类还不够聪明，还没弄清楚怎么创造“泛用人工智能” （编者注：本文作者在“目前适合部署在机器人上的人工智能系统”一文中有介绍。） 文章链接： http://rodneybrooks.com/forai-domo-arigato-mr-roboto/ 即便可能，人类距离理解和建立真正的“泛用人工智能”远比许多专家所说的要远。（经常有人提到“一个人工智能”，好像所有人工智能都是独立的个体一样。 这一点很让人困惑，就像本地人不把旧金山（San Francisco）叫做“Frisco”一样，没有一位认真的研究人员会用“一个人工智能”来形容人工智能。） B.奇点（Singularity）- 奇点的意思是指一个有着明确目标的AI实体，会在某一个点在AI的研究方面超越人类的研究速度。 与此同时，就如摩尔定律所言，计算机处理速度越来越快，AI在达到奇点后会开始自我研究与加速的过程，如同物理学中黑洞的奇点一样，我们也不知道奇点发生后AI到底会变成什么样子。 正因为这种不可预测性，“相信”奇点的人们很乐意赋予奇点发生之后的AI无所不能的特性。之所以把“相信”两个字用引号括起来，是因为这种“相信”多多少少带有些宗教的味道。以后对有些人来说，他们可以向这样的AI上传自己的大脑从而得到永生，而不必麻烦地相信通常意义上拥有超能力的神。这种前所未有的强大科技将成为这些人新的上帝，一个新的宗教就此诞生了，科技教！ 有些人对于宗教中的救恩日（Day of Salvation）何时到来有着非常明确的想法。一位奇点预言家的追随者们板上钉钉地相信，这件事将在2029年发生。 这种预测错误很大程度上受到了指数主义的影响，这也是在这里所讨论的的AI领域七个常见错误之一。 虽然现在的计算机拥有强大的计算能力，但这并不意味着我们已经拥有或者哪怕是接近拥有一种可以在人工智能领域进行自主研究，并且能通过重写自己的代码从而进行不断优化的程序。 事实上，现阶段我们还没有写出能自己理解一页代码的程序，同样的代码，计算机系的新生上了一个月的课之后就能理解的更好。所以，如果想要创造比人类更擅长编写程序的AI系统，我们面前有很长的路要走。 类似的，奇点崇拜者常常提到的通过在神经元层面模拟大脑来达到奇点的方法的进度也不怎么样。 三十年来，我们已经详细了解了C类线虫由302个神经元构成的完整“线路图”，以及它们之间的7,000个连接。这一点对理解其行为和神经元之间的联系非常有用。 但是，这是一项长达30年的研究，涉及数百人，都只为了尝试了解区区302个神经元。根据打算从头一步一步模拟线虫神经系统的OpenWorm项目，研究的进程还没有走到一半。 OpenWorm项目： https://en.wikipedia.org/wiki/OpenWorm 如果想模拟人类大脑中1000亿个神经元和甚至更大量的连接，难度是可想而知的。所以，如果你想通过奇点事件，把自己上传到计算机模拟里的话，还是先试着多活个几百年吧。 C.不同的价值体系 - 第三种情况， 是基于AI的机器在执行某些任务时通常做得很好，好到甚至在复杂的世界中也可以达到超人的表现。然而，这些机器并没有人类的价值观和思维方式，这就会引发各种各样的问题。 这个问题的某些版本的确是真的 - 比如说，如果我最近买了张去某个城市的飞机票，突然间我浏览的所有靠广告赚钱的网站都开始给飞往那个地方的机票打广告。这当然很蠢。我不认为这样的现象算得上高水平的AI，只能说这类广告的算法设计并不是很好。 但这个观点还是有支持者的（出于公正的考虑，以下保持匿名）： “有个很有名的回形针事例刚好能说明这个现象：如果一台机器的唯一目标就是最大化的量产回形针，那它有可能会发明些匪夷所思的技术，只为了把宇宙中能用的资源都转化成回形针，最终毁灭人类。” 当然… 不是这样的。无论如何我们都不会在现实世界中遇到这样的软件，一个为了实现人类给它制定的目标，可以聪明到可以颠覆人类社会，并忽视人类正是它的创造者这一事实。如果你认为技术会这样进化的话简直就是愚蠢至极，各种各样错误的原因很有可能在下文提到的七个问题中找到答案。 包括上文引用的部分，以及在墨尔本举行的人工智能国际联合会议IJCAI（International Joint Conference on Artificial Intelligence）中这位作者多次强调：我们人类需要用数学来证明AI的目标和人类是一致的。 情况C来自于研究员们，当他们发现一个有趣的智能方面的研究课题后，随即借用自己的名声把它宣传成一个短期内急需解决的问题。于是，当AI的奉迎者们知道了，便顺势将这个问题变成一个关乎人类存亡的重大问题。 顺便说一下， 多年来，通过大量的努力，我们还是无法证明一千行的代码不能被黑客破解，更遑论大型AI系统了。不过好消息是，数千年来，我们人类可以和马共存，尽管马是个拥有自我存在感、渴望和远超常人体力的独立个体，但人类仍为了自己的利益而驱使它们。而神奇的是，我们直到现在都没有任何一个和马相关的定理！ D.超邪恶、恐怖、残忍、人类灭绝型AI  - 最后这类就像第三种情况一样，但是这类AI对人类有明显的反感，甚至打算毁灭人类以获得更好的生存。 至少从上世纪六十年代末期开始，这种科幻思维在好莱坞特别流行。在上映于1968年的《2001：太空漫游》中，机器所造成的破坏仅限于一艘太空船。 而在1970年上映，情节也基于这个时间点的《电影巨人：福宾计划》中，人类在全球范围内都遭受到了浩劫。这个主题多年来一直持续着，距今不久的于2004年上映，以2035年为事件发生时间的电影《我，机器人》中，名叫VIKI的邪恶AI通过新型NS-5类人机器人接管了整个世界。 这种情况比上文的情况C错得更为离谱。我觉得这些电影中的想法会让人们对这些的危险感到心有余悸。 军事机器人杀手的话题，在新闻报道中这个话题很容易和情况D相混淆，更糟的是被那些忙着宣扬邪恶AI的人将其与情况D彻底混为一谈。 事实上这两个是完全不同的问题。此外，我认为关于军事机器人的很多观点都被严重误导了。然而，这是一个完全不同的话题 言归正传，如下是在AI预测方面经常犯的七类错误。这七类错误影响着A、B、C、D四种情况发生的时间和可能性。不过，其中有些错误对错误预估的影响要大于其他的错误。下文中，小标题里用字母标出了这七类错误主要会造成A、B、C、D中的哪些情况。第一类错误对所有情况都会造成影响！ 未来主义者Roy Amara，是位于斯坦福大学内的For The Future研究机构的联合创始人与主席，无数项目的资本风投家，也是硅谷的智囊之一。让他被世人所知的是他的那句著名格言，常被引用为“Amara法则”--我们总是倾向于高估技术带来的短期影响，并低估其长期影响。  关于Amara法则的双向性有一个很好的例子，即美国全球定位系统（GPS）30年的历程。自1978年起陆续在轨道上放置了24颗卫星（算上备份的话是30颗）。 地球上的任何一点可以同时看到其中的4颗，这样就可以计算经纬度和海拔高度。位于科罗拉多州Schriever空军基地的指挥中心不间断的监视卫星的轨道的精确度和机载原子钟的准确性，出现微小的偏差后便上传修正的数据。 如果没有这些上传的数据，GPS将会在一至两周之内出现定位到别的街道的错误，再过几个月之后，误差就可能将你定位在别的城镇了。 GPS的目标本是为了令美军精准的投放炸弹，这是设计之初的期望。美军在1991年的“沙漠风暴”军事行动中首次使用，起初的效果貌似十分理想。 但在90年代GPS计划一直受到质疑因为其精确程度一直没有达到最理想的效果，直到21世纪初被美军全面接受之前，整个项目面临着一次又一次被裁掉的风险，度过了一段艰难的日子。 如今，GPS的使用进入了长期的规划，当初把它投放到卫星轨道时根本没想到会有如此多的用途。比如当我在外面跑步时，正是利用Apple手表上的GPS模块记录我的位置，其精度可以达到分辨出我在沿着一条街的哪一边行进。 GPS信号接收器的尺寸之小、价格之低及应用之广估计是它原来的设计者门怎么也想像不到的。它在为全球的物理实验提供同步服务、成为美国国家电网的核心组成部分、甚至帮助股市里高频投资的操作者们规避时间误差所造成的灾难。 GPS应用在所有的美国大大小小的飞机导航系统上、跟踪定位获得假释的犯人、告诉人们什么种子应种植在哪片土地上。它获取卡车队伍的信息并报告司机们的表现、基于地面上反弹回去的信号判断地面湿度，并制定灌溉计划。 GPS始于一个单一的目标并艰难的为之努力。现在它已渗透进我们生活的诸多领域，如果没有了GPS，我们在生活中遇到的问题不止迷路这么简单，而是可能会处于一个饥寒交迫的环境，最终导致死亡。 在过去三十年中我们也看到了同样模式的技术型产品。首先是一个宏伟的设想，紧接着就是失望，然后一点点的发展，最后超越了当初所设想的目标。比如区块链（比特币是其第一个应用），人类基因组测序，太阳能，风能，甚至送货上门服务。 或许最著名的一个例子就是计算机。当1950年代第一台商业计算机问世时引起了广泛的恐慌，大家都认为以后所有人都会因计算机的出现而丢掉工作（可以看看1957年的电影《Desk Set》）。 但在此之后30年里计算机几乎没有对人类的直接影响，甚至到了1987年仍没有用在消费类设备上的微处理器。所有的改变都发生在接下来的30年中，也被称之为第二次工业浪潮，现在看看我们身上、车里、房屋里，计算机已随处可见。 为了阐述计算机的长期影响如何被一贯地低估，我们需要回顾一下旧科幻电影或电视剧中描绘的未来是什么样子。在1966年版的《星际迷航》中300年后宇宙飞船计算机的样子已经让30年后的人们笑掉大牙，但我们不妨三个世纪以后再回头来看看现在的科幻电影。 《星际迷航：下一代》和《星际迷航：深空九号》这两部电影的时间跨度是虽然达到13年（1986-1999），但影片中遥远未来的太空船里，演员手上仍需要携带大量的文件，与空间站的文件传输仍然不能通过网络的方式（就像当时的AOL网络一样），而飞船中用来检索资料的数据库由于仍采用互联网时代之前的“未来”设计样式而显得十分的落伍。 绝大多数的科技产品的短期效应会被高估，因为他们是笼罩着光环的新鲜事物。 人工智能由于被贴上新鲜事物的标签在1960年代和1980年代一次又一次的被高估，现在也是同样的情况。（一些大型公司释放出的在市场上应用AI的消息是带有欺骗性的，在不远的将来可能就会砸了自己的脚。） 并不是所有的科技产品的长期效应会被低估，但AI的长期效应的确被低估了。问题在于“多久”才算长期，以下是6个常犯的错误观点，会助于更好的理解为什么AI的长期效应是被严重低估了的。 2.[B,C,D]想象魔法 亚瑟·克拉克（Arthur C. Clarke）、罗伯特·海因莱因（Robert Heinlein）与艾萨克·阿西莫夫（Isaac Asimov）并称为科幻界的“三巨头”。但克拉克绝不仅是科幻作家，他更是一位发明家、科普作家与未来主义者。 早在1945年2月，他给《无线世界》（Wireless World）写了一封信，提到了与地球同步的轨道卫星的创意，同年10月他又发表了一篇论文，概述了这些卫星可以向全球范围提供了无线电信号的覆盖。 在1948年他写了一篇短篇小说《前哨（The Sentinel）》，为斯坦利·库布里克（Stanley Kubrick）的经典电影《2001太空漫游》提供了核心灵感。在电影拍摄期间，卡拉克为电影撰写了同名书籍，为电影观众们解答了诸多的疑惑。 在1962年至1973年期间，克拉克明确三大假说，后被称为克拉克三大定律（他说牛顿仅用了三条定律，对他来说三条也足够了）。 定律一：如果一个年高德劭的科学家说，某件事情是可能的，那他可能是正确的；但如果他说，某件事情是不可能的，那他也许是非常错误的； 定律二：要发现某件事情是否可能，唯一的途径是跨越“可能”的这个界限，从不可能回到“可能”中去； 定律三：任何非常先进的技术，初看都与魔法无异。 想象一下我们乘坐时间机器（时间机器本身就如同魔法一般）带着牛顿从17世纪晚期来到现在剑桥大学的三一学院教堂。这座教堂在牛顿生前已经伫立100多年了，所以当他突然发现身处其中时应该并不会感到太过震惊，在没有意识到当前的日期之前。 然后我们给牛顿先生展示一下苹果（大家都知道牛顿与苹果的故事）。从兜中拿出一个苹果手机，开机并递给牛顿先生让他看看发亮的屏幕和充满各种应用的图标。 别忘了牛顿的伟大成就之一就是通过三棱镜将白光分离成不同频谱的光，从而揭示了光的秘密。所以在阴暗的教堂里，从一个如此小的物体中释放出如此艳丽的光，无疑会给他一个巨大的惊喜。 接着给他播放一段英国田园风景的小视频，或许再配上一些他熟悉的动物和教堂中的音乐，这些画面暂时跟未来世界的样子无关。最后，打开一个网页，里面是500多页他亲笔注释的著作《自然哲学的数据原理》的电子版，教他用手势操作来放大查看细节。 牛顿能够解释出这么小的设备是怎么做到这些功能的吗？虽然他发明了微积分、研究出光学和重力等物理理论，但他从未能将炼金术和化学区分开。 所以他会很困惑，甚至无法设想出这台设备最基本的理念框架。这与他生前致力研究的神秘事物并无二致。对他来说这就是魔法无异。请记住，牛顿可是一个十分聪明的家伙！ 如果一类事物被定义为魔法，我们则很难知晓它的界限。假如我们进一步给牛顿展示手机如何在暗处发光、如何拍照及录音，如何用来当放大镜和镜子，还可以让手机以不可思议的速度来进行多位小数的算术运算，再把它佩戴到身上用作计步器。 牛顿看完这些后，会猜测这台小机器还能做什么？他会不会猜出通过这台设备就在这座教堂里即可与世界上任意角落的人通话？ 三棱镜效应是永恒的，牛顿会不会猜测出iPhone也会像三棱镜一样永远有效，而不明白事实上它需要充电（记住我们是在迈克·法拉利出生前100多年找到的他，所以当时关于电的概念并没有普及）？如果不需要火就可以产生光，那么能把铅炼成金吗？ 这就是我们所有人想象未来科技时所遇到的问题。如果距离我们所能理解的科技太过遥远，我们将不会知晓它的界限，那对于我们来说就是魔法。 一项科技一旦超越了那条“魔法线”，它将不可能再被证伪，因为那的确就是魔法。 每与别人探讨人类是否应该惧怕泛用人工智能时，经常遇到这样的情景，暂时先不论上文中C和D的情况，人们总是认为我不明白它有多强大。可这并不是一个论点，因为我们甚至都不知道它是否存在。以观察到的种种迹象显示我们仍不知道如何建造一个泛用人工智能。所以它的各项属性性能便无从知晓，所以从字面意思上看它的确具有强大的魔力，没有界限。 然而，宇宙中没有任何事物可以没有界限，再强大的AI也不例外。 留神那些说未来科技如同魔法一般的说法，这个说法永远无法被证伪，因为这是一种源于信念的说法，而不是源于科学的。 在日常的社交中，我们可以判断出我们周围人的个体能力值，的确有时个别例外情况会颠覆或混淆我们的估计，这也是种族主义、性别歧视与阶级歧视等问题的根源。 然而总的来说，我们通过观察一个人曾经做事的表现来评估他完成其他事情的能力，也能够从其在一项任务的表现来推测他能否胜任更艰巨的任务，我们自然而然的能从一个人表现出的能力去推断出他在相关领域的胜任能力。 当我们在国外向陌生人问路时，如果他们满怀信心的用我们问的语言进行回答，并且所指的路线看起来也没错。我们就会觉得值得再碰碰运气，继续问乘坐公交时怎么付费。 如果我们十几岁的孩子可以配置新游戏机连到家里的WIFI上，那么我们会认为只要他们愿意就可以把新的家用电脑也连到WIFI上。 如果一个人可以驾驶手动挡的汽车，坚信他也可以开动自动挡的汽车。可是如果这个人生活在北美洲，我们并不认为他可以反着来一遍。 如果我们在一座大型五金商店内询问员工家用电器的配件在哪，他却领我们走到了花园工具的那一行。我们就不太可能再去问同一个人哪能找到浴室里的水龙头。因为我们认为他既然不知道家用电器配件在哪，说明他其实不太清楚店里的布局，所以我们便倾向于找其他人问第二个问题。 现在，让我们来看一下当今AI系统的一些表现的案例。 假设一个人向我们展示一张人们在公园里玩飞盘的照片，我们自然的相信他可以回答下面这些问题：“飞盘是什么形状的？”、“一个人大概可以把飞盘扔多远？”、“飞盘可以吃吗？”、“大概多少人在玩飞盘？”、“3个月大的宝宝可以玩飞盘吗？”、“今天的天气适合玩飞盘吗？”等问题。 与之相反，我们不能指望当一个人因为文化差异，完全不明白照片里显示的是什么时，仍能够回答这些问题。如今，图像标签（image labelling）系统虽然可以比较准确的为网络上的图片打上“人们正在公园内玩飞盘”诸如此类的标签，但仍然不能回答上述那些问题。 而且事实是它们仅限于打标签，根本不能回答任何问题。它们不知道图片中的内容意味着什么，人类是什么，公园通常是在户外的，人类有年龄这个属性，天气本身远比图片上看到的天气要复杂得多等等…… 但是这并不代表这个系统毫无用处。他们对于搜索引擎公司来说具有重大的意义，因为仅是做好打标签的工作就可以让搜索引擎公司从单一文字搜索跨越到可以对图片进行搜索。 不过值得注意的是，搜索引擎通常会为一个问题提供多个答案，让搜索者自己决定哪一个才是真正相关的内容。搜索引擎公司一直为了能在推荐的前几个选项中包含最佳选项而不断的提升搜索引擎的性能。 这种依赖于用户去甄选答案的做法，使得搜索引擎没必要每次都将最佳答案排到第一个。 但如果只能给出一个答案，无论是搜索“巴黎的高档酒店”，或是在一个电子商务网站搜索“时髦领带”的图片，这些搜索引擎的用处将大打折扣。 这就是很多人犯错的地方，每当他们听说某个机器人或AI系统可以处理某一类任务，他们会按照推断人类的“表现 -> 胜任”方式去对这个机器人或者AI系统进行判断。 现阶段机器人和AI系统能做的事情还很有限，人类社会中的归纳概括模式对它们并不适用。如果谁用了和人类同样的推断方式，就会得到十分错误的判断。 “手提箱词”（Marvin Minsky创立的一个术语，意思是说一个单词包含有很多含义，如手提箱打开后里面有很多东西一样，比如：意识，思考，经验等等）。那篇文章讨论了机器学习中的“学习”一词，对人类而言可以有很多类型的学习。人类对于不同类型的学习当然有不同的应对。比如：学习使用筷子与学习一首新歌的体验就非常不同；学习编写代码与在某一城市中学习新的路线也截然不同。 当人们知道机器学习在某个新的领域取得了进展以后，往往会将自己对该领域的学习、思考模式套用过去，对很多模棱两可的词汇的理解就会有偏差，比如“思考”对于人类和机器是完全不同的。 而且很多人不明白，机器的学习是有很多的前提的，它需要研究人员或工程师进行大量的前期工作，要针对不同领域的写相应的代码来处理输入数据，还要有特定的训练数据集以及针对每个新的领域的不同的学习结构。 对人类而言，面对一个新的领域无需精密且繁琐的前期工作就可以直接开始全面的进行学习，这种海绵式的学习方式是目前机器学习远远无法达到的。 同样，当人们听到计算机现在可以击败国际象棋世界冠军（1997年）或围棋世界冠军（2016年）时，他们往往认为它就像人类一样是在“下”棋。 然而事实上这些程序并不知道游戏实际是什么，也不知道他们在玩什么。  正如在The Atlantic网站中，围棋世纪之战文章中指出的那样：驱动人类棋手李世石的是12盎司的咖啡，而AlphaGo作为分布式AI应用需要大量的机器部署，和超过100位科学家在其背后作为支持。 当人类选手进行比赛时，对规则进行小的变动并不会使他无所适从——好的选手懂得如何去适应规则。但对于AlphaGo或Deep Blue 来说并非如此。（Deep Blue 于 1997 年击败国际象棋大师 Garry Kasparov）  这类手提箱词的使用会让人们对现在机器能做到的事情产生误解。 一方面，研究人员与他们所在机构的新闻部门，都渴望宣称他们的研究取得了进展，因此这类手提箱词便有了用武之地。 无论研究人员多么谨慎（实情是往往并不是所有人都总是非常小心），只要研究结果传到新闻部门，然后进入参差不齐的新闻媒体之中，文字中的很多细节便会丢失。 标题大肆宣扬“手提箱”字眼，不断的使读者对人工智能已到达多么高的水平以及有多么接近目标产生误解。 我们甚至还没怎么谈到Minsky列举的许多关于AI系统的手提箱词;比如“意识”，“经验”或“思想”。对于我们人类来说，很难想象如何在没有意识或没有下棋经验，或者行棋思路的情况下下棋。 截至目前，我们的AI系统在人类的各种活动中还远远没有达到手提箱词所能代表的水平，甚至还没有到达初级阶段。当我们夸赞特定领域的AI应用，认为它们在一定程度上达到了“智能”的水平时，媒体，或者说大多数看客，又会将AI的能力泛化，认为其无所不能。 我们担心的是这些单词的部分含义哪怕只是在非常有限的一方面得到了证明，人们往往便将其神化，以为机器在这些方面的智能已经接近类似人类的能力。 用语很重要，但只要我们用一个词语描述有关AI系统的某个东西时，如果这个词也适用于人的话，人们就会高估其对于AI系统的意义。迄今为止大多数适用人类的单词在用到机器身上时，其表达的水平都不过是用在人身上时的千万分之一。 下面是一些已经应用于机器的动词，但在它们描述的实际能力方面机器又与人类完全不同： 预期（anticipate）、击败（beat）、 分类（classify）、 描述（describe）、 估计（estimate）、 解释（explain）、 幻想（hallucinate）、 听（hear）、想象（imagine）、 企图（intend）、 学习（learn）、 建模（model）、计划（plan）、 玩（play）、 认识（recognize）、读（read）、 推理（reason）、 反映（reflect）、 看（see）、 理解（understand）、走（walk）、写（write）。所有这些词语，都可以在相关论文中找到，但在论文中的意思往往只是这些词所蕴含的丰富含义的很小一部分。不幸的是，通过这些词的使用，给人了一种机器已经与人类相差无几了的错觉。 这就导致了人们误解并高估了当今AI的能力。 很多人都遭受过所谓的“指数论”之苦。 每个人对摩尔定律都有自己的想法，至少知道计算机的运算速度会随着时间发展变得越来越快。 戈登摩尔实际上说的是，芯片上的组件数量会每年翻番。 1965年摩尔做出预测的时候所用的下面这张图只有4个数据点：  只推断了10年，但迄今为止已经过去了50年，定律中所说的“每年”也已经变成了“每两年”，尽管这样也慢慢要行不通了。 芯片的元件数翻番使得计算机速度也加倍。而且还使得内存芯片每2年容量变成之前的4倍。同时也使数码相机分辨率越来越高，LCD屏幕像素呈指数增长。 摩尔定律见效的原因是在其将抽象的数字化问题变成了“是”与“不是”的问题。比如这样的一个问题“是否存在电流或者电压呢？”对这个问题而言，无论我们如何将其中的电子数减半再减半，答案都一直是肯定的。但如果一直减半到将其中的电子数只剩几个，量子效应便开始成为主导，答案将不再是肯定的。相似的，我们的硅晶芯片就走到这个关键的节点上。 摩尔定律和类似的指数论可能因三个不同原因失败： a. 它达到了一个物理限制，减半/加倍的过程不再有效。 b. 市场需求趋于饱和，因此推动定律生效的经济因素不再存在。 c. 过程从一开始就不是指数型的。 当一个人深信指数论时，他们可能就会无视上述任何一个原因，并继续用指数论捍卫自己的观点。 在第一个原因的作用下，摩尔定律现在已经近乎止步不前，但正是因为摩尔定律50年来一直发挥其作用，技术的不断创新，硅谷、风投的崛起才得以发生，也使一批极客成为全世界最富有的人。这些事实导致有太多的人认为，包括AI在内的技术的一切都是一直呈指数型发展的。 常识是很多指数型过程其实只是“S曲线”的一部分，也就是说到了一定程度指数型的高速增长就会放缓 。诸如Facebook、Twitter等社交平台用户数的指数型增长最终必将变成S曲线，因为可变成新用户的人数是有限的，所以指数型增长无法一直持续下去。这就是上述情况（b）原因的例子。 但还不止这些。很多时候，个人用户的需求可能阶段性看起来是指数型的，但随后就变得饱和了。 回到本世纪初，麻省理工学院的一个很大的实验室（CSAIL），需要给超过90家研究小组筹集研究经费，试图通过iPod内存的快速增长向赞助商说明世界在进行快速的发展。跟摩尔不一样的是有5个数据点！通过5年的观察，在每年6 – 9月会有新的机型发布，具体的数据是关于400美元可以给iPod提供多大存储。数据如下： Year GigaBytes 2003 10 2004 20 2005 40 2006 80 2007 160 数据有非常完美的指数型（Gregor Mendel如果有这样的数据恐怕会乐开花......）。 然后，用这些推断了几年后我们将对拥有的内容作何安排。 （译者注：Gregor Mendel，遗传学奠基人，早期因数据可靠性未受到重视） 如果推算到现在预计400美元的iPod应该有160000GB（或160TB）的内存。但是今天最高配的iPhone（售价超过400美元）也只有256GB的内存，还不到2007 产的iPod的2倍，而最高配的iPod Touch也只有128GB，相对于10年前的型号内存反而还下降了。 当内存容量大到可以容纳任何常人完整的音乐库时，这个特别的指数型就会突然崩塌。也就是说，当客户需求不再存在时，指数型也会随之停止。 同样的， 很多人以为AI会以同样的速度在先前的基础上不断的提升。但其实深度学习的成功是30年不懈努力的结果，并且没人之前能预想到今天的成功，这只是个黑天鹅事件。 当然这也不是说不会有更多的黑天鹅事件，长期止步不前的AI研究的可能在某一天突然有所进展，并使的许多人工智能应用的表现得到提升。 但是并没有任何一个“定律”说明这样的偶然事件会多久发生一次。对AI的创新与发展而言，这其中并没有物理过程，并不像摩尔定律中那样只需要将元器件做得更小就可以了。这也就是上面的第三个原因（c）的例子。 所以当你看到有人把指数型指数型增长作为AI发展的判断依据时，记住， ，且就算对真正的指数型而言，在达到物理极限或者缺少更多的经济动因时，指数型增长也将不复存在。 很多好莱坞科幻片的情节是这样的，电影中的世界和现实世界十分接近，除了有一两点科技上的不同。这一两点不同往往就是外星人突然出现的原因，原本一切如往常一般，但突然有一天，外星人就出现了。 外星人基于这一两点的不同突然出现似乎在逻辑上还可以接受，但如果是对新的科技而言呢？现实生活中，难道很多新技术都是在同一时间出现么。 在好莱坞的世界中，当整个人类科技受到极大冲击时，电影有时能给出合理的解释。比如《终结者》中，阿诺德·施瓦辛格所扮演的超级机器人来自未来，穿越回的世界就不需要通过一步步的发展进步到可以创造出超级机器人的科技水平。 但是在别的电影中，科技的发展过程就显得有些可笑。 在电影《机器管家》中，Richard(Sam Neill饰)在等待可以独立行走、交谈的类人机器人(Robin Williams 饰)提供早餐时，随手拿起了桌子上的一份报纸…打印在纸张上的报纸！不是平板电脑，也不是收听类似于Amazon Echo智能音箱播放的电台，也不是通过神经链接直接访问互联网。 《银翼杀手》中，Harrison Ford饰演了警探Rick Deckard，Sean Young饰演的机器人Rachael，在电影中Rachael和真人并无二样，然而Deckard怎么联系Rachael的？——用投币公用电话。正如Tim Harford最近指出的，这样的技术老到了读这篇博客的大多数读者都没见识过。（Harford在同一篇文章中评论道：“预测未来技术的发展是及其有趣但是无济于事的游戏”。真是令人深刻的洞见。） 在这两个好莱坞电影的例子中，作者、导演以及制片人设想出了拥有视觉、听觉、能够说话 - 像人类一样存在于这个世界的机器人。不考虑那些神奇的材料和工作原理，这些机器人也算得上是泛用人工智能了。可这些创造家们却不愿意去思考一下在这些吸引人的新技术们发展时，这世界会变成什么样子。 似乎许多AI研究者和专家们，尤其是那些沉迷于预言C、D的悲观主义者们，都忽视了这一点。 许多C、D相关的预言不仅仅在时间维度上犯了错，还忽略了一个事实：如果我们最终创造了如此智能的机器，这个世界将与现在迥然不同。我们并不会骤然间惊讶于超级智能，随着时间的流逝，人类逐渐发明并发展新的技术，世界将因为许多不同的智能设备而变得大不一样。与此同时，我们人类对新的技术以及事物的理解也将与现在大不相同。 比如说，在D类情况（邪恶人工智能打算消灭人类）之前应该出现过不那么智能、不那么好战的机器人，再之前有脾气暴躁的机器人，再再之前有令人讨厌的机器人，再再再之前有傲慢自大的机器人。 我们会一步一步的改变我们的世界，让生活的环境和新技术相互融合。这并不意味着未来世界不会有意外出现，而是说未来并不会像很多人想象的那样，突然一下子天翻地覆。那些惊世骇俗的假想很多是违背现实的，和未来一点关系都没有。 “好莱坞电影”式的修辞手法在争论中有时的确很唬人，但它们和真实的未来没有关系。 随着这个世界逐渐变成软件的天下，某些行业内的新版本发布频率变得非常高。诸如Facebook这样的平台几乎每小时都有新功能上线。因为很多新功能只要经过了集成测试，就算出了问题，版本回退导致的经济影响也是微乎其微。 常常发现在类似的平台上某些功能在短时间之内就突然失效了（今早Facebook的通知下拉菜单功能就失效了 ），也许就是因为发布时出了问题。但对于重要的盈利模块，例如广告投放，改动起来就很谨慎了，版本变化频率基本以周为单位。 这就是硅谷或者网站开发者们习惯的节奏，这的确有用，因为发布新代码的边际成本是非常低的，近乎于零。 而硬件则相反，部署的边际成本非常高，这从我们的日常生活中就能感觉到。如今我们购买的大部分车都不是自动驾驶，里面甚至都没有软件的影子，而这些车可能在2040年还行驶在路上，这给自动驾驶的大规模普及形成了先天的限制。 如果我们建造一座新房子，会默认这座房子能够维持超过100年。我现在住的房子就建造于1904年，而且它还不是附近最老的建筑。 出于成本因素的考虑，实体设备都会设计得很耐用，就算其中有很多的科技甚至事关存亡也不例外。 美国空军现在还在使用B-52轰炸机的变体B-52H轰炸机，这个版本是在1961年发明出来的，也就是说它已经56岁了。最新的一架是在1963年建造的，不过54年前而已。现在这些飞机还将服役到2040年，也有可能更长——据说有打算延长它们的使用期限到超过100年（和“千年鹰号”比比！） 在美国，对陆洲际弹道导弹（ICBM）是义勇兵三型的变体，于1970年引入，共450枚。发射系统依赖于八寸软盘驱动，一些发射流程的数字通信则使用模拟有线电话。 一些工厂里，甚至还看到过使用Windows 3.0的电脑，这一版本发布于1990年。很多工厂的主旨是“只要还没坏，那么就别修它。”这些电脑以及其中的软件已经可靠地运行了相同的软件并完成了他们的任务超过了二十年。 工厂中的自动化控制机制大多基于可编程逻辑控制器（PLC），包括美国、欧洲、日本、韩国以及中国的新型工厂，这是1968年为了替代电磁继电器而引入的。 “线圈”依旧是当今主要使用的控制单位，PLC的编程方式也和24伏特电磁继电器网的效果类似。同时，有些直连的电线被以太网线替代，它们基于RS485八位字符串协议，效仿原来的网络，通过模仿24伏的直流电来传输信息（较原有网络已经有了很大的进步）。 以太网接线并不是开放网络的一部分，而是以点对点的方式连接了这些翻新的自动化控制系统。在这个世界上的大多数工厂中，当你想改变信息流或者控制流时，都需要先请顾问团队们花几周的时间去明确相应的部分是怎么运转的，然后设计新的改动，再然后整个硬件团队再去重新开发和配置这些设备。 理论上整个过程可以更加的合理化，但在现实生活中并不是这样。 这类情况并不只发生在技术停滞了的工厂中，即使是在今天、当下这一分钟，搜索一下招聘信息 - 特斯拉还在给他们佛利蒙市的工厂寻找全职PLC技术顾问。当今最人工智能化的自动驾驶汽车的生产，仍然是由电磁继电器仿真来完成的。 许多AI研究者以及专家都认为这是个数字化的世界，将新的AI技术应用于整个行业包括供应链、工厂、产品设计方面是轻而易举的。 没有什么比这更不切实际了。  重新配置自动化设备所受到的阻力是任何人都想象不到的大。 在这个领域中，任何人都无计可施，只能让改变一点点的发生。那个回形针的例子，既制造回形针的人工智能系统决定聚拢所有的资源用来生产更多的回形针，即使是以牺牲人类所需要的资源为代价。显而易见这就是无稽之谈，因为这整个过程中需要有人去为这个系统未来几十年的物理布线去进行考虑和担忧。 大规模应用机器人和AI相关的想法所需的的时间，几乎都远远比业内、圈外的人们所想像的长得多 。自动驾驶就是一个很好的例子，一夜之间似乎所有人都知道什么是自动驾驶，并且认为很快就会大规模应用到生活中。但实际上，这个过程比想象中慢得多，整个发展过程可能需要花费数十年，而非几年。 如果你认为这过于悲观，想想看，第一辆上路的自动驾驶车是在30年前，而直到现在，我们还没有开始真正普及。1987年在慕尼黑的Bundeswehr University， Ernst Dickmanns和他的团队发明了自动驾驶的货车，在公共高速公路上以90公里每小时（56英里每小时）的速度行驶了20公里（12英里）。 1995年7月，来自卡耐基梅隆大学的Chuck Thorpe和 Takeo Kanade带领他们的团队测试了第一辆不用掌握驾驶盘和踏板的迷你货车。Google和Waymo已经研究自动驾驶车辆超过8年了，但是还没有任何大规模生产的计划。也许，从1987年开始尚需四十、五十甚至六十年，自动驾驶车辆才可以实现真正的普及。 机器人和AI的发明需要很长、很长的时间才可能成为现实并得到大规模应用。 当你看到专家们对机器人和AI做出积极或消极的预测时，我建议好好利用这7类错误来评估一下他们的论证。以我的经验来说，总是能在他们的论述中发现2到3个，或者4个类似的漏洞。 预测未来很难，尤其是在一切未知之前。 原文链接： http://rodneybrooks.com/the-seven-deadly-sins-of-predicting-the-future-of-ai/ Have a Great Definition "
66,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658387&idx=1&sn=094f9ada349ca0b6a849ad7721863a28&chksm=bd4c3f008a3bb616fabff0c6729a6cd85489639cb8f7f0a4313eeef941d841df97c61189df89&scene=27,手把手：四色猜想、七桥问题…程序员眼里的图论，了解下？（附大量代码和手绘）,"长文预警！本文作者Vardan Grigoryan是一名后端程序员，但他认为图论（应用数学的一个分支）的思维应该成为程序员必备。 本文从七桥问题引入，将会讲到图论在Airbnb房屋查询、推特推送更新时间、Netflix和亚马逊影片/商品个性化推荐、Uber寻找最短路线中的应用，附有大量手把手代码和手绘插图， 。 图论的傻瓜式教程   图论是计算机科学中最重要、最有趣，同时也是最容易被误解的领域之一。理解并使用图论有助于我们成为更好的程序员。 先看一下枯燥的定义……图是一组节点V和边E的集合，包括有序对G =（V，E）……🙄 在试图研究理论并实现一些算法的同时，我发现自己经常因为这些理论和算法太过艰深而被卡住...... 事实上，理解某些东西的最好方法就是应用它。我们将展示图论的各种应用，及其详细的解释。 对于经验丰富的程序员来说，下面的描述可能看起来过于详细，但相信我，作为一个过来人，详细的解释总是优于简洁的定义的。   所以，如果你一直在寻找一个“图论的傻瓜式教程”，你看这篇文章就够了。 免责声明 免责声明1： 我不是计算机科学/算法/数据结构（特别是图论方面）的专家。 我没有参与本文谈及的公司的任何项目。本文问题的解决办法并非完美，也有改进的空间。 如果你发现任何问题或不合理的地方，欢迎你发表评论。 如果你在上述某家公司工作或参与相应的软件项目，请提供实际解决方案。请大家耐心阅读，这是一篇很长的文章。 免责声明2： 这篇文章在信息表述的风格上与其它文章有所不同，看起来可能图片也与其所在部分的主题不是十分契合，不过耐心的话，相信最终会发现自己对图片有完整的理解。 免责声明3： 本文主要是将初级程序员作为受众而编写的。在考虑目标受众的同时， 但更专业的人员也将通过阅读本文有所发现。 哥尼斯堡的七桥问题   让我们从经常在图论书中看到的“图论的起源”开始—— 。 故事发生在东普鲁士的首都哥尼斯堡（今俄罗斯加里宁格勒），普莱格尔河（Pregolya）横贯其中。十八世纪在这条河上建有七座桥，将河中间的两个岛和河岸联结起来。 现在这个地区变成这样啦 问 他们当时没有互联网，所以就得找些问题来思考消磨时间。以下是18世纪哥尼斯堡七座桥梁的示意图。 你可以尝试一下，用每座桥只通过一次的方式来走遍整个城市。“每座桥”意味着不应该有没有通过的桥。“只有一次”意味着不得多次通过每座桥。如果你对这个问题很熟悉，你会知道无论怎么努力尝试这都是不可能的；再努力最终你还是会放弃。   Leonhard Euler（莱昂哈德·欧拉）   有时，暂时放弃是合理的。欧拉就是这样应对这个问题的。虽然放弃了正面解决问题，但是他选择了去证明“每座桥恰好走过并只走过一遍是不可能的”。让我们假装“像欧拉一样思考”，先来看看“不可能”。   图中有四块区域——两个岛屿和两个河岸，还有七座桥梁。先来看看连接岛屿或河岸的桥梁数量中的模式（我们会使用“陆地”来泛指岛屿和河岸）。 每块区域连接桥梁的数量   只有奇数个的桥梁连接到每块陆地。这就麻烦了。 两座桥与陆地的例子 在上面的插图中很容易看到，如果你通过一座桥进入一片陆地，那你可以通过走第二座桥离开这片陆地。 每当出现第三座桥时，一旦穿过桥梁进入，那就没法走上每座桥且只走一次离开了。如果你试图将这种推理推广到一块陆地上，你可以证明， 试着记住这个结论。 如果添加一个新的桥梁呢？通过下面这张图，我们可以观察各个陆地所连接的桥的数量变化及其影响。 注意新出现的桥   现在我们有两个偶数和两个奇数。让我们画一条包括了新桥梁的路线。 Wow   桥梁的数量是偶数还是奇数至关重要。现在的问题是：我们知道了桥梁数量是否就能够断定问题可不可解？为了解决问题桥的数量必须是偶数吗？欧拉找到了一种方法证明这个问题。而且，更有趣的是，具有奇数个桥梁连接的陆地数量也很重要。 欧拉开始将陆地和桥梁“转换”成我们所知道的图。以下是代表哥尼斯堡七桥的图的样子（请注意，我们“暂时”增加的桥并不在图中）： 需要特别注意的一点是对问题的概括和抽象。无论何时你解决一个具体的问题，最重要的是归纳类似问题的解决方案。在这个例子中，欧拉的任务是归纳桥梁问题，以便能在未来推广到类似问题上，比如说世界上所有的桥梁问题。可视化还有助于以不同视角来看问题。下面的每张图都表示前面描述的桥梁问题：   所以说图形化可以很好地描绘问题，但我们需要的是如何使用图来解决哥尼斯堡问题。观察从圆圈中出来的线的数量。从专业角度而言，我们将称之为 ，以及连接它们的 。V代表节点（vertex），E代表边（edge）。   下一个重要的概念就是所谓的 ，即入射（连接）到节点的边的数量。在上面的例子中，与陆地连结的桥的数目可以视为图的节点自由度。   欧拉证明了，一次并仅有一次穿过每条边（桥）来遍历图（陆地）严格依赖于节点（陆地）自由度。由这些边组成的路径叫做欧拉路径。欧拉路径的长度是边的数量。 有限无向图G（V，E）的欧拉路径是一条使G的每条边出现并且只出现一次的路径。如果G有一条欧拉路径，那么就可以称之为欧拉图。 定理： 一个有限无向连通图是一个欧拉图，当且仅当只有两个节点有奇数自由度或者所有节点都有偶数自由度。在后一种情况下，曲线图的每条欧拉路径都是一条闭环，前者则不是。   左图正好有两个节点具有奇数自由度，右图则是所有节点都是奇数自由度   首先，让我们澄清上述定义和定理中的新术语。 有限图是具有有限数量的边和节点的图。 图可以是有向图也可以是无向图，这是图的有趣特性之一。举个非常流行的关于有向图和无向图的例子，Facebook vs. Twitter。Facebook的友谊关系可以很容易地表示为无向图，因为如果Alice是Bob的朋友，那么Bob也必须是Alice的朋友。 没有方向，都是彼此的朋友。     还要注意标记为“Patrick”的节点，它有点特别，因为没有任何连接的边。但“Patrick”点仍然是图的一部分，但在这种情况下，我们会说这个图是不连通的，它是非连通图（与“John”，“Ashot”和“Beth”相同，因为它们与图的其他部分分开）。在连通图中没有不可达的节点，每对节点之间必须有一条路径。 与Facebook的例子相对，如果Alice在Twitter上关注Bob，那不需要Bob回粉Alice。所以一个“关注”关系必须有一个方向来指示是谁关注谁，图表示中就是哪个节点（用户）有一个有向边（关注）到另一个节点。   现在，知道什么是有限连通无向图后，让我们回到欧拉图：   为什么我们首先讨论了哥尼斯堡桥问题和欧拉图呢？通过思考实际问题和上述解决方案，我们触及了图理论的基本概念（节点，边，有向，无向），避免了只有枯燥的理论。然而我们还未完全解决欧拉图和上述问题。我们现在应该转向图的计算机表示，因为这对我们程序员来说是最重要的。通过在计算机程序中表示图，我们能设计一个标记图路径的算法，从而确定它是否是欧拉路径。   图表示法：介绍   这是一项非常乏味的任务，要有耐心。记得数组和链表之间的竞争吗？如果你需要对元素进行快速访问，请使用数组；如果你需要对元素进行快速插入/删除等修改，请使用列表。 我不相信你会在“如何表示列表”的问题上有困惑。但是就图的表示而言，实际上却有很多麻烦，因为首先需要你决定的是用什么来表示一个图。相信我，你不会喜欢这个过程的。邻接表，邻接矩阵，还是边表？抛个硬币来决定？   决定了用什么表示图了吗？我们将从一棵树开始。你应该至少看过一次二叉树（以下不是二叉搜索树）。   仅仅因为它由顶点和边组成，它就是一个图。你也许还记得最常见的一棵二叉树（至少在教科书中）的样子。 对于已经熟悉“树”的人来说，这段文字可能看起来太过细致了，但我还是要详细解释以确保我们的理解一致（请注意，我们仍在使用伪代码）。   如果你不熟悉树，请仔细阅读上面的伪代码，然后按照此插图中的步骤操作： 颜色只是为了有好的视觉表现   虽然二叉树是一个简单的节点“集合”，每个节点都有左右子节点，但二叉搜索树却由于应用了一个允许快速键查找的简单规则显得更加有用。 二叉搜索树（BST）对各节点排序。你可以自由地使用任何你想要的规则来实现你的二叉树（尽管可能根据规则改变它的名字，例如最小堆或最大堆），BST一般满足二分搜索属性（这也是二叉搜索树名字的来源），即“每个节点的值必须大于其左侧子树中的任何值，并且小于其右侧子树中的任何值”。 关于“大于”的阐述有个非常有趣的评论。这对于BST的性质也至关重要。当将“大于”更改为“大于或等于”，插入新节点后，BST可以保留重复的值，否则只将保留一个具有相同值的节点。你可以在网上找到关于二叉搜索树非常好的文章，我们不会提供二叉搜索树的完整实现，但为了保持一致性，我们还是会举例说明一个简单的二叉搜索树。   Airbnb房屋查询实例：二叉搜索树   树是一种非常实用的数据结构，你可能在项目开始的时候没有打算应用树这种结构，但是不经意间就用到了。让我们来看一个构想的但非常有价值的例子，关于为什么要首先使用二叉搜索树。 二叉搜索树中这个名字中包括了“搜索”，所以基本上所有需要快速查找的东西都应该放进二叉搜索树中。应该不代表必须，在编程中最重要的事情就是要牢记用合适的工具解决问题。在许多案例中用复杂度为O(N)的简单链表查找比复杂度为O(logN)的二叉搜索树查找更好。 通常我们会使用一个库实现BST，最常用的是C++里面的std::set或是std::map，然而在这个教程中，我们完全可以重新造轮子，重写一个BST库（BST几乎可以通过任何通用的编程语言库实现，你可以找到你喜欢的语言的相应文档）。 下面是我们将要解决的问题： Airbnb房屋搜索截图   如何用一些过滤器尽可能快地根据一些查询语句搜索住房是一个困难的问题；当我们考虑到Airbnb储存了上百万的房源信息后这个问题会变得更困难。   所以当用户搜索住房时，他们有机会接触到数据库中大概四百万个房源记录。当然，网站主页上只能显示有限个排名靠前的住房列表，并且用户几乎不会好奇地去浏览住房列表里百万量级的住房信息。我没有任何关于Airbnb的分析，但是我们可以用一个在编程中叫做“假设”的强大工具，所以我们假设一个用户最多浏览一千套房源。 这里最重要的因素是实时用户数量，因为这会导致数据结构、数据库选择的不同和项目结构的不同。可以很明显的看出，如果只有100个用户，我们一点不必担心，但如果一个国家的实时用户数量远超过百万量级的阙值，我们必须要十分明智地做每一个决定。 是的，“每一个”决定都需要明智的决策。这就是为什么公司在服务方面力求卓越而雇佣最好的员工。Google, Facebook, Airbnb, Netflix, Amazon, Twitter还有许多其他的公司，他们需要处理大量的数据，做出正确的选择以通过每秒数以百万的数据来服务数以百万的实时用户，这一切从招聘好的工程师开始。这就是为什么我们程序员在面试中要与数据结构、算法和解决问题的逻辑作斗争，因为他们所需要工程师需要具有以最快最有效的方式解决大规模问题的能力。 现在案例是，一个用户访问Airbnb主页并且希望找到最合适的房源。我们如何解决这个问题？（注意这是一个后端问题，所以我们不需关心前端或者网络阻塞或者多个http链接一个http或者Amazon EC2链接主集群等等）。 首先，我们已经熟悉了一种强大的编程工具（是假设而不是抽象），让我们从假设我们所处理的数据都能放在内存中。你也可以假设我们的内存已经足够大。多大的内存是足够的呢？这是另外一个好问题。储存真实的数据需要多大的内存，如果我们正在处理四百万单位个数据（假设），而且我们或许知道每个单位的大小，那么我们就可以轻易的算出需要的内存大小，例如，4M＊一个单位的大小。让我们来考虑一个“home”对象和他的特征， 事实上，让我们考虑至少一个在解决问题时需要处理的特征（一个“home”就是一个单位）。我们把它表示为C++语言结构的伪代码，你可以很轻松的将它转换成MongoDB架构或者其它你想要的形式，我们只是讨论特征名字和类型（想象为节约空间所使用的二元位域或位集）。   假设，上面的结构显然不是完美的，还有许多假设和未完成的部分（免责声明里我也说了）。我只是观察Airbnb的过滤器和设计属性列表来满足查找需求。这只是一个例子。现在我们要计算每个AirbnbHome对象需要占用多少内存。 名字只是一个支持多种语言标题的wstring，这意味着每个字符会占用2字节（如果我们用其它语言可能不需要考虑字符大小，但是在C++中，char占用1字节，wchar占用2字节）。 对于Airbnb住房列表的快速浏览让我们假设住房的名字最多包含100个字符（大多数都在50个字符左右，而不是100），所以我们将假设最大值为100，这就意味着占用不超过200字节的内存。uint是4字节，uchar为1字节，ushort为2字节（这些都是假设）。 假设图片用第三方存储服务储存，比如Amazon S3（目前为止，我知道这个假设对于Airbnb来说很可能是真实的，但是这只是一个假设），另外我们有这些照片的链接，考虑到链接没有标准的大小限制，但通常都不会超过2083个字符，所以我们用这个当作链接的最大大小。因为每个房源平均会有5张照片，所以图片最多占用10KB内存。   让我们重新考虑，通常存储服务提供的链接有一部分是固定的。 例如 http(s)://s3.amazonaws.com/<bucket>/<object> ，这是构建链接时常见的规律，所以我们只需要储存真实图片的ID。让我们假设我们用一种ID生成器来对图片产生20字节长的不重复的ID字符串。 那么每张图片的链接就会是这样：  https://s3.amazonaws.com/some-know-bucket/<unique-photo-id> 这让我们节省了空间，储存五张图片的ID只需要100字节的内存。同样的小技巧也可以应用在房东的ID上面，例如房东的ID需要20字节的内存（事实上我们对用户只用了整数ID，但是考虑到一些数据库系统有自己专用的ID生成器，如MongoDB，我们假设20字节长度的ID只是一个中位数，使它可以几乎满足所有数据库系统的变化。Mongo产生的ID大小为24字节）。 最后，我们用4个字节表示长度为32的位集，对于长度大于32小于64的位集用8个字节表示。注意这里的假设，我们在这个例子中用位集表示任意一个数值特征，但是它也可以取多个值，用另一种方法来说，就是一种多项选择的复选框。   例如，每个Airbnb房源都有一个关于可用设施的列表，比如熨斗、洗衣机、电视、wifi、衣架、烟雾报警、甚至笔记本办公区域等。或许房子里有超过20种设施，但我们依然把这个数目固定为20，因为这个数目是Airbnb过滤页面中可选择的设备数量。 如果我们用合理的顺序排列设备的名字，位集可以帮助我们节省一些空间。比如说，如果一个房子里有上述提到的设备（在截图中打勾的设备），我们可以在位集里对应的位置填充一个1。   位集能够用20个比特存储20个不同值   例如，检查房间里是否有“洗衣机”：   或者更专业的： 你可以尽可能地改善代码（并且改正编写的错误），我们只是想强调在这个问题背景下使用位集的思想。 同样也适用于“房屋守则”、“住房类型”等。正如上面代码的注释中提到的，我们不会储存经纬度以避免地理位置上的查询，我们会储存国家代码和城市名字来缩小地址的查找范围（删除掉街道只是为了简化）。 国家代码可以用2或3个字符或3个数字表示，我们会用数字化的表示并且用ushort表示每个国家代码。 城市往往比国家多，所以我们不能用“城市代码”（尽管我们可以生成一些作为内部使用），我们直接使用真实的城市名称，为每个名字平均预留50字节的内存，对于特殊的城市名比如Taumatawhakatangihangakoauauotamateaturipukakapikimaungahoronukupokaiwhenuakitanatahu (85 个字母），我们最好用另外的布尔变量来表示这个是一个特殊的非常长的城市名字（不要试图读出这个名字）。 所以，记住字符串和向量的内存消耗，我们将添加额外的32字节确保最后结构的大小不会超出。我们还会假设我们在64位的系统上工作，尽管我们为int和short选择了最合适的值。   420字节加上之前提到的额外32字节，总共452字节的容量，考虑到有时候你或许会受困于一些校准因素，所以让我们把容量调到500字节。那么每条房屋信息占用500字节内存，对于包含所有房屋信息的列表（有时候我们会混淆列表数量和真实房屋数量，如果我犯错了请告诉我），占用内存约500字节＊4百万＝1.86GB，近似2GB，这个结果看起来很合理。 我们在创建结构的时候做了许多假设，努力节约内存来缩小成本，我估计会最后地结果会超过2GB，如果我在计算中出错，请告诉我。接下来，无论我们要怎么处理这些数据，我们都需要至少2GB的内存。请克服你无聊的感觉，我们才刚要开始。   现在是这项任务中最难的部分。针对这个问题选择正确的数据结构（最高效的列表过滤方法）不是最难的部分。（对我来说）最难的是用大量的过滤器查找这些列表。 如果只有一个查找关键词（只有一个过滤器）那么问题会更容易解决。假设用户只对价格感兴趣，那么我们需要做的就只是选择在这个价格范围内的Airbnb房源。下面是我们用二叉搜索树完成这项任务的例子。     想象全部四百万的房屋对象，这棵树会变得十分巨大。当然，内存也会增长很多，因为我们用BST储存这些数据时，每个树上的节点都有另外两个指针指向它的左子节点和右子节点，这样每个子节点指针都会占用另外8字节（假设是64位的系统）。 对于四百万个节点来说，这些指针总共又会占用62MB，尽管这跟2GB原有的数据大小相比不算什么，但是我们也不能轻易忽视它们。 上个例子中树的所有节点都可以用O(logN)复杂度的算法找到。如果你不熟悉算法复杂度，不能侃侃而谈，我接下来会解释清楚，或者你可以直接跳过复杂度这部分。   算法复杂度 大多数情况下，计算一个算法的大O复杂度是比较容易的。提醒一下，我们总是只关心最坏的情况，也就是算法获得正确结果（解决问题）所需要的最大操作次数。 假设有一个包含100个元素的无序数组，需要比较多少次我们才能找到任意指定元素（同时也考虑指定元素缺失的情况）？ 我们需要将每个元素值和我们要找的值相比较，即使这个要找的元素有可能在数组的第一位（只需要一次比较），但是我们只考虑最坏的情况（要么元素缺失，要么是在数组的最后一位），所以答案是100次。   “计算”算法复杂度其实就是在操作数和输入大小之间找到一个依赖关系，上面那个例子中数组有100个元素，操作数也是100次，如果数组元素个数（输入）增加到1423个，找到任意指定元素的操作数也增加到1423次（最坏的情况下）。 所以在这个例子中，输入大小和操作数的关系是很明显的线性关系：数组输入增加多少，操作数就增加多少。 复杂度的关键所在就是找到这个随输入数增加操作数怎么变化的规律，我们说在无序数组中查找某一元素需要的时间为O(N)，旨在强调查找它的过程会占用N次操作（或者说占用N次操作*某个常数值，比如3N）。 另一方面，在数组中访问某个元素只需要常数时间，即O(1)。这是因为数组结构是一个连续数据结构，持有相同类型的元素（别介意 JS数组），所以“跳转”到特定元素只需要计算其到数组第一个元素间的相对位置。     我们非常清楚二叉搜索树将其节点按序排列。那么在二叉搜索树中查找一个元素的算法复杂度是多少呢？ 此时我们应该计算找到指定元素（在最坏情况下）所需要的操作数。看插图，从根部开始搜索，第一次比较行为将导致三种结果，（1）发现节点，（2）若指定元素值小于节点值，则继续与节点左子树比较，或（3）指定元素值大于节点值，则与右子树比较。 在每一步中我们都可以把所需考虑的节点减少一半。在BST中查找元素所需要的操作数（也就是比较次数）与树的高度一致。 树高是最长路径上的节点数。在这个例子中树高为4。 如图所示，高度计算公式为：以2为底logN+1。所以搜索的复杂度为O(logN+1) = O(logN)。所以最坏情况下，在400万个节点中搜索需要log4000000=~22次比较。 再说回树。二叉搜索树中元素访问时间为O(logN)。为什么不用哈希表呢？哈希表具有常数访问时间，因此几乎任何地方都可以用哈希表。 在这个问题中我们必须要考虑一个很重要的条件，那就是我们必须能够进行范围搜索，例如搜索从房价80美元到162美元的区间内的房子。 在BST中只需要对树进行一次中序遍历并保留一个计数器就可以很容易可以得到一个范围内的所有节点。而相同任务对于哈希表有点费时了，所以对于特定的例子来说选择BST还是很合理的。 不过还有另外一个地方让我们重新考虑使用哈希表。 那就是价格分布。价格不可能一直上涨，大部分房子处在相同的价格区间。看上面这个截图，直方图向我们展示了价格的真实情况，数以百万计的房价在同一个区间（18美元到212美元），他们平均价格是相同的。 简单的数组也许能起到很好的作用。假设一个数组的索引是价格，房子列表按照价格排序，我们可以在常量时间内获得任意价格区间（额，几乎是常数）。下面是它的样子（抽象来讲）：     就像哈希表，我们可以按照价格访问每一组房屋。价格相同的所有房屋都归在同一个单独的BST下。而且如果我们存储的是房屋的ID而不是上面定义的整个对象（AirbnbHome结构），会节省下一些空间。最有可能的情况是，将所有房屋的完整对象保存在一个哈希表中，房屋ID映射房屋对象，同时建立另一个哈希表（或者一个数组），用房屋ID映射价格。 当用户请求一个价格区间时，我们从价格表中获取房屋ID，将结果分割成固定大小（也就是分页，通常一个页面上显示10-30个条目），通过房屋ID获取完整房屋信息。记住这些方法。 同时，要记住平衡。平衡对BST来讲至关重要，因为这是在O(logN)内完成操作的唯一保证。不平衡BST的问题很明显，当你在排序中插入元素时，树最终会变成一个链表，这显然会导致具有线性时间性质的操作次数。 不过从现在开始可以忘记这些，假设我们所有的树都是完全平衡的。再看一眼上面的插图，每个数组元素代表一颗树。那如果我们把插图改成这样：   这更像一个“真实”的图了。这个插图描绘了了最会伪装成其他数据结构的数据结构——图。 图表示法：进阶   关于图有一个坏消息，那就是对于图表示法并没有一个固定的定义。这就是为什么你在库里找不到std::graph的原因。不过BST其实可以代表一个“特殊”的图。关键是要记住， 上个插图表示在单个抽象条件下可以有许多树，图中包含“价格vs房屋”和具有“不同”类型的节点，价格是只具有价格数值的图节点，并指向满足指定价格的所有住房ID（住房节点）的树。它很像一个混合的数据结构，而不是我们在课本例子中常常见到的简单的一个图。 这就是图表示法的关键，它并没有固定的和“合法的”结构用于图表示（不像BST有指定的基于节点的表示法，有左/右子指针，尽管你也可以用一个数组来表示一个BST）。 只要你“认为”它是一个图，你可以用你觉得最方便的方式（对特定问题最便捷）表达它。“认为是一个图”所表达的就是应用特定于图的算法。 其实N叉树更像一个图。   首先想到来表示N叉树节点的伪代码是这样的：   这个结构只表示这个树的一个节点，整棵树应该是这样的： 这个类模拟一个名为root_树节点。我们可以用它构建任意大小的树。这是树的起始点。为了增加一个新的树节点我们需要分配给它一个内存并将该节点添加到树的根节点上。   图与N叉树虽然很像，但稍微有点不同。试着画出来一下。     这个是图吗？说不是也是。它跟之前的N叉树是一样的，只是旋转了一下。根据经验来讲，不管何时你看到一棵树，也不管这是一颗苹果树，柠檬树还是二叉搜索树，你都可以确定他也是一个图。所以为图节点（图顶点）设计一个结构，我们可以得出相同的结构： 这足以构成一个图吗？当然不能。看看之前的两个图有什么不同。   都是图 左边插图中的图中的树没有一个“输入”点（更像是一个森林而不是单独的树），相反的是右侧插图中的图没有不可到达的顶点。听起来很熟悉哈。   定义：如果每对节点间都有一条路径，那么我们认为这个图是连通的。 很明显，在“价格vs房屋”图中并不是每对节点间都有路径（如果从插图中看不出来，就假设价格节点并没有彼此相连吧）。尽管这只是一个例子来解释我们不能构造一个具有单个GraphNode struct的图，但有些情况下我们必须处理像这样的非连通图。看看这个类： 就像N叉树是围绕一个节点（根节点）构建的，一个连通图也是围绕一个根节点构造的。树是“有根”的，也就是说存在一个起始点。连通图可以表示成一个有根树（和几个属性），这已经很明显了，但是要记住即使对于一个连通图，实际表示会因算法不同而异，因问题不同而异。然而考虑到图的基于节点的性质，非连通图可以表示为：   对于像DFS/BFS这样的图遍历，很自然就使用树状表示了。这种表示方法帮助很大。然而，像有效路径跟踪这样的例子就需要不同的表示了。还记得欧拉图吗？ 为了找到一个图具有“欧拉性”，我们应该在其中找到一个欧拉路径。这意味着通过遍历每条边一次去访问所有的节点，并且如果遍历结束还有未走过的边，那就说明这个图没有欧拉路径，因此也就不是欧拉图。 还有一个更快些的方法，我们可以检查所有节点的自由度（假设每个节点都存有它的自由度），然后根据定义，如果图有个数不等于两个的奇自由度节点，那这个图就不是欧拉图。 这个检查行为的复杂度是O(|V|)，|V|是图中节点的个数。当插入新的边来增加奇/偶自由度时我们可以进行追踪，这个行为复杂度为O(1)。这是非常快速。不过不用在意，我们只要画一个图就行了，仅此而已。下面的代码表示一个图和返回路径的Trace()函数。   注意这些无处不在的bug。上面的代码包含大量的假设，比如打标签，因此我们知道顶点有一个字符串类型的标签。你可以随意将它换成任何你想要的东西，不必太在意这个例子里的内容。然后还有命名，代码注释中写道，VELOGraph是Vertex Edge Label Only Graph的缩写（我起的名字）。 重点是，这个图表示法包含一个表，用来将节点标签和节点连接的边映射到该顶点，还包含一个边的列表，该列表含有节点对（由特定边连接）和仅由Trace()函数使用的标记(flag)。 回顾Trace()函数实现过程，边的标记(flag)用来表示已经遍历过的边（在任何Trace()被调用后都需要重置标记）。 推特时间线实例：多线程推送 邻接矩阵是另一种非常有用的有向图的表示方法，推特的关注情况图即是一个有向图。   有向图 这个推特的示例图中，共有8个节点。因此我们只需将这个图表示为|V|×|V|的方阵（|V|行|V|列，|V|为节点数）。如果节点v到u存在有向边，则矩阵的[v][u]元素为真（1），否则为假（0）。 推特的示例   可以看出，这个矩阵有些过于稀疏，但却有利于快速访问。想要知道Patrick是否关注了Sponge Bob，只需访问matrix[""Patrick""][""Sponge Bob""]；想要知道Ann的关注者都有哪些，只需运行出“Ann”的列（列头标黄）；想要知道Sponge Bob关注了谁，只需运行出“Sponge Bob”的行。 邻接矩阵也可用于无向图，与有向图不同的是，若有一条边将v和u相连，则矩阵的[v][u]元素和[u][v]元素都应为1。无向图的邻接矩阵是对称的。   应注意到，邻接矩阵除了可以储存0和1，也可以储存“更有用”的东西，比如边的权重。表示地点之间距离的图就是一个再恰当不过的例子。             上图表示出了Patrick, Sponge Bob和其他人住址之间的距离（这也被称作加权图）。如果两个顶点之间没有直接路径，矩阵对应元素就置无穷符号“∞”。 这一阶段的无穷符号并不意味着二者之间一定不存在路径，也不意味着一定存在。元素的值可能在用算法找出顶点之间路径长度以后重新定义（若要更好地储存顶点和与之相连的边的信息，可利用关联矩阵）。   虽然邻接矩阵看起来很适合用于表示推特的关注情况图，但存储将近3亿用户（月活跃用户数）的布尔值需要300 * 300 * 1 字节，这是大约 。 不知道你的磁盘有多少簇，但我的笔记本可没有这么大的内存。如果用位集呢？位棋盘有一点用，可以让所需存储空间缩减到10000Tb左右，但这还是太大了。前面提到过，邻接矩阵过于稀疏，因此想要储存全部有效信息，需要很多额外空间，因此表示与顶点相连的边的邻接表是更佳选择。 所谓更佳，是因为邻接矩阵既储存了“已关注”信息，也储存了“未关注”信息，而我们只需要知道关注情况，如下所示：   邻接矩阵 vs 邻接表   右侧的插图表示一个邻接表。每个表体现了图中一个顶点所有相邻顶点的集合。要指出的是，一个图可以用不同的邻接表来表示（荒谬但事实如此）。插图中标黄处使用了哈希表，这是一种相当明智的方法，因为哈希表查询顶点的时间复杂度是O(1)。 我们没有提到邻接顶点列表应该用哪一种特定的数据结构存储，链表、向量等都行，任你选择。关键在于，要想知道Patrick有没有关注Liz，我们需要访问哈希表（需要常数时间），遍历这个链表中的所有元素，并与“Liz”元素进行比较（需要线性时间）。 这种情况下，线性时间并不太坏，因为我们只需循环与“Patrick”相邻的顶点，而这些顶点的个数是一定的。那考虑到空间复杂度，这种表示方法是否还适用于推特的例子呢？我们需要至少3亿个哈希表来记录，每个都指向一个向量（我选择向量来避免列表左/右指针的内存消耗），每个向量里包含了...多少元素呢？ 没有相关数据，只找到了推特关注数的平均值，707。假设每个哈希表指向707个用户id（每个占8字节），并假设哈希表每个表头只含有关键字（仍然是用户id），则每个哈希表占据3亿 * 8字节，哈希表关键字占据707 *  8字节，总共就是3亿 * 8 * 707 * 8字节， 。这个结果不算令人满意，但和一万多Tb相比已经好很多了。 说实在的，我不知道这个结果是否合理，但考虑到我在32Gb的专用服务器上花费约为30美元，那么分片储存12Tb需要至少385个这样的服务和400多台控制服务器（用于数据分发控制），因此每月需要大约1.2万美元。考虑到数据有副本，而且总会有些问题出现，我们将服务器的数量扩大到三倍，再增加一些控制服务器。 假设至少需要1500台服务器，则每月需要大约4.5万美元。我当然觉得这不可行，毕竟租用一台服务器于我都有些吃力，但对于Twitter则似乎算不上事（与真正的Twitter服务器相比，确实不算事）。 这样计算够了吗？并不是，我们只考虑了关注情况的数据。推特最重要的是什么？我是指，从技术上来说，最大的问题是什么？ 而且不仅是快速，更像是闪电一样的光速。 假设Patrick发了一条关于食物想法的推文，他的所有关注者都应在一个合理的时间内收到这条推文。多长时间合理呢？我们当然可以随意假设，但我们感兴趣的是真实的系统。下图说明了有人发送推文的后续过程。     我们不知道一条推特需要多久才能推送给所有关注者，但公开的统计数据显示，每天有5亿条推文，因此上图的过程每天要重复5亿次。关于传达速度我找不到有用的数据，但可以模糊地回忆出，大约5秒之内，所有关注者都可以接收到推文。 而且还要考虑处理量很大的情况，比如有着上百万关注量的名人。他们可能只是在海滨别墅里用推文分享了美妙的早餐，推特却要辛辛苦苦把这“相当有用”的信息推送给以百万计的关注者。   为了解决推文推送的问题，我们不需要关注情况的图，而需要关注者的图。关注情况图（用一个哈希表和一些列表表示）可以很方便的找出被某一个用户所关注的所有用户，但却不能找到某一个用户的所有关注者，要想达到这个目标需要遍历哈希表所有的关键字。 因此我们应当构造另一个图，这个图在某种程度上对称相反于前者。这个新的图应该也由3亿个顶点组成，每个顶点指向邻接顶点的列表（数据结构不变），不过这个列表代表关注者。 在上图所示的情况下，每当Liz发送推文，Sponge Bob和Ann都会在他们的时间线上看到更新。实现这一点有一个常用技术，即为每位用户的时间线保留一个单独的结构。在推特这个有3亿用户的例子里，我们大概假设需要至少3亿个时间线（每位用户一个）。 总的来说，当一个用户发送推文，我们应当获取该用户的关注者列表，并更新这些关注者的时间线（将内容相同的推文插入它们的时间线）。时间线可以用列表或是平衡树表示（以推文发送时间的数据作为节点）。   这段代码只是我们从时间线真实的形式中提取出的思想， 。 这种方法对于处理量很大的情况至关重要，因为对于上百万关注者来说，相较于处在关注者列表前端的用户，处于尾端的用户总是较晚看到新推文。下面一段伪代码尝试说明了多线程推送的想法：   如此一来，无论关注者何时刷新时间线，总能接收到新推文。   公道地说，我们不过才触及Airbnb或推特所面临问题的冰山一角。天才工程师们要耗费大量时间，才能构造出推特、谷歌、脸书、亚马逊、airbnb等了不起的复杂系统。阅读本文时别忘了这一点。     推特的例子的重点在于图的使用，尽管没有用到图算法，而只涉及到图的表示。我们的确用伪代码写了一个推送推文的函数，但这只是寻找解决方案过程的产物，我指的“图算法”是这个列表中的算法。 令程序员心力交瘁的图论和图算法应用，某种意义上来说是有些许差异的。前面我们讨论了不用图表示时，高效筛选Airbnb房源的问题。此时，一处明显的缺陷在于，若有两个或以上的筛选关键词，则无法高效筛选。可以图算法可以解决这个问题吗？这我不敢保证，不过可以试一试。 把每个筛选条件当作独立的顶点会有什么结果呢？字面地理解“每个筛选条件”，10美元到1000美元以上的价格、所有城市的名称、国家代码、生活设施（电视、Wi-Fi等等）、成人房客数等等，每个信息都作为一个独立的顶点。   将“类型”顶点加入图能使这些顶点更“好用”，比如将所有代表生活设施筛选条件的顶点连接到“生活设施”顶点。     如果我们将Airbnb房源表示为顶点，并将它们连接到各自符合的筛选条件所对应的顶点上，会是什么情况呢（例如，若“房源1”有“厨房”这项设施，则将其连接至“厨房”）？     稍微处理一下这个示意图，能使之更像一种特殊的图：二分图。   顶点数量比图上显示的更多   二分图（亦称偶图）是一种特殊的图，其顶点可分为两个不相交且独立的集合，从而每条边的两个顶点分别在两个集合中。在我们的例子中，一个集合代表筛选条件（以F表示），另一个代表房源（H）。 例如，有10万个房源标价为62美元，则有10万条边以“62美元”为一个顶点，每条边的另一顶点为满足该条件的房源。考虑空间复杂度最坏的情况，即每个房源满足所有的筛选条件，边总数应为7万 * 400万。 如果每条边用｛筛选条件；房源｝来表示，并用4字节的整型变量表示筛选条件、8字节的长整型变量表示房源，则每条边占据12字节。存储7万 * 400万个12字节的值大约需要3Tb的内存。 不过我们的计算中有一个小错误，由Airbnb的统计数据得知，7万个左右的筛选条件中约有6.5万个是房源所在城市。值得庆幸的是，一个房源不能位于两个或以上的城市。 这意味着与城市相连的边的总数实际应为400万（每个房源只位于一座城市），因此只用计算70000－65000＝5000个筛选条件，故而只需5千 * 400万 * 12字节的内存，总计小于0.3Tb。 这个结果还不错。不过是什么构造出了这样的二分图呢？一般而言，网页/移动端请求会包括几个不同的筛选条件，例如这样：   我们只需找到上述请求对应的所有“筛选条件顶点”，再运行得到所有和这些顶点相连的“房源顶点”，而这就将我们引向图算法。 图算法：介绍 任何针对图形的处理都可以被称作“图算法”。 你甚至可以以写个打印一个图里所有节点的函数，就叫做“我的节点打印算法”。大多数人觉得很难的是那些写在教科书上的算法。霍普克洛夫特－卡普算法（Hopcroft-Karp）就是个二分图匹配算法的例子。下面我们就来试着用这个算法来过滤Airbnb房源吧。 给定一个Airbnb房屋（H）和过滤器（F）的二分图，其中H的每个元素（顶点）都可以有多个相邻的F元素（顶点）相连。 请查找一个和F子集内顶点相邻的H顶点子集。   这个问题的描述已经很绕了，而我们现在甚至还不能确定Hopcroft-Karp算法是否能解决这个的问题。不过我向你保证，解决问题的这个过程会让我们学到很多在图算法背后的基本原理。不过，这个过程并不那么短，所以请大家耐心。   Hopcroft-Karp算法是种以一个二分图作为输入，并产生一个最大基数匹配（maximum cardinality matching）的算法。 最大基数匹配得出的结果是一组由尽可能多的边组成的集合，而集合中所有的边都不会共享节点。 熟悉这种算法的读者可能已经意识到，这并不能解决我们的Airbnb问题，因为匹配要求所有的边都不会共享节点。   我们来看一个例子。为了简单起见，我们假设一共只有4个过滤器和8个房源。房源由A到H的字母表示，过滤器是随机选择的。假设四个过滤器分别为：每晚50美元，有一张床，提供Wifi，提供电视。 已知家庭A价格为50美元，有1张床。从A到H的所有房屋每晚价格都为50美元，床位为1张，但其中很少有提供WiFi或者电视的。下面这张插图详细说明了系统应返回哪一个房源，满足了顾客需求，即一间同时符合所有四种过滤器的住房。 这个问题的解决方案（见上图中左下角连线）要求能通过这些共享顶点的边找到那些可以通过所有四种过滤器的房屋(即D和G)，而Hopcroft-Karp算法去掉了具有共同节点的边，最后得到的是入射到两个子集顶点的边（见上图中右下角的红线）。   就像上图中所展示的，在所有的选择中我们只需要同时满足所有条件的D和G就可以。我们真正需要找的，是共享节点的所有的边。 我们可以给这样的方法设计一种算法，但处理时间对于要求立刻回复的用户来说并不理想。相比之下，建立一个节点带有多个排序键值(key)的平衡二叉搜索树(balanced binary search tree)可能会更快。这有点像数据库的索引文件，直接把主键(primary keys)或者外键(foreign keys)映射到一组所需要的数据记录。 Hopcroft-Karp算法（以及其他许多算法）都是同时基于DFS（深度优先搜索）和BFS（广度优先搜索）图遍历算法。  实际上，在这里介绍Hopcroft-Karp算法的实际原因是可以从二叉树这样性质优良的图循序渐进地转入更难的图遍历问题。   二叉树遍历非常优美，主要是因为它们的递归性质。  （你当然可以自己编写遍历算法）。 如果你曾经遍历过链表，那么遍历很容易理解。 在链表中只需打印当前节点的值（下面代码中的命名项）并在下一个节点继续这个操作即可。 二叉树和这个差不多。首先打印这个节点的值（或其他任何需要使用的值），然后继续到下一个节点。不过寻找下一个节点的时候会有两种选择，即当前节点的左子节点和右子节点。所以你应该对左右子节点都做同样的事情。但你在这里有三个不同的选择： 先打印目前节点的值，然后打印相连的左子节点，最后是右子节点； 先打印相连的左子节点，然后打印目前节点的值，最后是右子节点； 先打印相连的左子节点，然后打印右子节点的值，最后是目前节点。   显然，递归函数看起来非常优雅，虽然它们的运行时间一般都很长。 每次递归调用函数时，这意味着我们需要调用一个完全新的的函数（参见上图）。 “新”的意思是，我们应该给函数参数和局部变量分配另一个堆栈存储空间。 这就是为什么递归调用在资源上显得很昂贵（额外的堆栈空间分配和多个函数调用）而且比较危险（需要注意堆栈溢出）。 因此相比之下更建议通过迭代法来实现同样的功能。 在关键任务系统编程（比如飞行器或者NASA探测器）中，递归是完全禁止的（这个只是传言，并没有实际数据或者经验证明这一点）。 Netflix和亚马逊个性化推荐实例：倒排索引 假设我们要将所有Netflix影片存储在二叉搜索树中，并将影片的标题作为排序键。 在这种情况下，无论何时用户输入开头为“Inter”的内容，程序都会返回一系列以“Inter”开头的电影列表，例如[Interstellar星际穿越，Interceptor截击战，Interrogation of Walter White绝命毒师]。 如果这个程序可以找出标题中包含“Inter”的所有电影（包括并没有以“Inter”开头，但是标题中包含这个关键字的电影），并且该列表将按电影的评分或与该特定用户相关的内容进行排序就更好了（例如，某用户更喜欢惊险片而不是戏剧）。   这个例子的重点在于对二叉搜索树进行有效的范围查询。但和之前一样，在这里我们不会继研究冰山还没露出的部分。 基本上，我们需要通过搜索关键字进行快速查找，然后获得按关键字排序的结果列表。其实这很可能就是电影评分或基于用户个性化数据的内部排名。 当然，我们会尽可能坚持KISK原则（Keep It Simple，Karl）。    “KISK”或““let’s keep it simple”或“for the sake of simplicity”，这简直就是教程编写者从真实问题中找一些抽象化的简单的例子，并以伪代码形式来讲解的超级借口。这些事例的解决方案简单到往往在祖父母一辈的电脑上都能运行。   这个问题也可以很容易应用到亚马逊的商品搜索中，因为 。 Netflix里有不少影片，亚马逊里有很多商品，在这里我们把影片和商品叫做“物品”，所以每当你查找“物品”时，可以联想Netflix中的电影或亚马逊的任何合适的产品。  关于这些物品，最常见的就是用程序去解析标题和描述（在此我们只考虑标题）。所以如果一个操作员（比如一位通过管理板将物品数据插入Netflix / Amazon数据库的员工）把新项目插入到数据库里，物品的标题就被一些被叫做“ItemTitleProcessor”的程序处理，从而产生一系列关键字。   每个物品都有一个唯一的ID，这个ID和物品标题中的关键字有直接关联。这是搜索引擎在爬全球各种各样的网站时所做的事。他们分析每个文档的内容，对其进行标记（将其分解为更小的词组和单词）并添加到列表中。 这个表将每个标记（单词）映射到已被标记成 ”包含这个标记” 的文档或网站的ID上。 因此，无论何时搜索“hello”，搜索引擎都会获取映射到关键字“hello”的所有文档。现实中这个过程非常复杂，因为最重要的是搜索的相关性，这就是为什么Google很好用。Netflix /亚马逊也会用类似的表。同样的，读者们请在看到物品（item）时想想电影或网购的商品。   倒排索引 又来了，哈希表。是的，我们将为这个倒排索引（索引结构存储了一个和内容相关的映射）保留一个哈希表。 为什么选择二叉搜索树呢？ 这是因为我们希望可以保持物品的排序，并同时对按顺序排好的部分进行处理（响应网页前端的请求），例如请求分页时的100个项目。 这并不能说明二叉搜索树的强大功能，但假设我们还需要在搜索结果中进行快速查找，例如，你想要查找关键字为“机器”(machine)的所有三星电影。 这里需要注意的是，在不同的树中同一个物品重复出现并没有问题，因为通常用户可以使用多个不同的关键字找到同一个物品。我们将使用如下定义的物品进行操作：   我们将使用下面提到的这个方法运行程序： 每次将新物品插入数据库时，它的标题都会被处理，并添加到总索引表里，该表会创建一个从关键字到对应物品的映射。 可能有很多物品共享相同的关键字，因此我们将这些项目保存在按照评分排序的二叉搜索树中。当用户搜索某个关键字时，他们会得到按评分排序的物品列表。我们如何从排序了的树中获取列表呢？答案是通过中序遍历。   下面这段代码实现中序遍历： 但是！首先我们首先需要评分最高的项目，而中序遍历首先输出的是评分最低的项目。这个结果和中序遍历的性质有关，毕竟从低到高的中序遍历是自下而上的。 为了得到理想的结果，即列表按降序而不是升序排列，我们应该仔细研究一下中序遍历的实现原理。 我们所做的是通过左节点，然后打印当前节点的值，最后是右节点。 正因为我们一直从左开始，所以最先的得到的是“最靠左”的节点，也就是最左节点，这是在整个二叉树里具有最小值的节点。因此，简单地将遍历方法改成右节点优先，就可以得到降序排列的列表。 和其他人一样，我们可以给这种方法命名，比如“reverse in-order traversal”，反序遍历。现在我们来更新一下之前写的代码（这里引入单个列表，注意，前方bug出没）： 就是这样，我们可以快速提供物品的搜索结果。 如上所述，倒排索引主要用于Google之类的搜索引擎。 尽管Google是个特别复杂的搜索引擎，但它确实使用了一些简单的想法（虽然用非常现代化的方法实现），以将搜索查询与物品文档进行匹配，并尽可能快地提供搜索结果。   这里，我们用了树的遍历来按照某种排序来处理搜索结果。在这一点上，先序、中序和后序遍历看起来可能绰绰有余，但有时还需要另一种类型的遍历。大家可以试着解决这个众所周知的编程面试题“如何逐层打印一个二叉树？”:   深度优先搜索DFS和广度优先搜索BFS   如果你对这个问题不熟悉，请想一下遍历树时用来存储节点的数据结构。如果我们拿逐层树遍历和先序遍历、中序遍历、后序遍历比较，最后会得到两种主要的图遍历方法， 。   深度优先搜索寻找最远的节点，广度优先搜索先探索最近的节点。   深度优先搜索：做的多，想的少。 广度优先搜索：先四处观望再进行下一步动作。   DFS很像先序遍历、中序遍历、后序遍历，而BFS可以逐层遍历节点。为实现BFS，需要一个队列（数据结构）来保存图的“层次”，同时打印（访问）其“父母层”。 上图中，放入队列的节点为浅蓝色。基本上逐层进行，每层节点都从队列中获取，访问每个获取的节点时，将其子节点插入到队列中（用于下一层）。下面的代码非常简单，很好地说明了BFS的思路。假设图是连通图，可以修改以适用于非连通图。   这一思路对基于节点的连通图表示非常简单。请记住，对于不同表示，图遍历的实现也不相同。BFS和DFS是解决图搜索问题的重要方法（但记住图搜索算法有很多很多）。 虽然DFS是优美的递归实现，但迭代实现也可行的。而BFS的迭代实现我们会用一个队列，对DFS需要一个堆栈。图论中的一个热门问题，是找节点间最短路径。来看最后一个例子。 Uber最短路线实例 Uber有5000万乘客和700万司机，所以高效地将司机与乘客进行匹配非常重要。司机使用Uber司机专用应用来接单，乘客就用Uber应用叫车。 首先是定位。后台需要处理数百万条乘客请求，并发送给附近的司机，通常会发送给多个司机。虽然将乘客请求发送给附近所有司机看起来更简单，甚至有时候也更有效，但是进行一些预处理往往效果更好。     除了处理收到的请求，根据乘客坐标查找定位区域，进而查找坐标最近的司机外，还需要为乘客找到合适的司机。假设已经有了包含乘客及几个附近车辆的小地图，（已经对比了车辆当前坐标和乘客坐标，并确定了附近车辆，这一过程称为地理信息处理），小地图如下：     车辆到乘客的可能路线用黄色标出。那么现在的问题是 。虽然这个问题更像Google地图而不是Uber应该考虑的，但我们还是要解决这个简化的问题，因为通常乘客附近有多辆车，Uber需要计算距离最近且评分最高车辆发送给乘客。 对于上图而言，要分别计算三辆车抵达乘客的最短路线，再决定哪辆车是最佳选择。为简化问题，这里讨论只有一辆车的情况。以下标出三条抵达乘客的路线。 抵达乘客的可能路线   接下来进入重点，先将小地图抽象成图：   这是无向加权图（确切地说是边加权图）。为了找到顶点B（汽车）和A（乘客）之间的最短路径，应该找包含尽可能小的权重的边的路径。我们用Dijkstra版本；你也可以自行设计你的方案。以下是Dijkstra算法的维基百科。   将开始的节点称为起始节点。Y节点的路径长度定义为从出发点到Y点的总路径长度。Dijkstra算法将会分配一些初始距离值然后逐步改善它们。 1.将所有节点设为未访问。设置一个包含所有未被访问节点的集合，称为未访问集合。 2. 对所有顶点的路径长度赋暂定值：将起始节点的路径长度设为0，所有其他顶点的路径长度设为无穷大。将起始节点设为当前节点。 3.对于当前节点，考虑其周围所有未访问的相邻节点，并且计算通过当前节点到它们的暂定距离。将新计算得到的暂定距离与当前分配的距离进行比较并选择较小的值然后分配。例如，如果当前节点A的距离为6，连之相邻B的长度为2，则通过A到B的距离将为6 + 2 = 8。如果B先前被标记的距离大于8，则将其更改为8.否则，则保持当前值。 4.当我们考虑完当前节点的所有相邻节点时，将当前节点标记为已访问并将其从未访问节点集中移除。被访问的节点将不会再次被查看。 5.如果目标节点已经被标记为已访问（当目标是两个特定节点之间的路径）或者未访问集合中的节点之间的最小暂定距离是无穷大时（目标完全遍历时;发生在初始节点和剩余的未访问节点之间没有连接时），将会停止。算法已经完成。 6.否则，选择未访问过的并且具有最小暂定距离的节点，把它作为新的“当前节点”，然后回到步骤3。 应用Dijkstra算法到示例中，顶点B（车）是起始节点。前两步如下：   所有的节点都属于未访问集合，需要注意图示右侧的表格。对于所有节点，它将包含从B到前一个（标记为“Prev”）节点的所有最短距离。例如，从B到F的距离是20，前一个节点是B。     将B标记为已访问，然后移动到它的相邻节点F。     现在将F标记为已访问，并选择具有最小暂定距离的点为下一个未访问节点，即G。依然需要注意左侧的表格，在前面的图例中，节点C，F和G已经将它们的暂定距离设置为通过之前所提到的结点的距离。     如同算法阐述的那样，如果目标节点被标记为已访问（在我们的例子中，当要两个特定节点之间的路径时），那我们可以结束算法了。因此，下一步终止算法返回下面的值。     所以我们既有从B到A的最短距离又有通过F节点和G节点的路径。 这是Uber中的一个再简单不过的例子，只是沧海一粟。然而，这是很好的起点，可以帮你迈出探索图论应用的第一步。 关于图论还有很多内容有待研究，这篇文章只是冰山一角。 读到最后的你非常棒 ，奖你一朵小红花，别忘了点赞和分享哟，谢谢。 原文链接： https://medium.freecodecamp.org/i-dont-understand-graph-theory-1c96572a1401 【今日机器学习概念】 Have a Great Definition "
67,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658283&idx=2&sn=b49fdb6396fd7b9d38f9774bd809f27b&chksm=bd4c3fb88a3bb6ae7032656363f84272287c3281cb5e0f99cc4e08422d78ec905231d446d4c0&scene=27,业界 | 福布斯：2018年机器学习试点及实施数量将翻倍,"大数据文摘作品 编译：Zoe Zuo、赖小娟、小鱼 对人工智能发展话题的讨论曾被几度推向高潮，为了更快抢占深度学习的市场，各个科技企业也在迅速布局。根据预测，2018年深度学习的市场呈现出以下趋势： 从2013年至2017年间，机器学习专利的年复合增长率（Compound Annual Growth Rate，CAGR）达到34%，在所有已授予的专利类别中增速排名第三。 国际数据公司（International Data Corporation, IDC）预测，人工智能（AI）和机器学习（ML）上的支出将会从2017年的120亿美元增长到2021年的576亿美元。 德勤全球（Deloitte Global）预测，2018年机器学习的试点与实施数量将比2017年增加一倍，至2020年将再次翻番。 以上精彩的见解来自机器学习中市场预测、市场评估和前景规划等内容的最新系列。机器学习影响着世界范围内众多的数据密集型产业，推动大众对资本风险投资、私募股权融资、兼并与收购等领域的持续关注，参与者都期望在机器学习领域知识产权与专利的追逐中胜出。 芯片组定制（custom chipsets）是机器学习知识产权增长最快的领域之一。德勤全球预测，全球各数据中心今年将使用多达80万件机器学习芯片。 2018年，企业将加大在机器学习项目上的研究、投资与试点力度。虽然不同预测机构使用的方法和数据来源不尽相同，但所有市场预测、市场评估和前景规划都反映出，机器学习正在改善着企业的敏锐性和洞察力，使企业发展得更快、获得更多收益。 后台回复“ ”下载所有研究报告PDF~ 机器学习的市场预测、市场评估和前景规划中有以下几项关键内容： 1.在商业智能（Business Intelligence，BI）和分析市场，支持机器学习的数据科学平台（Data Science Platforms）的数量有望在2021年实现13%的年复合增长率。 数据科学平台的市场占有率将超越眼下正热的商业智能和分析软件，后者同期的年复合增长率预计为8%。数据科学平台2017年的市值为30亿美元，到2021年将上升至48亿美元。 数据科学平台的发展速度将超过商务智能和分析软件 2.从2013年至2017年间，机器学习专利的年复合增长率达到34%，在所有已授予的专利类别中增速排名第三。 2017年，IBM、微软、谷歌、领英（LinkedIn）、Facebook、英特尔和富士通是发布机器学习专利最多的七大公司。 机器学习专利排名 3.在受访机构中，有61%的机构表示他们最经常选择机器学习/人工智能作为公司2018年最重要的数据科学计划 。在积极使用机器学习和人工智能的过程中，有58%机构表示在其生产中运用了相关模型。 最受关注的机器学习与人工智能计划 （从上到下依次为：机器学习/人工智能、大数据/商业分析、数据安全与合规、物联网、管理数据增长、迁移遗留系统、数据中心合并） 4.亚马逊、苹果、谷歌、特斯拉和微软等技术市场领袖凭借自身在机器学习和人工智能投资上的极大优势，引领着各自领域内的行业发展。 这些公司都将机器学习植入新一代产品内，依托机器学习和人工智能来改善用户体验、优化销售渠道。 投资等级与企业转型的抗衡 (图例从左到右以此为：技术、零售、通讯、媒体和技术、工业工程、汽车、金融机构集团、医疗、航空航天与国防) 5.2017年，福雷斯特研究公司（Forrester）针对14家供应商制定了23项评估标准，评估得出，SAS （Statistical Analysis System，全球最大的软件公司之一）、  (Systems, Applications & Products in Data Processing，全球最大的企业管理和协同化商务解决方案供应商）三大公司引领了预测分析和机器学习市场。 据福雷斯特预计，到2021年，预测分析和机器学习市场的年复合增长率将达到21%，原因是这些公司通过其客户端注意到客户询价与购买活动有明显增加。              Forrester WaveTM：2017年第一季度预测分析和机器学习的解决方案。 (白色圆圈为供应商完全参与，灰色圆圈为供应商不完全参与) 6.德勤全球预测，2018年机器学习试点与实施的数量将比2017年增加一倍，至2020年将再次翻番。 推动机器学习试点增长的因素包括应用程序界面（API）的更加广泛支持、自动化数据科学任务、训练数据的需求减弱、训练数据的进程加快以及对结果更加深入的分析。 2018德勤全球关于机器学习的预测 7.有60%的机构处于机器学习应用的不同阶段，45%（将近一半）的机构认为机器学习拓展了数据分析与洞察力的应用范围，35%的机构已经能借助机器学习更快地完成数据分析，提升洞察速度，增强了机构的敏锐性。35%的机构还发现，机器学习提升了他们研发新一代产品的能力。 如果你的机构当前在使用机器学习，从中实际收获了什么？ （从上到下依次为：更全面的数据分析和洞察力、加速数据分析及提升洞察速度、增强研发能力（下一代产品）、提升内部流程（运营）的效率、增进对客户/潜在客户的理解、竞争优势、成本削减、提升外部流程（价值链）的效率） 8.据麦肯锡（McKinsey）估算，2016年人工智能的年度外来投资总规模在80亿到120亿美元之间，其中机器学习就吸引了60%的投资。 机器人和语音识别是最受投资者青睐的两个领域。 投资者最乐意投资机器学习初创公司，因为基于代码的初创企业在更新产品特性时能够迅速作出响应。基于软件的机器学习初创公司相对于机器人初创公司更受偏爱，因为后者投资成本过高。由于诸如此类的因素，机器学习领域的企业并购迅速火热起来。下图描绘了不同技术受到的外来投资的分布。 机器学习领域获得了最多的投资，尽管相关技术之间的界限并非十分清晰。 （图中涉及的技术分别为：自动驾驶汽车、机器学习、多用途及非特定性应用、计算机视觉、自然语言、智能机器人、虚拟代理。评估包含了专攻人工智能领的公司的年度风险资本投资，业务涉及人工智能的公司的私人股权投资，以及各公司之间的并购。） 9.德勤全球预测，数据中心使用的机器学习芯片数量将从2016年的10万至20万，今年将暴增至80万。 其中至少有25%是现场可编程门阵列（Field Programmable Gate Arrays，FPGA）芯片和特定用途集成电路（Application Specific Integrated Circuits，ASICs）芯片。德勤发现，机器学习加速器技术的可用市场总量（Total Available Market，TAM）在2020年将达到260亿美元。 全力加速：新一代机器学习芯片 10.亚马逊借助机器学习来改善用户对其业务的使用体验，包括产品推荐，替代性产品预测，欺诈检测，元数据验证与知识获取。 亚马逊的机器学习布局 （图中从左往右依次是：零售、客户、卖家、目录、数码） 11.国际数据公司（International Data Corporation，IDC）预测， 12.全球机器学习市场2017年的规模为14.1亿美元，预计2022年增长到88.1亿美元，年复合增长率达到44.1% 。该市场在世界范围内迅速扩张，其中的贡献因素包括在数据聚合、集成与分析上优势突出的技术，以及更具扩展性的云平台。 13.认知科学与人工智能系统2017年的全球收入为125亿美元，2020年将超过460亿美元。 《人工智能投资指南》（An Investors’ Guide to Artificial Intelligence），摩根大通，2017年11月27日（PDF第110页）。 美国商业专利数据库（专利分析）（IFI Claims Patent Services (Patent Analytics) ），《8项当前增长最迅猛的技术》（8 Fastest Growing Technologies SlideShare Presentation）。 数据科学协会（Data Science Association），《预测分析和机器学习供应商2017》（Predictive Analytics & Machine Learning Vendors 2017）；由SAP提供的《Forrester WaveTM：预测分析和机器学习解决方案，2017年第一季度》（The Forrester Wave™: Predictive Analytics And Machine Learning Solutions, Q1 2017）。 《2018德勤全球预测》（Deloitte Global Predictions 2018 Infographics）。 《机器学习：竞争优势的新型试验田》（Machine Learning: The New Proving Ground for Competitive Advantage），Google和MIT技术研究综述（PDF第10页）。 《人工智能，下一个数字前沿》（McKinsey Global Institute Study, Artificial Intelligence, The Next Digital Frontier），麦肯锡全球全球研究院研究报告（PDF第80页）。 《机器学习市场 - 至2022年的全球性预测-市场概况与产业趋势》（Machine LearningMarket - Global Forecast to 2022 - MarketOverview & Industry Trends） 链接： https://www.prnewswire.com/news-releases/machine-learning-market---global-forecast-to-2022---market-overview--industry-trends-300531729.html 来源：《根据最新IDC支出指南，认知科学与人工智能系统今年的全球性支出预计达到125亿美元》（Worldwide Spending on Cognitive and Artificial Intelligence Systems Forecast to Reach $12.5 Billion This Year, According to New IDC Spending Guide.）。 链接： https://www.idc.com/getdoc.jsp?containerId=prUS42439617 《2018展望：机器学习与人工智能，一份对1600余名数据从业者的调查》（2018 Outlook: Machine Learning and Artificial Intelligence, A Survey of 1,600+ Data Professionals）, MemSQL（PDF第14页）。 《应用机器学习的建议》（Advice for applying Machine Learning），吴恩达，斯坦福大学（PDF第30页）。 《管理人员的机器学习指南》（An Executive’s Guide to Machine Learning），麦肯锡季刊，2015年6月。 链接： https://www.mckinsey.com/industries/high-tech/our-insights/an-executives-guide-to-machine-learning 《投资人的人工智能指南》（An Investors' Guide to Artificial Intelligence），摩根大通，2017年11月27日（PDF第110页）。 《人工智能和机器学习在金融市场发展和对金融稳定的影响》（Artificial intelligence and machine learning in financial services Market developments and financial stability implications），金融稳定委员会（PDF第45页）。 《大数据和AI策略——面向投资的机器学习和数据方法》（Big Data and AI Strategies Machine Learning and Alternative Data Approach to Investing），摩根大通（PDF第280页）。 《Google和MIT技术评论研究：机器学习：竞争优势的新探索》（Google & MIT Technology Review study: Machine Learning: The New Proving Ground for Competitive Advantage）（PDF第10页）。 《全力加速：新一代机器学习芯片》（Hitting the accelerator: the next generation of machine-learning chips），德勤（PDF第6页）。 《机器怎么学习？算法是机器学习的关键》（How Do Machines Learn? Algorithms are the Key to Machine Learning），博思艾伦咨询公司（信息图表）。 链接： https://www.boozallen.com/s/insight/blog/how-do-machines-learn.html 《据 IBM 预测，到 2020 年，对数据科学家的需求增长幅度将达到 28%》（IBM Predicts Demand For Data Scientists Will Soar 28% By 2020），福布斯，2017年5月13日。 链接： https://www.forbes.com/sites/louiscolumbus/2017/05/13/ibm-predicts-demand-for-data-scientists-will-soar-28-by-2020/?utm_content=buffer91f1f&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer#391b252b7e3b 《亚马逊的机器学习》（Machine Learning At Amazon），亚马逊网络服务（PDF第47页）。 《机器学习的演变（信息图）》（Machine Learning Evolution (infographic)），普华永道，2017年4月17日。 链接： http://usblogs.pwc.com/emerging-technology/machine-learning-evolution-infographic/ 《机器学习：如火如荼》（Machine learning: things are getting intense），德勤（PDF第6页） 《机器学习报告：计算机通过案例进行学习的力量和潜力》（Machine Learning: The Power and Promise Of Computers That Learn By Example），英国皇家协会机器学习项目（PDF第128页）。 《人工智能：下一个数字前沿》（Artificial Intelligence, The Next Digital Frontier），麦肯锡全球研究院研究报告（PDF第80页）。 《麦肯锡报告：2017机器学习与人工智能现状》（McKinsey's State Of Machine Learning And AI, 2017），福布斯，2017年7月9日。 链接： https://www.forbes.com/sites/louiscolumbus/2017/07/09/mckinseys-state-of-machine-learning-and-ai-2017/#4448c95d75b6 《2017年预测：人工智能将推动洞察革命》（Predictions 2017: Artificial Intelligence Will Drive The Insights Revolution），福雷斯特研究公司，2016年11月2日（PDF第9页）。 《风险与回报：机器学习经济影响的场景》（Risks And Rewards: Scenarios around the economic impact of machine learning），经济学人智库（PDF第80页）。 《凭借人工智能更上一层楼——人工智能给德国及其工业部门带来了什么？》（Smartening up with Artificial Intelligence (AI) - What’s in it for Germany and its Industrial Sector?），数字/麦肯锡咨询公司（PDF第52页）。 《究竟什么是机器学习？》（So What Is Machine Learning Anyway?），商业内幕（Business Insider），2017年11月23日。 链接： http://www.businessinsider.com/what-is-machine-learning-quick-explainer-2017-11 《2017年人工智能/机器学习领域十大最具创新力的企业》（The 10 Most Innovative Companies In AI/Machine Learning 2017），连线（Wired）。 链接： https://www.fastcompany.com/3069025/the-10-most-innovative-companies-in-ai-machine-learning-2017 《人工智能的商业影响与应用案例》（The Business Impact and Use Cases for Artificial Intelligence），Gartner（PDF第28页）。 《人工智能，自行搭建还是购买？》（The Build-Or-Buy Dilemma In AI），波士顿咨询公司，2018年1月4日。 链接： https://www.bcg.com/publications/2018/build-buy-dilemma-artificial-intelligence.aspx?linkId=47806407 《新一代医学：人工智能与机器学习》（The Next Generation of Medicine: Artificial Intelligence and Machine Learning），TM Capital（PDF第25页）。 《企业人工智能路线图》（The Roadmap to Enterprise AI），基于Gartner研究的Rage Networks简报(PDF第17页)。 《你会尽快接纳AI吗？》（Will You Embrace AI Fast Enough？），科尔尼管理咨询公司（AT Kearney），2018年1月。 链接： https://www.atkearney.com/operations-performance-transformation/article?/a/will-you-embrace-ai-fast-enough 后台回复“ ”下载所有研究报告PDF~ 原文链接： https://www.forbes.com/sites/louiscolumbus/2018/02/18/roundup-of-machine-learning-forecasts-and-market-estimates-2018/#38e935912225 Have a Great Definition "
68,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658269&idx=3&sn=6c6e4a6019cc6fbf4125b7f0ec2c012d&chksm=bd4c3f8e8a3bb6983cf83341fd6ac757b66f9346ca14400cba135ac2d42033e4151f089b7878&scene=27,学界 | 胶囊网络是如何克服卷积神经网络的这些缺点的？,"大数据文摘授权转载自OReillyData 作者：Aurélien Géron 胶囊网络（CapsNet）是一种新的热门的神经网络架构。它可能对深度学习带来深远的影响，特别是对计算机视觉领域。等一下！计算机视觉不是差不多已经被解决了吗？我们不是已经看到了多种卷积神经网络（CNN）的神奇案例？它们不是已经在计算机视觉任务（例如分类、定位、物体检测、语义分割或实例分割，见图1）上实现超越人类的水平了吗？ 图1 一些主要的计算机视觉任务。当前，每种任务都需要一个不一样的CNN架构。比如分类里的ResNet，物体检测里的YOLO，实例分割里的Mask R-CNN等。图片由Aurélien Géron提供。 恩，是的。我们已经见到了很多神奇的CNN，但是， 它们需要非常多的图片进行训练（或重复使用了已用海量数据训练过的神经网络的一部分）。 而CapsNet使用少得多的训练数据就能泛化。 CNN们并不能很好地应对模糊性，但CapsNet可以。所以它能在非常拥挤的场景里也表现得很好（尽管它目前还需要解决背景图的问题）。 CNN会在池化层理丢失大量的信息，从而降低了空间分辨率（见图2），这就导致对于输入的微小变化，其输出几乎是不变的。在诸如语义分割这样的场景里，这会是一个问题，因为细节信息必须要在网络里被保留。现在，这一问题已经被通过在CNN里构建复杂的架构来恢复这些损失的信息所解决。 在CapNet里面，细节的姿态信息（比如对象的准确位置、旋转、厚度、倾斜度、尺寸等）会在网络里被保存下来，不用先丢失再恢复。输入上微小的变化会带来输出上的小变化，信息被保存。这被称为“等变的”。这就让CapsNet能使用一个简单和统一的架构来应对不同的视觉任务。 最后，CNN需要额外的组件来自动识别每个小部分属于哪个物体（例如这条腿属于这只羊）。而CapsNet则可以给你这些部分的层级结构。 图2 DeepLab2的图像分割管道，来自Liang-Chieh Chen等。注意这里面CNN的输出（右上角图）是非常得粗糙。这就需要一些额外的步骤来恢复丢失的细节。图片来自论文《DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs》，获作者友情授权使用。可以查看S. Chilamkurthy的这篇很棒的博文来了解语义分割的神经网络的架构有多么复杂多样。 CapsNet是在2011年在Geoffrey Hinton等人的一篇名为《Transforming Autoencoders》的论文中首次出现。但仅在几个月前（即2017年11月），Sara Sabour、Nicholas Frosst和Geoffrey Hinton发表了一篇名为《Dynamic Routing between Capsules》的论文，其中介绍了CapsNet架构。 该架构在MNIST（著名的手写数字图像数据集）上达到了最先进的性能，并且在MultiMNIST数据集（一种有重叠的不同数字组的手写数字的变体）上获得了比CNN好得多的结果。见图3。 图3 MultiMNIST图片（白色）和由CapsNet重构后的结果（红色和绿色）。“R”=重构后的结果；“L”=标注。例如，对第一个样例（左上角）的预测是准确的，重构的结果也对。但是在第五个例子里，预测（5,7）是错的，不是（5,0）。因此，5被正确地重构了，但是0没有。图片来自论文《Dynamic routing between capsules》，作者友情授权使用。 尽管有上述这些优点，但CapsNet还远未到完美的程度。首先，它们在更大的图片上（例如CIFAR10或ImageNet数据集里）还没有CNN的表现好。另外，CapsNet的计算量很大，同时它还不能区分靠的很近的相同的物体（这被称为“拥挤问题”，人类也有这个问题）。 但是这里的关键点是胶囊网络是非常有希望的，看起来只要做一些修改就能让胶囊网络充分释放它们的潜能。毕竟现代CNN在1998年就被发明了，但也要经过几次改进，直到2012年的ImageNet大赛上才达到业界领先水平。 简而言之，一个胶囊网络是由胶囊而不是由神经元构成。一个胶囊是一小群神经元，它们可以学习在一个图片的一定区域内检查一个特定的对象（比如，一个矩形）。 它的输出是一个向量（例如，一个8维的向量）。每个向量的长度代表了物体是否存在的估计概率[1]，它的方向（例如在8维空间里）记录了物体的姿态参数（比如，精确的位置、旋转等）。如果物体有稍微的变化（比如，移动、旋转、尺寸变化等），胶囊将也会输出一个长度相同但是方向稍微变化的向量。因此胶囊是等变的。 和常规神经网络很类似，CapsNet也是由多层构成（见图4）。处于最底层的胶囊被称为向量胶囊：它们每个都只用图片的一小部分区域作为输入（称为感知域），然后试图去探测某个特殊的模式（例如，一个矩形）是否存在，以及姿态如何。在更高层的胶囊（称为路由胶囊）则是探测更大和更复杂的物体，比如船等。 图4 一个两层的CapsNet。在本例里，向量胶囊层有两个5x5胶囊的特征图。其中第二个胶囊层有两组3x3胶囊的特征图。每个胶囊输出一个向量。每个箭头代表不同的胶囊的输出。蓝色的箭头代表那些检测三角形的胶囊的输出；黑色箭头代表试图检测矩形的胶囊的输出。图片由Aurélien Géron提供。 向量胶囊层是用几个常规卷积层实现。例如在这篇论文里，他们使用两个卷积层输出256个包含标量的6×6特征图。然后把这个输出变形成32个包含8维向量的6×6特征图。最后，他们使用一个新奇的压缩函数来确保这些向量的长度都是在0到1（来代表概率）之间。就这样，它们就产生了向量胶囊的输出。 下一层的胶囊也试图去检测物体和它们的姿态，但是它们的工作机制很不一样。它们使用的是一种叫按一致性路由的算法。这里是CapsNet的主要魅力所在。先让我们看一个例子。 假设我们只有两个向量胶囊：一个识别矩形的胶囊和一个识别三角形的胶囊，而且假定他们都能检测到相应的形状。矩形和三角形可以是房子或是船的一部分（见图5）。根据矩形的姿态，它们都是稍微向右旋转了一点，那么房子和船也都会向右旋转了一点。 根据三角形的姿态，这个房子几乎完全是上下颠倒的，而船则是稍微向右旋转了一点。注意在这里，整体的形状和整体与部分的关系都是在训练中学习的。现在可以看到矩形和三角形在船上的姿态是一致的，而在房子上的姿态则非常不一致。因此，很有可能这里的矩形和三角形是同一条船上的一部分，而房子上则不是。 图5 按一致性路由。第一步——基于对象的部分是否存在和姿态来预测对象是否存在及其姿态，接着查看预测间的一致性。图片由Aurélien Géron提供。 因为我们现在已经很有信心地知道矩形和三角形是船的一部分，所以把矩形和三角形的输出更多指向船的胶囊而更少指向房子的胶囊就顺理成章了。用这个方法，船的胶囊将会获得更多的有用输入信号，而房子的胶囊则接收更少的噪音。对每一个连接，按一致性路由算法会维护一个路由权重（见图6）：它对于一致的会增加权重，而对于不一致的则降低权重。 图6 按一致性路由。第二步——更新路由权重。图片由Aurélien Géron提供。 这个按一致性路由算法会涉及到一些循环：一致性检测和路由权重更新（值得注意的是，这一步骤会在每次预测时发生，不只是一次，也不只是在训练时）。这一算法对于拥挤的场景特别有用。例如图7里的场景是比较模糊的，因为你能看到中间有一个上下颠倒的房子，但这样会让上面的三角形和下面的矩形无法得到解释。 按一致性路由算法更有可能收敛到一个更好的解释：下面是一条船，而上面是一个房子。这样模糊性就“可以被解释了”：下面的矩形最好是被看成一条船的一部分，同时这样也解释了下面的三角形。一旦下面的两个部分被解释好了，剩下的部分就很容易地被解释成一个房子。 图7 按一致性路由可以分解拥挤的场景，例如这里的图片。因为它可能会被错误地解释为中间是一个上下颠倒的房子和两个无法解释的部分。相反的，下面的矩形会被路由给船，而这也就把下面的三角形带进了船。一旦这个船被解释清楚，那么就能很容易地解释上面的两个部分是一个房子了。图片由Aurélien Géron提供。 就是这些！你现在知道CapsNet背后的关键原理了！如果你想了解更多的细节，可以查看我的两个关于CapsNet的视频（一个是关于它的架构，另外一个是如何实现它）和带有我的注释的这个用TensorFlow实现的胶囊网络（Jupyter Notebook文件）。请随意对视频和GitHub上的文件进行评论，或是通过我的Twitter账号@aureliengeron联络我。希望你觉得这个博文对你有帮助。 [1] 这是由S. Sabour、N. Frosst和G. Hinton发表的论文《Dynamic routing with capsules》里提出的最初的架构。但是在文章发表后他们又提出了一个更通用的架构。其中物体出现的概率以及姿态参数都在输出向量里按不同的方式编码了。不过核心的观点还是没有改变。 Aurélien Géron Aurélien Géron是一名机器学习咨询师，还是O’Reilly图书《Hands-on Machine Learning with Scikit-Learn and TensorFlow》的作者。他在谷歌时，曾在2013到2016年间领导了YouTube的视频分类团队。 Géron在2002到2012年创立了Wifirst公司并担任CTO。在法国，Wifirst是一家领先的无线服务供应商。在2001年，Géron创立了Polyconseil并担任CTO。这家公司现在管理着共享电汽车服务Autolib。在此之前，他作为软件工程师在多个领域工作，包括金融、防务、医疗保健等。 没看够，快来参加今年北京的O'Reilly和Intel AI Conference吧～ 戳 “ ” 登录官网查看详情。 扫码使用大数据文摘专属8折优惠码WENZHAI报名，享受折上折👇 【今日机器学习概念】 Have a Great Definition "
69,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658269&idx=2&sn=900168343889d48782ad3c29b4dc757b&chksm=bd4c3f8e8a3bb698f8297f0acf787be260e352bec0608b076de42820be67b5c510d0e9784ce8&scene=27,快讯 | Elon Musk拟跨界做喜剧，号称要建立跨星系传媒帝国Thud!（轰！）,伊隆·马斯克（Elon Musk）可能要跨界做一个喜剧项目了。他有可能刚刚透露了它的名字。 昨晚，马斯克发出了一条推特，只有一个单词：Thud！（轰！） 在吃瓜群众的追问之下，他又发了一条推特解释说：“这是我新成立的跨星系传媒帝国的名字，感叹号可以去掉。” 轰！这是在逗我吗？🌚 外媒Gizmodo猜测，这个名称可能是对Terry Pratchett同名奇幻小说的致敬，毕竟马斯克被认为喜欢向科幻和摇滚致敬——在发射Falcon Heavy火箭的时候，他就致敬了《银河系漫游指南》和大卫·鲍伊的歌曲。 不过，在媒体私信他求证时，马斯克否认了他在做出致敬，他说：“Thud!就是一个东西撞到地面的时候产生的厚重而沉闷的声音。” 在搞笑的成分之外，马斯克的推特可能指向一些他真的要做的事情。 本周早些时候，据Daily Beast报道，马斯克雇佣了Onion（洋葱新闻，美国一家提供讽刺新闻的组织）的前主编Cole Bolton和执行编辑Ben Berkley，他们正在进行一个秘密项目。 马斯克在2014年也试图收购洋葱新闻，但交易失败。他现在可能正在尝试某种替代方案。 所以，Thud!到底是不是马斯克最新项目的名字？鉴于他的推特的口气，我们还分不清这是一个笑话，还是的确是项目的名字。但是清楚的是，马斯克的确在关注喜剧和媒体，并且应该很快会有所行动。 几天前在SXSW（西南偏南艺术节）上，马斯克也意外露脸，参加了《西部世界》专场，还和弟弟Kimbal Musk、西部世界导演Jonathan Nolan一起唱了首 歌 。 喜剧项目、银河媒体帝国，这是不是他进入娱乐圈的第一步呢？ 毕竟，马斯克称这是下一件大事：“很明显，喜剧是继电动车、太空探索和脑机接口之后的下一个领域。” 新闻来源： http://fortune.com/2018/03/15/elon-musk-thud-the-onion/ https://gizmodo.com/elon-musk-starts-media-business-possibly-named-thud-1823776382 https://www.thedailybeast.com/elon-musk-wanted-to-buy-the-onion-now-hes-poaching-its-staffers-for-a-secret-project Have a Great Definition 
70,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658269&idx=1&sn=77c1c453b8848b2789a1032a58fab6e1&chksm=bd4c3f8e8a3bb6986856446d1d7e16e8b3806c5822c087e49f140e572a8d3bada25d77d12bee&scene=27,招人难留人难？你可能犯了招聘数据科学家的这十宗罪,"大数据文摘作品 编译：惊蛰、吴双、Aileen 作为用人方，你会觉得招聘数据科学家有困难吗？或者，雇用他们之后他们在公司里呆的时间并不长？实际上，这有可能是你绊着了自己的脚。 在机器学习、AI和大数据构成的数据科学领域中，招聘员工和留住员工两件事常常会让HR感到非常挫败。造成这种现象的原因很容易被归咎于候选人的浮躁，毕竟数据科学现在太热门了，数据科学家供不应求。虽然一定程度上这是事实，不过还有一个更重要的原因：你无意识的一些行为破坏了自己招聘和留住数据人才的努力。 我见过不少在招聘上遇到问题的公司，并将其作为雇主的经历和数据科学家们找工作时的抱怨做了个对比。在这个基础上我找到了十个招聘中常见的问题，并分别给出了解决方案。 下面提到的建议，可供各位HR参考。 数据科学现在正是媒体的宠儿。原因很直接： 虽然这么说，但有些公司其实并没搞清楚数据科学到底是什么，其又能给公司带来多大收益的时候就匆匆加入了这个大部队。我把这种现象叫做上缴“数据科学虚荣税”，他们使用数据科学只是为了说自己在使用数据科学。 如何知道自己公司在数据科学方面的努力是会有所成效的呢？你可以向自己和其他决策层同事们提几个问题，比如投资预期回报率(ROI)是多少，或者数据科学的使用可以对公司带来什么样的好处。模糊的、不切实际的，或者无法实现的答案—比如“我们可以用机器学习解决这个棘手的特别复杂的问题！”—都不是好兆头。 解决方案: 想清楚公司“要做什么”以及“为什么要做”。 忽略媒体炒作和营销代理商的宣传手段，请关注你的商业模式和公司理念。问一问自己为什么对数据科学感兴趣，并弄清楚它可以带来什么收益。 这样可以方便确定如何在公司的业务中使用它们。 你的目标在很大程度上决定了你想做什么。这是愿景，但愿景只是第一步。数据科学在战略和战术层面对你到底意味着什么？你又有没有整理出如何执行这个宏伟愿景的计划呢？ 如果你没有一个详细的计划，就仿佛无头苍蝇一样，其结果只是浪费时间、精力、士气和金钱，但什么都收获不到。没有计划比没有目标更糟糕，因为即使你有做事的潜力，但实际上最终并没有真正做成什么。 解决方案：制定数据策略路线图。 请把“想做什么”和“怎么做”联系起来。其要点是： 关键是要够具体。纸上谈兵或者过于简化问题只会徒增失望。 另一篇关于开发数据策略的文章： http://qethanm.cc/2016/02/17/what-is-a-data-strategy/ 媒体和营销代理商经常单独谈到数据科学，这导致人们误以为他们可以直接上手先进的数据科学项目，比如最近流行的深度学习。 事实上，一个成功的数据科学项目是有很多层基础的，即使在第一阶段的数据处理之前，还必须要清洗数据和拥有一个稳健的基础技术设施。 解决方案：从基本的工作开始，然后慢慢深入。 开发收集所需数据的机制，并部署存储系统以保证数据的保存和检索 。然后，检查已有数据，确保它们可以进行分析。如果你发现“我们不知道有什么或者需要什么数据”，那说明你跳过了开发数据策略的步骤，参见上一条建议。 如果你已经有了这些数据和基础设施，为了让之后的处理更方便，你可以先尝试一些商业智能（BI，即business intelligent）技术，如计数，摘要和汇总。 商业智能技术不仅对公司整体有益（比如大家都希望得到的按地区划分的销售额数据），它还可以快速而廉价地测试数据。 通过摘要和汇总，我们可以快速找到数据中的不一致或者有问题的地方。如果商业智能的测试失败了，那么更高端的数据科学处理也无法进行。 你希望求职者做好万全准备，对吗？其实你自己也应该这样做。从有经验的数据科学家那里，我听到的最常见的抱怨就是在接到一个冷冰冰的电话或者一封邮件之后，发现电话或邮件另一边那个吹嘘某知名公司开了个很好的岗位的那个人，并没有提供这个岗位的详细信息。 当然，你应该告诉这些求职者休假政策和办公环境是怎么样的。 你还应该详细讲解他们在加入公司之后将要做的事情。有经验的从业者（甚至一些聪明的的职场新人）都会想要知道公司使用了哪些工具，他们可能会参与什么样的项目，以及他们的工作对公司有什么用。 有些招聘人员在这里会用一些模糊的回答敷衍了事，比如说“团队用Python写代码”或“在聘用你之后,我们会告诉你具体负责的工作”。这么做很容易让求职者失去兴趣。如果这么做了，不要指望他们之后会接听你的电话。 解决方案：找个经理，招人的接洽工作自己来做。 在正式的面试之外，其实有很多可以找到不错潜在雇员的机会。拥有招聘权的你，有能力—也有责任—走出办公室，自己找人才。  这样就可以在轻松的环境中，积极主动地面对潜在的职位候选人。 在参加活动的时候，不要一见面就说“我们在招人”然后把他们直接送到HR。相反，你可以和他们讨论几个目标职位，问一问他们想做什么样的项目。评估一下他们的兴趣、技术水平，看一看他们和自己的团队合不合的来，最后再找到HR，正式确定这次招聘。 你遇到过数据科学的岗位开放几个月之后还是没招到人的情况吗？甚至都没人来投简历？如果这是你第一次招聘数据科学相关工作时遇到的事，就可要加倍注意了。 在这种情况下，有可能出问题的不是候选人而是工作描述和对求职者的预期。这个领域很多岗位描述要求的简直是个全能王：不仅经验丰富，用得惯各种工具，scikit-learn，TensorFlow，神经网络，文本分析和流失预测（churn predictions），还要有统计学博士学位 。 对了，他们是不是还需要把他们的模型整合到产品的网站上？或者还要管理数据库？ 我明白。我也相信这句老话：如果你不说，你就找不到符合要求的。但这里还有另一面：提出了要求，也并不意味着一定会被满足 。 如果你一直在找符合每个要求的候选人，那多半会等待很长时间。而且，符合这些条件的少数几个人在很久以前就很有可能已经被抢走了，这意味着这些人根本不在你的搜索范围之内。 更糟糕的是，符合大部分要求的人将会从字里行间了解到，写着这样招聘信息的公司都不怎么样，所以这种方式是找不到知识渊博并且很抢手的数据科学家的。 解决方案：把职位要求放现实一点。 这个问题经常会在还未建立数据策略时发生。如果缺乏这样的策略，说明你并不清楚自己需要什么，所以以防万一，你更倾向于向求职者要求所有可能会用到的技术。 这个时候，虽然符合条件的数据科学家可能会出现，但多半不太可能。 符合要求的申请人会看到你有实际可行的期望，所以更有可能申请这个工作。 对数据科学的报道中经常提到薪水：年纪轻轻往往就享有高薪，不仅如此，公司还把薪水当作激励脑力工作的手段。这样的待遇谁不想要呢？然而，有些公司的面试流程却让人看不到录取希望。其中有些流程的设置既不让人开心，也不切实际，以至于公司自己赶走了他们本想聘用的候选人。 例如，假设你的公司使用scikit-learn之类现成的工具，但你却仍然希望求职者可以在白板上写出实施K均值聚类算法(K-means clustering)的代码；或者，你向某候选人发了一个需要花好几天才能完成的项目作业；又或者你不接受没参加过Kaggle竞赛的人，或者在GitHub上没什么东西的人，又或者没有特定学术背景的人。 与其说这些是对优秀人才的甄选，还不如说是招聘人才的障碍。这些条件的设置并没有真正衡量出候选人的实际技能，更重要的是，这么做反而会赶走合格的申请者。这些人都知道自己很受欢迎，可以去其他地方找工作。 解决方案：更实际的面试。 最基本的，把面试中的技术性题目限制在公司真正会用的工具上，而且也请按照实际使用这些工具的方式来问问题。你可以在理论层面深入一些，询问候选人在处理一些问题时如何使用（或者更简单点，是否使用）某种技术。 面对经验丰富的候选人时，可以问一些关于他们之前工作的开放性问题， 并给他们足够的发挥空间，从而了解这些人在过去是怎样解决问题的。 如果你非常想在面试中保留类似demo或者在白板上写程序的话（实话说，其实并不需要），那么一定要确保这些环节和他们在工作中真正做的事情相关。 除非你的公司已经有了可靠的数据基础架构和内部的商业智能(BI)实践，否则你将需要找个数据工程师来构建数据管道(data pipeline)，或者给数据科学家们准备好可用的数据。很多公司因为并不觉得这是真正的数据科学而跳过了这一步，然而实际上他们犯了一个昂贵的错误。 如果你直接先聘请了数据科学家，那他们将会因为没有数据可用而觉得无聊，最终离开公司。 或者，他们也许会承担数据工程师的角色但却对此感到不快（记得，他们入职的并不是这个岗位！）这一点通常是他们离开的先兆。 不过，所有这些发生的前提都是你有能力让他们成功入职，好的数据科学家其实在面试中就会发现你没有做好准备，而拒绝你的offer。 解决方案：先聘请数据工程师。 虽然这么做的话，你的同事们或上级可能会有些质疑：“我本以为我们要做的是数据科学，但你雇的这个人整天都在弄数据库！”但是你需要坚定你的立场，并向他们解释为什么聘用数据工程师是必要的第一步。 其额外的好处是， 这是因为你的数据科学家进行数据准备的时间会减少。基于此，你可以降低对数据科学家的要求来更快速地招到符合标准的人。 如果你的第一位数据领域聘用人员是非常有经验的数据专业人士（除了拥有非常完善的数据技能外，还拥有全面的技术背景），并且你的公司内部已经有功能强大的商业智能技术时，则可以降低这项要求。 在这种情况下，大部分数据基础已经到位，数据科学家可以在最初自己上手所需的数据工程相关工作。不过，这样做的前提是未来这个数据团队在规划上是会扩张的。数据科学家可以去雇用专职数据工程师或其他数据科学家来接管自己的部分工作。 但是这引出了我的下一个论点： 市场对数据科学家的强烈需求产生了一些副作用，其中一个就是，他们期望高额的薪水。一些公司（尤其是初创公司）会对经验丰富的专业人士对薪资的预期感到畏缩。所以他们试图通过聘用一个工作经验很少或没有工作经验的人来节省资金，无论是刚毕业的学生还是仅仅在类似新手训练营的培训项目里接触过数据科学的人。 乍一看，这决定看起来不错，因为节约的薪资很容易被量化。然而事实上这种方式并不好，主要是因为这种方式对被聘用的人很不公平：作为第一个也是唯一的数据科学家，当他陷入困境时根本无法找更有经验的人寻求帮助（他有时候甚至可能都意识不到自己陷入了困境）。 必须自学所有东西的结果就是难以发挥自己的技能。这个人甚至有可能会因此感到沮丧并离开公司。 解决方案：最开始先找一位经验丰富的数据人员。 这里指的是那些熟知各个环节，只需极少的帮助就能够迅速行动的人。在他们的帮助下公司将更快地看到在数据科学投资上的回报。这些人的薪水确实高于入门级人员，但这笔花费其实很值。 那你还应该去聘请初级数据科学家吗？当然！不过关键是要首先建立一个经验丰富的数据科学家团队，不然就是创建一个能够帮助这个人成长的环境。 这是一个鸡生蛋蛋生鸡的问题：为了实现（数据科学相关的）解决方案你就需要聘用一位数据科学家，而聘用数据科学家你就需要有数据科学经验的人来梳理设计解决方案和匹配人才需求。可如果你的公司或团队本身已具备一定的数据科学经验，那么这解决方案早就应该已经实施了，何必招人！  一些公司试图摆脱这种困境。这些公司将软件开发人员和数据科学家安排到同一个团队中（都是技术相关的，对吧？），并任命首席开发人员或CTO去领导公司的招聘。这样的领导往往跳过开发数据策略的步骤来直接开始写岗位描述。 虽然他有技术经验，但缺乏数据背景，因此招聘信息根本没有用。然后，HR和猎头就开始了对候选人的盲目地大范围追逐。等到候选人接受面试时，就会意识到公司内部并没有数据科学人才，没有人能听懂他们在说什么，所以没有人能够真正评估自己技能和经验。最终，面试失败了。 而那些经历过面试的人呢？领导会说：“他们确实不错，但并不是我们正在找的人......下一个！”这个位置毫不意外地保持开放几个月，有时甚至还超过一年。 解决方案：写招聘信息和面试候选人的时候寻求外部帮助。 如果你的公司本身还没有什么数据科学方面的经验，请聘请经验丰富的数据专家与你一起写岗位描述或者做面试。 这位专家不会取代你的人力资源和招聘团队，但可以缩小寻找候选人的范围，也可以和候选人有交流合作，从而加强招聘部门的工作成效。 希望你已经能用上文中提到的技巧来改进数据科学人才的招聘方式了。这个时候，你已经制定了一套现实的数据策略，调整了面试过程，也从外部聘请了一些有经验的人士来撰写岗位描述，帮助你面试候选人。然后怎么办呢？你现在已打开了大门，数据学家就会蜂拥而入，对吧？事实上并不是如此。 解决方案：请耐心等待。 文章中提到的所有解决方案都可以帮助你做足最好的准备，拿到一手好牌。 即使你做的都是正确的事情，你仍然在与其他公司竞争数据人才。别太急，要有耐心！ 原文地址： https://towardsdatascience.com/10-common-mistakes-in-hiring-data-scientists-30db415f4ff2 【今日机器学习概念】 Have a Great Definition "
71,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658247&idx=2&sn=7c87bacceef56ee9ba8f6dd72e4c35ed&chksm=bd4c3f948a3bb682747f6a2d93db16313d73b1f2d4f25b7974e015fac713fd1a146c93bcd0e8&scene=27,业界 | 来吧，迎接AI面试官的暴击！,大数据文摘作品 编译：Zoe Zuo、王梦泽、钱天培 深患面试恐惧症？一见到面试官就直哆嗦？ 怎么办？完蛋啦！ 比面试官更可怕的生物已经诞生了，TA就是AI面试官！  近日，一个名为HireVue的AI面试平台公司逐渐浮出水面。 HireVue借助AI来分析应聘者在视频面试中的措辞、语调和面部活动。 目前，HireVue已筹资9500万美元，并与联合利华（Unilever）和高盛（Goldman Sachs）等公司合作——这似乎昭示着， 马克•纽曼（Mark Newman）在2004年创立了HireVue这个视频面试平台。应聘者录制面试视频并将其上传至平台数据库，这样招聘者在比较应聘者们的表现时会很方便，同时也节省了时间。 四年前，HireVue融合AI技术，进入了发展的新阶段。 HireVue结合了专利语音识别软件以及获得许可的面部识别软件，并协同排名算法，确定哪些候选人最接近理想人选。 通过分析当前担任某一职务的最优秀的员工，可以收集到有关他们肢体语言、语调与关键词的数据，由此总结出一些特质，再将这些特质综合起来，就知道什么是理想的候选人了。 排名算法会让表现好的候选人脱颖而出，招聘者就可以着重了解这些候选人的答案，并确定谁可以进入下一轮，通常是面对面的面试。 说了这么多，这个AI面试官到底长啥样咧？ 文摘菌找到了一位歪果仁小哥身先士卒写的面试日记，一起来看看！ Hello，我就是文摘菌说的歪果仁小哥哥。下面是我的面试日记。 应聘者可以使用带有摄像头的电脑、手机或平板来进行面试。我在iPhone 7 Plus上下载了HireVue的应用，这款手机屏幕比较大也很清晰。 我进入了一间空的会议室，把我的手机架在了水杯上。 应用界面非常直观，我被告知面试共有11题，用时（至少）25分钟。 在视频录制时，HireVue的员工提了一个这样的问题，“如何描述你在上一团队中所扮演的角色？” 问题1：你好，我是Kayla。我们团队的员工都有不同的背景和经验。请做个自我介绍。上一份工作是什么类型的？你有什么兴趣和爱好？ 由上所见，视频的分辨率较低，HireVue的首席技术官Loren Larsen告诉我，他们是故意这样设置的，因此应聘者可以仅关注题目本身。 其他的公司会选择录制清晰度较高的视频，这些都是可以依据自己公司的品牌和需求来进行定制。 看到我的脸出现在屏幕上的瞬间，我感到非常不舒服。 我有30秒的时间来准备，然后再用几分钟来做出回答。但最重要的是，我和所有的HireVue使用者一样，回答的次数不受限制。 由于回答次数不受限，你可以在转到下一个问题之前回顾你的答案，并决定是否要重新作答。 我充分的利用了这一特点，于是很快的将25分钟的面试延长到45分钟。Larsen告诉我，他们对回答问题的次数，分有限制和无限制做了试验，发现大多数的人会选择无限制。 招聘者没有将面试形式局限在纯视频上。我的面试过程中有一道文字题，需要给焦虑的客户就产品问题回复邮件。 我需要给出答案并用最清晰可靠的方式将其表达出来。 隔天我与HireVue的员工Larson会面，并一起讨论了我的面试结果。 我的“洞察力得分”是65%，排名第二。这意味着根据这个软件，我拥有完美客服代表65%的品质。 Larson向我展示了招聘者在分析我的答案时的界面。 软件评测 软件的初衷是，AI可以帮助优秀的应聘者脱颖而出，招聘者就可以重点关注这些候选人。 Larsen表示，他理解当人们第一次听到HireVue时可能会觉得它很可怕或有具有侵略性，但其实对人类来说，它是一种能让工作更有效率的工具。他说 在我看来，这项技术非常实用，尤其是当招聘人员需要面对数百个工作申请时。 然而HireVue的优势同时也是它潜在的弱点， AI面试官的评判标准取决于HR提供的数据。 这样一来，HR在过去犯得错误也会随之进入到AI面试官的决策过程中。 Larsen表示，他和他的团队将致力于减少人类在这个过程中的参与，将他们的AI评估朝着这样一个可能存在也可能不存在的理想情况进行完善。 理想情况下，当候选人上传了自己的面试视频后，算法就能很自信地直接给出面试结果。 录还是不录，全在AI的一念之间。 原文链接： http://www.businessinsider.com/hirevue-ai-powered-job-interview-platform-2017-8 【今日机器学习概念】 Have a Great Definition 
72,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658247&idx=4&sn=e555529ffa14f41d76695e847a5f3301&chksm=bd4c3f948a3bb682bf2a93a53df8961947976a0dd635ab58c01ac038bb56a89e58575fb654a8&scene=27,报名 | 第二届大数据教育高峰论坛（成都）,全球数据爆发增长，对经济发展、社会治理、国家管理、人民生活都产生了重大影响，并正在深刻地影响着世界社会、政治、经济、文化和军事等方面的变革。为此，2015年9月，国务院印发《促进大数据发展行动纲要》，系统部署大数据发展工作，推动大数据发展和应用。大数据是国家战略性的基础核心资源，已经成为企业、社会和个人关注和投入的新焦点。现在，我国从上至下，全社会都已充分意识到了数据的价值。 会议背景 大数据专业或大数据课程越来越受到高校学生的欢迎，但制约大数据专业发展的重要因素——教育水平问题依然普遍存在，提高办学水平是大数据专业人才培养的当务之急。对于从事大数据专业教育工作者来说，了解大数据国家策略、行业发展动态，分享大数据专业建设或课程教学经验，交流产、学、研合作的可能，是促进大数据专业教育发展、提高人才培养质量的重要措施之一。 正是基于此，在2017年4月于桂林成功举办首届大数据教育高峰论坛的基础上，教育部高等学校计算机类专业教学指导委员会决定举办本次论坛。特邀请各高校相关院系选派教学主管领导、课程负责人、骨干教师，各技术公司负责人，参加本次论坛。 会议内容 大数据研究最新进展 大数据关键技术及产业应用现状 大数据产业发展与人才需求 数据科学与大数据技术专业申报与建设 大数据与云平台建设 大数据实验实训室建设 校企合作、共建大数据教育的新生态 大数据人才培养模式探讨 大数据开放实验室解决方案及实践 大数据与机器学习、深度学习 大数据与现代人工智能 大会嘉宾 陈  钟    教育部高等学校计算机类专业教学指导委员会副主任，北京大学信息科学技术学院教授 陈宝权    教育部“长江学者”特聘教授、国家973项目首席科学家、国家“万人计划”领军人才，山东大学计算机科学与技术学院院长、教授 陈国青    教育部管理科学与工程类专业教学指导委员会主任、教育部“长江学者”特聘教授，清华大学经济管理学院EMC讲席教授、学术委员会主任 杜小勇    中国计算机学会数据库专业委员会主任，中国人民大学理工学科建设处处长、信息学院教授 方志军    中国人工智能学会智能服务专业委员会委员、中国管理科学与工程学会常务理事，上海工程技术大学电子电气工程学院院长、教授 金  海    教育部“长江学者”特聘教授、国家杰出青年基金获得者，华中科技大学教授 汪德诚    清华大数据产业联合会副秘书长、北京惟数科技有限公司(大数据文摘)创办人 吴  斌    北京邮电大学计算机学院通信软件工程中心教授 周  涛    国家“青年拔尖人才支持计划”、国家自然科学基金优秀青年基金获得者，电子科技大学教授、互联网科学中心主任 周傲英    教育部“长江学者”特聘教授、国家杰出青年基金获得者、教育部跨世纪人才，华东师范大学副校长、教授 庄越挺    教育部“长江学者”特聘教授、国家杰出青年基金获得者，浙江大学计算机科学与技术学院教授 支持单位 主办单位 教育部高等学校计算机类专业教学指导委员会 承办单位 电子科技大学 协办单位 清华大学出版社 合作媒体 书问、搜狐新闻、网易云阅读、凤凰新闻 、zaker、数据猿、花火网、书圈、中国搜索 DT学院、UC头条、中国图书网、今日头条、天天快报、科技日报、网易新闻、百度百家、科技云报道、雷锋网、《科技与出版》、《计算机教育》、《大数据文摘》、《实验室研究与探索》 请各单位积极组织和推荐院系教学主管领导、课程负责人和骨干教师参加会议，参加会议的代表请于2018年5月11日前将回执发给组委会联系人。 论坛时间及地点 会议时间： 2018年5月19日至5月20日，5月18日下午报到。 会 务 费： 1500元/人，住宿由会务组统一安排，交通、食宿费用自理。 会议地点： 成都天之府温德姆至尊豪廷大酒店，成都市高新西区望丛中路1088号，电话：028—87890888 住宿地点： 成都天之府温德姆至尊豪廷大酒店（450元/间·天） 联 系 人：  贾斌 电    话：   18601290130 邮    箱：   bdpt2018@163.com 报名方式 1.扫下方二维码填写报名申请。 2.或戳 ，填写表单申请。 请各单位积极组织和推荐院系教学主管领导、课程负责人和骨干教师参加会议，参加会议的代表请于2018年5月11日前将回执发给组委会联系人。 
73,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658247&idx=3&sn=e2278492aba440a0428b629106abe6e2&chksm=bd4c3f948a3bb682c613f3ea60f4f4314a7f49fc44cdfd3a19d8c05dd483339d1cb3cb382b29&scene=27,快讯 | 谷歌宣布全面禁止与加密货币相关的广告,据海外媒体CNBC报道，谷歌正在全面取缔与加密货币相关的广告。 谷歌将不再允许在其任何广告平台上投放有关加密货币相关内容的广告，包括ICOs、钱包和交易建议。 谷歌产品管理总监斯科特·斯彭塞(Scott Spencer)告诉CNBC，该公司正在更新其金融方面的广告政策，禁止任何有关加密货币相关内容的广告，包括ICOs、钱包和交易建议。 这意味着 此政策修改2018年6月生效。 斯科特说：“我们很难获取加密货币的所有交易细节，不得不谨慎行动，因为我们的消费者已经受到了伤害。” 在此之前，Facebook也发出过类似的禁令。 原文链接： https://www.cnbc.com/2018/03/13/google-bans-crypto-ads.html# Have a Great Definition 
74,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658247&idx=1&sn=6862dae25a9b476618770096353fe745&chksm=bd4c3f948a3bb682f914c02320e94bdb06aeaec6295f2bb1904c001722d10baf5d9737156d2c&scene=27,程序员界年度人口普查：6成以上开发者日工作超9小时，且从不运动,大数据文摘作品 每年，海外最大的程序员集聚地之一Stack Overflow都会在自家开发人员社区发起一次大规模调查，来给程序员们画个像。从最喜爱的技术、工作偏好，甚至年龄学历性取向，堪称程序员世界一年一度的人口普查。 今年是发布年度开发者调查结果的第八年，也是受访者数量最多的一年。与 相比，今年的调查增加了几个有趣的主题，比如人工智能和编码伦理（点击查看大数据文摘相关报道《 》 ），对于这个最近争论声颇高的话题， 超过10万名开发人员参加了这一平均问卷填写时间超过30分钟的调查，从对填写时间的容忍足以看出程序员的耐心。 以下是今年调查结果的一些重要内容： DevOps和机器学习是当今软件行业的重要趋势。与这类技术相关的语言和框架的热度也不断上升，在这些领域工作的开发人员的薪水最高。 只有很小一部分开发者表示他们会写不道德的代码，或者他们没有义务考虑代码的道德影响，但除此之外，受访者看到了很多灰色代码。开发人员不确定他们将如何报告道德问题，并对谁最终负责不道德的代码有不同的看法。 开发人员总体上对人工智能提供的可能性持乐观态度，但对AI的危险性态度并不一致。 在我们的调查中，Python在编程语言的热度有所上升，超过了今年流行的C＃，就像去年它超过了PHP一样。 在评估未来的工作时，不同类型的开发人员应用不同的优先级。女性认为最重要的是公司文化和专业发展的机会，而男性则认为他们最优先考虑的是薪酬和特定技术。 我们摘录了本次报告的一些关键内容如下，对完整报告内容感兴趣的读者可以去往以下链接查看报告原文。 链接地址：https://insights.stackoverflow.com/survey/2018/#overview 将近60％的受访者认为自己是后端开发人员，约20％认为自己是移动开发人员。 最常见的组合是后端，前端和全栈开发人员。 高度相关的职业是数据库管理员和系统管理员，DevOps专家和系统管理员以及设计人员和前端开发人员。 许多开发人员的工作并不是以写代码为主。超过80％的受访者表示敲代码是他们的一种爱好。 工作之外的其他兴趣或责任似乎并没有减少开发者对敲代码的兴趣。 调查显示，负有照顾责任的父母，经常户外活动的人比其他群体更容易爱上“搬砖”。 在学习新内容时，超过80％的受访者依靠Stack Overflow Q＆A。  此外，开发人员理解良好文档的价值，因为超过80％的人在学习时也将文档用作学习资源。 我们的受访者包括专业编程人员，学生和业余爱好者。 绝大多数人通过台式机和笔记本进行编程，通常会投入9-12个小时。 开发人员说，他们不会经常因为工作量而跳过饭菜，而且大多数人表示他们至少会做少量运动。 超过60％的受访者表示至少每周锻炼一次，但选择“从不”运动的人数最多。 JavaScript连续六年被评为最常用的编程语言。 Python的排名上升，今年超过了C＃，去年刚超过了PHP。 我们看到专业开发人员和整体开发人员的技术选择紧密结合。 一些相关的技术通常聚集为一个生态系统，开发者通常会选择使用同一种生态的编程语言。 在这张图表中，我们看到一个用于Web开发的大型集群（JavaScript，HTML和CSS）通过SQL连接到Microsoft技术（C＃，Visual Studio和.NET Core）。沿着左边，我们看到了一个将Java，Android和iOS连接到Linux，bash / shell和Python的连线。 其他较小的相关群集包括Scala / Spark，C / C ++和其他包含特定语言IDE的小型技术。 部分开发人员参与讨论了当今世界机器学习和人工智能作用的重要性：哪些技术可能会带来危险后果？哪些技术又令人兴奋？ 关于何种技术是最危险的，每个答案都大致相同，开发人员对此没有多少共识。 开发人员认为，机器学习和人工智能算法背后的创造者和技术人员是最应该对人工智能所带来的社会问题负责。 大约四分之一的受访者认为监管机构应该负主要责任。 开发人员对人工智能问题的关注取决于他们所做的编码工作。例如，当计算机变得比人们更聪明时，数据科学家对算法公平性的关注度将比任何其他问题提高1.5倍，这是任何类型开发人员中最重视的部分。许多开发者讨论了是否将系统性偏见纳入到算法决策中，以解决AI被滥用而自身不具备检查和推理的决策途径的缺陷。 在假设情况下，当要求开发人员为不当用途的产品或目的编写代码时，超过一半的受访者表示他们不会写这样的代码。 道德情景可能很复杂，大约三分之一的受访者认为要取决于具体情况做决定。 大多数开发人员认为，管理者是为不道德代码的结果负最终责任的人。 不到20％的受访者表示，编写用于不道德目的的代码的开发者是最应该对此负责的。 几乎80％的受访者声称，开发人员应当考虑他们代码的正确用途。 在这道题的开放性回答里，我们看到了开发人员关于责任的深思熟虑。代码的不道德的使用只是偶然情况，但开发人员可以成为抵御不道德代码的最后一道防线。 Have a Great Definition 
75,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658195&idx=2&sn=7a7d998af042769ebe6e16437043c8de&chksm=bd4c30408a3bb956b0922d1fbfa65eccb53fb7d3f8ae7062e76f9e6ea2ac9c6b4ba6ecff772d&scene=27,手把手：教你如何用深度学习模型预测加密货币价格,"大数据文摘作品 编译：张南星、王梦泽、元元、Yawei Xia 如果要评选2017三大流行金酸梅奖，毫无疑问，获奖的肯定是指尖陀螺、人工智能以及加密货币。加密货币是一项颠覆性的技术，它背后的原理引人注目，我十分看好它未来的发展。 实际上，我并没有持有任何加密货币，但说起凭借深度学习、机器学习以及人工智能成功预测加密货币的价格，我觉得自己还算是个老司机。 一开始，我认为把深度学习和加密货币结合在一起研究是个非常新颖独特的想法，但是当我在准备这篇文章时，我发现了一篇类似的文章。那篇文章只谈到比特币。我在这篇文章中还会讨论到以太币（它还有一些别名：ether、eth或者lambo-money）。 类似文章链接： http://www.jakob-aungiers.com/articles/a/Multidimensional-LSTM-Networks-to-Predict-Bitcoin-Price 我们将使用一个长短时记忆（LSTM）模型，它是深度学习中一个非常适合分析时间序列数据的特定模型（或者任何时间/空间/结构序列数据，例如电影、语句等）。 如果你真的想了解其中的基础理论，那么我推荐你阅读这三篇文章：《理解LSTM网络》、《探究LSTM》、原始白皮书。出于私心，我主要是想吸引更多的非专业机器学习爱好者，所以我会尽量减少代码的篇幅。如果你想自己使用这些数据或者建立自己的模型，本篇文章同样提供了Jupyter (Python) 笔记供参考。那么，我们开始吧！ 理解LSTM网络 http://colah.github.io/posts/2015-08-Understanding-LSTMs/ 探究LSTM http://blog.echen.me/2017/05/30/exploring-lstms/ 原始白皮书 http://www.bioinf.jku.at/publications/older/2604.pdf Jupyter (Python) 笔记 https://raw.githubusercontent.com/dashee87/blogScripts/master/Jupyter/2017-11-20-predicting-cryptocurrency-prices-with-deep-learning.ipynb 在建立模型之前，我们需要获取相应的数据。在Kaggle上有过去几年比特币详细到每分钟的价格数据（以及其他一些相关的特征，可以在另外一篇博客中看到）。但是如果采用这个时间颗粒度，其中的噪音可能会掩盖真正的信号，所以我们以天为颗粒度。 另外一篇博客： http://www.jakob-aungiers.com/articles/a/Multidimensional-LSTM-Networks-to-Predict-Bitcoin-Price 但这样的话，我们会面临数据不够的问题（我们的数据量只能达到几百行，而不是上千或者上百万行）。在深度学习中，没有模型能够解决数据过少的问题。 我也不想依赖于静态文件来建立模型，因为这会使未来注入新数据更新模型的流程变得很复杂。取而代之，我们来试试从网站和API上爬取数据。 因为我们需要在一个模型中使用多种加密货币，也许从同一个数据源中爬取数据是个不错方法。我们将使用网站coinmarketcap.com。 截至目前，我们只考虑比特币和以太币，但是用同样的渠道获取最近火爆的Altcoin相关数据也不难。在我们导入数据之前，我们必须载入一些python包，它们会让分析过程便捷很多。 解释一下刚才发生了什么，我们加载了一些python包，并导入了在这个网站（链接见下）上看到的表格。经过简单的数据清理，我们得到了上面的这张表。通过简单地把URL地址（此处代码忽略）中的“bitcoin”换成“ethereum”，就可以相应的获得以太币的数据。 网站链接 ： https://coinmarketcap.com/currencies/bitcoin/historical-data/ 为了验证数据的准确性，我们可以作出两种货币的价格和成交量时间线图。 图注：上半部分-收盘价； 下半部分-成交量 图注：上半部分-收盘价； 下半部分-成交量 我们有了数据，现在可以开始创建模型了。在深度学习领域中，数据一般分为训练数据和测试数据，用训练数据集建立模型，然后用训练样本之外的测试数据集进行评估。 在时间序列模型中，一般我们用一段时间的数据训练，然后使用另一段时间的数据测试。我比较随意的把时间节点设为2017年6月1日（也就是说模型将用6月1日之前的数据训练，用其后的数据进行评估）。 图注：紫色线-训练集； 蓝色线-测试集 上半部分-比特币价格($); 下半部分-以太币价格($) 你可以观察到，训练集的数据大多处于货币价格较低的时候，因此，训练数据的分布也许并不能很好地代表测试数据的分布，这将削弱模型推广到样本外数据的能力（你可以参照这个网站把数据变换成平稳的时间序列）。 网站链接： https://dashee87.github.io/data%2520science/general/A-Road-Incident-Model-Analysis/ 但是为什么要让不如人意的现实干扰我们的分析呢？在我们带着深度人工智能机器模型起飞前，讨论一个更简单的模型是很有必要的。最简单的模型就是假设明天的价格相等于今天的价格，我们简单粗暴地称之为递延模型。下面我们用数学语言来定义这个模型： 图：简单递延模型 上半部分-比特币价格($); 下半部分-以太币价格($) 稍稍拓展一下这个简单的模型，一般人们认为股票的价格是随机漫步的，用数学模型表示为： 我们将从训练数据集中获取μ和σ的取值，然后在比特币和以太币的测试数据集上应用随机漫步模型。 图：单点随机游走模型（测试数据） 上半部分-比特币价格($); 下半部分-以太币价格($) 哈哈，看看这些预测线，除了一些弯折，它基本追随了每个货币的实际收盘价格，它甚至预测了以太币在六月中旬及八月下旬的涨势（以及随后的跌势）。 那些仅仅只预测未来某个点的模型展现出来的准确性都很误导人，因为误差并不会延续到后续的预测中。无论上一个值有多大的误差，由于每个时间点的输入都是真实值，误差都会被重置。 比特币随机漫步模型尤其具有欺骗性，因为y轴的范围很大，让这个预测曲线看上去非常平滑。 不幸的是，单点预测在时间序列模型的评估中十分常见（比如文章一、文章二）。更好的做法是用多点预测来评估它的准确性，用这种方法，之前的误差不会被重置，而是被纳入之后的预测中。越是预测能力差的模型受到的限制也越严重。数学模型如下： 文章一链接： 文章二链接： 我们基于所有的测试数据集得到了随机漫步模型，并对收盘价格进行了预测。 图：完全区间随机模型 上半部分-比特币价格($); 下半部分-以太币价格($) 模型预测对随机种子的选取极度敏感，我已经选择了一个预测以太币结果较好的完全区间随机漫步模型。在相应的Jupyter笔记中，你可以通过交互界面尝试下面动图中的种子值，看看随机漫步模型表现差的情况。 图：单点漫步模型/完全区间随机模型对比 纵坐标-以太币价格($) 需要注意的是，单点随机漫步总是看上去非常准确，即使其背后没有任何含义。希望你能够带着怀疑的眼光看任何宣称能够准确预测价格的文章。但也许我不需要担心，加密货币的爱好者们似乎并不会被虚有其表的广告语所诱惑。 就像我之前所说的，如果你对LSTM的原理感兴趣，可以阅读：《理解LSTM网络》、《探究LSTM》、原始白皮书。（链接见上文） 幸运的是，我们不需要从头开始建立网络（甚至不需要理解它），我们可以运用一些包含多种深度学习算法标准实现的函数包（例如TensorFlow、 Keras,、PyTorch等等）。我将采用Keras，因为我发现对于非专业的爱好者来说，它是最直观的。如果你对Keras不熟悉，那么可以看看我之前推出的教程。 TensorFlow Keras PyTorch 之前的教程 我建好了一个新数据表格model_data，移除了部分列（开盘价，当日的价最高价、当日最低价），重新安排了新的列：close_off_high代表当天收盘价格和最高价格的差值，-1和1的值分别代表收盘价格与每日最低或者最高价格相等。 volatility列就是最高价和最低价的差值除以开盘价。你可能还会注意到model_data数据集是按照时间由古至今排列的。实际上模型输入不包括Date，所以我们不再需要这一列了。 我们的LSTM模型将会使用以往数据（比特币和以太币均有）来预测某一特定货币第二天的收盘价格。我们需要决定在模型中使用以往多少天的数据。 同样的，我又随意地决定选择使用之前10天的数据，因为10是一个很好的整数。我们用连续10天的数据（称之为窗口）建立了多个小数据表格，第一个窗口将由训练数据集中的第0-9行组成(Python从0开始计数)，下一个窗口由1-10行组成，以此类推。 选择较小的窗口规模意味着我们能在模型中使用更多的窗口，不利之处在于这个模型没有充足的信息以预测复杂长期行为（如果能够预测的话）。 深度学习并不喜欢变化范围大的输入值。观察一下这些列，有些值在-1到1之间，其他的值则达到了上百万。我们需要进行数据标准化，保证我们的输入值的变化范围是一致的。 一般-1到1的值是最理想的，off_high列和 volatility列的值是符合要求的，但是对于其他的列，我们需要把输入值按照窗口的第一行值进行标准化。 表格展示了LSTM模型的输入的一部分（实际上会有几百个相似的表格）。我们对一些列进行了标准化处理，使它们在第一个时间点的值为0，以便预测相较此时间点而言价格的变动。 现在我们准备构建LSTM模型，实际上使用Keras来构建会非常简单，你只需将几个模块堆叠在一起。 更好的解释请戳这里： https://dashee87.github.io/data%2520science/deep%2520learning/python/another-keras-tutorial-for-neural-network-beginners/ 代码如下： 不出所料，build_model 函数建立了一个空模型，名字为model(即这行代码model= Sequential),LSTM层已加在模型中，大小与输入相匹配（n * m的表格，n和m分别代表时间点/行和列）。 函数也包含了更通用的神经网络特征，例如 dropout和activation functions。现在我们只需确定放置到LSTM层中的神经元个数（我选择了20个以便保证合理的运行时间）和创建模型的训练数据。 代码如下： 我们建好了一个LSTM模型，可以预测以太币明日的收盘价。让我们来看看模型表现如何。首先检验模型在训练集上的表现情况（2017年6月前的数据）。代码下面的数字是对训练集进行50次训练迭代（或周期）后，模型的平均绝对误差（mae）。我们可将模型的输出结果视为每日的收盘价，而不是相对的变化。 训练集：单时间点预测 蓝色线-实际价格；绿色线-预测价格 纵坐标：以太币价格($) 平均绝对误差：0.0583 正如我们所期待的，准确性看起来很高。训练过程中，模型可以了解其误差来源并相应地做出调整。 实际上，训练误差达到几乎为零不会很难，我们只需用上几百个神经元并且训练数千个周期（这就是过度拟合，实际上是在预测噪音，我在build_model 函数中加入了Dropout() ， 可以为我们相对小的模型降低过度拟合的风险）。 我们应该更关注模型在测试集上的表现，因为可以看到模型处理全新数据的表现。 测试集：单时间点预测 蓝色线-实际价格；绿色线-预测价格 纵坐标：以太币价格($) 平均绝对误差：0.0531 撇开单点预测误导性的局限，LSTM模型似乎在测试集中表现良好。但它最明显的缺陷是以太币的价格在暴增后（例如六月中旬和十月）不可避免的下降，模型无法探测出来。 实际上这个问题一直存在，只是在这些剧烈变化的时间点更加明显。预测价格曲线几乎是实际价格曲线向未来平移一天的结果（例如七月中旬的下跌）。此外，模型似乎整体高估了以太币的未来价值（我们也是~），预测曲线总是高于实际曲线。 我怀疑这是由于训练集所属的时间范围内，以太币的价格以天文数字增长，因此模型推断这种趋势仍会持续（我们也是~）。我们也建立了一个相似的LSTM模型用来预测比特币，测试集的预测图如下 完整代码的Jupyter notebook链接： https://github.com/dashee87/blogScripts/blob/master/Jupyter/2017-11-20-predicting-cryptocurrency-prices-with-deep-learning.ipynb 测试集：单时间点预测 蓝色线-实际价格；绿色线-预测价格 纵坐标：比特币价格($) 平均绝对误差：0.0392 正如我之前所说的，单点预测会有欺骗作用。如果仔细观察你会注意到，预测值通常会反映出先前的值（例如十月）。深度学习模型LSTM已经部分推导出了p元自回归模型(autoregression model,AR)，未来的值仅仅是先前p个值的加权和。AR模型的数学公式如下：                  好的方面是，AR模型常运用于时间序列中 ，因此LSTM模型似乎有了合理的用武之地。坏消息是，这是对LSTM能力的浪费，我们可以建立更加简单的AR模型，花费时间更少，可能会得到相似的结果。 测试集：5个时间点的预测 蓝色连续线：实际价格 其他颜色线：预测价格 上半部分：比特币价格($);下半部分:以太币价格($) 这个预测结果显然没有单点预测的结果吸引眼球。然而，我很开心这个模型输出有些微妙的状况（例如以太币的第二条线）；它并没有简单的预测价格会朝着一个方向统一移动，这是个好现象。 回过头来看一下单点预测，深度机器人工神经模型运行的还可以，但随机漫步模型也不差。和随机漫步模型一样，LSTM模型对随机种子的选择也很敏感（模型的权重最初是随机分配的）。 因此，如果我们想去比较这两个模型，就需要多次运行（大约25次）之后获取模型误差的估计值，测试集中实际和预测的收盘价之间差值的绝对值记为误差。 左图： 比特币测试集（运行25次） 纵坐标：平均绝对误差 横坐标：LSTM模型，随机游走模型   右图： 以太币测试集（运行25次） 纵坐标：平均绝对误差 横坐标：LSTM模型，随机游走模型 也许AI还是值得广而告之的，上图显示了对每个模型进行25次初始化后测试集的误差。LSTM模型在比特币和以太币上价格的平均误差分别是0.04和0.05，这个结果完胜随机漫步模型。 战胜随机漫步模型是很低的标准，将LSTM与更合适的时间序列模型做比较会更有趣（比如加权平均，AR，ARIMA 或Facebook的 Prophet algorithm）。另一方面，我相信改进LSTM模型并不难（尝试加入更多层和/或神经元，改变批次的大小，学习率等）。 也就是说，希望你已经发现了我对应用深度学习预测加密货币的价格变化的疑虑。这是因为我们忽视了最好的框架：人类智能。显然，预测加密货币的完美模型*应是： （译者注： 如果在时过境迁之后，加密货币的价格接近月球的高度， 那么所有不在OmiseGo区块链中的加密货币会一直升值） *本篇文章不涉及财务建议，也不应该做财务建议使用。尽管加密货币的投资在长时间的范围看肯定会增值，但它们也可能会贬值。 我们收集了一些加密货币数据，并将其输入到酷炫的深度智能机器学习LSTM模型中，不幸的是，预测值与先前的输入值并无太大差别。那么问题来了，如何使模型学习更复杂的行为？ 改变损失函数：平均绝对误差（MAE）使模型中规中矩，得不到“出格”的结果。例如，如果采用均方误差（MSE），LSTM模型会被迫更加重视检测高峰值/低谷值。 许多定制交易的损失函数也会使模型朝着没那么保守的方向演化。  限制保守的AR类模型：这会激励深度学习算法来探索更具风险/有趣的模型。不过说起来容易做起来难啊。 获取更多且/或更好的数据：如果过去的价格已经足以预测较为准确的未来价格，那么我们需要引入其他具有相当预测能力的特征。这样LSTM模型不会过度依赖过去的价格，也许会解锁更复杂的行为，这可能是最可靠同时也是最难完成的解决方案。 如果以上是积极的一面，那接下来的负面消息是，有可能加密货币的价格变化模式根本找不出来；没有任何模型（无论多么深）可以将信号与噪音分开（这与利用深度学习预测地震类似），即使出现了某种模式也会很快消失 。 想想看2016年和2017年末狂热的比特币差别多么大，任何建立在2016年数据的模型肯定难以复刻2017年空前的变化。以上讨论就是在建议你，不妨节省些时间，还是坚持研究AR模型吧。 但我相信他们最终会为深度学习找到用武之地，与此同时，你可以通过下载 Python 代码建立自己的LSTM模型。 Python 代码： https://github.com/dashee87/blogScripts/blob/master/Jupyter/2017-11-20-predicting-cryptocurrency-prices-with-d eep-learning.ipynb 原文链接： https://dashee87.github.io/deep%20learning/python/predicting-cryptocurrency-prices-with-deep-learning/ Have a Great Definition "
76,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658195&idx=1&sn=c77b993ca95b2835bac474ee9eb19668&chksm=bd4c30408a3bb956351eb6e7a0d758eb0681a37387c8f445e28e7223bae5b6ec9558a9d2ae92&scene=27,物理学家史蒂芬·霍金去世，享年76岁,据海外媒体BBC报道，物理学家史蒂芬·霍金（Stephen Hawking）去世，一位发言人代表他的家人对外公布了这一消息，并没有透露更多细节。 目前，这一消息已经迅速登上推特等各社交网站热搜。 霍金生前一直致力于探索 ，以及AI发展的原则。他认为人工智能的全方位发展可能招致人类的灭亡，比如最大化使用智能性自主武器。 对此他在2017年2月与Elon Musk联手推出了 ，告诫AI发展的底线。呼吁全世界的人工智能领域从业者在发展AI的同时严格遵守这些原则，共同保障人类未来的利益和安全。 霍金在美剧《生活大爆炸》中客串 
77,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658123&idx=3&sn=deaed293de61672362e23e6714746503&chksm=bd4c30188a3bb90eca8279c19f89b98bed2a7f5a67f2fb670d13491ae0b88328db26a6b2e085&scene=27,大咖 | 清华魏少军：今天多数AI芯片创业者会成为技术变革的先烈,大数据文摘作品 “今天的一部分甚至大部分的AI芯片创业者会成为技术变革的先烈。” 在近日于上海召开的GTIC 2018全球AI芯片创新峰会上，清华大学微纳电子系主任、微电子所长魏少军教授如此评价今天的AI芯片创业大潮。 从AI芯片的发展历程讲到架构创新、发展桎梏，魏少军教授为现场听众讲述了芯片领域一些不太一样的观点。 演讲的最后，魏少军教授也给现场的企业家留下了两个问题： “未来能否出现像通用GPU这样独立存在的通用AI处理器？如果存在的话它的架构是什么样，如果不存在，AI公司将何去何从呢？” 会后，大数据文摘也就这两个问题专访了英伟达AI技术中心亚太首席技术官 Simon See。 Simon介绍，目前AI芯片主要分两种：一类是数据中心（云）中用于训练的芯片；第二类是面向端的手机、安防等的芯片，主要是推理功能，不排除未来有训练的需求。毫无疑问GPU在这两个方向都是市场上应用最广泛的通用AI芯片。  “是否未来会出现像GPU一样通用的AI芯片现在还很难讲。但是，要想达到这个目的还需要很长时间，到时候可能很多芯片公司可能已经改变了设计，或者不存在了。” 魏少军教授现场演讲如下，速记来自主办方： 主持人介绍我们是做人工智能芯片，错了，我是做芯片设计，研究芯片设计的方面和理论。 2年前我们伟大征兆前一些年的成果尝试做了一些AI芯片，结果效果不错。后来，在国际上连续发表了一些有影响里的论文，有些结果被一些引用，突然发现了我自己成了AI芯片的专家，其实不是。 今天跟大家做一些沟通，主要希望提出一些可能跟我们在坐的大佬们不太一样的观点，供大家批判和产生共鸣。我的观点中有冒犯在坐各位，请大家务必原谅。 谈四个方面们内容，集成电路芯片是实现人工智能的载体，AI其实在50年代出现过，经过30年后又一次火起来了。从基本的概念到机器学习，再到深度学习。 现在看深度学习是当下研究的主要内容，其实深度学习只是人工智能比较窄的一面，为何我们如此热衷于研究一个很窄的方面呢，原因就是前年AlphaGo在人机围棋比赛中战胜了人类围棋高手李世石这一标志事件。 早在2011年的流行一个游戏其实比阿尔法狗更有代表性，当然可能大家不一定同意我的观点。 智能化到底是什么？具体来讲就是：人类在面对一件事情所做的处理和决策。处理加决策，它支撑了我们现在计算逻辑分析思维经验支持判断的各种主要内容，我们称之前者为能力，后者为智慧。 中文有时候比较宽泛一些，智能包含智慧和能力，我们在处理多数事情的时候需要的智慧而非能力，人工智能这个词有问题，不清楚，英文叫人工智慧，并未将智慧和能力两者结合在一起。 芯片是实现AI的当然载体，无论从英特尔的GPU等重要的提供商，还是CPU加是FPGA，或者其它的出现多个芯片的平台，CPU加IPG等，所有这些东西都离不开芯片，所以讲一句话，无芯片不AI，做AI一定要有芯片，芯片是AI不可或缺的基本内容。 人工智能芯片如此重要，怎么实现它？AI的算法非常多，算法不断的延进，一个算法对应一个应用，我们没有一个算法覆盖所有的应用，你希望找到适应所有算法的架构，而不是一个应用做一个芯片。 我们当前的AI项目复杂程度不一样，无一例外都需要一个专用的神经网络实现。在这样的情况下，我们需要在芯片当中实现一个具备深度学习的引擎。 如今的深度学习所需要的计算量和参算量都非常庞大。以往的深度学习计算量较小，完成的工作量也有限，当时觉得有个10万个参数就很多了。 但是今天已经大有不同，比如说2017年当神经网络做到17层需要每秒196亿次的运算速度，新增加了1.38亿个参数。到了2015年的时候参数增加到1.5亿个。因此我们需要一个好的计算引擎，否则无法完成这些运算工作。 随着AI算法的不断发展，对AI芯片也提出了更高的计算诉求。AI芯片不仅要适应算法的引进，当然前提是算法适应所有的应用，还需要具有架构可变性，同时也要有高效的架构变换能力。 运算速度要多快？当架构中10个引擎同时工作，效率一定会提高，同时我们不能忽略能量效率。计算量的要求是多少？大概每瓦10个TOS，每秒完成10万亿次的运算或许能满足基本需求。 AI芯片进入家电和消费电子，还需要解决低功耗、低成本、小体积和开发简便等计算问题，方便搭载在各种设备上，且无需其他芯片的支持 。开发设计芯片本身难度很大，再加上与CPU、软件和FPGA匹配，需要我们探索架构上的创新。 应用和架构创新是发展应用创新的必由之路，我们说今天的应用涵盖所有的各个方面，例如人脸识别，语音识别、机器翻译。 我们看到屏幕上已经做到了记事的传译，还包括无人驾驶，智能陪伴、能源、农业或者生产，似乎AI涵盖了我们生活各个方面。但是我想问几个问题，我们哪些需要，哪些应用真的需要AI？ 我们用AI的时候我们希望这些AI解决什么样的问题，什么是AI的杀手级的应用，什么样的AI是我们每天都需要的？我觉得这些问题到今天为止都没有答案，有些貌似是AI的东西好像是AI，但是实际上并不是AI。 我们说开发应用确实很难，做芯片的人一定会考虑架构是什么。架构创新很重要，从感知传输到中间的处理和后面的执行，都离不开基本架构。 大家对AI的通俗理解是，这是一个传感器，通过执行器和中间的传输网络实现输入输出的对应。基本的逻辑是这样，那么智慧处理的根本架构是什么？ 计算无处不在，架构是计算的基本前提，GPU就是因为有很好的计算量而占据了优势。我们想要构建一个所谓能够具备智慧处理能力的芯片，一个智能的软件和硬件。智能软件包含这几方面的内容，形成知识能力，组织能力，思维推理能力。 软件定义芯片 在智慧芯片的构建过程中软件的地位一点不比芯片差，而相反我们看到芯片更多提供计算的平台，多任务并行的能力，极高的运算效率，和灵活高效的存储和实时动态的能力 。 我们因此经常说，实现智能的核心其实是软件不是芯片，芯片不过是支撑智能的基础而已。因此我们要改变一些思路，就是我们做芯片的人，特别做AI芯片的人把软件放在足够高的来看。 因此我们说希望在这种情况希望我们硬件可以跟着软件不断变化，所谓软件定义芯片的概念，芯片不能被软件定义，那你是做不好。 这个概念我们在10年前就提出来了，但是因为大众对其了解甚少。去年有一个很有意思的国家电子设计能力的课题，提到了软件定义硬件的概念，即，让硬件结果可以软件变化的时候，可以从300变化到1000个纳米，硬件跟软件变化，硬件的功能和架构，随软件变化而变化。这个工作10年前已经完成，走在美国同行的前面。 大家说FPGA早可以做了，其实FPGA也不行。第一就是FPGA颗粒度是细力度，所以配置一样信息量内容需要很长的时间，十几毫秒甚至要停要更长的时间，无法实现静态配置。在线更新也需要很长时间，信息需要装载进整个电路，面积效率很低，效率只有5%，千万面积的FPGA实现几十万的信息，能量效率很低，功耗很大。 FPGA需要非常先进的工艺，工艺还要调整，电路和技术的调整是必须的，要想使用FPGA不懂电路设计寸步难行。用FPGA做一个简单的验证系统的成本都非常高，实用系统恐怕更加困难。所以我们说FPGA无法承担软件芯片。 想要构建软件芯片非常困难，什么样系统可以完成STC。从架构上去考虑，右边给出一个完全一致的硬件结构，没有考虑硬件本身的开销，这样的计算效率一定是最高的，但是软件的设计可以无穷大，而硬件设计总有边界。 把软件分成若干块，一块一块搬过去，运行完了以后，执行第二个模块，任务依赖性第三个模块搬过去，回来计算第四个、第六完成这样的多级发展，要求我们的硬件结构和功能必须是动态的、随时可以改变的，这就是软件定义芯片的基本概念，但如何快速实现它这是工作的难点。 我们过去10年当中的努力就是解决这个问题，这样的计算架构是非常经典的架构，我们可以看到这两者一个是所谓的控制单元划分的内容逐步送进去执行，根据要求配置计算单位并且完成执行，问题是要出现完全可重构的数据通道和可完成变成的控制单位，这样做到就是软件可变化的。 软件芯片与传统芯片的结构是有差别，经典的计算模式做了一个比较，它是弓形的，可传播的、计算是函性的，它是应用使用计算。 经典模式中一个处理任务的软件，有多个等效的处理软件。经典架构当中，软件硬件不变。而在我们现在的架构中，硬件和软件都在做动态的选择性的改变，经典架构用高度复用的方式，降低它的成本。 而在我们这边是荣誉应用，是不是改变的计算模式，很遗憾告诉大家，我们还是在架构当中，有些人我说改变了模式，我做出了丰富的计算架构，其实我说，你没有弄明白。 我们利用软件定义芯片可重构硬件的结构实现AI芯片的时候，可以利用软件独特优势来把硬件按照AI的算法来不停的变换，以达到最佳的计算效率。我们从AI的应用定义采用深度神经网络，再来决定硬件的功能，这样的结构我们认为是一个最佳的方式，我们只是在无意当中尝试一下，构建一个芯片叫“思考者”。 结束语 我们说应用领域的确立是AI领域的确立前提，而AI的杀手级应用还没有出现，因此我们说AI的发展有很长的路要走，主要的是，能否出现像通用GPU独立存在的通用AI处理器？ 如果存在的话它的架构是什么样，如果不存在，我们今天的已满足特定应用的芯片恐怕只能做IT核了，我们AI公司何去何从呢。 这个问题留给企业家们思考，可能大家不同意我的观点，两到三年内一定会碰到一个低潮，今天的一部分甚至大部分的创业者成为技术变革的先烈，但是我钦佩大家，也是最令人动容的伟大事件。 【今日机器学习概念】 Have a Great Definition 
78,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658168&idx=2&sn=fa20d68fac83f528e0651bdea742b908&chksm=bd4c302b8a3bb93da17160352a0da1251b325fd81d683eebad0b5f17fc4ea7ec5f8a3ef71438&scene=27,业界 | 每天1.4亿小时观看时长，Netflix怎样存储这些时间序列数据？,大数据文摘作品 编译：丁慧、笪洁琼、蒋宝尚 网络互联设备的增长带来了大量易于访问的时间序列数据。越来越多的公司对挖掘这些数据感兴趣，从而获取了有价值的信息并做出了相应的数据决策。 近几年技术的进步提高了收集，存储和分析时间序列数据的效率，同时也刺激了人们对这些数据的消费欲望。然而，这种时间序列的爆炸式增长，可能会破坏大多数初始时间序列数据的体系结构。 Netflix作为一家以数据为驱导的公司，对这些挑战并不陌生，多年来致力于寻找如何管理日益增长的数据。我们将分享Netflix如何通过多次扩展来解决时间序列数据的存储架构问题。 Netflix会员每天观看超过1.4亿小时的内容。 Netflix通过分析这些观看数据，为每位会员提供了实时准确的标签和个性化推荐服务，如这些帖子中所述： 如何判断你在观看一个节目？ https://medium.com/netflix-techblog/netflixs-viewing-data-how-we-know-where-you-are-in-house-of-cards-608dd61077da 帮助你继续观看Netflix的节目。 https://medium.com/netflix-techblog/to-be-continued-helping-you-find-shows-to-continue-watching-on-7c0d8ee4dab6 从以下3个维度累积历史观看记录： 随着时间的推移，每个会员的更多观看记录数据将被存储。 随着会员数量的增长，更多会员的观看记录数据会被存储。 随着会员每月观看时间的累积，每个会员的更多观看记录将被存储。 过去十年的发展，Netflix已经在全球拥有1亿名会员，其观看记录的数据亦是大幅增加。在本篇博客中，我们将重点讨论如何应对存储观看历史数据带来的巨大挑战。 观看记录的第一版原生云存储架构使用Cassandra的理由如下： Cassandra对时间序列数据建模提供了很好的支持，其中每行都有动态的列数。 观看记录数据的读写速度比约为9：1。由于Cassandra的写入效率非常高，因此Cassandra非常适合频繁写入操作的工作。 根据CAP定理，团队更倾向于最终的一致性。Cassandra支持通过调整一致性进行权衡。 在最初的方法中，每个成员的观看历史记录都存储在Cassandra中，并使用行键存储在一行中：CustomerId。这种水平分区的方式能够随着会员数量的增长而有效扩展，并且使得浏览会员的整个观看记录的常见用例变得简单、高效。 然而随着会员数量的增加，更重要的是，每个会员的流量越来越多，行数和整体数据量也越来越多。随着时间的推移，这导致了昂贵的操作成本，对于读写具有海量观看记录的会员数据而言性能较差。 下图说明了初始数据模型的读写流程： 图1：单个图表数据模型 写流程 当会员点击播放时，一条观看记录将作为新的列插入。点击暂停或停止后，则该观看记录被更新。可见对于单列的写入是迅速和高效的。 读流程 通过整行读取来检索一个会员的所有观看记录：当每个会员的记录数很少时，读取效率很高。但是随着一个会员点击更多标题产生更多的观看记录。此时读取具有大量列的行数据会给Cassandra带来额外的压力，并造成一定的读取延迟。 通过时间范围查询读取会员数据的时间片：将导致了与上面的性能不一致，这取决于在指定的时间范围内查看记录的数量。 通过分页整行读取大量观看记录：这对于Cassandra来说是好的，因为它并不需要等待所有的数据返回就可以加载。同时也避免了客户端超时。然而，随着观看记录数量的增加，整行读取的总延迟增加了。 放缓原因 让我们来看看Cassandra的一些内部实现，以了解为什么我们最初简单设计的性能缓慢。随着数据的增长，SSTable的数量相应增加。 由于只有最近的数据在内存中，所以在很多情况下，必须同时读取memtables和SSTable才能检索观看记录。这样就造成了读取延迟。同样，随着数据量的增加，压缩需要更多的IO和时间。由于行越来越宽，读修复和全列修复因此变得更加缓慢。 缓存层 虽说Cassandra在观看记录数据写入方面表现很好，但仍有必要改进读取延迟。为了优化读取延迟，需要以牺牲写入路径上的工作量为代价，我们通过在Cassandra存储之前增加内存分片缓存层（EVCache）来实现。 缓存是一种简单的键值对存储，键是CustomerId，值是观看记录数据的压缩二进制表示。每次写入Cassandra都会发生额外的缓存查找，并在缓存命中时将新数据与现有值合并。 读取观看记录首先由缓存提供服务。在高速缓存未命中时，再从Cassandra读取条目，压缩并插入高速缓存。 多年来随着缓存层的增加，这种单一的Cassandra表格存储方法表现良好。基于CustomerId的分区在Cassandra集群中可扩展性亦较好。 直到2012年，观看记录Cassandra集群成为Netflix最大的Cassandra集群之一。为进一步扩展，团队决定将集群规模扩大一倍。 这就意味着Netflix要冒险进入使用Cassandra的未知领域。与此同时，伴随着Netflix业务的快速增长，包括不断增加的国际会员数和即将投入的原创内容。 重新设计：实时和压缩存储方法 显然，需要采取不同的方法进行扩展来应对未来5年的预期增长。团队分析了数据特征和使用模式，重新设计了观看记录存储方式并实现了两个主要目标： 较小的存储空间 每个会员的观看记录增长与读写性能保持一致 对于每个会员，观看记录数据被分成两个集合： 实时或近期观看记录（LiveVH）：频繁更新的最近观看记录数量较少。这样的数据以非压缩形式存储，如上面简单的设计中所述。 压缩或存档观看历史记录（CompressedVH）：大量较早的观看记录很少更新。 这样的数据将被压缩以减少存储空间。压缩的观看历史记录存储在每行键的单个列中。 LiveVH和CompressedVH存储在不同的表格中，并通过不同的调整以获得更好的性能。由于LiveVH的频繁更新和拥有少量的观看记录，因此压缩需频繁进行，且保证gc_grace_seconds足够小以减少SSTables数量和数据大小。 只读修复和全列修复频繁进行保证数据的一致性。由于对CompressedVH的更新很少，因此手动和不频繁的全面压缩足以减少SSTables的数量。在不频繁更新期间检查数据的一致性。这样做消除了读修复以及全列维修的需要。 使用与前面所述相同的方法将新观看记录写入LiveVH。 写流程 使用与前面所述相同的方法将新观看记录写入LiveVH。 读流程 为了从新设计中获益，观看历史记录的API已更新，可以选择读取最近的或完整的数据： 最近观看记录：对于大多数的用例，只需从LiveVH中读取数据，通过限制数据大小降低延迟。 完整的观看记录：作为LiveVH和CompressedVH的并行读取实现。由于数据压缩和CompressedVH的列较少，因此通过读取较少的数据就可以显著加速读取。 CompressedVH更新流程 当从LiveVH中读取观看历史记录时，如果记录数量超过可配置的阈值，那么最近的观看记录就被汇总一次，压缩并通过后台任务存储在CompressedVH中。然后使用行键（行关键字）：CustomerId将数据存储在新行中。新的汇总是版本化的，写入后会再次检查查数据的一致性。只有在验证与新版本数据一致后，旧版本的数据才会被删除。为简单起见，在汇总过程中没有加锁，Cassandra负责解决极少的重复写入操作（即最后一个写入操作获胜）。 图2:实时和压缩的数据模型 如上图所示，CompressedVH中汇总的行也存储元数据信息，如最新版本号，对象大小和块信息（稍后更多）。版本列存储对最新版本的汇总数据进行引用，以便CustomerId的读取始终只返回最新的汇总数据。 汇总起来的数据存储在一个单一的列中，以减少压缩压力。为了最大限度地减少频繁观看模式的会员的汇总频率，最后几天查看历史记录的值将在汇总后保存在LiveVH中，其余部分在汇总期间与CompressedVH中的记录合并。 对于大多数会员来说，将其整个观看记录存储在单行压缩数据中将在读取流程中提升性能。对于一小部分具有大量观看记录的会员，由于第一种体系结构中描述的类似原因，从单行中读取CompressedVH速度缓慢。不常见用例需要在读写延迟上设一个上限，才不会对常见用例造成读写延迟。 为了解决这个问题，如果数据大小大于可配置的阈值，我们将汇总起来的压缩数据分成多个块。这些块存储在不同的Cassandra节点上。即使对于非常大的观看记录数据，对这些块的并行读取和写入也最多只能达到读取和写入延迟上限。 图3：自动缩放通过组块 写流程 如图3所示，根据可配置的块大小，汇总起来的压缩数据被分成多个块。所有块都通过行键：CustomerId $ Version $ ChunkNumber并行写入不同的行。在成功写入分块数据之后，元数据通过行键：CustomerId写入到自己的行。 对于大量观看记录数据的汇总，上述方法将写入延迟限制为两种写入。在这种情况下，元数据行具有一个空数据列，以便能够快速读取元数据。 为了使常见用例（压缩观看记录小于可配置阈值）被快速读取，将元数据与同一行中的观看记录组合以消除元数据查找流程，如图2所示。 读流程 通过关键字CustomerId首次读取元数据行。对于常见用例，块数为1，元数据行也具有最新版本汇总起来的压缩观看记录。对于不常见的用例，有多个压缩的观看记录数据块。使用版本号和块数等元数据信息生成块的不同行密钥，并且并行读取所有块。上述方法将读取延迟限制为两种读取。 缓存层更改 内存缓存层的增强是为了支持对大型条目进行分块。对于具有大量观看记录的会员，无法将整个压缩的观看历史记录放入单个EVCache条目中。与CompressedVH模型类似，每个大的观看历史高速缓存条目被分成多个块，并且元数据与第一块一起被存储。 结果 利用并行，压缩和改进的数据模型，实现了所有目标： 通过压缩缩小存储空间。 通过分块和并行的读/写操作保证读/写一致性。常见用例的延迟受限于一次读操作和一次写操作，以及不常见用例的延迟受限于两次读操作和两次写操作。 图4：结果 数据大小减少了约6倍，花费在Cassandra维护上的系统时间减少了约13倍，平均读取延迟减少了约5倍，平均写入延迟减少了约1.5倍。更重要的是，它为团队提供了可扩展的架构和空间，可以适应Netflix观看记录数据的快速增长。 原文链接：https://medium.com/netflix-techblog/scaling-time-series-data-storage-part-i-ec2b6d44ba39 【今日机器学习概念】 Have a Great Definition 
79,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658195&idx=3&sn=08ce904ccb822ce62d12ec345e6e3189&chksm=bd4c30408a3bb956b2b76a7341e879830a2d025401a4bc5de4f4995a8303be52dcff3423dd46&scene=27,Reading Club | 算法和人生选择：如何给洗好的袜子排序呢？,大数据文摘作品 作者：Andy 主播：段天霖 在美国的计算机程序及代码问答平台Stack Overflow上，有这样一个神级问题，它在2013年被提出之后，就引发了上千人总计万字以上的激烈讨论：如何在洗完衣服后把洗衣机里10双不同花色甚至大小的袜子精准并高效地匹配起来呢？ 其实小到一双袜子，大到整个人类社会，排序都是无处不在的：当你打开微信，聊天信息是由最新时间排序的；当你在某宝剁手，商品是按热度排序的；当你百度一下你就知道，你所看到的链接也是按照相关性排列的，甚至度娘和其他搜索引擎本身就是一个复杂的排序引擎。 本周，我们来聊聊【排序】这个或大或小的话题。点击收听由来自杜克大学美女主播段天霖与大家分享：无处不在的排序。 如果真要追本溯源，排序从某种意义上促成了计算机的诞生。 19世纪末，美国人口大量增长，导致人口普查整理表格时需要花费大量时间。那时可没有Excel这么方便的排序功能，都得靠人力。应运而生的就是由Herman Hollerith发明的可以用来储存信息的打孔卡以及配套的“读卡系统”Hollerith Machine。当时很多人并不看好这项发明的应用前景，认为它只适用于处理政府事务，事实证明悍跳预言家是很容易被实力打脸的，几年后，Hollerith的公司合并更名为International Business Machines，简称IBM。 在介绍具体的算法之前，我们需要一个标尺来度量在这样大量级下算法的性能。 偷懒的计算机科学家们从数学里借来了Big-O表示法，O 表示 order of function (函数的阶)，而计算机科学里习惯称计算复杂度。值得注意的是，它所衡量的是在最差初始情况算法完成排序时的计算复杂度，而并非最优情况。 根据最差情况下的计算复杂度，我们可以将不同算法大致分为以下几个量级： O(1)，也叫“常数复杂度” 表示计算时间与n无关。比如今晚你要喊老铁来家吃饭，得先收拾一下房间，因为你的客厅并不会根据人数的多少而变大变小，单论打扫的时间应当是一个与人数无关的常数。 O(n)，线性复杂度 假设你要为每位老铁准备一道菜，那准备菜的时间便会随人数n线性增长。所以收拾房间和准备晚餐的时间一个是O(1)一个是O(n)，那么到目前为止你所花费的时间用Big-O表示是不是就是O(n+1)呢？并不是。Big-O表示法关注的并不是一个具体的数值，而是一个计算的复杂级别，这是因为n非常大时，往往低级别的计算复杂度可以直接忽略。还有n前的常数项都要省去，比如2n和n的Big-O表示法都是O(n)。 O(n^2 )，又叫“平方复杂度” 准备工作完毕，老铁们陆续到来，秉着团结友爱的精神你和n个老铁总共n+1个人决定要两两之间来一个深情拥抱 ，那么你们所需要的时间就是平方复杂度O(n^2)了。 O(2^n)，指数复杂度 一种比较坏的情况，每增加一个对象花费翻倍。 最经典的两种经典排序算法就是冒泡排序和插入排序。有多经典呢？要知道奥巴马当年因为在和谷歌CEO的访谈中正确回答了一个关于冒泡排序的问题，不知道获得了多少程序员的选票。 为了更好地了解这两个经典算法，我们来假设有一队高矮不一的小朋友杂乱地站成一列，而我们的任务是要帮助他们按照身高来排队。 冒泡排序，就是从第一个小朋友开始，和第二位比，如果比他高就交换，矮就不变。然后第二个位置，和后面一位比，同样的操作... 当到达队尾，再循环回队头，直到将整个队伍过一遍，而没发生一次交换。这样交换的方式有点像气泡上浮的感觉，因此叫冒泡算法。 图片来源：维基百科 而插入排序，则是先随便挑个小朋友站出来，然后再从其余中挑一个，和站出来的小朋友比，放到适当位置。之后挑下一个，和已经排好的小朋友比较，插入到适当位置... 直到把人都放入排序组。 图片来源：维基百科 合并排序 (Merge Sort) 有没有比平方级更高效的算法呢，这个倒真可以有，这就要说天才冯诺依曼提出的合并排序 (Merge Sort)算法了，它利用一种叫做分而治之(Divide and Conquer)的思想找到了一种介于O(n)与O(n^2)之间的复杂度，那就是线性对数(Linearithmic)复杂度O(n logn)。 图片来源：维基百科 其实真要说起来，线性级的复杂度也不是完全不可能，起码在华盛顿附近一个叫做普雷斯顿的小镇，有一个叫做普雷斯顿排序中心的神秘组织就号称到达线性复杂度的排序算法，并在美国国家图书馆排序比赛中取得了两次冠军。 他们能在线性时间内做到的只是部分排序，也就是将书分类放入几个内部不用排序的桶，然后对桶进行排序就好了。这种方法叫做桶排序 (Bucket Sort) 法，那么假设有m个类和n本书，需要比较的最大次数就是mn次，而当n很大m比较小时，其中m可被忽略表示成O(n)，线性复杂度就这样达成了。 仔细一想，生活中很多时候我们都不需要达成完全排序，而只是关注序列的某一部分，比如说百度时我们真正关心的只是前面的链接，而选秀节目只关心10进7、5进3，海选的千军万马并不需要决出谁是第2万名或是2万零一名。 首先马上能想到的是单淘汰赛 (Single Elimination)，抓对厮杀，赢的进入下一轮，输的淘汰。不过这种赛制下实力第二的选手如果在前几轮中遭遇实力第一的选手，那么他们中总有一名要过早止步而拿不到任何名次，因此很多人都非常质疑这种赛制的公平性。 其实聪明的中国古人早就已用上合并排序算法，那就是科举制。 科举制从上到下分为殿试、会试、乡试、院试，还有县试和府试，而天下读书人从最低的县试与府试开始排序，之后合并到上一级，重新排序，再到上一级... 正与合并排序的思想相同。这样超前的排序方式一方面让李世民大叹：“天下英雄入我轂中矣！”，另一方面也着实漏掉了不少后人公认的才子，毕竟一次比赛或考试的结果也是由很多因素决定的。因此在评价一个算法时我们不仅要关注它的排序效率，还需要关心它有多强的抗干扰性，即在这样一个充满不确定性的世界中取得足够可信结果的能力。 算法中的许多假设和前提是将现实世界中我们所面对的情况极大简化了的，我们在做重大选择的时候，很少能用一两个简单的数值作为决定的标准，就像用某一特定个维度的表现来概括一个人是很不负责也不公平的。因次排序算法所启发我们的，依旧不是一个普适的解决方案，而是一种包容和平衡的视角：根据不同的需求和背景来选择最适合的方案。 以上就是Algorithm to Live by第三章的内容主要内容，点击 收听大数据文摘喜马拉雅专栏音频《生活中的算法》专辑。 点击收听前两章内容： Reading Club | 算法和人生抉择：午饭到底吃什么？ 大数据文摘读书会正在进行中， 加入我们~ 【今日机器学习概念】 Have a Great Definition 
80,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658168&idx=1&sn=b80b83c51cd319ae925618a6dbb7d3e3&chksm=bd4c302b8a3bb93dc50eb985069743eccc87b6899c0097d0576f1232041f9030640c1878fd3c&scene=27,为什么说加密技术的首个杀手级应用会出现在色情行业？,BlockChange作品 编译：张南星、Katrine Ren、魏子敏 去中心化正在成为一种新的流行。 从货币到交易，去中心化趋势正急风骤雨般迅速席卷各个行业（点击查看BlockChange相关报道 ）。 而其挟裹的巨大能量与其诞生之处——金融业密不可分。这一天生与利益紧密联系的领域激发着所有人的占有欲望。 除了对利益的占有，另一种人类的原始本能——情欲很可能催生区块链的第一个杀手级应用。 其实自古以来，情欲和技术总是密不可分，无论何时出现的交流新技术，一般都在“情欲”的助力下“飞入寻常百姓家”。 让我们先来回忆一下技术和色情相互促进的历史。 古登堡色情材料打印装置 在古登堡发明了色情材料打印机器五十年后，意大利作家Piertro Arentino为我们带来了许多色情书籍。之后相机一发明，人类就开始创作色情照片。在1874年，一个伦敦小电影行业的老司机因为发行了13万张色情照片被风化纠察队枪毙。 但实际上情欲和科技的故事可以追溯到更久之前。我们总以为色情片是现代发明。但事实并非如此。 当人类会绘画和雕塑时，他们已经开始描绘或者雕刻人们“不可描述”的场景了。 一些古希腊瓷器上绘画的莱斯波斯岛，你妈妈不想让你看到的瓷器 无论是古希腊色情瓷器上所绘画的人，印度的性寺庙，都灵纸莎草性爱全书中柔软得不可思议的埃及人（连Brazzers House（国外某著名小黄片网站）都望其项背），德川幕府时期露骨的木刻春宫图，或是中国古代小说《金瓶梅》，艺术家们总是尽情游弋在人类赤裸而又荒诞的光荣性史中，并向世人展示。 迄今为止发现最古老的壁画中，人类在一个纵深的洞穴里展现了迷幻的性爱白日梦——2万8千年前的澳洲土著就充分说明，人类的对爱的脑补是自古有之的传统。 也许把绘画和雕塑视为科学有些奇怪，但是它们可以是类科学，笔就是工具。纸张的发明从根本上改变了人类记录的方式，让那些珍贵的思想不再随着人类的死亡而消逝。 但科学也包含了量变和质变。 工匠们使用了各种方法，按照想象改造材料，为人类创造了印有蓝色花纹的明朝花瓶以及瓷器，精美绝伦。瓷器也需是人类发明的第一种合成材料，将黏土、长石、骨灰、石英以及其他的材料混合，然后加热至上千度，它们就能转换成一种完美的新材料，这就是最好的类科学。 随着时代不同，人们对于情欲的态度总是有起有落，态度时而开放时而保守。但是对于肉欲的火热激情却不会湮灭。无论世间对我们最原始的本性进行多强的抑制，火焰永不会熄灭，本性总会指引我们找到出路。 实际上，对于情欲的完全控制是一种相对来说比较新的现象。追溯到更早的时代，社会对于情欲的态度与对其他欲望的态度并无二致。 维多利亚时代人们的教条陈规破坏了人们对情爱的追捧。 从维多利亚时代开始，社会视性暴露为异端。虽然很多国家禁止某些性行为，但仅仅观看裸体女郎图片并不是重罪，直到在抑制罪恶协会这个扫兴的组织的坚持下，1857年英国通过了淫秽作品法（1857年）。这个法令禁止色情片的销售和传播，并且给予法院收缴并销毁它们的权利。 随着二十世纪的到来，从中国到印度，越来越多的国家开始了全新高度的反性长期抗战，以摧枯拉朽之式打击色情产业，中国的超级防火墙禁止了上百万个成人网站，印度明令禁止使用WhatsApp传播淫秽图片。 但是哪里有压迫哪里就有反抗，每当你有张良计，我便有过墙梯，一些有趣的事情发生了。 在过去，色情仅仅是新技术应用的领域之一，但是随着现代社会对欲望的压抑愈演愈烈，人们转而向新技术求助以越过重重阻碍。 在如今20世纪，色情产业不再转移市场，它们自身就在创造市场。 在第二次世界大战后，8mm家庭摄影机就开始席卷商业市场。最大的用途之一不是拍摄在花园和家人度过的悠闲日子，或是在家中后院野餐烤肉的快乐时光，而是嘿嘿哈。不久之后，相机商铺就开始存储色情短片，并促进了电影放映机、屏幕及其他周边产品的销售量增长。 1953年，一位年轻的创业者休海夫纳用毕生存储5000美金，购买了女神玛丽莲梦露的裸体照，作为《花花公子》杂志的创刊号头条。随后开始了常年与联邦政府、州政府以及当地政府在邮局展开的游击战。从1800开始生效的猥亵法规定了通过邮件传播淫秽材料的违法性。但是在1957年，最高法院出规国会只能禁止“完全没有社会重要价值”的东西。现在，整个美利坚的男人们终于能在家中浴室里偷偷地翻看《花花公子》了。 1970年是家庭视频播放器崛起的一年，也是Betamax和VHS两种是视频格式斗争的一年。Betamax能够提供更高画质的影片，但是只支持播放60分钟，而VHS的画质差得多，但是能够播放3个小时。Sony掌握了Betamax格式的所有权，但是他们做了一个极其错误的决定——拒绝在该平台上制作任何成人色情材料。 结果呢？ 在20世纪70年代末，成人电影占据了美国录像带销量的半壁江山，尽管播放器的成本可达到昂贵的800美元。 可惜啊可惜，Betamax因此必死无疑。 而且我们都知道， 单单是Pornhub（北美流量最大的成人网站），2017年平均每天就有810万访问者（一年有285亿），被搜索247亿次，相当于每分钟搜索5万次，每秒钟800次。 我们已经充分体会到这个产业对于VR（虚拟现实）的市场推动作用，比如说Oculus以及Vive并没有在大型游戏或者世界级应用上得到重视，但是它们已经在色情产业受到极大地追捧，通过一个昂贵的头盔，它能够让你与你最爱的成人影片演员在你侬我侬的清晨中醒来。作为全球第一家把分散区块链用于小黄片匿名上传和传播的平台，Okoin已经把VR视为色情帝国加密的一种方式，其目前已经获得了330万美元的资金支持。 但是一个新技术在色情产业的应用让主流社会看到，它也许可能成为加密技术未来完美的突破性应用：电商产业。 当亚马逊仅仅只是Jeff Bezo的灵光一闪时，Richard J. Gordon已经在20世纪90年代创造了第一个电子信用卡系统，而他最早的用户是谁？ X-rated娱乐公司（最大的成人电影生厂商）。 依托于大大小小公司的委托，Gordon得以发家致富，其中包括大型网站ClubLove，它在1998年发布了名不见经传的Pam和Tommy Lee两天性交的录像带，发表后大受欢迎，几乎人手一部。 如今付款渠道以及大型成人网站对这个产业形成了垄断，快要榨干了艺人们的收入。 成人网站对人气演员的抽成高达50%，这比社会主义时期法国的最高税收等级都要高，这意味着成人电影的艺人们需要付出相当于以前两倍的努力才能勉强过活。 放高利贷的人都没有收那么多。 当然，现在许多加密技术供应商的费率比垄断者们有竞争优势得多。SpankChain希望把交易成本从50%降低到5%”，也就是说许多成人超级巨星们被榨取的钱都真正进入他们的口袋。他们已经吸引一批最成功的成人影片巨星作为代言人，并且在这个领域中大受关注。 但是另一个人人关注的问题可能才是真正让色情产业与加密技术完美结合的原因： 。 穿上军用大衣，在雨幕中偷偷摸摸地到当地成人电影院已是过去式，但CR让人们能够在自己家就能观看色情影片。信用卡提供了购买色情片的极大便利，但是月末的信用卡账单却可能让一个男人陷入麻烦。 这就是为什么诸如Monero，Zcash和ZCoin的加密网站极有可能在未来成为所有色情片交易的中流砥柱。如今排名靠前的大型色情网站或者去中心化色情网站表层的加密支付渠道能够极大降低高利贷者的放贷利率。 催促色情娱乐公司尽快加入去中心化支付行列中的另一个原因是：公司道德规范。 在一篇关于SpanChain的博客中，一个成人影片巨星说道： 相反的，区块链是开放且不可知的，没有任何道德权威方能够知道到底谁用过Monero。这个特性尤其适用于那些由于不可抗力因素而无法开业的公司。 但是“用后即焚”的支付仅仅是区块链在这个行业应用的冰山一角。 因为加密货币可编程的特性以及微交易的发明，色情产业以及其他相同境地之下的主流产业发现了创造新收入的重要渠道。 例如广告投放。 如今广告似乎就是一条单行道，广告商们付钱给一个集中性网站，然后把他们的广告塞到每个人的喉咙上，最后获得极低的回报。 人们厌烦广告，而浏览器拦截插件的存在就昭示了我们是有多讨厌广告。 即使是在Google，这个建立在广告利润上的帝国，在它自己的浏览器中都有广告拦截插件，你就知道这个世界是有多厌烦赤裸裸的广告行为了。 但如果仅仅是牺牲一下你的注意力，你就能获得报酬呢？如果你这是看一下广告，然后投一下票，你就能获得报酬，不管是你否喜欢这个广告，你是否还是会厌烦？ 今天，如果你点击了一个广告并选择“不再显示此广告”，它极有可能还是会出现在你的手机上或者Facebook推送上。微交易会从根本上解决这些问题，因为这就是诸如BAT（Basic Attention Token）的注意力经济货币平台建立的最基本前提。广告的评价被保存在去中心化的信用银行中，并且它将越来越重要，因为只有最好的、最吸引注意力的广告才有可能出现在用户面前。 Vice Token似乎已经有了正确的答案——我付钱，你看片。 像Vice Token所提供的微支付货币不可能成为法定货币，这样的交易方式会毁灭任何商业模式，垄断信用卡公司将迅速断绝与每秒发送上万个微支付交易公司的关系。如果你想成立一个网站，让用户可以只给观看过的视频付钱，基本上是不可能的，因为大量的月度注册费才是支撑电商世界留存的根基。 这只是微支付无数可能性中的一个。 使用加密技术的网站能够让人们为他们想看的影片流量付钱，而不是承担给昂贵的会员注册费。另一个想法是按照与一个演员度过的时间付钱，不管是10分钟还是10个小时。 哪个会成功呢？是我提到的专注色情产业的货币会成功，还是一个诸如Monero的一般支付系统会成为色情狂热分子的默认货币？也许是两个的混合体，人们在后台完成秘密交换，使用一般货币去购买虚拟货币。 但是毫无疑问的是，未来的色情片爱好者、演员等相关人员将无法抗拒去中心化平台的魅力。不管是因为隐私、低费率还是根据观看内容付费，只想为受欢迎的内容付钱， 当然，色情产业的先驱者们将在不远的未来成为主流市场的商业模范。 这意味着60年代的口号错了。 革命将会在电视上播放。 或者至少是以流量的方式。 原文链接： https://hackernoon.com/why-porn-might-just-be-cryptos-first-killer-app-596cf822ef3f Have a Great Definition 
81,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658168&idx=3&sn=5d3fed7129d559cb4442d0ea16ad242d&chksm=bd4c302b8a3bb93d195cd690464b495041dc30ad016f97c7189dbbbe2b6460dc3aa5bda1d372&scene=27,《麻省理工科技评论》2018年“35岁以下科技创新35人”中国评选报名正式启动！首批32名重量级评委公布,"大数据文摘转载自Deep Tech深科技 自1999年起，《麻省理工科技评论》每年在世界范围内评选35岁以下的科技创新领军人物，涵盖范围包括 等几乎所有新兴技术领域。这份世界级权威性榜单旨在寻找从事创新科技研发、科技应用和商业发展的青年人才，给予这些青年创新者应得的关注，肯定他们在技术领域的创新工作，并且激励他们继续在专业领域上取得更大的成就，达到“make a better world”的共同目标。 不管是理论研究、技术研发还是商业发展，科学技术创新都离不开人的努力。自1899年创刊以来，《麻省理工科技评论》一直都是科技创新的倡导者和见证者，致力于关注技术突破与创新，每年评选的35岁以下创新科技青年，就是旨在提醒我们—— 在所有的创新背后，是一群有理想、有忧虑、有野心的年轻人。 该榜单曾经的获奖人包括： 谷歌创始人Larry Page和Sergey Brin、Facebook创始人Mark Zuckerberg、苹果首席设计官Jonathan Ive、基因编辑技术CRISPR主要贡献者张锋、百度前首席科学家吴恩达、Paypal及Slide创始人Max Levchin等。 随着中国已成为世界科技创新的强劲参与者、竞争者，其中崭露头角的中国年轻人也逐渐增多。 图丨首届 中国区“35岁以下科技创新35人”获奖人合影 青年是人生开启时最重要的一个阶段，一个人在35岁之前的所作所为，很有可能会奠定其人生发展的基础。 作为一个前瞻性的评选，并不会以青年人过去的成就论资排辈，也不局限于时下最火热的技术，而是旨在遴选不仅可创新，还可良好地转化研究成果、有能力引爆未来的科技创新青年，并将他们团聚在一起，形成一个创新者社群。 一如2017年的中国区榜单评委中，多位重量级评委，比如鲍哲南教授 (斯坦福大学)、Ben Y. Zhao教授 (芝加哥大学)，James Collins 教授 (麻省理工学院)、卢冠达教授 (麻省理工学院)、杨培东教授（加州伯克利大学）以及周昆教授 (浙江大学)，也都曾是该榜单获奖者。 图丨首届 中国区“35岁以下科技创新35人”评委名单 （排名不分先后） Ian的研究兴趣涵盖大多数深度学习领域，尤其是生成模型和机器学习安全和隐私。他发明了生成对抗网络，是最早研究对抗样本的有影响力的学者之一。他同时还是麻省理工学院出版社《深度学习》一书的第一作者。 2016 年，他在 OpenAI 组织了 “ 自组织机器学习会议 ” （ Self-Organizing Conference on Machine Learning ）。 Ian曾在 2017 年被《麻省理工科技评论》评选为 35 岁以下科技创新青年。 Eric Horvitz 对机器学习、自然语言理解、决策、人机合作等多个领域均有涉及，研究成果落地到健康管理、交通、电商、操作系统、空间科学等不同方面。 Eric Horvitz 因其对人工智能领域的杰出贡献，曾获 Feigenbaum Prize 奖和 Allen Newell Prize 奖。并获选美国国家工程院院士、美国文理科学院院士、人工智能协会主席。 联发科技是全球前五大无晶圆半导体 IC 设计公司，产品着重在无线通讯及智能终端机领域。各式晶片支持世界各地的行业标准，广泛地运用在手机、电视、网络与各种智能设备中。 2012 年、 2014 年及 2016 年，蔡先生获哈佛商业评论 “ 全球百大 CEO” 殊荣。 2015 年，蔡先生荣膺全球半导体联盟（ GSA ）颁发 “ 张忠谋博士模范领袖奖 ” 。 王坚博士于 2008 年 9 月加入阿里巴巴集团担任首席架构师一职，负责集团技术架构以及基础技术平台建设。作为阿里云和 YunOS 操作系统的创始人，王坚于 2009 年 9 月至 2013 年 9 月担任阿里云首任总裁。 2012 年 9 月，王坚被任命为阿里巴巴集团首席技术官，自 2015 年 5 月起担任阿里巴巴集团技术委员会主席。加入阿里巴巴集团前，王坚曾任微软亚洲研究院常务副院长。 杨教授的研究方向包括人工光合作用、纳米线电池、纳米线光子学，以及低维纳米结构在光电等能源领域中的应用等。其研究小组在纳米导线上制造出了世界上最小的激光器 —— 纳米激光器。 2015 年美国麦克阿瑟 “ 天才奖 ” 获得者。杨教授曾在 2003 年被《麻省理工科技评论》评选为 35 岁以下科技创新青年。 周志华主要从事人工智能、机器学习、数据挖掘等领域的研究工作。主持多项科研课题，出版《机器学习》 (2016) 与《 Ensemble Methods: Foundations and Algorithms 》 (2012) ，经常担任 NIPS 、 ICML 、 AAAI 、 IJCAI 、 KDD 等重要国际学术会议的领域主席。担任 中国计算机学会 常务理事、 人工智能专业委员会 主任， 中国人工智能学会 常务理事， 江苏省计算机学会 副理事长，江苏省人工智能学会理事长， IEEE 南京分部副主席。 Anima 的研究专注于大规模机器学习领域，尤其是高维统计及张量算法的发展和分析，开创了在非凸优化问题上寻找最优解决方案的研究。她为亚马逊旗下最赚钱的云服务部门  AWS  展开前瞻研究，数学、张量、算法是核心，云服务、机器学习都是手段，只为达到她 “ 解放人工智能 ” 的最终目标。 高通工程研发领导者，同时也是高通布局机器人市场的重要推手。数年前， Charles Bergan 就已经开始了在机器学习、神经网络领域的探索，协助高通发展可运行人工智能的手机软硬件。高通著名的 “ 神经形态芯片 ” 就是由 Charles 全权负责设计开发的，他的目标是将深度学习变成智能手机的基本配备。 鲍哲南教授一直致力于化学、材料科学、能源、纳米电子学和分子电子学等领域的研究。她开拓了高电荷迁移性质的聚合物半导体和空气中稳定的有机半导体材料的分子设计原理；她采用新的印刷技术制造了第一例高性能单晶有机半导体场效应晶体管；她还创造了世界上第一例用有机晶体管驱动的全新结构的电子纸。被评为《自然》杂志 2015 年度十大科技创新人物之一。鲍 教授曾在 2003 年被《麻省理工科技评论》评选为 35 岁以下科技创新青年。 陈刚教授是国际热传递、纳米技术和能源领域的权威人物。美国国家工程院认为，陈刚教授因其首次打破被公认为物体间热力传导基本法则的 “ 黑体辐射定律 ” 公式，证实物体极度近距时的热力传导，可以高到定律所预测的千倍，而被授予美国国家工程院院士称号。 Daniel E. Hastings博士曾担任美国空军首席科学家。现任麻省理工学院航空航天学教授、系统工程部主任、麻省理工学院-新加坡联盟首席执行官。Hastings博士同时也是空军科学顾问委员会主席，也是Charles Stark Draper实验室主任及公司董事会成员。 国际著名的营销学专家，曾经在沃顿商学院任教多年，任沃顿商学院出版社主编委员会主席，硅谷开源软件公司 Cignex 董事。在加入麻省理工斯隆管理学院之前， Schmittlein 曾任多家国际企业商业咨询顾问，如  AT&T ， American Express ， Boston Scientific, Ford Motor Company 等。 胡玲文博士在核反应堆设计、安全分析和应用方面有超过 20 年的经验。她提出了研制 “ 次临界设施 ” 的计划，计划打造小型、安全且造价低廉的核反应堆，而核反应堆的原型堆将会是在 1974 年就建成的麻省理工学院反应堆上进行升级。采用新方法后费用将会得到大幅缩减，连建造时间也可以被压缩一半。 Michael Hurlston 曾先后在 Oren 半导体， Avasem  集成电路公司， Micro Power 系统公司， Exar  和  IC Works 等公司工作。后于 2001 年加入博通，担任多个销售，市场和其他管理职位，后升任博通公司移动连接产品 / 无线通信和连接业务总经理。于 2018 年 1 月被任命为  Finisar CEO 和董事会成员。 季维智是云南省灵长类生物医学动物重点实验室理事长，生物医学动物模型国家地方联合工程研究中心主任。 “ 世界经济论坛全球未来理事会 ” 理事（ 2016-2018 ）， “ 国家干细胞研究指导协调委员会 ” 专家， “ 国家重大科学研究计划生殖与发育专家组 ” 成员 (2006-2014) ， “ 国家实验动物研究委员会 ” 专家组成员和 973 项目首席科学家。 Dim-Lee Kwong 教授是新加坡科学技术研究局（ A*STAR ）资讯通信研究所（ I2R ）的执行董事，新加坡国立大学电气与计算机工程教授。他领导的跨学科团队由超过 400 位研究人员（ 250 名以上的博士）组成，致力于与一些战略性产业、医疗机构和政府机构一起解决未来制造、医疗、金融服务和数字化的需求中的问题。 现任国家应对气候变化战略研究和国际合作中心中心研究员，并担任国家能源咨询委员、国家高技术专家委员会委员、国家环保部科技委员会委员、国家能源局能源互联网专家委员会委员。此前，李俊峰先生在国家发展改革委能源研究所先后担任副所长和学术委员会主任等职。 刘炯朗，前台湾清华大学校长。国际知名学者，在即时系统、电脑辅助设计、VLSI布局、组合最佳化、离散数学等领域均有杰出贡献。曾当选 IEEE Fellow、ACM杰出会员。2011年荣获“电子设计自动化界诺贝尔奖”之称的卡夫曼奖；2014年获IEEE基尔霍夫奖；2015年获中国计算机科学协会海外杰出贡献奖。2016年获ACM/SIGDA先驱。 中国科学院特聘研究员，博士生导师， IEEE Fellow 、国家杰出青年科学基金获得者、国家自然科学基金创新研究群体学术带头人、国家重点研发计划首席科学家、国家万人计划领军人才、国家百千万人才工程入选者、国家 “ 有突出贡献中青年专家 ” 、中国科学院 “ 百人计划 ” 入选者、科技部中青年科技创新领军人才、享受国务院特殊津贴专家。 卢冠达教授是 MIT 合成生物学中心的核心人物。共同创办了多家针对人类健康研发创新诊断及治疗技术的生物科技公司。包括  Sample6 、 Senti Biosciences 、 Synlogic 、 Eligo Biosciences 、 MBCure 及 Engine Biosciences 。曾荣获 ACS 合成生物学青年研究员奖、生物医学工程期刊青年研究员奖、美国国立卫生研究院（ NIH ）新创新者奖、美国青年科学家与工程师总统奖、埃里森医学基金会新学者奖等。 他被誉为 “ 可穿戴之父 ” ，研发出了世界第一款通用可穿戴计算机，此后，他相继发明了包括智能手表可视电话、高动态范围成像技术、 EyeTap  数字眼镜等一系列广为人知的创造性技术与设备。 2013 年， Steve Mann 教授召集了全球在义体人类伦理道德、监控和逆向监控、人文智能等领域的顶尖思想家，形成了世界上首套超人工智能和多感觉增强的道德体系。 360 集团创始人兼 CEO ，知名创业导师，免费安全之父。 2006 年，周鸿祎创立 360 ，创新性地推出 “ 免费安全 ” 战略，颠覆了传统互联网安全行业，开创了中国互联网的新格局。 2011 年 3 月，周鸿祎率领 360 集团在美国纽交所成功上市，将之发展成为全球领先的互联网安全企业。 中科院西安光机所光学博士，中科创星创始合伙人。米磊博士是中国 “ 硬科技 ” 理念提出者，硬科技创新联盟发起人，致力于硬科技创业理论的研究和实践，提出科技创业是中国未来三十年发展主旋律的观点。致力于打造硬科技创业雨林生态，目前已成功孵化 140 余家硬科技企业。 美国卡内基梅隆大学计算机科学学院机器学习系主任、教授，美国工程院院士，美国科学促进会（ AAAS ）会士，国际人工智能协会（ AAAI ）会士， Tom Mitchell 在机器学习、人工智能、认知神经科学等领域卓有建树，撰写了机器学习方面最早的教科书之一《机器学习》，是机器学习领域的著名学者。 Dan Roth 的研究是通过机器学习和推理的方法帮助机器理解自然语言。他是 AAAS 、 ACL 、 AAAI 和 ACM 会士，曾担任《人工智能研究》（ Journal of Artificial Intelligence Research ）的主编。 2017 年，他因 “ 在自然语言理解、机器学习和推理领域中做出重大的概念和理论创新 ” 而获得国际人工智能联合会议（ IJCAI ）颁发的约翰 · 麦卡锡奖。 Donald Sadoway是世界顶级材料化学家，他曾发明一种全新的电极，将锂电池的能量密度提高两倍以上，更发明了 “ 液态金属电池 ” ，让大规模电网级别储能成为了可能。他还很擅于挖掘学生的潜能，开设了全 MIT 最受欢迎的课程，直接导致了著名的 “ 麻省理工学院开放课程 ” 的诞生。 史元春现为清华大学计算机系教授，人机交互与媒体集成研究所所长，清华信息科学与技术国家实验室普适计算研究部主任，教育部 “ 长江学者 ” 特聘教授，兼任青海大学计算机系系主任。研究方向主要集中在人机交互、普适计算、多媒体。 曾任 Lyric Semiconductor 公司的联合创始人、首席执行官，该公司基于  Vigoda  博士在麻省理工学院期间的博士研究成果，开发出了用于数据机器学习的首个微处理器架构。后被 Analog Devices 收购，并将 Lyric 公司的技术应用于时下的智能手机、电子产品、医疗设备、无线基站及汽车制造中。 Vigoda 博士曾同时在麻省理工学院、三菱、惠普、圣菲研究所主持并参与科研。 Oriol 是 Google DeepMind 的深度学习及应用开发研究员，此前在  Google Brain 工作。他专注于在机器学习、神经网络、强化学习领域提出新的研究方法。目前， Oriol 正在负责领导 DeepMind 的人工智能团队在美国著名游戏公司暴雪（ Blizzard ）开发的游戏星际争霸 2 中对战人类。 张峥现任上海纽约大学计算机科学教授，兼任纽约大学纽约分校库朗数学研究所计算机科学系教授、以及数据科学中心教授。在加入上海纽约大学前，陈教授曾在微软亚洲研究院创建了系统研究组，并担任首席研究员及区域经理。在迁至北京工作前，张教授还是惠普实验室的项目总监及技术骨干。 周昆教授为教育部长江学者特聘教授，国家杰出青年科学基金获得者，国际电气电子工程师协会会士（ IEEE Fellow ）。周昆教授研究领域为计算机图形学、人机交互、虚拟现实和并行计算。在图形学基础算法、 GPU 并行计算、虚拟化身、可计算制造等方向取得多项成果。曾在 2011 年被《麻省理工科技评论》评选为 35 岁以下科技创新青年。 赵瑞林，现在是Illumina大中华区的总经理。加入Illumina之前，他负责Thermo Fisher中国区的市场部和商业运作部门。他还曾经在Orbusneich担任过财务副总裁，以及在微创医疗担任商务发展副总裁和大血管事业部的总经理。他还曾经是强生公司负责产品设计的工程师。他在美国的哈佛大学----麻省理工学院的健康科学与技术系获得医学工程学和医学物理的博士学位，以及在宾夕法尼亚大学的沃顿商学院获得工商管理硕士学位。 参选者年龄须在2018年10月1日时不满35岁（即出生日期不早于1983年10月1日）。以身份证或护照文件上的年龄为准。   参选者必须为中国籍（含港澳台，所在地无限制） 本评选对学历没有特别要求 包括但不限于电子计算机与硬件、互联网与电子通信技术、软件技术、纳米技术和先进材料、生物医药、航空航天、能源、交通等。 评审机制： 《麻省理工科技评论》的目标就是发现真正的创新——不论是新技术的发明，还是现存技术的创新应用亦或是价值革新。不论是发明了一种新的实用技术，还是通过将现有的技术应用到不同寻常的场景中，从而产生了新的领域、服务，或是解决了重大的现实问题的人，都可能是我们所寻找的创新者。 在评审参选人的时候，会考虑7个因素： 理想的获奖人需要在这些方面体现出竞争性。但是这些因素之间没有 一个绝对的权重标准，候选人亦无必要在所有方面都表现出色。 时间安排： 评选材料： 个人陈述应当以第一人称尽量精简地描述参选者的创新工作,尤其是关于技术创新及其影响。可以提供相关的媒体文章、同行评估的论文或公司网址等信息供评审委员会参考。 推荐信应阐释推荐人和参选者之间的关系,以及为什么认为参选者所做的工作很杰出。避免过于泛泛的描述。推荐信须有推荐人签名，并附所在机构的信纸抬头，可为扫描件或电子版。   请点击 提交申请材料，或将申请材料发送至 邮箱 ： tr35@mittrchina.com，邮件主题为： ， 1. 简历  2. 个人陈述  3.1 推荐信＋推荐人1姓名 3.2 推荐信＋推荐人2姓名 3.3 推荐信＋推荐人3姓名 4. CV/Resume 5. Personal Statement 6.1  Recommendation Letter+ Referee 1 6.2  Recommendation Letter+ Referee 2 6.3  Recommendation Letter+ Referee 3 【今日机器学习概念】 Have a Great Definition "
82,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658123&idx=1&sn=5f0c4bdfcb11e623e93874387f5e6d19&chksm=bd4c30188a3bb90e536612140d0ccf52e511aaaee148b0e7e7ce351c198938d5ff6b855d613c&scene=27,机器学习是如何借鉴物理学思想的？从伊辛模型谈起（万字长文）,"大数据文摘作品 翻译：大力、白丁、阮雪妮、Lisa、彭湘伟、Shan LIU、钱天培 物理和机器学习，这两个听起来不相关的领域，居然有着千丝万缕的联系！ 文摘菌第一次听说时也吓了一跳。 而就真有这样一个神奇的模型，将物理和机器学习紧密联系到了一起——它就是伊辛模型。 伊辛模型 ——一个描述物质磁性的简单模型——会帮助阐释两个领域之间的广泛联系。 今天，文摘菌会先从简单物理直觉谈谈这个模型，然后导出物理学中著名的变分原理，从而严格推出这个模型。 然后我们就会发现，正是这个变分原理打开了机器学习的窗口。我们将玻尔兹曼分布归为指数组，使一一对应透明化，并且通过变分原理来证明近似后验推断与大量的数据之间的关系。 如果你有物理学基础的话，我希望看了这篇文章后会对机器学习有更好的认知，并且可以读懂相关领域的论文。如果你专攻机器学习，我希望你看了这篇文章之后可以看得懂统计物理学中平均场论和 伊辛模型 的论文。 物理学中的伊辛模型 现在我们来思考一个自旋向上或者向下的晶格： 什么样的特性会促使这个系统变成一个可靠的磁性模型呢？ 想想你玩磁铁的情景——如果你把两块磁铁放的很近，它们会彼此拉的更近。如果它们是同性的磁极则会相斥。如果它们离的很远，则完全不会发生这种吸引的情况。 这意味着在我们的模型里，邻近的自旋会互相影响：如果围绕s_i 点的自旋都是向上的，那它也会是向上的。 我们参照位置i处的自旋为s_i。自旋只能处于两种状态中的一种：向上（s_i=+1）或向下（s_i=-1）。 我们引入交互作用参数J，用物理学的直觉来推论出自旋会相互吸引（它们想指向相同的方向）或相互排斥（它们要指向相反的方向）。 这个参数描述了自旋i和自旋j之间的交互强度。 如果两个相邻自旋指向相同的方向，我们用J来表示它们交互的总能量；如果指向相反的方向，则用J来表示。 然后我们就可以得到系统的能量方程，或者叫哈密顿量： 如果自旋i和自旋j相邻，J_ij=J；反之J_ij=0。因子1/2是考虑到i和j求和时候的重复计算。注意系统的自旋是有限多的（N个自旋）。 自旋组态或者系统的状态是所有自旋的特定值的组合。集合{s_1=+1，s_2=+1，s_3=−1，...，s_N=+1}是组态的一个例子。 热力学第二定律告诉我们在固定温度和熵的情况下，系统会寻求最小化其能量的组态方法。这让我们可以推理出交互作用的情况。 如果交互作用强度J为零，自旋之间没有交互联系，所有组态的系统能量也为零（能量小到可以忽略不计）。但如果强度J为正，自旋会按照某种规则排列起来使系统的能量E(s_1，s_2，...，s_N)最小。由于能量方程中求和前面的负号，这便与最小化一致。 然后引入磁场H。 假定自旋的晶格在磁场中，比如地壳周围的磁场。磁场对每个自旋单独作用，每个自旋都会试图与磁场方向保持一致。我们可以加入每个自旋的作用的求和项来表示系统在磁场中的能量方程： 我们可以通过观察磁场强度H变大或变小（增强或减弱）会发生什么来推导出H的大小。如果H变大，自旋之间的交互作用减弱，磁场项会起主导作用，自旋就会按照磁场分布排列以使系统能量最小。但是如果磁场很小就很难推导出来了。 现在我们明确了伊辛模型的定义和它的性质，我们来思考一下我们的目标。关于伊辛模型我们可以解决什么问题？例如，如果我们观察系统，它会处于什么状态？最可能的自旋组态是怎么样的？平均磁化强度是怎么样的？ 玻尔兹曼分布 我们可以把目标设定的更清晰一些数学更简明一些吗？那么我们需要定义一个自旋组态的分布。很显然的我们可以得出系统处于平衡态的概率。 这便是 。对于一个特定的组态，分子叫做玻尔兹曼因子。这个因子给一个特定的系统和其能量状态提供了可高可低的权重。 我们想要知道，给定一个特定的自旋组态，系统处于这个状态的概率的玻尔兹曼分布。 譬如，我们的组态的第一批自旋是向上、向上、向下，等等。我们将这个情况代入到公式里面得到P(s_1=+1，s_2=+1，s_3=−1，...，s_N=+1)=0.7321这意味着这种状态发生的可能性很大。 这个分布与直觉相符：低能量的比高能量的状态更可能出现。例如，在J=+1的情况下，自旋会开始排列，其中最可能出现的排列状态是所有的自旋指向相同的方向。为什么呢？因为这符合最小化能量的方程，其中的玻尔兹曼因子有最大的权重。 参数β与温度的倒数成正比，β=1/T*k_B并且用来方便的标记。（准确的说，这包括了使概率密度无量纲化的常数k_B）温度控制着粒子间的交互作用的强度进而影响整个模型。如果T→∞，温度很高，温度的倒数就很低，β≪1，所以交互强度J就不重要。但是在低温状态下，J除以一个较小的数就很大，因此交互强度够大会显著影响系统状态。 配分函数 分母Z是最重要的。它确保了分布的积分为1，由此这是一个合理的概率分布。我们需要这个正则化来计算系统的性质。计算平均值和其他值只能借助一个概率质量函数。Z被称为“配分函数”或者“正则常数”，它是每个状态下玻尔兹曼因子的和。 为了阐述为什么我们不能求出分布的精确解，我将这个和明确地写出来：我们需要将所有可能的组态求和。每个自旋都有两种状态，又有N个自旋。这意味着求和的阶数会有2^N。即使对一个只有一百个自旋的微小系统来说，这个计算量已经比整个宇宙的原子数量还要多了，我们没有可能算得出来。 利用玻尔兹曼分布来计算系统特性 我们得到的概率分布反映了系统可能处于的状态，但是被卡在了配分函数这个磨人的小妖精上。暂时假定我们能够通过无穷运算得出玻尔兹曼分布的配分函数，那么从系统的波尔茨曼分布中我们能了解到哪些有趣的情况呢？ 该分布使我们能够把系统作为一个整体，利用期望值（例如计算可观测量）来计算其特性。举个例子，磁化强度m是所有自旋粒子的磁化强度均值。 我们为什么要关注这个磁化强度呢？因为它能够反应系统的宏观状态，而非某个特定的微观状态。我们丢失了特异性，因为我们对第一个自旋粒子s_1一无所知，但是透过所有其余自旋粒子可能出现的状态，我们掌握了其运动状态。 相同的自旋方向意味着系统处于有序状态，磁性为阴极或阳极；而相反的自旋方向则说明系统处于无序状态，平均磁化强度为零。 以上都是系统在全球范围内不同的相位，与温度息息相关。如果温度T无限升高，其倒数β则趋近于零度，系统的所有状态就会像波尔茨曼分布描述的那样处于等可能状态，此时系统可以在有序相和无序相间来回切换。 这种相变以及温度对其的影响方式在衡量伊辛模型与真实世界物质匹配程度高低中发挥着重要作用。 别忘了我们求不出配分函数Z的值。想要回答磁化强度值等此类有趣的问题，我们似乎陷入了一个无解的境地。然而谢天谢地，通过独立分析每个自旋粒子并估出近似值，这个问题就被进一步简化了。 物理学中的平均场理论 鉴于我们无法通过计算得出配分函数计算所需的总值，我们就改换山头转向平均场理论吧。 这个“约莫”的技巧使我们依然有能力回答平均磁化强度等关于系统的一系列问题。我们将继续研究磁化强度m与温度的依赖性。 从单个自旋粒子入手更容易把这个技巧说明白： 伊辛模型在H磁场中的第一个自旋粒子。磁场用虚线表示。其附近的粒子通过互动形成了有效磁场，表示为连接粒子的线。 这个单一粒子对系统全部能量的贡献一言以蔽之，就是能量中的对应项。 总值大于z距离最近的粒子。在我们正在探讨的二维点阵中，z=4。根据单一粒子围绕平均值上下波动，我们能够为这个自旋粒子重写能量函数如下： 接下来的这一步至关重要：我们将忽略相邻自旋粒子均值附近的波动。换句话说，我们假设项(s_j−m)→0，这样一来s_0的所有邻居都等于其平均值，s_j=m 这在什么时候会成立呢？ 当均值附近波动很小时，比如低温“有序”相。该假设大大简化了该自旋粒子的哈密尔顿量。 这是单一自旋粒子的平均场能量函数，相当于一个处于有效磁场中的非相互作用自旋粒子H^{eff}=zJm+H。 我们为什么说这个自旋粒子是非相互作用的呢？该自旋粒子的能量方程仅依赖于其状态，s_1，与任何其他自旋粒子的状态无关。通过引入相邻自旋粒子我们得到了平均磁场强度，进而估算出了交互效果，也就是平均场。 在这个平均场大的模型中，每个自旋粒子都受到整个系统所在的磁场H的影响，以及其相邻自旋粒子zJm的“有效”平均磁场的影响。 我们用下面的公式来进行说明 公式中ΔH=zJm是每个自旋粒子相邻粒子的平均磁场（平均场）。 忽略了每个自旋粒子的波动之后，问题被进一步简化。现在位于均匀磁场H中的是N独立自旋粒子，而非N相互作用自旋粒子；并通过ΔH这个小小的矫正值来体现相互作用的影响。 我们将平均场模型的能量函数写作： 可见函数中不再出现相互作用项了（s_is_j这一项未出现在能量函数中） 换句话说，我们既可以单独观察每个自旋粒子，也能够将所有结果合理汇总，得到整个系统的模型。 我们从根本上改变了问题的本质。 我们现在要做的就只是计算单一自旋粒子的配分函数，而非整个系统的配分函数Z了。 我们能够用解析解4直接作出回答： 那么由N自旋粒子推导出的整个平均场模型的配分函数就是 配分函数在手，波尔茨曼分布我有；回答诸如磁化强度等与系统有关的问题也不在话下。 我们利用自旋粒子分布的期望值推导除了磁化强度。最后一步需要该值来计算任意自旋粒子i的情况，其平均磁化强度应等于系统整体的平均磁化强度： 由此我们得到了一个简明易懂的磁化强度等式 这里我们用到的平均场参数为ΔH=zJm。 这个针对磁化强度m的公式是一个温度函数。虽然它并没有封闭解，但是我们能够调整等式两端，查找交集部分来得到隐含解（拖动滑块来设定新温度）： 首先，我们来考虑一下没有外磁场的情况，即H=0。 高温条件下等式只有唯一解：m=0。这与我们的直觉是一致的-如果考虑整个系统的能量情况，温度倒数β趋近于零，所有自旋粒子的所有状态都处于等可能水平，其平均值为零。 低温条件下有3个解：m=0和m=±∣m∣。增加的±解的出现条件是tanh函数在原点的坡度大于以下： 相变“临界温度”的出现条件是βzJ=（1/T*k_B）*（zJ）=1，或（k_B）*（T_c ）= zJ。 由此我们得到了一个可检验的预测：我们能够取一个磁性物体，然后测量其相变温度。 我们的目标达成了吗？ 我们最初的目标是从磁化强度等全球特质的角度，掌握该模型在不同温度下的表现。 通过研究单一自旋粒子和估算其他自旋粒子作为有效磁场的影响，我们显著降低了问题的复杂程度。以此为基础，我们能够进一步研究相变。然而，我们的论证总感觉有些底气不足，所以接下来我们继续深入研究，打牢地基，证明我们的直觉。 推导变分自由能原理：Gibbs-Bogoliubov-Feynman不等式 我们是否能知道，当我们做出“忽略自旋粒子在其均值附近的波动”的假设时，我们做出了什么样的权衡取舍呢？更具体地说，我们应该如何评价我们从平均场理论中所得到的结论呢？ 我们可以通过直接研究这个棘手的配分函数来重新得到在之前部分中出现的平均场的结果。我们可以试着用一个简单一点的函数来估计这个配分函数。 让我们一起回顾一下，这个系统的配分函数Z是 和之前一样，系统的能量是 计算这个配分函数的难度来源于带有s_is_j的交叉项。我们发现如果没有这一项的话，我们就能把问题简化为处理一个由独立的自旋粒子组成的系统了。 为了导出变分原理，我们假设一个有如下形式的能量函数 在之前的推导中我们已经通过我们的物理直觉得到了平均场参数为ΔH=zJm。 现在就有一个问题：这是最优的有效磁场吗？我们可以认为ΔH是通过调整能得到原始系统最优解的平均场模型的参数。 这被称为“微扰法”：我们对系统的磁场进行微扰，并试着寻找能够得到原始系统一个好的近似的最优扰动。 一个好的近似需要什么？我们的困难在于计算配分函数。因此我们想要用我们的平均场系统的变分函数Z_{MF}来近似估计原始系统的配分函数。但愿Z_{MF}是容易计算的，不需要进行和宇宙中原子个数相同量级的求和运算。 首先让我们看看能否用我们的近似来表达原始系统Z的配分函数。通过计算能量的波动，我们可以计算平均场系统的能量偏离参考系的程度。 让我们把原来的配分函数重新表达为： 在下一步中，我们需要定义函数A关于平均场波兹曼分布的期望。 这就意味着我们可以把原系统的配分函数表达为平均场配分函数的函数。 这就是原始系统的配分函数的一个因式分解。这是以偏离参考系的能量波动的期望波兹曼因子为权重的平均场配分函数。 然而，对这个复杂的指数函数积分是很困难的，即使是对平均场系统来说也不容易。我们将利用一个经典的物理技巧来简化这一过程——将它泰勒展开。 假定能量波动很小；ΔE≪1。于是我们便可以对这个指数进行泰勒展开： 在上式中我们省略了波动ΔE的二次项。于是我们得到了对原始系统配分函数使用一阶微扰法的结果： 这个估计有多好呢？让我们引入一个简单的恒不等式：e^x≥（x+1）。 把这个式子用到配分函数的准确因式分解的期望中，取f=−β*ΔE: 现在我们得到了配分函数的一个下界： 这个不等式就是Gibbs-Bogoliubov-Feynman 不等式。这个式子告诉我们，通过平均场近似，我们可以得到原配分函数的一个下界。 利用Gibbs-Bogoliubov-Feynman不等式对伊辛模型进行变分处理 让我们来应用这一理论：在伊辛模型中我们是否能得到同样的磁化强度呢？ 在平均场伊辛模型中，我们独立地处理每个自旋粒子，因此系统的能量函数就分解为独立的部分： 这里ΔH是有效磁场强度。这是配分函数下界取最大值时的参数。 把它代入从Gibbs-Bogoliubov-Feynman不等式中得到的配分函数的下界中，并求导来使下界取到极大值： 首先我们得求出期望： 在这里我们用到了平均场的假设：自旋粒子是各自独立的。因而有： 我们还假定，对于一个足够大的系统，模型边缘上的自旋粒子（边界条件）可以被忽略。因此所有的自旋粒子都有相同的平均磁化强度:   把它代入配分函数的下界并求导，有 这里用到了之前的结论： 这证实了我们之前的推理：最优的平均场参数是ΔH=Jzm。在这一过程中共有三个步骤。我们首先定义了我们关心的模型，然后写下了它的平均场近似，最后我们对配分函数的下界求极大值。 以机器学习视角对Ising模型的展望 现在，让我们以机器学习的语言来构建我们刚刚的思考过程。更具体的说，让我们以随机建模的思路来思考这个问题。 在机器学习中，我们需要一些定义来展现变分原理与变分推断之间的等价关系。 Ising模型是一种无向图模型，或者说马尔科夫随机场。我们可以用图表来表示模型里的条件依赖关系；图中的节点为随机变量。这些随机变量是伊辛模型的自旋，如果两个节点会相互影响，就用一条边链接他们。由此我们可以对下图中随机变量的联合分布进行编码: Ising模型的无向图模型表达。节点为随机变量，边表示他们分布的条件依赖关系。   将该图像模型联合分布参数化，就得到波尔兹曼分布。该图与物理自旋表现非常相似，再次强调，自旋代表随机变量。 我们同样可以将节点分布写成指数形式。指数族分布可以使我们推导出一个广泛类的数个模型。 指数族 指数族是一种将类似Ising模型的概率分布数据化的方式。这些分布族支持可以写成如下具体简单的数学公式 这里η是自然参数，h(x)是基础度量值，t(x)是充分统计量  a(η)是对数配分函数, 也叫对数正规化子。有很长一段时间内我对于指数族倍感困惑，最后是具体是具体的推导过程帮助了我理解。   例如，我们看到过伯努里分布的以下表达： 我们可以把他写成指数族的形式 与以上公司相比，指数族展示了伯努利的自然参数，基础度量值，充分统计量，分别为η=log(π\1−π)，t(x)=x，a(η)=−log(1−π)=log(1+e^η)和h(x)=1。 和物理学更多的联系：对数正规化子是配分函数的对数。这一点在伯努利的指数族中尤为明显： 现在我们可以确定η类似于温度，拥有自旋x。我没找到了Ising模型的指数族形式！ Ising模型的指数族形式 让我们通过伯努利分布的指数族公式把Ising模型的能量公式与指数族形式联系起来 我们引入了一些新的注释到图像模型中：我们把一个节点分布除以一个图中在顶点V上的自然变量的集合，并与E中的边联合。 这就是Ising模型的指数族形式，一个关于θ的概率模型。为了使它和我们之前得到的形式一样。如果i和j共享一条边（比如他们相邻）设θ_ij=(1/2)*βJ，并设θ_i = H。 我们可以看到，Ising模型有两组模型参数。自旋与自旋的相互作用参数乘以温度 βJ的倒数，控制着图中每条边的影响。温度倒数乘以磁场影响着每个自旋。我们也可以得出结论：温度倒数是一个全局模型参数。对一个已定的互动场或磁场，我们可以通过改变温度来索引一个具体的模型。 这点既很微妙有很重要。我们的在随机变量（N自旋）上的联合分布由模型参数索引。通过改变倒温度参数β，我们可以选择一个具体的模型（在对应温度下的伊辛模型）。对于一个特定的自旋与自旋相互作用参数j也是亦然。 关于模型我们能问什么问题？ 计算磁化强度m=(1/N)*⟨s_1+...+s_N⟩=⟨s_i⟩意味着计算E_p(si)的期望。从概率的角度来说，这意味着计算node i的边际期望。 但计算边际分布是很棘手的，基于我们之前讨论过的原因：它需要边际化所有 j≠i的点 这种情况是不可行的：我们不仅需要为N点的联合分布计算标准化的定值，这需要2^N个项，而且我们需要边际化N−1个变量(另外的2^(N-1)个项) 当从物理角度考虑这个模型时，这等同于我们在配分函数里面看到的那样。 我们还可以继续依靠变分原理来回答有关边际分布的问题吗？ 机器学习中的变分推论 如果我们可以计算所有随机变量的配置总和，我们就可以计算这个配分函数。但我们不能，因为这个总和以2^N级增长。 以物理学家的身份，我们的策略是估算配分函数。 从机器学习的角度，这个技术叫做变分推论。我们改变一些简单的东西来推论复杂的东西。 让我们来看看机器学习是怎样推导变分自由能，并且应用在估测配分函数上的。 我们有一个随机变量的概率模型pθ(s_1，...，s_N)，然后我们想要寻找计算它的标准化常量或者配分函数。 让我们构建一个更简单的概率分布qλ(s_1，...，s_N), 以λ为参数，并且用它来估测我们的模型。 我们的估测怎么样呢？一个测量方法是看我们的估测和目标分布之间的Kullback-Leibler差异有多大。 这个qqq和ppp之间的差异，或者相对熵，计算了当使用q来估计p时的信息损失总量(以bits或者nats为单位) 这给了一个调整我们估测的标准。我们调整λ参数直到最小化估测的Kullback-Leibler误差。 KL差异是由以下双竖线组成的 让我们假定我们正在处理一个指数家族的分布例如Ising模型。已知能量方程E(s_1, ..., s_N)，我们让p在模型中呈Boltzmann分布 假设qqq的分布的能量方程是有λ参数的： 为了测量我们使用qqq代替ppp来估测所损失的信息，我们把他们代入Kullback-Leibler差异中： 我们定义变量下限L(λ) 如下： 我们可以把变量下限移到方程的另一边来得到以下的等式： 根据Jensen’s不等式，易得KL差异总是大于等于零。这意味着如果我们将L(λ)变大，KL差异一定变小（同时，我们的估测必须改善）。因此我们可以降低偏分方程的边界： 这意味着我们可以调整我们估测中的参数λ来提高下限值，并且得到一个对变分方程更好的估测！ 注意到在变量下限的定义中，我们不用担心计算变分方程的费力的任务：它不需要取决于λ。 这是很棒的：我们已经构建了对于p概率模型中的q_λ的估测并且找到一个调整参数来让估测变得更好的方法。 有趣的部分是我们可以不用通过计算它棘手变分函数的方式来提高模型的估测。我们只需要估测它的能量方程E(s)，这是更容易去计算的。 这是不是厉害得难以置信？我们是不是忽视了什么？我们已经失去了用绝对项去测量这个估测好坏的能力，为了估测，我们仍然需要去计算变分方程来计算KL差异。我们确实知道只要我们改变λ来提高下限值L(λ)，我们的估测就越好，并且这对一系列问题的变形都足够了。 变分推断就是Gibbs-Bogoliubov-Feynman不等式 我们来看看变分推断是否和我们在物理中看到的Gibbs-Bogoliubov-Feynman不等式是一回事。该不等式如下： 取对数后： 我们已经确认了变分族服从Mean-field Boltzmann分布 λ表示我们用于最大化下边界的变分参数。 这就表明了，变分推断在机器学习中，最大化了变分函数的下边界。这其实就是Gibbs-Bogoliubov-Feynman不等式。 近似后验推断中的evidence lower bound 在机器学习中，我们在意数据中存在的模式。这便引出了潜在变量这一概念。潜在变量是指未被观察到的，但实际上可以发现观测数据中存在的模式的变量。 例如，在线性回归中，我们可能假定人们年龄和他们收入之间存在线性关系。回归系数变捕捉到了我们想从大量数据对（年龄、收入）中发现的潜在模式。 我们把一个概率模型看作是潜在变量z和数据x构成的模型。潜在变量的后验分布（对于观测数据的条件概率）可以被写成p(z∣x)。 什么是后验呢？在年龄和收入相关关系的回归分析例子中，我们想得到回归系数基于观测数据的后验分布。我们选择系数的先验分布本身就是建模的一部分。先验分布的选取反应了我们希望观测到的统计关系。 后验分布由贝叶斯定理可以得到： 分母代表的数据的边际分布就是证据，p(x)=∫p(x,z)dz。这是关于潜在变量，数据和变分函数的标准化联合分布。这个变分函数含有一个由随机变量加和构成的结构。它就像我们之前两次看到的一样复杂。 我们是否可以在做后验推断时摒弃复杂的变分函数呢？ 简化过程是类似的：虽然在变分函数中有一个复杂的加和，但是我们可以用之前开发的工具——变分推断，去近似它。 让我们写出变分函数中变分的下边界： 通过改变参数λ，我们可以得到一个近似的后验分布qλ(z)。它可以近似于我们想得到的，但又算不出来的后验分布，p(z∣x)。 如果我们用变分法去近似一个后验分布，我们的变分函数就是log{p(x)}。因此我们认为变分下界L(λ)就是Evidence Lower Bound or ELBO，并且可以通过最大化ELBO得到很好的近似后验分布。 过去20年中，这个技术被广泛应用于机器学习。它变得流行是因为复杂的变分函数在大型数据集中需要被分析。而变分的原理——最优化下边界，就是利用最优化的方法在大数据中计算贝叶斯推断。 这是一个令人兴奋的领域，因为随机优化的新技术可以让我们去探索物理和机器学习的新领域。 机器学习技术在物理中有用么？ 在机器学习领域，大量用于近似变分函数的技术都可以在物理中见到。 例如，black box variational inference 和 automatic differentiation variational inference都是物理中的通用方法。它们为构建代表性的近似分布和高效的优化技术搭建了框架。 这就像在问熟悉变分法的物理学家，随机优化用在变分法中了么？这样有效么？ 物理学中的工具对机器学习有用么？ 是的！Gibbs-Bogoliubov-Feynman最初就是发展于物理领域。90年代，Michael Jordan在MIT的小组发现将其应用于机器学习的方式。 似乎有不同的方式来构建灵活的分布族以近似计算分布。Replica Trick，Renormalization Group Theory等其他的理论才刚刚从统计物理学中引入到机器学习中。 另一个从物理中引入工具的例子是Operator Variational Inference。在这项工作中，我们开发了一种构建算子的架构。这种算子用于描绘近似的效果。这个架构使我们可以很好地平衡近似精度和计算量。Langevin-Stein算子和Hamiltonian算子是等价的，他们最初都呈现于物理领域的论文中。 一个有趣的问题值得考虑：为什么KL会发散？物理学的解释是明确的。它对应于变分函数的一阶泰勒展开，并且有非均衡扰动分布的假设。（难道）有二阶泰勒展开对应于另一种发散么，并且能得到更精确的结果？ 我最近学习了副本理论（Replica Theory）。Replica Trick是一种使用疯狂的公式，来精确计算系统中变分函数的技术。它引出一个问题：我们使用概率图模型时应该有什么假设？ 我非常乐忠于看到更多的物理学工具迁移到数据科学和机器学习中去。 我们怎样才能转换地更快呢？我们怎样才能更有效率地传送机器学习和物理之间的技术呢？代码实例会有帮助么？ 这篇博文的主旨在于以一个学科社区的语言（物理学）来匹配至另一个社区（机器学习）。同时这篇长综述通过举例，从机器学习的角度（黑盒变分推断，随机优化等）去思考统计物理的架构（with mean-field methods, replica theory, renormalization theory等）和当代变分推断，展现不同领域间是如何互补的。 术语解释 期望：角括弧⟨  ⋅  ⟩ 代表期望。在机器学习文献中，关于分布P的期望，被写作Ep[  ⋅  ]。例如⟨f(s)⟩表示旋转f(s)的函数的期望。这个期望是关于Bolrzman分布的： 物理学中的旋转，在统计和机器学习中成为随机变量 变分推断中的evidence lower bound是物理术语中的负自由能。 原文链接： https://jaan.io/how-does-physics-connect-machine-learning/ 【今日机器学习概念】 Have a Great Definition "
83,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658123&idx=2&sn=6553a0255f6637ec544aded2b493a6aa&chksm=bd4c30188a3bb90e010b5f5ef9e858e7bdd217801504b4c1ad4873f069b04317516de8a90d99&scene=27,Elon Musk现身SXSW，并与西部世界导演聊了一小时,Elon Musk昨晚给了SXSW 2018（西南偏南艺术节）的听众们带来了一个大惊喜：现身 在奥斯汀市的穆迪剧院，并与西部世界导演乔纳森·诺兰对聊了一小时。 从行程到整个谈话本身，Musk的一切安排都颇为随意。诺兰作为主持人，就征集好的观众问题向马斯克提问，从火星殖民、公司运营谈到了人工智能的未来。 这场对话持续了约一个小时。最后，马斯克的弟弟Kimbal Musk拿着吉他、头戴牛仔帽登台，诺兰和马斯克也都戴上了牛仔帽，三人开始合唱西部片《神勇三蛟龙》中的插曲My Little Buttercup，还号召全场观众一起来。 神勇三蛟龙（Three Amigos） 欣赏一下男神的歌声👇 马斯克发推：我们一定会唱得很糟糕👆 此前一天，马斯克在SXSW上做了个一分钟的演讲，还播放了一段由诺兰重新创作的、堪比科幻大片的SpaceX猎鹰重型火箭发射视频。在油管上获得了近200万的观看量。 感兴趣的读者可以点击观看56min视频完整版（英文），没有时间观看全部内容的读者，文摘菌也从中提炼了精华对话罗列如下。 关于太空事业，各位可以做的最重要的事情就是持续的鼓励。等未来真的有一天，人类可以乘坐太空非常往返火星、月球甚至银河系，那会是一个耗能极高的产业。并且，第一批太空公民将面临巨大危险。 我们需要在太空建设一系列基础设施，火星上应该会建非常酷的酒吧——火星酒吧（笑声）。 明年上半年我们会建成更短小的飞船，这种飞船最酷的地方是其能效会有巨大的降低。这种BFR飞船也会比猎鹰系列造价低很多，为之后建设月球或者火星城市的基础设施做准备。 我的大部分时间，大概80%、90%的时间花在工程和设计上，我们的首席运营官（COO）Gwynne Shotwell会更多负责商业运营。 我认为为了做出正确的决定，你需要了解一些细节层面的东西，否则你的决定就不一定是正确的。 Q: 在火箭行业你如何制定商业计划书（business plan）？因为会出现很多意料之外的发射失败。 A: 蛤？我根本没有商业计划书（笑声） Q: 如何评价／排序自己的三家公司? A: Tesla是我最大的事业，然后是spaceX，boring company本来是当一个玩笑成立的，因为这个名字听起来也像个笑话。 我认为到明年年底，自动驾驶将在所有类型的驾驶车辆中出现，并且比人类的驾驶安全100%-200%。明年年底，也就是说18个月之后。 我们要确保，这一超级智能与人类共生，这是人工智能面临的最大问题。我本身不是个对规则和条条框框很认可的人，但在AI的问题上，我们需要有一个原则来确保每个人对AI的研发是安全的。这非常非常重要，AI带来的威胁比核武器的威胁要大很多很多。 【今日机器学习概念】 Have a Great Definition 
84,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658072&idx=2&sn=3415cb56428dbab35cd2f59dcd25c468&chksm=bd4c30cb8a3bb9ddfb24530040f35e4662ad8e54bb66e425bcc4a7282b95f7435a75eb1f49a7&scene=27,案例 | lightgbm算法优化-不平衡二分类问题（附代码）,"大数据文摘投稿作品 投稿作者 ｜ 苏高生 本案例使用的数据为kaggle中“Santander Customer Satisfaction”比赛的数据。此案例为不平衡二分类问题，目标为最大化auc值（ROC曲线下方面积）。目前此比赛已经结束。 竞赛题目链接为： https://www.kaggle.com/c/santander-customer-satisfaction  2.建模思路 本文档采用微软开源的lightgbm算法进行分类，运行速度极快。具体步骤为: 读取数据； 并行运算：由于lightgbm包可以通过设置相应参数进行并行运算，因此不再调用doParallel与foreach包进行并行运算； 特征选择：使用mlr包提取了99%的chi.square； 调参：逐步调试lgb.cv函数的参数，并多次调试，直到满意为止； 预测结果：用调试好的参数值构建lightgbm模型，输出预测结果；本案例所用程序输出结果的ROC值为0.833386,已超过Private Leaderboard排名第一的结果(0.829072)。 3.lightgbm算法 由于lightgbm算法没有给出具体的数学公式，因此此处不再介绍，如有需要，请查看github项目网址。 lightgbm算法具体介绍网址： https://github.com/Microsoft/LightGBM 读取数据 数据探索 1.设置并行运算 2.数据各列初步探索 3.处理缺失值 impute missing values by mean and mode 处理缺失值后 4.观察训练数据类别的比例–数据类别不平衡 5.剔除数据集中的常数列 6.保留训练数据集与测试数据及相同的列 注： 1）由于本次使用lightgbm算法，故而不对数据进行标准化处理； 2）lightgbm算法运行效率极高，1GB内不进行特征筛选也可以运行的极快，但是此处进行特征筛选，以进一步加快运行速率； 3）本案例直接进行特征筛选，未生成衍生变量，原因为：不知特征实际意义，不好随机生成。 特征筛选–卡方检验 1.试算最大权重值程序，后面将继续优化 从此图可知auc值受权重影响不大,在weight=5时达到最大。 3.特征选择 1)特征选择 2)制图查看 3)提取99%的chi.squared （ lightgbm算法效率极高，因此可以取更多的变量） 注：提取的X%的chi.squared中的X可以作为超参数处理。 4)写出数据 算法 1.调试weight参数 从此图可知auc值在weight=4时达到最大,呈递减趋势。 2.调试learning_rate参数 从此图可知auc值在learning_rate=2^(-5) 时达到最大,但是 2^(-(6:3)) 区别极小，故取learning_rate = .125，提高运行速度。 3.调试num_leaves参数 从此图可知auc值在num_leaves=650时达到最大。 4.调试min_data_in_leaf参数 从此图可知auc值对min_data_in_leaf不敏感，因此不做调整。 5.调试max_bin参数 从此图可知auc值在max_bin=2^10 时达到最大,需要再次微调max_bin值。 6.微调max_bin参数 从此图可知auc值在max_bin=1000时达到最大。 7.调试min_data_in_bin参数 从此图可知auc值在min_data_in_bin=8时达到最大,但是变化极其细微,因此不做调整。 8.调试feature_fraction参数 从此图可知auc值在feature_fraction=.62时达到最大,feature_fraction在[.60,.62]之间时，auc值保持稳定,表现较好;从.64开始呈下降趋势。 9.调试min_sum_hessian参数 从此图可知auc值在min_sum_hessian=0.005时达到最大,建议min_sum_hessian取值在[0.002, 0.005]区间,0.005后呈递减趋势。 10.调试lamda参数 从此图可知建议lambda_l1 = 0, lambda_l2 = 0 11.调试drop_rate参数 从此图可知auc值在drop_rate=0.2时达到最大,在0, .2, .5较好；在[0, 1]变化不大。 12.调试max_drop参数 从此图可知auc值在max_drop=5时达到最大,在[1, 10]区间变化较小。 二次调参 1.调试weight参数 从此图可知auc值在weight>=3时auc趋于稳定, weight=7 the max 2.调试learning_rate参数 结论：learning_rate=.11时，auc最大。 3.调试num_leaves参数 结论：num_leaves=200时，auc最大。 4.调试max_bin参数 结论：max_bin=600时，auc最大;400，800也是可接受值。 5.调试min_data_in_bin参数 结论：min_data_in_bin=45时，auc最大；其中25是可接受值。 6.调试feature_fraction参数 结论：feature_fraction=.54时，auc最大, .56, .58时也较好。 7.调试min_sum_hessian参数 结论：min_sum_hessian=0.0065时auc取得最大值，取min_sum_hessian=0.003，0.0055时可接受。 8.调试lambda参数 结论：lambda与auc整体呈负相关，取lambda_l1=.0002, lambda_l2 = .0004 9.调试drop_rate参数 结论：drop_rate=.4时取到最大值，.15, .25可接受。 10.调试max_drop参数 结论：drop_rate=.4时取到最大值，.15, .25可接受。 1.权重 2.训练数据集 3.训练 4.结果 5.输出 注： 此处给在校读书的朋友一些建议： 1.在学校学习机器学习算法时，测试所用数据量一般较少，因此可以尝试大多数算法，大多数的R函数，例如测试随机森林算法时，可以选择randomforest包，如果数据量稍微增多，可以设置并行运算，但是如果数据量达到GB级别，并行运算randomforest包也处理不了了，并且内存会溢出；建议使用专业版R中的函数； 2.学校学习主要针对理论进行学习，测试数据一般较为干净，实际数据结构一般更为复杂一些。 大数据文摘微信公众号后台回复 可获得完整代码。 本文为投稿作品，仅代表个人观点。 "
85,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658051&idx=2&sn=92d1256301b4f58f9a7b7c04fd53911b&chksm=bd4c30d08a3bb9c61fda01a015e8cf63f8fc88e8f1fd140b83f51d1425c9e9ebb9bc87fff601&scene=27,重磅译制 | 更新：牛津大学xDeepMind自然语言处理 第7讲（下）条件语言模型,大数据文摘重磅课程汉化《牛津大学xDeepMind自然语言处理》 本周更新至：Lecture 7 条件语言模型（2） 马上观看👇 点击文末 ，即可免广告观看 牛津大学Deep NLP是一门关于自然语言处理（NLP）的高阶课程。课程由 和 （AlphaGo的开发机构）联合开设，是牛津大学计算机系2017年春季学期最新课程。由Phil Blunsom主讲，同时邀请到多位来自DeepMind和NVIDIA的业界讲师来做客座讲座。 大数据文摘已联系课程主讲人取得翻译授权，并联合北京邮电大学模式识别实验室 组织了视频汉化， 发布。 课程视频【中文字幕】学习地址： （连载中，请收藏！点击文末 ，可直接加入学习） http://study.163.com/course/introduction/1004336028.htm 牛津大学课程页面（所有资料汇总）： https://github.com/oxford-cs-deepnlp-2017/lectures 本课时PPT精华 后台对话框内回复“ NLP ”获取本课时PPT 后台对话框内回复“ NLP ”获取本课时PPT 课程 ，复制打开链接免费加入学习： http://study.163.com/course/introduction/1004938039.htm 《斯坦福CS231n深度学习与计算机视觉》课程已更新完毕，李飞飞与Andrej Karpathy（现任Tesla AI部门主管）主讲，已有近9万人参与学习，复制打开链接免费加入学习： http://study.163.com/course/introduction/1003223001.htm 本期工作人员 翻译 李楠  闵峰  乔一宁  张世平   刀哥  momo  无敌乔卡特 终校 彭俊逸  蒋宝尚 项目管理 龙牧雪  李楠 顾问 张闯  寒小阳  汪德诚 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 
86,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658072&idx=1&sn=063b4b46c080af07d65d5f6dc99f3822&chksm=bd4c30cb8a3bb9dd59d924ea492a388f3d5d83ecf855c4a9685c486fdd08dae269ce5c6bb094&scene=27,GAN之父Ian Goodfellow ：那个赋予机器想象力的人类,大数据文摘作品 编译：文明、Gao Ning 、Aileen 通过使用两个神经网络的相互对抗，Ian Goodfellow创造了一个强大的AI工具。而现在，他以及我们所有人都必须开始面对其所带来的后果了。 *本文系mit technology review的人物特写，希望阅读英文原文的读者请拉至文末查看原文链接。 2014年的一晚，Ian Goodfellow和一个刚刚毕业的博士生一起喝酒庆祝。在蒙特利尔一个酒吧，一些朋友希望他能帮忙看看手头上一个棘手的项目：计算机如何自己生成图片。 研究人员已经使用了神经网络（模拟人脑的神经元网络的一种算法），作为生成模型来创造合理的新数据。但结果往往不尽人意。计算机生成的人脸图像通常不是模糊不清，就是缺耳少鼻。 Ian Goodfellow朋友们提出的方案是对那些组成图片的元素进行复杂的统计分析以帮助机器自己生成图片。 边喝啤酒边思考问题时，他突然有了一个想法。如果让两个神经网络相互对抗会出现什么结果呢？他的朋友对此持怀疑态度。 当他回到家，他女朋友已经熟睡，他决定马上实验自己的想法。那天他一直写代码写到凌晨，然后进行测试。第一次运行就成功了！ 那天晚上他提出的方法现在叫做GAN，即生成对抗网络（generative adversarial network）。 该方法已经在机器学习领域产生了巨大的影响，也让他的创造者Goodfellow成为了人工智能界的重要人物。 CHRISTIE HEMM KLOK 在最近几年，通过深度学习技术，AI研究人员取得了令人瞩目的进展。向深度学习系统输入足够的图像，它就能进行学习，比如识别出一个将要过马路的行人。这一技术使得自动驾驶技术，Alexa、Siri等会话技术支持的虚拟助手成为可能。 虽然使用深度学习的人工智能工具们能够学习如何识别事物，但它们并不擅长创造事物。 要实现这一功能并不是简单的让它们能够画漂亮的图片或者谱优美的歌曲，而是要让它们尽量少的依赖人类来告诉它们世界该是什么样子以及它们该怎么工作。 如今，AI程序员通常需要明确告诉机器输入的训练数据是什么，即一百万张图片中哪些图片是过马路的行人以及哪些不是。而这样的过程不仅花费极大，需要大量人工参与，还限制了系统对于一些稍微偏离训练集的数据的处理。 未来，计算机将会更好地消化原始数据，并没有明确命令的情况下，从原始数据中找出它们需要从中学习的东西。 这将标志着 “无监督学习”的一大飞跃。无需离开车库，自动驾驶汽车就可以自学如何处理不同的路况；无需四处走动，机器人就能够预估到在一个忙碌的仓库中可能遇到的障碍。 我们能够想象和思考不同的场景，这是我们作为人的一部分。当未来技术方面的历史学家回过头来看时，可能会把GAN方法的提出看作是迈向创造具有类人意识机器的一大步。脸书的人工智能首席科学家Yann LeCun将GAN称之为‘近20年来深度学习领域最棒的想法’。 前百度大脑首席科学家吴恩达认为GAN代表着“一项重大而根本性的进步”，它鼓舞了全球越来越多的研究人员。 Goodfellow现在是位于加州山景城谷歌总部的谷歌大脑团队中的一名研究员（大数据文摘之前报道过他在 ）。当我最近在那里见到他的时候，他似乎对于AI名人的身份感到惊讶，认为这有点“超现实”。 同样让人惊讶的是，他已经发现有人在用GAN达到不法目的，所以他现在大部分的时间都花在对抗坏人，应对这些坏行为上。 GANs的魔力来自于两个神经网络的对抗（点击查看大数据文摘总结的 ）。 它模仿一名图片伪造者和一名艺术鉴定师之间想要打败对方的交锋过程。这两个网络都在同样的数据集上训练，第一个网络称作生成器，生成器用来生成仿造的输出如图片或者笔迹，仿造得越真实越好。 第二个网络称作判别器，将生成器生成的图片与训练集中真实的图片进行比较，然后判断哪些图片是真实的哪些是假的。根据判定器的结果，生成器将更新参数，然后生成新的图片。如此循环，直到判别器不再能判断图片的真伪。 一位使用真实名人照片进行培训的GAN，自己创造出了一系列想象中的明星。  在去年一个众所周知的例子中，英伟达（一家投资重心在人工智能领域的芯片公司）的研究人员训练了一个GAN模型，通过学习真实名人的图像生成虚构名人的图像。不像其他的机器学习方法那样需要成千上万的训练图像，GANs只需要几百张图片就能达到相当好的效果。 GAN的想象能力还很有限。譬如，一旦训练了大量狗狗的图片，GAN模型就能够生成一张相当真实的狗狗的图片，差别可能只是狗狗身上的斑点有些许不同。但它不能生成一张全新动物的图像。 原始训练数据的质量对结果的影响仍然巨大。一个生动的例子是，GAN模型开始生成一些带有随机字母的猫的图片。这是因为训练数据中包含了来自互联网的猫表情包，所以机器认为这些表情包上的字母是猫的一部分。 华盛顿大学机器学习研究员Pedro Domingos说过，GANs的性能并不稳定。如果鉴别器太容易被欺骗，那么生成器输出的图像将看上去不太真实。而校准这两个相互对抗的神经网络也是很困难的，这就解释了为什么GANs有时会生成一些奇怪的东西，比如有两个头的动物。 然而，这些挑战并没有阻止研究人员。自从Goodfellow等人在2014年发表了关于他的发现的第一份报告之后，数百篇与GAN相关的论文陆续发表。GAN的一名粉丝甚至还创建了一个名为“GAN zoo”的网页，专门用于追踪已经开发出来的不同版本的GAN。 网页链接（两个网页内容一致）： https://deephunt.in/the-gan-zoo-79597dc8c347 https://github.com/hindupuravinash/the-gan-zoo GAN最明显的即时应用是在涉及大量图像的领域，比如视频游戏和时尚领域（例如让游戏角色看起来像是在雨中奔跑）。但展望未来，Goodfellow认为GANs将会推动更大的进步。他说:“在科学和工程的很多领域都有一些东西需要优化。”例如药物需要提高药效以及电池需要提高效率等。“这将是下一个浪潮。” 在高能物理中，科学家们利用强大的计算机来模拟数百个亚原子粒子，在瑞士的CERN的大型强子对撞机这样的机器中可能发生的相互作用。这类模拟需要大量的计算能力，非常缓慢。 耶鲁大学和劳伦斯伯克利国家实验室的研究人员开发了一种GAN，在对现有的模拟数据进行训练后，它学会了对特定粒子的行为做出精确的预测，而且速度快得多。 Goodfellow创造的GANs可以用来想象各种各样的事物，包括新的室内设计。 医学研究是另一个有潜力的领域。由于有隐私方面的担忧，研究人员有时无法获得足够多的真实患者数据（进行研究），例如分析为什么某种药物不起作用。宾夕法尼亚大学的凯西格林说，GANs可以通过生成几乎和真实情况一样好的假记录来帮助解决这个问题。这些数据可以得到更广泛的分享，推进研究，而真正的记录则受到严密保护。 然而，技术也有黑暗的一面。对于那些想要影响从股价到选举等方方面面的人来说，一台可以制造假新闻的机器简直是一个完美的武器。 人工智能工具已经用来在色情片的身体上放上其他人的脸（ ），以及用政客的声音说出自己想说的话。虽不是GANs制造这个问题，但是GANs的存在将会让事情变得更糟。 Hany Farid在达特茅斯学院在学习数字取证，他正在研究用更好的方法来识别假视频，比如由呼吸引起的面部颜色的轻微变化，而这些变化GANs很难准确地模仿。但他警告说，GANs会反过来学习这些变化。Farid说:“从根本上来说，我们处于弱势地位。 这种猫捉老鼠的游戏也会对网络安全产生影响。研究者已经强调了“黑匣子”攻击的危险性，GANs被用于找出机器学习模型，因为许多安全程序都是用这些模型来识别恶意软件的。 当搞清防御模型算法的工作原理后，攻击者就能避开防御然后插入流氓代码。同样的方法也能用于逃避垃圾邮件过滤器等安全防御措施。 Goodfellow很清楚这一危险。他现在领导一个谷歌的团队，专注于让机器学习变得更加安全。他警告说，人工智能社区必须吸取以往创新浪潮的教训：技术人员总是在事后才开始考虑安全和隐私问题。 当他们意识到风险的时候，坏人已经有明显的领先优势了。他说，“很明显，我们已经错过了起点，但希望在落后太多之前，我们能在安全问题上取得重大进展。” 尽管如此，他认为不存在一个纯粹的技术手段可以解决造假问题。相反，他认为，技术依赖于各种社会因素而进步，比如通过演讲和辩论课等，教会孩子们批判性思维。 “在演讲和辩论中，你会和另一个学生竞争，你在考虑如何编造有利于自己甚至是误导的说法，或者如何提出具有说服力的正确的主张。”他可能是对的，但他得出的“技术不能解决假新闻问题”的结论，并不是人们想要听到的。” 原文链接： https://www.technologyreview.com/s/610253/the-ganfather-the-man-whos-given-machines-the-gift-of-imagination/ Have a Great Definition 
87,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658022&idx=2&sn=f9f1c9794b9d064f429ab663e662d140&chksm=bd4c30b58a3bb9a3df3ae8c4c1e5506be1abf512ce4b2db31984c2b6435795cd89c93d41488b&scene=27,学界 | MIT新福利！通用人工智能系列讲座公开视频+课件,作为学院派的代表，MIT在各大理工院校中一直对课程开放持比较保守的态度。而面对AI热潮，今年的MIT持续放出利好消息。 这一次公开给全球AI学习者的，是通用人工智能领域一个大咖云集的讲座合辑。 继开放 （大数据文摘经授权汉化） 和 之后，MIT近期又开放了一门偏工程的人工智能课程——MIT 6.S099: Artificial General Intelligence（通用人工智能），官方介绍该课程将采用工程方法探索建立人类智能的可能研究路径。 与MIT在上个月同期放出的一门深度学习入门课程相比（6.S191: Introduction to Deep Learning），这门课程更偏工程和业内，同时也请到了非常多的大咖加盟。除了MIT自家的教授和其他高校研究者的日常课程，还有5次课程邀请到了相关从业者，包括特斯拉的AI研究中心负责人Andrej Karpathy、波士顿动力CEO Marc Raibert、OpenAI的联合创始人Ilya Sutskever等都讲带来各自领域的演讲。 目前，在官网上，课程信息、录像和课件都在持续已公开。感兴趣的同学可以注册观摩了。 官网注册链接： https://agi.mit.edu/ 课程常见问题列表如下： https://docs.google.com/document/d/1ZqgghxV1lpZeWUv5zNK0gMUBHfYTw9n6eYzzx9j8nok/edit 相关课程介绍如下： 这门课将用工程方法探索建立类人智能的可能研究路径。 讲座将介绍我们目前对计算智能的理解，以及深度学习、强化学习，计算神经科学、机器人技术，认知建模、心理学等领域的深入见解，还将包括人工智能安全和道德伦理等方面的课程。 这一系列课程将力图让学生了解最先进的机器学习方法、相关局限性以及如何克服这些限制。该课程还将包括几次业界嘉宾讲座。 每次课程时间：60-90分钟 在网站上注册登陆学习。课程材料免费向公众开放。 通用人工智能 讲    座 Lex Fridman 搭建可以观察、学习和思考的机器人 特邀嘉宾 Josh Tenenbaum （ MIT ） 人工智能的未来 特邀嘉宾 Ray Kurzweil （ Google ） 大脑如何产生情绪 特邀嘉宾 Lisa Feldman Barrett （ NEU ） 计算理论 特邀嘉宾 Stephen Wolfram （ Wolfram ） 认知建模 特邀嘉宾 Nate Derbinsky （ NEU ） 深度学习 特邀嘉宾 Andrej Karpathy （特斯拉） AI 安全与自主武器系统 特邀嘉宾 Richard Moyes 机器人技术 特邀嘉宾 Marc Raibert （波士顿动力） 深度强化学习 特邀嘉宾 Ilya Sutskever （ OpenAI ） 以人为本的人工智能 讲    座 即将上线 Have a Great Definition 
88,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658022&idx=1&sn=36495ca1087a498d9fac1e0083d0e5dc&chksm=bd4c30b58a3bb9a371a8e2935c4b958955ef2b83c52038afeaf4e122a41b034a830dba485dfe&scene=27,李飞飞纽约时报最新博文：如何让AI更好地关怀人类,妇女节前一天，著名AI科学家、斯坦福大学教授李飞飞在《纽约时报》网站发表了题为“How to Make A.I. That's Good for people ”（如何让AI更加以人为本？）的文章。文章中，她表达了对AI发展的兴奋与担忧，并提出“AI以人为本，造福人类”发展道路。 这篇文章也对前几天，AI圈对于 的巨大争议产生了有趣的呼应和回答：无论我们的技术自动化到什么程度，它对世界的影响，无论好坏，始终是我们的责任。 大数据文摘对这篇文章全文进行了编译，希望看到英文原文的读者请下拉到文末原文链接查看。 李飞飞：如何让AI更加以人为本 十年前人工智能还仅仅限于学术圈，如今已经疯狂增长。从硅谷到北京的科技公司都押注人工智能，风投为研发投入数十亿资金，创业公司如雨后春笋。如果我们的时代是下一次工业革命，那么正如很多人所说，AI绝对是其动力之一。 对于像我这样的研究人员来说，这是一个特别激动人心的时刻。十几年前我还在读计算机科学专业的研究生时，电脑连照片中的锐利边缘都几乎无法检测出，更别说识别人脸。但随着大数据的发展，神经网络算法和计算机硬件的快速进步， 然而，我担心这股热潮让我们忽视了AI对社会的消极影响。 除了它的名字，这个技术没有任何“人工”的成分——它是由人类制造的，旨在表现得像人类，旨在影响人类。 它包含三个目标，旨在帮助负责任地开发机器智能。 李飞飞倡导“AI民主化”👆 首先 以人类视觉的丰富感知为例，它是如此复杂、深层次，并且能在明确地觉知前景和灵敏地捕获背景中取得自然平衡。相比之下，机器感知仍然非常狭窄。 有时候这种差异微不足道，例如，在我的实验室里，图像字幕算法可以识别出“骑马的人”，而完全没有注意到两个都是铜像。同样的算法用来识别彩虹之下草原之上的斑马时差异更明显。虽然识别和描述实现了技术上的正确性，但完全没有审美意识，没有任何人类可以自然感受到的活力或深度。 这听起来有点吹毛求疵，但是这也指出了我们人类感知超越机器算法的一个主要方面。如果我们不能洞察人类体验中这些“模糊”的维度，又如何期待机器能预测我们的需求，何谈为人类的福祉做贡献？ 要让AI对人类思维的全方位更敏感不是一件容易的事。 这种合作代表着回归，而非背离我们这个领域的起源，年轻AI学生们可能会惊讶于今天深度学习算法原理，起源于 David Hubbard和Torsten Wiesel发现的猫视觉皮层中神经元的层次结构对刺激的反应机制。 同样，包含数百万张训练图片的ImageNet，帮助发展了计算机视觉。这个项目，是基于认知科学家和语言学家George Miller在1995年创建的WordNet数据集。WordNet旨在组织英语的语义概念。 重新连接AI与认知科学、心理学甚至社会学，将给人工智能一个更加强大的发展基础。而且我们可以期待这样发展出来的技术，会让合作和交流更加自然，从而实现以人为本的第二个目标： 想象一下AI在手术中的作用。它的目标不是把整个过程完全自动化，相反，智能软件和专用硬件的结合可以帮助外科医生专注于自己的优势——如灵活性和适应性——而让机器从事更加常规性的工作， 以避免人类容易发生的失误、疲劳和被干扰。 或者考虑老人护理的情景。机器人可能并不是老人看护的最佳人选，但智能感应器在帮助人类护理员方面前景很好。通过自动监测药物剂量和自动核对安全检查清单，人类护理员可以将更多的精力放在建设与被护理者之间的关系上。 这些都是自动化取代那些重复的、容易出错的甚至是危险工作的例子。而剩下的创造性的，需要智力和情感的工作，由人类来完成仍然是最适合的。 然而，没有任何聪明才智会完全消除工作流失的威胁。解决这个问题是以人为本的AI的第三个目标： 今天对工作流失的焦虑只是一个开始。其他问题还包括弱势群体中机器学习从业人数的偏倚，AI对数据的高需求与保护个人隐私之间的关系，以及全球智能竞赛的地缘政治影响。 充分面对这些挑战要求各大机构的共同付出。大学的独特定位是通过跨学科项目、课程和研讨会来促进计算机科学与传统上不相关的学科，如社会科学甚至人文科学之间的联系。 各国政府可以作出更大的努力，鼓励计算机科学教育，特别是在AI中代表性不足的年轻女孩、少数种族和其他群体。公司应该将积极投资智能算法与伦理道德结合，兼顾抱负与责任。 李飞飞创建AI4ALL女高中生夏令营，得到梅琳达·盖茨投资 👆 没有哪项技术比AI更能反映它的创造者。实际上，虽然有人认为机器没有价值观， 无论我们的技术自动化到什么程度，它对世界的影响——无论好坏——始终是我们的责任。 原文链接： https://www.nytimes.com/2018/03/07/opinion/artificial-intelligence-human.html 【今日机器学习概念】 Have a Great Definition 
89,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657940&idx=2&sn=1e90024cbea10fdb94e2998e40992071&chksm=bd4c31478a3bb85130007fe43c9b569aa768fee71b9b68beee2e8deeb7f5440d19d6fdfad6cb&scene=27,业界 | 谷歌正与五角大楼合作，为军用无人机图像识别提供TensorFlow API,谷歌内部邮件暴露，其正在为美国国防部AI项目“Maven”提供TensorFlow API，用于分析无人机拍摄的画面。 该合作计划公布后在谷歌内部引起了广泛的讨论，有不少人表达了对TensorFlow用于军事的担忧和不赞成。 此前，大数据文摘曾报道过联合国 特定常规武器公约会议上曝光的一段可怕的视频 ：一群神似《黑镜III》中机器杀人蜂的小型机器人，通过人脸定位瞬间杀死了正在上课的一众学生，场面血腥。视频虽然是虚构的，但 伯克利大学教授、资深AI研究者Stuart Russell借此提醒所有人： 视频里 。 “不作恶”的谷歌，会怎样推动AI的军事应用呢？ 谷歌董事长埃里克·施密特（Eric Schmidt）在去年秋天的一次演讲中表达了对科技企业与五角大楼合作的担忧。他说：“科技界普遍担心的是，军工企业不正确地使用他们研发的产品杀人。”虽然谷歌表示其参与Maven项目与作战用途无关，但这仍引起了许多员工的担忧。 五角大楼快速推进的Maven项目，也被称为“算法战跨职能小组”(Algorithmic Warfare Cross-Functional Team，简称AWCFT)，成立于2017年4月。此项目的任务是加速国防部对大数据和机器学习技术的整合。据华尔街日报报道，国防部2017年在人工智能相关领域投入了74亿美元。 新美国安全中心（Center for a New American Security）的助理研究员Greg Allen称，该项目的第一项任务是 ，因为这些录像数据之多以至于人类无法分析。尽管国防部已经投入资源开发先进的传感器技术以在无人机飞行期间收集信息，但并没有创建出高效的数据梳理工具。 “在Maven项目之前，国防部门尚未有人知道如何恰当地购买、使用人工智能服务。”Allen表示。 Maven的任务是使用机器学习来识别无人机镜头中的车辆和其他物体，从而减轻分析人员的负担。根据五角大楼的说法，Maven最初的目标是为军方提供先进的计算机视觉技术，使其能够自动检测和识别无人机全动态摄像机捕获的多达38种物体。 人工智能已经应用在了执法和军事中，但研究人员警告说， 。例如，ProPublica在2016年报告说，用于预测获释人员二次犯罪可能性的算法经常表现出种族偏见。 尽管谷歌的参与引起了员工的担忧，但目前谷歌尚未开发能够获得敏感的政府数据的产品。与之相反，其云计算服务竞争对手亚马逊和微软Azure正在提供以政府为导向的云产品，旨在储存机密信息。 一名谷歌发言人声明说，谷歌向国防部提供了其用于机器学习应用的工具TensorFlow APIs，这能帮助军方分析人员识别图像中的物体。对于人们对将机器学习技术用于军方用途存在的顾虑，该发言人表示，谷歌正在制定相关“使用规则和安全区”。 “我们长期与政府机构合作并提供技术解决方案。这个提供开源TensorFlow API的项目是国防部的试点项目，可以帮助识别未分类数据上的对象，”谷歌发言人说，“用该技术 标记的 图像有人类审查，并且仅用于非冒犯性用途。机器学习的军事使用自然引起了担忧。我们正在内部讨论此议题，并打算制定相应的技术使用准则。” 国防部正在加速Maven项目的执行，并预计其成立六个月后即可投入运行。据报道，自12月以来，该项目已被部署在与伊斯兰国（IS）的对抗中。 为了满足该项目的迫切时间要求，国防部积极寻求与学界和业界的人工智能专家合作，以弥补军方和硅谷之间的技术差距。 上个月辞去谷歌母公司Alphabet执行主席职务的 施密特（Schmidt），现担任国防创新委员会主席。在7月份的一次会议上，施密特和国防创新委员会的其他成员讨论认为国防部需要建立一个信息交换中心来为军方的人工智能训练数据。  2017年底，Maven团队着手寻找商业合作伙伴，他们的专业知识是实现人工智能梦想所必需的。在华盛顿举行的国防科技峰会上，Maven海军陆战队上校Drew Cukor说，人类和计算机之间的共生关系对于帮助武器系统探测物体至关重要。 在与许多来自硅谷的军事和工业技术专家对话中，Cukor宣称 。“你们许多人会注意到， 施密特（Schmidt） 现在称谷歌是一家人工智能公司，而不是数据公司。”但Cukor并没有提及谷歌是Maven的合作伙伴。 “没有任何‘黑匣子’能够提供政府需要的AI系统，至少现在还不行，”他继续说道，“关键力量必须整合在一起，唯一方法就是与商业伙伴合作。” 国防部发言人拒绝透露谷歌是否是Maven项目的唯一合作伙伴，也不愿表明谷歌在该项目中的角色。 该发言人说： “与其他国防部计划类似，Maven项目并未对合同细节的具体内容做出说明，包括项目承包商和分包商的名称和身份。” 原文链接： https://www.gizmodo.com.au/2018/03/google-is-helping-the-pentagon-build-ai-for-drones/ Have a Great Definition 
90,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658051&idx=1&sn=a3f58601e68a63ce30d53397f82ad57a&chksm=bd4c30d08a3bb9c62628aac436217cc707816b03f47d5fc14b16ce5da2a3d8706b2aa75dad84&scene=27,语言学博士、Kaggle数据分析师，她说：读研不是必选项，这4项技能学校不教,大数据文摘作品 编译：王一丁、吴双、Yawei Xia 学校里教的数据科学和实际工作中的数据科学的差距，往往让很多刚毕业踌躇满志的职场菜鸟陷入迷茫。 事实是，在学校里你可以把模型做得天花乱坠，但是在公司里你的老板需要用业绩担保为你的研究结果背书，这么一想就不难理解为什么在实际操作层面，公司的模型会更偏向保守，而一些套路很深的职场老鸟会意味深长地说“ ”。 从数据科学毕业生到业界的数据科学家的转型，需要很多经验和行业知识打基础。本文作者Rachael Tatman是 的讲师之一，最神奇的是她的背景：威廉玛丽学院（美国第二古老的大学）英语本科、华盛顿大学语言学博士，现任Kaggle数据分析师。让我们看看她 都给数据职场新人提了哪些建议。 数据科学与研究生学位 首先要说明一点： 一个教你如何做研究的学位并不是必须的，除非你在做尖端的机器学习研究（老实说，包括我在内的99.9%的数据科学家并不是在做这件事！）。任何一个企图神话这份工作的人都可能只是想让你花钱读一个学位。 读研期间，我确实学到了许多有价值的技能。我学会了如何处理混乱的数据，问对的问题，在不同的场景下选择适合的数据分析工具，为分析计算及机器学习编写代码，以及清晰地交流技术概念等等。这些是每一个数据科学家必要的技能。 但数据科学家需要的技能并不仅仅是这些。我从学校到工作岗位这段时间，经历过的最有挑战的两个阶段：一是明确我缺少的技能是什么，二是明白如何快速地掌握它们。 如果你现在的境遇与我当初相似，我的经验应该会对你很有帮助。下面列出的四项是 ，以及一些如何学习它们的实用技巧。 SQL 据我了解，大多数以从事数据科学为业的研究生都熟悉R或Python（或对两者都很熟悉！）。与此同时，却只有很少一部分人熟悉SQL。那么这可能会是当你准备进入数据科学行业工作时面临的一个问题：在Python和R之后，SQL是数据科学中使用最广泛的第三种工具（而你很可能对它的掌握程度并不够）。 SQL（通常读作“sequel”）是一种与数据库交互的编程语言。 好在SQL的基本知识比较简单并且有很多学习资源，上手并不难。 怎么学SQL： 选一门课。 网上有很多在线学习课程，包括可汗学院（Khan Academy），DataCamp，Stanford和Udemy。面授课程可能比较难找，但是如果你在本地的大学或社区大学有注册，或报名了编程训练营，也有机会找到。 相关资源： https://www.khanacademy.org/computing/computer-programming/sql https://www.datacamp.com/courses/intro-to-sql-for-data-science https://lagunita.stanford.edu/courses/DB/SQL/SelfPaced/about https://www.udemy.com/introduction-to-databases-and-sql-querying/ 开发创建一个SQL案例集。 用查询实例来说明你在真实数据库上的操作能力是证明你熟悉这种语言的好办法。一种方法是在Kaggle的BigQuery数据集上编写核心程序（kernels，即托管的R或Python笔记本）。我整理了一份帮你快速入门的指南，HackerRank和SQLZoo上也有不少SQL的练习资源。 相关资源： https://www.kaggle.com/rtatman/sql-scavenger-hunt-handbook/ https://www.hackerrank.com/domains/sql/select https://sqlzoo.net 成为一名多面手   研究生院是很好的学习场所，日复一日的研究工作能帮助你拓展知识边界。但随着项目深入，你会发现你需要钻研某一特定领域，且会越来越细分。最终你会成为最了解这一细分领域的人。这很好，学术研究就是会让你成为这样的又“精”又“专”的人。 然而数据科学家却不是这样开展工作的。除非你足够幸运，能够一直在与你学术论文主题匹配的领域中工作，否则，你会不断接到你之前所研究领域之外，甚至还会有一些之前从未闻及的挑战。所以你必须快速处理并不是自己专长领域的研究。 这里是一些成为多面手的小贴士： 阅读学科之外的内容。 学术学科倾向于使用专门特定的统计工具。例如，在社会语言学方面，我们更多的使用混合效应回归（mixed-effects regression）来做工作，但其实还有很多其他的统计方法。在不同学科中进行阅读会使你接触了解到各种不同的技术和问题，并有助于你快速进入新的领域。 训练自己分析新类型的数据。 数据科学家需要处理各种数据。你可能已经在处理某一类型数据上有了丰富经验，但也需要考虑拓展其它类型数据的分析能力。你处理过时间序列数据吗？文本数据呢？图片数据呢？视频数据呢？音频数据呢？预训练模型呢？或者关系数据库？ 找出你的知识与实际应用之间的差距，并尝试就一些新的数据来源进行操作。Kaggle拥有各种来源超过10000个公共数据集，你还可以在Zenodo或Dataverse项上找数据。 相关资源： https://www.kaggle.com/datasets https://zenodo.org https://dataverse.org 和你所工作领域之外的人讨论技术。 与自己工作领域之外的人就技术进行交流，不仅可以学到很多，同时也有机会去练习自己如何把技术给外行人讲清楚，参与讨论的双发都会获益良多。 源代码管理/版本控制 我读研的时候是学过源代码管理的（得益于一个软件技能学习网站（Software Carpentry））。源代码管理的能力是非常有价值的，但是据我所知，我的很多同学对此并没什么了解。 源代码管理，也称版本控制，是一种对单个集中式文档或代码库进行管理及更改的方法。该方法的基本思路是，你可在任何副本上进行工作，且其修改都会使原件得到更新。这很益于单个项目的开发（它可以让你回归到实际工作的那个版本，并找到之前中断的地方），对技术合作来说也十分必要。 怎样学习使用版本控制： 在每个研究项目或课题中都使用版本控制方法。 我觉得这非常有必要。在做论文研究的整个过程中，版本控制多次救我于水火之中。 将GitHub用于个人项目（如果有的话）或可以分享的研究。 这件事可做可不做，但如果加入使用Github的团队会很有益处。此外，活跃的GitHub配置文件是向潜在雇主展示工作流程化的一种好方式。 “够用”就行 当你在学术环境中工作时，你确实需要确保一切都尽力完美。你的研究结果会被专家进行严格评估，如果通过的话，它会被永久地添加到学术文献中。然而，在实际工作中， 。   我在实际工作中学到的第一批新术语之一是MVP，即“最小化可行产品”。这个想法是，当你的东西足以满足一部分与之交互的人的需求时，就把它与人们进行分享。在数据科学环境中，这意味着，你的数据不是必须要去回答每一个问题，也不是必须要使用最精准的模型。也许之后你可以对其进行更深入的分析或其他调整，但在项目达到“够用”时你应该就准备好将其发布。 如何提高判断“够用”的能力： 练习判断“目前已够用”。 下一次你参与一个项目时，要经常停下来，也许在你每天结束之前，考虑你是否已经创造了一些有价值的东西（很可能有！）。花点时间练习如何描述你已经完成了什么有用或有趣的事情。 考虑对研究中间阶段的分享。 可以的话，考虑在博客上或对实验室的同事分享你的下一个研究项目的中间阶段。研究可能并非完美，但这不也是你研究中的一部分吗？想想在数据收集过程中，你学到了什么值得分享的东西？你想想自己做了什么是已经“够用”的，别人可能会觉得它很有价值的东西？   以上便是四种我在研究生学校没学到，但现在每天工作中都会或多或少用到的核心技能。从事数据工作的同行们，你们毕业后，要利用一切可以学习这些技能的机会！ 原文链接： https://medium.freecodecamp.org/the-four-data-science-skills-i-didnt-learn-in-grad-school-and-how-to-learn-them-f2b039fc0f59 Have a Great Definition 
91,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651658022&idx=3&sn=1fd04bfb69853af854d3c9fd5c85e5c4&chksm=bd4c30b58a3bb9a3f644f65b9018aac9db42c0fb031edab5c3ce7978f7a63d2ba20153ea1f54&scene=27,论文Express | 开网约车赚外块？MIT最新研究称多数Uber司机收入低于当地最低线,MIT的一份研究显示，大多数共享打车司机的工资低于当地最低工资，很多人甚至入不敷出。 一份MIT的最新研究显示，美国Uber和Lyft司机的平均时薪为税前3.37美元，低于该地区最低工资标准，而且许多人是亏钱的。 大数据文摘后台回复 “打车” 获取这份研究报告       这是一篇关于能源与环境政策研究的论文，研究人员对预约用车公司的1100余位驾驶员的调查，对其运营成本数据分析。通过对保险、维护、修理、燃料和其他费用方面进行分析，报告发现：30％的司机在工作中亏损，74％的司机的收入要低于其所在州的最低工资。 在调查结果中，MIT提出了关于劳工标准的新担忧，在共享经济蓬勃发展的今天，Uber和Lyft这样的公司连续面对对其所属司机待遇的评审，司机被划为独立承包商，拥有很少的权益或保护。 斯坦福大学汽车研究中心执行主任、该论文的作者之一Stephen Zoepf说：“目前来看，这种商业模式是难以持续的。” “这些公司正在亏损。这些企业的生存得益于‘风险投资’的补贴......实质上司机又通过低收入这种工作方式来补贴企业。” 该报告称， 平均每月司机利润为661美元。 尽管大多数司机都将车辆用于个人使用和载客，但他们驾驶的里程中，大部分是因工作而产生的，这也就会产生很大的短期和长期成本。 维护、修理和折旧的成本不可避免，“实际上，作为司机所做的事情就是借用汽车的价值，”Zoepf补充说，“司机很可能并没有意识到他们的开支有多少。” 其他研究和调查发现，Uber司机每小时的收入更高，部分原因是对因工作所产生的成本（如花费的时间、产生的里程等）有更多的考量。 曾经对司机做过调查的网站Rideshare Guy创始人、Harry Campbell表示，中位数为3.37美元的时薪似乎有些低，但同时也指出，确实有不少共享打车司机在拿到收入后会非常惊讶（并没有原想的那么多）。 “我们从司机那里听到的最普遍的反馈是，他们的收入比预期的要少得多” Campbell说，他与Zoepf一起完成该论文中的调查。 “这行的人员流动性很大，从司机那里听到的首要原因是—他们挣的不够多。” Campbell指出，Uber本身一直在努力降低企业运营成本。去年，在发现公司实际亏损是预期亏损的18倍后，公司关闭了其在美国的汽车租赁业务。 一些司机称租赁计划使他们陷在债务之中。 这一研究遭到了Uber和Lyft的质疑。 Uber发言人在一份公开声明中指责了这项研究：“尽管这篇论文确实引起了人们的关注，但其方法和结论却存在严重纰漏。我们已与该论文的作者联系，表达了我们的顾虑，也提出与论文作者一方可以就研究进行合作，以改进之前的研究方法。” Lyft发言人在一封电子邮件中表示：“我们还没有详细审查这项研究，但初步审查发现了一些可疑的假设。” 参考素材： https://www.theguardian.com/technology/2018/mar/01/uber-lyft-driver-wages-median-report Have a Great Definition 
92,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657940&idx=3&sn=638b7725c80cdfa2ed7bc371f2f9d7aa&chksm=bd4c31478a3bb851a2a80545b48b6047f8844a3e7a7f04a75bd3a7e212efe503e7a612a14bfa&scene=27,论文Express | 淘宝广告是怎么优化的？阿里团队实时竞价系统策略,"作者：小鱼 经常逛淘宝的同学应该会发现，淘宝移动客户端首页下拉有一个“猜你喜欢”的板块，经常会推荐一些你曾经在淘宝搜索过的相关物品，偶尔确实给大家带来小惊喜，那么 淘宝是怎么做到的呢？ 最近，阿里团队在arXiv.org上发表了两篇关于实时竞价（RTB）系统中的算法的论文，称不仅能帮助商家在广告竞价中给出合理的策略，还能最大化商家的利润。 在大数据文摘公众号后台对话框内回复 “竞价” 即可下载两篇论文~ 以下是第一篇论文部分内容： 基于多智能体强化学习的实时竞价案例 实时广告为广告商提供了一个为每个展位的访客竞价的平台。为了优化特定目标，如最大化广告投放带来的收入，广告商不仅需要估计广告和用户兴趣之间的相关性，最重要的是需要对其他广告商在市场竞价方面做出战略回应。本文提出了一个实用的分布协同多智能体竞价系统（DCMAB），并用于平衡广告商之间交易的竞争和合作关系。并利用阿里行业的实际数据已经证明了该建模方法的有效性。 竞价优化是实时竞价最关心的问题之一，其目的是帮助广告商为每次拍卖的展示给出合理的出价，最大化竞价系统的关键绩效指标（KPI），如点击量或利润。传统的竞价算法缺陷在于将竞价优化作为一个静态问题，从而无法实现合理的实时竞价问题。 多智能体强化学习的关键在于如何设计使每个智能体良好合作的机制和学习算法。淘宝有数量庞大的广告商，多智能体强化学习正好可以用来解燃眉之需。 淘宝的展示广告系统 在淘宝广告系统中，大多广告商不仅投放广告，也在淘宝电子商务平台上销售他们的产品。淘宝广告系统可以分为三部分如下图所示：第一步是进行匹配。通过挖掘用户的行为数据获得用户的偏好预测，当接受到用户请求时，根据实际情况，从整个广告语料库中实时匹配部分候选广告（通常按照顺序）。其次，实时预测系统（RTP）预测每个推荐广告的点击率（pCTR）和转化率（pCVR）。最后，对候选广告进行实时竞价和排名显示。 淘宝广告系统概述 匹配、实时预测和排名依次处理用户的请求，然后返回特定数量的广告。 这些广告展示在淘宝客户端的“猜你喜欢”板块中。 多智能体广告竞价算法原理 将实时竞价看作一个随机游戏，也叫做Markov对策。Markov 对策是将多步对策看作一个随机过程，并将传统的Markov 决策过程( MDP)扩展到多个参与者的分布式决策过程（参考文献：李晓萌, 杨煜普, 许晓鸣. 基于 MarkoV对策和强化学习的多智能体协作研究[J]. 上海交通大学学报, 2001, 35(2):288-292.）。 商家和消费者被分在不同的集群中。每个商家群集都有一个Agent来调整不同消费者集群的广告竞价。 对于行动a_ij，i迭代的是商家集群数，j为消费者集群数。 bratio_k代表商户k的基本调整率。 由于输出行为（竞价调整）处于连续空间中，论文采用梯度确定性策略来学习竞价算法。 （a）淘宝广告系统中的DCMAB工作流程图 状态服务器负责维护Agent的工作状态，包括总体信息g，消费分布d和消费静态特征x^q。 （b）DCMAB 网络结构设计 DCMAB示意图 算法实现流程图如下： 实验 数据集和评估设置 数据集来自阿里的行业数据，广告的推荐效果展示在淘宝App首页“猜你喜欢”中； 广告商的收入作为主要的评估依据。 对比方法 手动设置竞价（Manual） 上下文老虎机（Bandit） Advantageous Actor-critic (A2C) 连续动作控制（DDPG） 分布协同多智能体竞价系统（DCMAB） 实验结果 表中为不同算法下广告商自主竞价的收益 表中列出了不同算法的收敛性能（假定算法的训练收敛性能在后50个数据集没有变化的情况下）。 表中每行数据显示对应算法的结果，每一列数据是本次实验中不同Agent集群的结果和广告商的总收入。研究人员对每个算法进行了4次实验并给出了平均收入和标准差。 各种算法的学习曲线与基线的对比 实验结果表明，DCMAB收敛比DDPG更稳定，验证了将所有Agent的行为输入行为-价值（action-value）函数这种建模的有效性。DCMAB和DDPG的学习速度快于A2C和老虎机，显示了基于记忆回访的梯度确定性策略的优点。 第二篇论文是关于预算约束竞价，给大家做简单介绍，感兴趣的同学可以下载全文阅读。 基于无模型强化学习的预算约束竞价 实时竞价（RTB）几乎是在线展示广告最重要的机制，每个页面视图的合理出价对良好的营销结果起着至关重要的作用。预算约束竞价是RTB机制中的典型场景，即广告商希望在有限预算下最大化获得用户印象的总价值。 但是，由于交易环境的复杂性和不稳定性，实时竞价的最优化策略往往很难实现。为解决上述问题，本文将预算约束竞价视为马尔可夫的决策过程进行处理。与之前的基于模型的工作完全不同，本文提出一种基于无模型增强学习的新型框架，顺序调节竞价参数而不是直接生成报价。 基于这个思路，通过部署深度神经网络并学习如何给出适当回报，从而引导智能体提供最佳策略；本文也设计了一个自适应贪婪策略来动态调整探索行为和进一步提高性能。通过在真实数据集上测试表明，本文提出的框架真实有效。 以上就是两篇论文的介绍啦，感兴趣的同学在大数据文摘公众号后台对话框内回复 “竞价” 即可下载两篇论文~ Have a Great Definition "
93,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657932&idx=2&sn=26f2ab9f4a62efd894f4637ac4893e67&chksm=bd4c315f8a3bb8492388784392eaca87a5cbaa5438aa4b8a7dbeb540f88f7356492d26dc7153&scene=27,求职必备 | 如何快速进入数据科学行业,直播课程5 ：matplotlib与seaborn技能大全(上) 实战辅导5：Titanic/航班数据的可视化练习， 对pandas分析得到的链家网数据，做可视化 直播课程6：matplotlib与seaborn技能大全(下) 实战辅导6：Bokeh与Bokeh server地图可视化 直播课程7 ：机器学习起步：概念、流程、算法一览与sklearn 实战辅导7：完成经典Titanic分类问题，完成自行车租赁回归问题机器学习建模 直播课程8 ：机器学习算法应用进阶 实战辅导8：完成Kaggle比赛数据分析与建模参数选择、效果评估 直播课程9 ：模型优化与模型融合 实战辅导9：用模型融合完成Titanic分类问题的建模优化，完成天池AI电力预测大赛机器学习建模优化 直播课程11：Hadoop与Map-Reduce 实战辅导11：MIT/麻省理工map-reduce作业，互联网公司面试的Map-reduce题目，电商大数据map-reduce统计 直播课程12：Spark大数据处理与Spark SQL 实战辅导12：Spark维基百科数据分析，Spark进行stackoverflow数据分析 直播课程13：Spark大数据机器学习 实战辅导13：一起来打怪之Spark机器学习案例 完成实训营5期的学习全流程，你将掌握数据科学的核心技能，具体为以下几点： 4480元 
94,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657932&idx=3&sn=512c1bf0a16beaf9480dbdbabcd5a7b9&chksm=bd4c315f8a3bb849434bfa449b8aa34dc45ea64b0660530937f885993d452b41f222597312e6&scene=27,学界 | Coursera上也能读硕士了！10个线上学位项目，物美价廉？,"大数据文摘作品 今日凌晨，吴恩达发布推特宣告Coursera十个线上硕士学位项目上线。他非常兴奋地表示，这不仅降低成本，更重要的是便利性+灵活性+全球接入。 Coursera在推进线上教育上一直不遗余力，目前，其正在与世界一些顶尖大学合作推出在线硕士项目，其与亚利桑那州立大学，伦敦帝国理工学院和伦敦大学以及密歇根大学合作的学位课程刚刚上线。 学习地址： https://www.coursera.org/browse/degrees-and-professional-certificates Coursera及其高校合作伙伴称，这些新证书可以充分利用该平台广泛覆盖的3,100万用户的优势，以降低招收学生（以及他们收取的学费）的成本，并帮助大学开始将学位课程缩短。 这一方式不仅仅可以扩大其提供的完整学位课程的数量 - 它还与其大学合作伙伴合作帮助将学位分解开来，以方便无法用大块完整时间完成学业的学习者。 在伊利诺伊州，一位M.B.A.的学生可以在成功完成数字营销的三门课程之后，获得该专业的证书，该证书大约是M.B.A.线下课程内容的六分之一。 课程的灵活性确实能够让很多学习者在工作之余获得一份硕士学位，Coursera课程质量无可挑剔，“物美”不虚其名，但是是否“价廉”呢？ M.B.A.课程除外，文摘菌做了下调查，在Coursera上读一个伦敦大学的本科学位需要9600-17000镑（英国正常学费约1万镑/学年，本科读3年就是3万镑），虽然也不便宜，但还是比线下读个学位便宜了不少。 Coursera即将上线的10个学位项目 创新与创业硕士（Master in innovation and entrepreneurship），巴黎HEC商学院  数据科学计算机科学硕士（Master of computer science in data science），伊利诺伊大学厄巴纳-香槟分校 会计科学硕士（Master of science in accountancy），伊利诺伊大学厄巴纳-香槟分校 工商管理硕士（Master of business administration），伊利诺伊大学厄巴纳-香槟分校 Coursera新增加的学位项目 计算机科学学士（Bachelor of computer science），伦敦大学  应用数据科学硕士（Master of applied data science），密歇根大学 计算机科学硕士（Master of computer science），亚利桑那州国家大学 计算机科学硕士（Master of computer science），伊利诺伊大学厄巴纳-香槟分校 公共卫生硕士（Master of public health），帝国理工学院 公共卫生硕士（Master of public health），密歇根大学 【今日机器学习概念】 Have a Great Definition "
95,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657940&idx=1&sn=741681c19b3e18e638b8d4cff482a91a&chksm=bd4c31478a3bb851a8de4a45321c3f79efd665cd28dbea3f9e114ae2cfec0f548bdce3ce1fa1&scene=27,为什么谷歌、Facebook的AI研究员都坐在CEO身边？,如果你想了解一家科技公司的发展重点，可以先看看这家公司的座位表。 在谷歌的硅谷总部，首席执行官（CEO）Sundar Pichai与谷歌大脑（谷歌旗下致力于人工智能研究的实验室）在同一楼层工作。 七英里外，当Facebook创立自己的人工智能实验室时，人工智能研究人员的桌子曾被临时安放在一个会议室的鱼缸旁边，这个会议室是Facebook创始人兼CEO马克·扎克伯格的“御用”会议室。 Facebook的CTO Mike Schroepfer表示，“我可以跨过我的办公桌与扎克伯格和桑德伯格（Facebook COO）击掌，而AI团队就坐在我们的旁边。” 即使是位于盐湖城地区的在线零售商Overstock.com，现在也组建了一支名为OLabs的小型研发团队。他们就坐在CEO Patrick Byrne的办公室外。 2018年2月12日，犹他州米德维尔市Overstock的总部，科研团队OLabs的座位直接位于CEO的办公室外。 越来越多的科技公司正在将研究实验室和其他对未来影响深远的项目移到离老板更近的位置。 有一点是明白无误的：研究人员做的事情对CEO很重要，甚至可能代表公司的未来。 “在技术和创新的驱动下，世界的变化日新月异，” 哈佛商学院名誉教授John Kotter表示（他写过多本关于商业领导力的书籍），“许多企业都认为科技创新的速度应该是一切的核心竞争力。” 一年前，谷歌大脑的数学家、程序员和硬件工程师团队在公司园区另一侧的一座小办公楼里办公。 但在过去几个月里，他们换了一个楼办公，现在正坐在Pichai和其他高层工作区域的旁边。 负责谷歌大脑的著名工程师Jeffrey Dean从他的座位走到Pichai的办公室，只需几步路。同样离Pichai很近的还有Ian Goodfellow和Norm Jouppi。Ian Goodfellow是新的AI技术“对抗神经网络”的主要研究人员，这种技术可以用机器生成真假难辨的图片。Norm Jouppi正在研究新一代的计算机芯片，同样致力于加速人工智能的发展。 “每一个CEO都会认真考虑员工们坐在哪里的问题，以便他们能与之随意交谈，” 谷歌云计算团队的负责人，同时也是谷歌母公司Alphabet的董事会成员Diane Greene表示，“把哪个团队移到CEO旁边，很显然体现了该团队的重要性。” 谷歌越来越看重AI，并对Goodfellow这样的AI研发人员寄予厚望。 虽然人工智能仍有许多问题悬而未决，但Pichai和其他的谷歌高层希望AI能加速从智能手机、家用电器到互联网服务和机器人等所有这一切的进展。 Ian Goodfellow和他的 “AI圣经”著作《深度学习》 对Byrne来说，改变Overstock的座位表有点像军中常见的管理策略，当一名指挥官与一个小型的“特别行动队”密切合作时，这意味着这个小的团队比其他部门有更多灵活性。 Byrne说：“我们正在变得官僚主义。调换座位是在官僚体制外创造更多竞争的一种方式。” 很多大公司正试图复制硅谷初创公司的氛围：让老板坐在每个员工的旁边。随着创业公司的成长，他们经常把关键技术团队放在CEO旁边。Greene曾是软件公司VMware的CEO，她一直在阐述一种观点：CEO要坐在顶尖工程师旁边，因为工程师们决定着公司的未来。 老板周围的座位是有限的。 Facebook最初组建虚拟现实团队以探索其庞大的社交网络中VR应用的未来时，这个团队坐到了扎克伯格旁边。但现在不再是这样了，Facebook表示这是因为这个团队变得太大了。 Facebook的VR眼镜 但在如今的硅谷，虚拟现实不再是最热门的话题，这份荣誉目前属于人工智能。 在Facebook，一直以来，座位在哪里很重要。传统上，该公司的广告组坐得离扎克伯格最远。Antonio García Martínez（他著有一本关于他在Facebook公司的经历的书籍）表示，在Facebook上市并开始大力推动营收之后，广告团队的主要成员被转移到了老板旁边。 通过OLabs，Overstock成为第一家接受比特币数字货币支付的大型零售商。该实验室中最终诞生了一家子公司，这家公司试图将比特币的特性应用于金融交易。在谷歌和Facebook的AI实验室的影响下，这个团队将注意力放在了机器学习上，致力于构建一个通过分析大量数据自行学习的系统。 “如果一位CEO接近这些研究人员，除了向他们学习，同时也是在向他们展示他们对公司的重要性。 ”Kevin Quennesson说。Kevin 曾经负责Twitter的AI团队， 现在是一家创业公司的CEO。 Kevin还警告说，公司要求研究人员产生成果可能为他们带来过大的压力，毕竟，做研究是一项未知的旅程。Bagley说，在与CEO进行如此多的自发交流之后，有时很难区分“正式指令和非正式的头脑风暴”。 Martínez表示，你在Facebook的地位取决于你的桌子离扎克伯格有多近。如果你的座位靠近老板，其他团队就会怨恨你。 公司发展的的优先级也经常会发生变化。在Overstock，一个新的比特币项目将挤入OLabs旁边。在Facebook，AI团队已不再与扎克伯格肩并肩坐在一起，因为这个团队已经变得太大了。 Yann LeCun（图右，现任Facebook首席AI科学家， ） 尽管如此，AI团队的工作对公司来说仍然特别重要，因为它会确保“社区的安全和完整性”，Schroepfer说。防止社交网络上出现虚假、误导信息或危险活动，这已经成为Facebook的准则。所以，AI团队的座位距离扎克伯格仍然只有几步之遥。 原文链接： https://medium.com/the-new-york-times/why-a-i-researchers-at-google-got-desks-next-to-the-boss-218096952831 Have a Great Definition 
96,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657917&idx=1&sn=d4a799dbcc64183169dbd0e0d411c9ab&chksm=bd4c312e8a3bb838edd7202e416e7c451c48785c31c6e9679fbf72c7949741b082f0dff6db1d&scene=0,谷歌重磅：全球首个72量子比特处理器，有望实现机器学习硬件加速,当地时间3月5日，谷歌在美国洛杉矶举行的美国物理学会年会上介绍了最新研究成果，新量子处理器Bristlecone。谷歌研究中心同时发布博文，宣布了谷歌量子AI实验室的这一研究进展。 谷歌称，这一最新的处理器将为谷歌研究量子比特技术的系统错误率以及可拓展性提供一个测试平台，其也将在机器学习上有很好的应用。 谷歌对量子计算的研究由来已久，早在2016年8月，谷歌的工程师就曾经低调发布了一篇论文《Characterizing Quantum Supremacy in Near-Term Devices》，描述了他们的量子计算研究计划。 根据这篇文章， 目标是打造世界上第一个可执行经典计算机无法执行的任务的量子计算机。 这一研究工作一直由谷歌的量子AI实验室进行，其目标是搭建一个可用于解决实际问题的量子计算机。 而本次发布，让谷歌和全人类离这一目的都更近了一步。 谷歌量子AI实验室对量子计算的介绍： 量子计算融合了20世纪两次重大科学革命：计算机科学和量子物理学。量子物理学是晶体管、激光器和其他推动计算机革命的技术的理论基础。但在算法层面上，今天的计算机仍然使用“经典”布尔逻辑。量子计算同时指硬件和软件层面的设计，在算法层面上，用量子定律代替布尔逻辑。量子计算有望高速实现某些计算，如优化、采样、搜索及量子仿真。 对量子计算感兴趣的读者可点击查看大数据文摘的科普文章 。 谷歌称，其最感兴趣的是 。这是因为在这些领域，许多任务都依赖于解决硬优化问题或执行高效采样。 谷歌创立量子AI实验室的目标就是搭建一个可用于解决实际问题的量子计算机。谷歌的策略是探索短期应用，同时做到向前兼容，即兼容大规模通用纠错量子计算机。量子处理器如果想运行经典的仿真之外的算法，除了需要大量的量子比特，至关重要的是，处理器在读出和逻辑运算（例如单比特门和双比特门）时也必须具有低错误率。 新量子处理器Bristlecone的超导系统是基于门的，目的是研究量子比特技术的系统误差率和可拓展性，为在量子模拟、优化和机器学习中的应用提供一个测试平台。 谷歌最新的量子处理器Bristlecone（左）。在右边的放大示意图上，每个“X”代表一个量子比特，量子比特之间以线性阵列方式相连。 该设备的设计原则保留了谷歌之前的另一研究——9-qubit线性阵列技术（9-qubit linear array）的基本物理特性，其在读出率（1％），单量子比特门（0.1％）和双量子比特门（0.6％）上（最好结果），已经显示出了非常低的错误率。  新量子处理器Bristlecone“超现实”地使用了72个量子比特排成的正方形阵列。 谷歌称，这个数值的选择能够展示量子霸权的未来，通过面编码研究一阶和二阶纠错的使用，促进量子算法在实际硬件上的发展。 2D概念图显示了误差率和量子比特数之间的关系。 Quantum AI实验室的预期研究方向为图中红色曲线，我们希望通过建立纠错量子计算机访问短期应用程序。 谷歌相信，在研究投入具体的应用领域之前，对量子处理器的能力进行量化非常重要。谷歌的理论团队因此设置了一个基准测试工具：通过将随机量子电路应用于器件，并根据经典模拟检查采样输出分布，来分配单个系统误差。 如果一个量子处理器运行误差足够低，它就能够在一个定义明确的计算机科学问题上超越经典超级计算机，这一优势被称为量子霸权（quantum supremacy）。这些随机电路需要有足够多的量子比特和计算长度（深度）。 尽管这个目标还没有人达到，但据谷歌最新计算，其量子霸权可达49个量子比特，电路深度超过40个，双量子比特错误率低于0.5％。谷歌相信，量子处理器在超级计算机上的实验性运行将成为这个领域的分水岭，这也仍然是谷歌关键目标之一。 科学家Marissa Giustina正在位于Santa Barbara的量子AI实验室安装Bristlecone芯片 谷歌表示，正在努力使Bristlecone中的72个量子比特达到与9个量子比特设备相近的误差率。Bristlecone这样级别的设备要以较低的系统误差操作，需要在软件、控制电子设备和其本身的处理器等全套技术之间进行协调。如果真的实现了，那么谷歌就为构建更大规模量子计算机提供了一个有力的证明 。 Google Research博文链接： https://research.googleblog.com/2018/03/a-preview-of-bristlecone-googles-new.html Have a Great Definition 
97,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657898&idx=1&sn=1d67fa6ed40fa06ad1b35256d8482f22&chksm=bd4c31398a3bb82f733cbf469b4a38a4eb18af17d5e6e67d5d06030e2f212b2e2afa1ecb6200&scene=0,吴恩达导师Michael I.Jordan学术演讲：如何有效避开鞍点（视频+PPT）,机器学习中，非凸优化中的一个核心问题是鞍点的逃逸问题。梯度下降法（GD，Gradient Descent）一般可以渐近地逃离鞍点，但是还有一个未解决的问题——效率，即梯度下降法是否可以加速逃离鞍点。 加州大学伯克利分校教授Michael I. Jordan（吴恩达的导师）就此做了研究，即，使用合理的扰动参数增强的梯度下降法可有效地逃离鞍点。在去年旧金山的 O'Reilly和Intel AI Conference ，他就此研究做了一次演讲。 此前，大数据文摘曾发出过Michael I. Jordan在清华手写板书的授课笔记（ ），非常受欢迎，这次，让我们看看他是如何解读自己的学术成果的。 Michael I. Jordan：如何有效避开鞍点 时长13分钟，带有中文字幕 暂时无法观看的小伙伴可以下拉看文字版 后台回复 “鞍点” 获取演讲PPT合集。 很荣幸来到这里。我刚从中国飞回来，大约是昨天午夜时分，我感觉好极了。如果有一个地方人们谈论AI比旧金山还多，那就是中国。这很神奇吧。与之相反，如果我去参加一个理论会议，我会做一个关于系统的演讲，但我更倾向在系统会议演讲中和大家探讨理论研究。我认为拓展视野并意识到所有的问题是非常重要的。 我们处在一个非常经验主义的人工智能和机器学习的时代，比我的职业生涯中的任何时刻都更重视经验。这很好，有很多新的探索，但是我们的理解理论远远落后。所以我在自己的研究中更多地关注这个问题。今天我想给大家讲一些研究结果。Chi Jin主导这项研究，他是我在伯克利的研究生，还有Ronge Ge，Praneeth Netrapalli，Sham Kakade几位学生参与了这个项目。 论文链接： https://arxiv.org/abs/1703.00887 我要讲的是鞍点，以及如何有效地避开它们。 你们都知道局部最小值是我们的克星，所以我一直在讨论这个问题，那就是如何避免局部最小值。但问题并不明显，有很多机器学习的问题没有局部最小值。即使你有局部最小值，梯度下降似乎可以轻松回避它们。神经网络如果足够大的话就会有足够的冗余，要做到这一点并不难。达到零就是全局最优解。这就是你们在实践中看到的。也许这并不是真正的问题。如果一个回路的局部最大值不是问题，它的鞍点是剩下需要解决的。 鞍点在这些体系结构中大量存在，不论是在简单的模型还是在神经网络中。它们会导致学习曲线变平。你会经常看到一个学习曲线下降很快，之后很久都是平的。这就是靠近鞍点的表现。最终你会逃离鞍点。继续下去，你可能会碰到另一个鞍点。你会看到一个学习曲线，它这样上升和下降。某种意义上，这不是问题，如果你最终得到正确答案。 特别是如果你没有那么多时间来运行你的算法。所以你可以在多维度中理解这个。 让我给你们看一张鞍点的图片。在左边我们有一个“严格”的鞍点。有一个负曲率的方向，这个负曲率是严格小于零的。在右边，它是个非严格鞍点，但第二个特征值严格为零。 如何逃离鞍点？如果你沿着中间部分往下走，你最终会摆脱它，但这可能需要很长时间。 就像现在一般的研究中一样。在这种情况下，可能只有一条出路，其他的方向都不行，所以要找到逃逸的方向可能要花很长时间。当维度越来越大的时候，就有问题了。基于梯度下降的算法可能会有麻烦。 如果你有一个海森矩阵，这个问题将会消失，因为你会知道所有的方向，但你必须计算一个海森矩阵的特征向量。这两种情况都不好，因为它太复杂了也太慢。所以，梯度方法是个问题。 在这个领域还有很多有待证明的东西，这些是最近的结果。对于连续时间上的梯度流，梯度下降将会逐渐避开鞍点。 所以你需要考虑这个问题。 梯度下降可以用指数时间来逃离鞍点，这是另一个新结果。我们都喜欢随机评级，因为每次迭代都很简单。有一篇重要的论文证明在多项式时间内你会逃离鞍点，这是最近的工作。多项式级的复杂度是不好的。这对理论学家来说是好事，但这对实际的操作是不利的。所以这是一个开放问题，我们能否证明一个更强的定理，来理解为什么梯度下降通常是好用的。 我们来回忆一下梯度下降是什么。现在我们来讨论一个凸问题，是一个类似碗的形状。我们希望寻找f(x)的最小值。这是梯度下降方程。可以证明它是收敛于全局最优解的，以1/k的速率，对于平滑函数。 这是一个惊人的数学事实。也许并不是所有人都这样认为，但事实的确如此。这意味着你可以运行无限维度的梯度下降，仍然不会减慢它的速度。计算梯度可能需要与维度数量成正比的时间，但只是线性的在维数中。但这是针对凸问题。 针对一个非凸的例子，我们不讨论最终值。我们将梯度设置为0，你可以证明你会得到一个驻点。但它可以是局部极小值或局部最大值或鞍点。当前最让我们困扰的是鞍点，我们到达和逃脱鞍点的速度。 现在最流行深层神经网络，在某种意义上是非凸的。但是实际操作中有很多重要的问题，这些问题都没有虚假的局部最小值，这很好。它们有一个全局最优值。所有的鞍点都是严格鞍。也就是说，你可以漏出，找到一个有负曲率的方向。 所以对于非凸问题，如果我们可以解决基于梯度方法的收敛问题，就是作为鞍点条件的一个函数，你就可以为所有这些问题求得全局的收敛速度，这是我们今天要做的。但是如果你喜欢神经网络，那么你就得注意了。 让我们看下一般非凸性问题。这是Nesterov提出的定理。在一阶驻点，假设我们有一个具有利普希茨梯度的函数。如果你懂些数学知识你会发现，梯度在x1和x2之间变化不大。一阶驻点不意味着梯度完全等于零，而是渐进收敛的，相当于我们在零点周围放了一个半径为埃普西隆的小球。问题是击中那个球需要多长的时间。 对于任意的埃普西隆，这就给了我们一个达到最优值的收敛速度，这个速率是由Nesterov得出的，他证明收敛速度正比于1/e的平方。这是一个很好的速率，它不是非常快但是已经足够好了，但这里的关键在于公式中维度不是必须的， ，这是梯度下降一个有意思的特性。 让我们来谈谈这次演讲的主要内容，那么二阶驻点有怎样的性质呢？我们对鞍点尤其感兴趣，但我们同时也很关注局部最小值，我们稍微增加光滑度，可以证明一个定理，我们引入海森-利普希茨性质，很明显二阶驻点是一阶驻点的扩展，这个梯度同样趋近零且不等于零，同时海森矩阵的最小特征值不严格大于等于零。我们给自己放松了一个小区间，从而又得到了一个收敛速度，所以可以看看我们达到二阶驻点速度有多快。 当梯度很小的时候我们会加入噪声。这一步操作频率很低，大概每t个时间步进行一次，t是一个超参数，在这个定理中，我们通过从一个球状区域中随机采样实现噪声的注入，我们也可以做其他分析，但是这里简化了。这不是传统意义上的随机梯度，而是每一步都注入噪声的随机梯度。以上就是我们得出下面定理的背景知识。这个定理非常美妙，所以我认为这个算法也是很值得仔细研究的。 这就是我们的主要成果，即使我设置了这些约束，我们仍然可以得到一个正比于1/e平方的收敛速度，和梯度下降的性能是一样的，维度依赖也被消除了一点。这是一个标准的学术界的小技巧。这和之前梯度下降的性质是一样的，除了这里的大O里有一个跟d相关的因子，但它不是d的多项式，它是对数多项式，是 。所以对我来说这给出了一个解释，就是为什么扰动梯度下降算法能高效解决高维问题。维度的对数不算大问题，这是一个很小的数字，你可以通过高速计算机处理它。 这是一个出人意料的结果。我们再来总结一下，这是经典梯度下降算法的研究成果，这是扰动梯度下降的结果，公式是一样的，这里我们没有写出那个关于d的对数的四次方的因子，现在我很怀疑四次方是不是最终的答案，我猜接下来的一两年里会取得新进展，使得对数的阶数降下来，达到一阶对数或者二阶对数，但是现在我们只能证明出对数的4次方这个结果。 这里简要地介绍一下此前的工作，最近的很多研究都是2014年 2015年 2016年做出的，并且到今天依旧十分热门。如果你了解海森矩阵的话，在幻灯片的底部你可以看到一些经典的结果，在小维度问题中，不包括现代机器学习中的神经网络，你可能想要计算海森矩阵，然后计算它的特征向量 它会告诉你脱离的方向，在这种情况下可以达到多快呢，最快速度可以达到1/e的1.5次方，只比埃普西隆的平方好一点点，不是特别好，所以这并不值得，你可以把这个结果先记下来。 在幻灯片顶部，你可以看到一系列引出我们这个结果的工作，Ge et al.证明收敛速度是维度的多项式复杂度，很美妙的结果，改变了我们一直认为指数级是最优结果的看法。Levy后来又将这个结果提升为d的三次方，更加精确，但仍然不是很令人满意，当d达到100或者1000的话这个结果还是不够好。然后我们的工作将它降到了对数级，所以我打算向你们展示，我不会在这里证明它，论文中详细证明了，你们可以去看看论文，对于数学功底很好的人我想说这实际上是一个非常有意思的理论，它运用了概率论，尤其是随机扩散过程，所以实际上包含了一些微分几何的东西，用概率理论证明。 这里我只给你们一个概念，大家都知道鞍点周围有一个饼状区域，如果你进入了这个区域情况就会变得很糟糕，你会被困在里面，你将会在鞍点上停留很长时间，这个时候有一些随机扰动的话就可以把你踢出去，你想确保你不会一而再再而三地陷入困境，这个理论就是关于如何去远离这个饼状区域。 我们都知道饼状区域的存在，并且我们可以分析它，但是为了得到一个更快的收敛速度，人们会用一个更加扁平的饼状区域代替原先的，但扁平化会使得原先的区域变得更广更大，它覆盖了整个原先的饼状区域，但现在变得很大。这就给出了多项式d的三次方的收敛速度，所以你不能这样做，你不能用一个扁平的饼状区域来代替它，你要用真正的饼状区域，但这就涉及到一些很深奥的微分几何，所以我们转而使用扩散过程。 这个过程是指你从两个点开始，这两个点中间的距离正好是饼状区域的宽度，只要这两个点在饼状曲面上位置任意，你会问，他们要多久才能分开，这是一种证明风格，用到了几个内部随机过程参数以及微分几何，所以如果你真的想要去解释这些东西的话，你肯定会用到这些数学知识。 我们虽然知道这一点，但我认为这是我们想要继续深入所必须的一种观念之一。 我来总结一下，如果我们不知道这个区域的形状应该怎么做。对我们来说，理解它是很重要的，但是我们已经证明了它很薄，我认为还需要进一步的研究，如果我们想把这个对数阶数降到平方或者更低的话，或许我们需要更高深的微分几何知识以及分析，但是我认为想到新的思路不会很困难。 扰动梯度下降，它确实能够脱离鞍点，高效性只是它的一方面，所以这有些振奋人心，你不需要去计算二阶信息，所以我们这种基于梯度的方法是很优秀的。现在我们分析下扰动版本 ，如果你分析随机梯度会怎么样，你们对于加速算法以及诸如此类的算法有什么看法，如果你们希望了解更多的话，这里有一篇博客是我的学生Chi Jin和我在一周之前写的，你可以就此继续研究。非常感谢。 博客链接： http://www.offconvex.org/2017/07/19/saddle-efficiency/  后台回 复 “鞍点” 获取演讲PPT合集 没听够？参加今年北京的O'Reilly和Intel AI Conference还不晚~ 本周五（3月9号）结束早鸟票优惠，扫码使用大数据文摘专属8折优惠码WENZHAI报名，享受折上折 👇 【今日机器学习概念】 Have a Great Definition 
98,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657932&idx=1&sn=bd1b1f6ed032f8ee5c57cbfd08d9dfbb&chksm=bd4c315f8a3bb849eca8209881aa5bd960424aec1f57cf54c57d50eea461ae4ea6d4b6b21044&scene=27,算法识别团伙犯罪引发巨大争议，研发者：我只是个工程师,"“我只是一个工程师。” 面对自己开发的算法可遭受到的道德指责，哈佛大学的一位论文作者这样公开回应道。 可能连他自己也没有想到， 在这波讨论中，二战时一位德国火箭科学家Wernher von Braun的故事持续被提到：在被问及“你的火箭要发射到哪里”时，这位研究者回复道，“That's not my department! （这不归我的部门管） ” 技术人员是否应该在研究之外分出心力，了解自己研究背后更深的影响呢？ 这一在战争年代常 引发巨大争议的话题，在人工智能的威胁日渐露出的今天，又被重新提上辩论场。 我的征途是星辰大海，但是不小心打到了伦敦 引发讨论的是哈佛大学Crowd Innovation Lab参与的一项研究—— 在美国，当有人殴打行人、抢劫商店或冷血杀人时，警察需要派遣一个特别的执法小组，调查此人是否隶属某个犯罪团伙成员。现在，一种新的算法正在试图自动化识别团伙犯罪。 这一研究引发了另外一批科学家的反对：其非但不会减少犯罪率，反而会削弱人们对社会的信任，或者将无辜的人打上犯罪团伙成员的烙印。 2018年2月，研究人员在新奥尔良举办的人工智能、道德与社会（AIES）会议上发表了这一最新成果。 论文链接： http://www.aies-conference.com/wp-content/papers/main/AIES_2018_paper_93.pdf 后台对话框内回复 即可下载这篇论文。 争议声自演讲现场开始发酵。 一位听众、谷歌软件工程师Blake Lemoine当场愤然离席。他表示：“这个研究成果无懈可击，但研究人员是否考虑过可能出现的意外副作用？” 多年来，科学家们一直在使用计算机算法来绘制犯罪网络图，或者预测未来犯罪的地点和时间，这种做法被称为警务预测。但有关将犯罪标记为与犯罪团伙的研究很少。 这一新算法中，研究人员可以根据四种信息将罪犯识别为犯罪团伙成员： 。加州长滩市检察官Doug Haubert表示，此类分析有助于在罪犯得到充分调查之前对犯罪行为进行定性，这改变了警方原有的反应方式。 为了对犯罪行为进行分类，研究人员发明了一种特别的神经网络算法。一个神经网络是由很多层计算单元组成的，这种数据处理的方法使人联想到大脑的神经元。这种新的机器学习形式可以根据反馈情况对算法进行改进、优化。  在该研究中，研究人员利用加州洛杉矶警察局（LAPD）2014年至2016年期间的数据，在50000多起犯罪团伙性质和非犯罪团伙性质的凶杀案、严重袭击案和抢劫案数据上训练了算法。 研究人员在另一组LAPD数据上测试了他们的算法。这个网络是“部分生成的”，因为即使没有收到警官关于犯罪的描述，模型也可以使用上述四个因素来填补缺失的信息，然后用所有的片断来推断犯罪是否与犯罪团伙有关。 与未采用这种新方法的精简版神经网络相比，部分生成算法将错误率减少了近30％。研究人员还没有测试他们的算法是否比训练有素的官员的判断更准。 “这篇论文很有趣”，卡迪夫大学研究犯罪数据的计算机科学家Pete Burnap说，“但是，尽管预测可能有用，还是不可能比警官们的直觉更准确”。  Haubert对此表示赞同，但他表示，借助数据建模有时可以产生“更好更快的结果”，这样的分析“在可以获得大量数据的城市地区尤其有用”。 但是， Lemoine在AIES会议问答环节提出了担忧。 更进一步的担忧是， 当时，哈佛大学的一位计算机科学家Hau Chan正在介绍这项工作，他回答说，他不确定新工具将被怎样使用。 “ ”，他说。 Lemoine引用了一首关于战时火箭科学家Wernher von Braun的歌曲的歌词：“ ”随即愤怒地走了出去。 Wernher von Braun 被涉及的部分歌词： Don't say that he's hypocritical Say rather that he's apolitical ""Once the rockets are up, who cares where they come down? That's not my department!"" says Wernher von Braun Lemoine随后接受了Science的采访，“我们该不该为警察建立工具，这并不是我想讨论的重点。”Lemoine说（他特意指出，他是以个人身份发声，而不是代表谷歌）。  “我认为， 。” 这篇论文的另外两位作者也就此问题接受了Science记者近20分钟时间的采访。“目前这 很难说”，加州大学洛杉矶分校的人类学家Jeffrey Brantingham说。 “这是一项基础研究”，南加州大学的计算机科学家Milind Tambe表示同意。 采访中，这两位研究人员更乐于谈论的是部分生成神经网络的其他应用：分类野生动物犯罪，改善草场管理，预测哪些人最擅长向朋友传播公共卫生信息。 而对于算法该如何使用，他们一直三缄其口。 素材来源： http://www.sciencemag.org/news/2018/02/artificial-intelligence-could-identify-gang-crimes-and-ignite-ethical-firestorm 【今日机器学习概念】 Have a Great Definition "
99,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657917&idx=2&sn=b3202036c19bd5cfe2848e7024504730&chksm=bd4c312e8a3bb83819580d337a674ee262ce0fa254632e64b8ea291f64a074ade698fcac4f79&scene=0,手把手 | 数据科学速成课：给Python新手的实操指南,"编译：王梦泽、丁慧、笪洁琼、Aileen 数据科学团队在持续稳定的发展壮大，这也意味着经常会有新的数据科学家和实习生加入团队。我们聘用的每个数据科学家都具有不同的技能， 。例如，团队中大多数人都曾研究计量经济学，这为概率论及统计学提供了坚实的基础。 典型的数据科学家需要处理大量的数据，因此良好的编程技能是必不可少的。然而，我们的新数据科学家的背景往往是各不相同的。编程环境五花八门，因此新的数据科学家的编程语言背景涵盖了R, MatLab, Java, Python, STATA, SPSS, SAS, SQL, Delphi, PHP to C# 和 C++。了解许多不同的编程语言在有些时候确实很有必要，然而我们更希望使用一种编程语言来完成大多数的项目，这样我们可以在项目上更容易的进行合作。由于无人知晓一切，一种首选的编程语言让我们有机会互相学习。 我们公司更倾向于使用Python。在开源社区的大力支持下，Python已经成为了处理数据科学强有力的工具。Python容易使用的语法，强大的数据处理能力和极好的开源统计库，例如Numpy, Pandas, Scikit-learn, Statsmodels等，使我们可以完成各种各样的任务，范围从探索性分析到构建可伸缩的大数据管道和机器学习算法。只有对那些较宽松的统计模型我们有时会将Python和R结合使用，其中Python执行大量的数据处理工作和R进行统计建模。 我的理念是通过实践来学习，因此为了帮助新数据科学家使用Python进行数据科学研究，我们创建了Python数据科学（速成）课（Python Data Science (Crash) Course）。这门课的目标是使我们的新员工（也包括其他部门的同事）以互动的方式和自己的节奏来学习解决实际的业务问题。与此同时，更有经验的数据科学家可以回答任何问题，但也不要小看从StackOverflow或者图书馆的文档中寻找答案的的技能，我们也当然愿意向新数据科学家传授这项技能！ 在文章中，我们会按阶段来介绍这个实践课程。 阶段一：学习Python的基础知识 显而易见，第一步是学习Python这个软件，即学习Python语法及基本操作。幸运的是，如果你能处理好代码缩进的话，Python语法就不没那么难了。我在使用Java编程语言时无需考虑注意缩进问题，然而当我之后开始使用Python时在缩进上容易出错。   因此，如何开始学习Python？由于我们更喜欢通过实践来学习的方式，所以我们总是让新员工从Codecademy Python课程开始。Codecademy提供了交互式的Python课程体验，无需担心安装软件会麻烦，可以在浏览器中直接学习使用Python。 Codecademy Python课程用时大约13个小时，完成之后，你应该能够在Python中进行简单的操作。 提示：数据科学家还可以在Codecademy上学习SQL，这门课程也十分重要。 阶段二：在Anaconda环境下本地安装Python 在结束了Codecademy课程后，我们显然会想去开始编写自己的代码，然而因为我们不继续在浏览器中运行Python，需要在我们本地电脑上安装Python。 Python是开源的，并可通过www.python.org.免费下载。然而官方版本只包含了标准的Python库，标准库中包含文本文件、日期时间和基本算术运算之类的函数。Python标准库不够全面，无法进行多样化的数据科学分析， 为了避免单独下载安装所有的库，我建议使用Anaconda Python发行版。Anaconda实际上是与大量的库结合在一起的Python，因此你不需要手动安装它们。此外，Anaconda附带了一个简单的命令行工具，在必要时安装新的或更新现有的库。   提示：尽管默认情况下Anaconda几乎涵盖了所有很棒的库，但还有一些没有包含在内。你可以通过conda install package_name or pip install package_name语句来安装新的包。例如，我们经常在项目中使用进度条库 tqdm。因此，我们需要先执行pip install tqdm语句来完成Anaconda的新安装。 阶段三：使用PyCharm进行简单的编码 安装了Python之后，我们可以在本地电脑上运行Python代码。打开编辑器写下Python代码，打开命令行并运行新创建的Python文件，路径为python C:\Users\thom\new_file.py。 为了使事情变得简单一些，我更喜欢在Pychanm环境中编写Python代码。PyCharm是一种所谓的集成开发环境，对开发人员编写代码时提供支持。它可以处理常规任务， 如果忘记了某处的空格或使用了未被定义的变量名称，PyCharm会发出警告提示。想要使用版本控制系统例如Git来进行项目合作？PyCharm会帮助你。不管怎样，使用Pycham可以在编写Python程序时节省大量的时间，charm名副其实。 阶段四：解决一个模拟的业务问题 假设现在经理提出了一个他面对的业务问题，他希望能够预测用户在公司网站上进行首次点击/参与（例如订阅简报）的概率。在给出了一些想法后，我们提出可以基于用户的页面浏览量来预测订阅转换概率，此外，你构建了以下假设： 为了检验假设是否成立，我们需要从网络分析师处获得两个数据集： • Session数据集 包含所有用户的所有页面浏览量。 1. user_id: 用户标识符 2. session_number: 会话数量(升序排列) 3. session_start_date: 会话的开始日期时间 4. unix_timestamp: 会话的开始unix时间标记 5. campaign_id: 将用户带到网站的活动的ID 6. domain: 用户在会话中访问的（子）域 7. entry: 会话的进入页面 8. referral: 推荐网站，例如：google.com 9. pageviews: 会话期间的页面访问量 10. transactions: 会话期间的交易量 • Engagement数据集 包含所有用户的所有参与活动。 1. user_id:唯一的用户标识符 2. site_id: 产生参与活动的网站ID 3. engagement_unix_timestamp: 发生参与活动的unix时间标记 4. engagement_type: 参与活动的类型，例如订阅简报 5. custom_properties: 参与活动的其他属性   不幸的是，我们有两个单独的数据集，因为它们来自不同的系统。然而，两个数据集可以通过唯一用户标识符user_id来匹配。我已经在GitHub上放置了我用来解决业务问题的最终代码 ，然而我强烈建议你仅在自己解决了这个问题后再去查看代码。此外，你还可以找到创建两个虚构数据集的代码。 代码链接： https://github.com/thomhopmans/themarketingtechnologist/tree/master/7_data_science_in_python 无论我们应用任何统计模型解决问题，都需要预先清洗和处理数据。例如，我们需要为会话数据集中的每个用户找到其首次活动的数据（如果有的话）。这就要求在user_id上加入两个数据集，并删除首次活动后的其他所有活动数据。 Codecademy Python课程已经告诉你如何逐行阅读文本文件。Python非常适合数据管理和预处理，但不适用于数据分析和建模。 Python的Pandas库克服了这个问题。Pandas提供了（数值）表和时间序列的数据结构和操作。因此，Pandas让Python数据科学工作变得更加简单！ 我们的Python代码中的第一步是加载Python中的两个数据集。Pandas提供了一个简单易用的函数来读取.csv文件：read_csv（）。本着学习的原则，我们建议您自己找出如何读取这两个数据集。最后，你应该建立两个独立的DataFrames，每个数据集都需要有一个。 小贴士：在这两个文件中，我们都有不同的分隔符。此外，请务必查看read_csv（）中的date_parser选项，将UNIX时间标记转换为正常的日期时间格式。 任何（大）数据问题中的下一步是减少问题规模的大小。在我们的例子中，有很多与我们问题无关的列，例如会话的媒介/来源。因此，我们在Dataframes上应用索引和选择只保留相关的列，比如user_id（必需加入这两个DataFrames），每个会话和活动的日期（在此之前搜索首次活动和会话）以及页面访问量（假设验证的必要条件）。 另外，我们会筛选出DataFrame中所有非首次的活动。可以通过查找每个user_id的最早日期来完成。具体怎样做呢？使用GroupBy：split-apply-combine逻辑！ Pandas最强大的操作之一是合并，连接和序列化表格。它允许我们执行任何从简单的左连接和合并到复杂的外部连接。因此，可根据用户的唯一标识符结合会话和首次活动的DataFrames。 在上一步中使用简单的合并，我们为每个会话添加了首次活动的时间标记。通过比较会话时间标记与首次活动时间标记，你应该能够过滤掉无用的数据并缩小问题的规模。 如上所述，我们希望预测页面访问量对转换（即首次活动）概率的影响。因此，我们的因变量y是一个二进制变量，用它表示会话内是否发生了转换。由于我们做了上面的过滤（即在首次活动后删除所有非首次活动和会话），所以这种转换按照定义在每个用户的最近一次会话中进行。同样，使用GroupBy：split-apply-combine逻辑，我们可以创建一个包含观察值的新列，如果它是用户的最后一个会话，观察值将为1，否则为0。 我们的自变量是页面访问量。但是，我们不能简单地将会话中的页面访问量计算在内，因为早期会话中的页面访问会影响转换概率。因此，我们创建一个新的列，用来计算用户页面访问量的累计总和。这才是我们的自变量X。 通过Pandas库我们最终得到了一个包含单个离散X列和单个二进制Y列的小型DataFrame。并用（二元）逻辑回归模型来估计基于一个或多个独立变量的因变量的二元响应概率。StatsModels是Python的统计和计量经济学库，提供了参数估计和统计测试工具。因此，它包含逻辑回归函数也就不足为奇了。那么，如何通过StatsModels来拟合逻辑回归模型呢？请自行百度... 技巧1：不要忘记给逻辑回归添加一个常数。 技巧2：另一个非常棒的拟合统计模型（如逻辑回归）库是scikit-learn。 在拟合逻辑回归模型之后，我们可以预测每个累计访问量的转换概率。但是，我们不能仅仅通过交付一些原始数据来将我们最新发现的结果传达给管理层。因此，数据科学家的重要任务之一就是要清晰有效地展示他的成果。在大多数情况下，这意味着提供我们的可视化结果，因为众所周知，一图胜千言... Python包含几个非常棒的可视化库，其中MatplotLib是最知名的。而Seaborn是建立在MatplotLib上的另一个很棒的库。 MatplotLib的语法大概是以前使用过MatLab的用户所熟知的。但是，我们倾向选择Seaborn，是因为它提供更漂亮的图表而且外观很重要。 我们通过Seaborn得到了模型拟合的可视化结果，如下所示： 我们可以很好地利用这个可视化结果来证明我们的假设是否成立。 最后一步是就验证我们提出的假设是否成立。回想一下，我们认为更多的网页访问量导致首次活动的可能性更高。 首先，我们从以前的可视化结果中可以看出，假设是成立的。不然，预测的概率也不会单调递增。尽管如此，我们还是可以从拟合的模型总结中得出同样的结论，如下所示。 我们看到，统计结果中，pagesviews_cumsum系数在显著性水平为1％时显示为正。因此，这足以表明我们的假设成立，加油！此外，您刚刚已经完成了第一个Python数据科学分析工作！ :) 是不是感觉很棒？快上手试试吧！ 原文链接： https://www.themarketingtechnologist.co/helping-our-new-data-scientists-start-in-python-a-guide-to-learning-by-doing/ Have a Great Definition "
100,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657917&idx=3&sn=cd047a6ebe3b4fab7d092ba62b898279&chksm=bd4c312e8a3bb838396e9dcc8fad3cecf94c71e6237bc7709a52c0a19ef5dc93467db56cbe08&scene=0,AI大事件 | 机器学习增强人类记忆力，谷歌上线AI速成课，TensorFlow 1.6发布,呜啦啦啦啦啦小伙伴们大家好呀！过去的一周中AI圈都发生了什么？大佬们讨论了哪些问题？研究者们发布了哪些值得一读的论文？又有哪些开源的代码和数据库可以使用了？快快跟随文摘菌盘点过去一周AI大事件！ AI以不可思议的方式击败Q*bert游戏 来源：WWW.THEVERGE.COM 链接： https://www.theverge.com/tldr/2018/2/28/17062338/ai-agent-atari-q-bert-cracked-bug-cheat?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 最近的一个实验展示了一个人工智能代理以前所未有的方式打败了80年代经典游戏Q*bert。它发现了一个让游戏在特定点瘫痪的bug。训练AI代理来发现游戏中可能出现的意外错误也许会成为一个新的游戏维护方式。 使用机器学习解码并增强人的记忆力 来源：WWW.WIRED.COM  链接： https://www.wired.com/story/ml-brain-boost/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 研究人员在患者解决记忆任务时收集了植入患者大脑中电极的训练数据。然后使用相同的电极刺激该患者的神经活动。这样的刺激使患者记忆词汇的能力平均提高了15％。 谷歌的人工智能芯片智能相机现已上市 来源：TECHCRUNCH.COM 链接： https://techcrunch.com/2018/02/27/googles-ai-powered-clips-smart-camera-is-now-available/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI Google将这个产品称为“智能相机”，这是因为设备上部署了机器学习，旨在使体验尽可能简洁。Google表示，通过使用设备上的机器学习，该设备可以捕捉到人和宠物面部表情最合适的瞬间并进行拍摄。 机器学习速成课程（Google） 来源：DEVELOPERS.GOOGLE.COM 这个系列课程是Google推出的15小时以上的机器学习速成课程，包含一系列视频讲座，实际案例研究和动手练习。使用Tensorflow。 研究机会：NLP和转移学习 来源：RUDER.IO 链接： http://ruder.io/requests-for-research/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这篇文章为初级研究人员和那些试图进入研究领域的初学者提供了启发和思路。它收集了一系列有趣的研究课题，重点关注NLP和转移学习。 变体自动编码器简介（视频） 来源：WWW.YOUTUBE.COM 这个视频将简要介绍变体自动编码器，这是一类可以学习以完全无监督的方式压缩数据的神经网络。 神经网络能一直做好物体识别吗？ 来源：AIWEIRDNESS.COM 链接： http://aiweirdness.com/post/171451900302/do-neural-nets-dream-of-electric-sheep?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 如果一切都按照规则进行，图像识别的效果将会很好。但是，只要人们或羊（要识别的物体）做了什么意想不到的事情，这些算法就会显示出它们的弱点。 增加深度可以加速优化吗？ 来源：WWW.OFFCONVEX.ORG 链接： http://www.offconvex.org/2018/03/02/acceleration-overparameterization/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI “深度对神经网络意味着什么？”是深度学习理论中的一个基本问题。理论研究支持的传统观点认为，增加图层会增加表现力，但优化会变得更加困难。然而，事实证明，增加深度有时可以加速优化。 机器人研究概要（OpenAI） 来源：BLOG.OPENAI.COM  链接： https://blog.openai.com/ingredients-for-robotics-research/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这篇文章介绍了OpenAI开源的8个模拟机器人环境和Hindsight Experience Replay算法的标准实现。算法实现可以在基础库中找到。 Lore：如何在15分钟内建立深度学习模型 来源：TECH.INSTACART.COM Lore是一个Python框架，使机器学习可以被工程师使用，并且可以被机器学习研究人员维护。这篇文章将介绍使用Lore设计和部署模型的示例。 TensorFlow 发布 1.6.0版本 来源：GITHUB.COM 链接： https://github.com/tensorflow/tensorflow/releases/tag/v1.6.0?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 新地版本包含针对CUDA 9.0和cuDNN 7预构建的二进制文件，针对非插槽变量的新优化器内部API，对SavedModels导出的改进，对XLA CPU / GPU添加的FFT支持等等。 GANs的Keras实现 来源：GITHUB.COM  链接： https://github.com/eriklindernoren/Keras-GAN?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这个项目对来自各种研究论文的许多GANs进行了Keras实现。其中一些是论文中提出的简化版，但它们仍然是很好的学习资源。 建立具备内在动机和自我感知的代理来学习玩耍 来源：ARXIV.ORG 链接： https://arxiv.org/abs/1802.07442?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 婴儿是游戏的专家，具有在缺乏清晰的外部奖励信号的非结构化环境中进行新颖的结构化行为的惊人能力。作者研究了好奇心驱动的内在动机，并提出一个“世界模型”网络，学习预测代理人行为的动态后果。同时，他们训练了一个单独的“自我模型”，使代理能够跟踪自己世界模型的误差图然后使用自我模型来对抗发展中的世界模型。 回归基础：Atari的标准演进策略 来源：ARXIV.ORG 链接： https://arxiv.org/abs/1802.08842?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 作者从定性上证明，ES算法与传统的RL算法相比具有非常不同的性能特征：在某些游戏中，他们学习利用环境的能力更强，而其他代理则可能陷入次优局部最小值。因此，将它们的优势与传统RL算法的优势相结合可能会导致现有技术的新进展。 保罗万象的网络（Schmidhuber） 来源：ARXIV.ORG 链接： https://arxiv.org/abs/1802.08864?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 对日益普遍的问题求解器进行渐进式培训，不断学习解决新的任务，而不会忘记以前的技能。问题求解器是称为ONE的单个递归神经网络，并且可以以各种方式进行训练，例如， 黑盒优化，强化学习，人工进化以及监督和无监督学习。 Have a Great Definition 
101,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657898&idx=2&sn=064356ee244b8bdf4fe6f6374f2ab69b&chksm=bd4c31398a3bb82f703871344a0002adee5aadef2bb0cc392f1175dce3825f2dcc124532d28f&scene=0,BlockChange | 区块链将如何颠覆金融服务业,大数据文摘作品 编译：王梦泽、GAO Ning、小鱼 区块链和金融天然的密不可分。 加密货币技术正处于高速发展中，尽管有一些政策的声音，但像比特币和以太币等这些流行的加密货币，大家仍对其保持着很高的关注度。   这两种货币的技术核心都是安全性极高的加密数字分布式账本，即区块链。 本质上来说，区块链是一种数字分布式账本，将加密货币的交易记录按时间顺序在账本中公开记录。 随着加密数字货币的迅速发展，银行业对区块链的兴趣也与日俱增，银行资助的区块链项目也在不断增加。   目前正在进行的大型项目包括IBM的Hyperledger Fabric项目、公用事业结算币（USC）项目以及R3区块链联盟项目， 为何银行业需要区块链？   目前，不同银行间通过签订协议进行相互交易，就像从商店购买东西一样繁琐。举一个常见的例子，一家银行同意从另一家银行以特定的现金价格购买一些股票，通常需要耗时很多天，还可能遇到某一方违约的交易风险， 就这样一笔简单的交易过程却繁琐而缓慢 。Oliver Wyman的报告中指出，每年结算期用来偿还交易失败的费用就会使金融业损失650-800亿美元。 区块链项目因其数字性质能够确保上述操作安全、及时地处理，这有可能会减少甚至消除结算时间。与此同时，银行支持的区块链项目对于稳定全球货币汇率速度、增加交易安全性等方面都将有所帮助。在如此多的优势之下， IBM Hyperledger Fabric项目 IBM的Hyperledger Fabric项目是一个采用区块链进行国际支付的贸易融资平台。其中7个最重要的赞助商包括德意志银行(Deutsche Bank)、汇丰银行(HSBC)、比利时联合银行（KBC）、法国外贸银行（Natixis）、荷兰合作银行(Rabobank)、法国兴业银行(Rabobank)和意大利联合信贷银行(Unicredit)。IBM的区块链平台在IBM云端运行，为各方间的互联互通提供了一个安全性极高的交易环境。   该项目的设计具有高度的可扩展性， 十月中旬，IBM公布了与区块链创业公司Stellar的合作关系，将Hyperledger Fabric项目的影响力扩大到了全球新水平。 公用事业结算币（USC） 世界上最大的六家银行，巴克莱银行、加拿大帝国商业银行、瑞士信贷银行、汇丰银行、三菱日联金融集团和道富银行均已宣布支持由瑞银集团和Clearmatics（伦敦的区块链初创企业）牵头的公用事业结算币(以下简称USC)，还有一些其他的行业巨头也已经宣布支持该项目，包括纽约梅隆银行、德意志银行和桑坦德银行。   USC专门处理传统银行使用区块链技术进行交易的问题，它是一种更高效的交易工具。此外，USC有中央银行的现金支持，预防发生违约和信用风险的问题，这解决了货币支持的问题。USC拥有如此多的抵押利息，这些保障措施功不可没，它使得银行能够参与到相对年轻的数字货币生态系统中。USC无疑是银行业采用金融科技的标志，它确保了全球范围内标准化的区块链技术的广泛使用。 R3区块链联盟 R3区块链联盟是银行主导的区块链领域内另一个重要项目，在2017年5月获得了1.07亿美元的融资，联盟成员包括淡马锡、SBI 集团、美银美林和英特尔与一些行业巨头如Wells Fargo和ING等。 R3联盟的一个主要项目是开发Corda平台，未来计划建立一个专门针对金融机构的基础架构网络，来构建他们自己的分布式账本的应用程序和服务。上述计划表明这些银行现在已经有了自己的区块链开发团队，未来该团队将会继续壮大。R3联盟也关注政府对区块链的认可程度，   上述项目针对当前区块链在金融行业的应用给出了可靠的潜在解决方案，表明了银行业在将区块链完全融入到现有的基础设施中所做出的巨大努力。行业消费者和参与者们对未来几个月银行业将迎来的巨大变化而深表期待。 原文链接： https://techcrunch.com/2018/01/28/bank-based-blockchain-projects-are-going-to-transform-the-financial-services-industry/ 【今日机器学习概念】 Have a Great Definition 
102,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657848&idx=1&sn=fc7d6988b8c9ff8151a3d3612c119bfa&chksm=bd4c31eb8a3bb8fd8c52b34c07a4d4f8bf39f58d33434b6044cabfcc8946f3feb6731c721d2b&scene=0,量子计算101：浅谈其需求、前景和现实,大数据文摘作品 编译：Zoe Zuo、张南星、元元、Aileen 量子纠缠这两天忽然火了，还是因为一件与科技互联网都完全无关的桃色事件。 没有看懂的同学可自行搜索 被爱因斯坦称为“幽灵般的超距作用”的量子纠缠，有没有可能发生在两个人类个体身上？ 量子计算到底有什么神奇之处？ 虽然人类历史上的技术革新几经波澜壮阔，依然有一些计算问题在数字革命中遗存下来，似乎无法被攻克。受到这些问题的掣肘，科技上的关键性突破迟迟不能实现，甚至全球经济也为此拖累。 在过去的几十年里，传统计算机的计算能力和处理速度几乎每两年就翻番，但似乎在解决这些一直存在的计算问题上毫无进展。 想知道为什么吗？你去询问任何一个计算机科学家，他们大概都会给出这样的答案：目前的传统数字计算机都是建立在一个局限性颇多的传统计算模型上的。放眼长远，要高效地解决世界上那些最根深蒂固的计算问题，我们必须诉诸一个全新的、更为强大的家伙：量子计算机。 从根本上说， ：前者虽然能跑，但是后者会飞。两种计算机就是如此迥然不同。在这里，我们要仔细看看关键性差异具体体现在何处，深入理解究竟是什么让量子计算机如此出类拔萃。本文不会告诉你量子计算机最根本的工作原理，因为没有人真的知道答案。   传统计算机的硬限制 近几十年来，传统计算机的运行速度与计算能力每两年就翻倍（另一说仅18个月），这就是著名的摩尔定律（Moore's law）。尽管这种惊人的更新速度已经开始放缓，但我们多少可以相信，今天体型庞大的超级计算机会进化成明天物美价廉的笔记本电脑。依照这种发展速度，我们也有理由假定，在可预见的未来，没有什么计算任务是传统计算机完成不了的。然而，除非我们所说的未来是指万亿年之后（或者更久），否则我们的假定对于某些棘手的计算任务来说完全不可靠。      事实上，诸如算出大整数的质因数这样的计算任务，即使是未来速度最快的传统计算机也无法完成。背后的原因在于，计算一个数的质因数的复杂度呈指数式增长。什么是指数式增长（exponential growth）？我们得探究一下这个概念，因为这对于我们理解为什么量子计算机潜力巨大而传统计算机后劲不足至关重要。     有些事物是按照固定速度增长的，有些事物则随着总数量的增加而增长得越来越快。当增长的速度随着总量逐渐增加而变得更快（而非恒定）时，这一增长就是指数式的。 指数式增长是极其强大的，它最重要的特征之一就是， 。 不举例子的话，这个定义可能有点难以捉摸，所以让我们先看个小故事吧。 传说有个国王答应奖励一个聪明人，这个人便向国王请求奖励他大米，规则是在棋盘的第一个格子上放一粒米，第二个格子上放两粒米，第三个格子上放四粒米，然后以此类推，每一个格子上的米粒数须是前一个格子上的二倍。国王欣然应允，但很快就意识到，要填满整个棋盘，所需的大米数量远远多于全国大米存量，而且会花掉他所有的财产。 米粒的指数式增长  任何一个方格上的米粒数量都符合以下规则，或者说公式： 在这个公式里，k指方格的序号，N指该方格上米粒的数量。   • 如果k=1（第一个方格），那么N = 2⁰，等于1。 • 如果k=5（第五个方格），那么N = 24，等于16。 这就是指数型增长，因为这里的指数或者说幂是随着方格的推移而增加的。 为了更进一步解释这个概念，我作了图来表示一个指数型函数是如何随着输入量的增加而增长的。 1的33次倍增 X坐标轴：秒数（=倍增次数），Y坐标轴：百万 由图可知，该函数开始时增长相对缓慢，但没多久就急剧增长到传统计算机在没有足够输入规模的情况下无法计算出来的数字。       好了，故事就讲到这里，我们将目光转向现实世界中的指数问题，比如我们之前提到的那个问题：质因数分解（prime factorization）。 以数字51为例，看看你多久能找到两个不同的质数，使得这两数乘积为51。如果你熟悉这类问题的话，大概只需要几秒钟就能想出答案，3和17这两个质数相乘可得51。 事实证明，这样看似简单的过程却是数字经济的核心，是最安全的加密算法的基础。我们之所以在加密中采用这一技术，是因为质因数分解中涉及的数字会越来越大，导致传统计算机越来越难以分解它们。当数字位数达到一定规模，即使用速度最快的传统计算机进行分解，也要花费数月、数年、数个世纪、数千年，乃至永远。 考虑到这点，传统计算机就算在可预见的未来能够持续实现运算能力每两年翻番（当然这不大可能），也永远无法彻底解决质因数分解的问题。现代科学和数学的一些核心问题同样棘手，包括分子模拟和数学上的最优化问题。任何试图深入这些问题的超级计算机定会以崩溃告终。 下面是来自IBM Research的一幅精彩插图，该图展示了世界上最强大的超级计算机所能模拟出的最复杂的分子F团簇（F cluster）。你能发现（在图片左下方），该分子其实根本不复杂，如果我们想借助模拟更为复杂的分子的方法来寻找更好的药物疗法、研究生物，我们就得另辟蹊径。 分子模拟问题 图注： Chemistry:化学 Nitrogenase enzyme…:参与氮气（N2）转化为铵根（NH4）过程的固氮酶 Simulating this cluster…:模拟该簇已经是传统计算机运算能力的上限 These regions are…:这些区域参与了不同的反应阶段 Iron sulfide clusters…:不同规模的铁硫簇（FexSy） Fe Protein:铁蛋白 MoFe Protein:钼铁蛋白 F cluster:F团簇 P cluster:P团簇 S cluster:S团簇   走进量子计算机 传统计算机在严格意义上是数码系统，纯粹依赖于传统计算原理与性质。量子计算机则是严格的量子系统，相应地依赖于量子的原理与性质，其中最重要的两点就是 （superposition）与 （entanglement），它们赋予量子计算机非凡的能力，以解决那些看似无法克服的难题。   要理解叠加的概念，我们先了解最简单的系统：双态系统（two-state system）。开/关转换（On/Off switch）就是一种普通、传统的双态系统，它总处于开或者关的状态。 一个双态量子系统（two-state quantum system）就完全是另一回事了。当然，无论你何时观测量子系统的状态，都会发现它确实处于开或者关的状态，但是在你没有观测时，一个量子系统是有可能处于开关同时存在的叠加状态的。无论有多么反直觉，甚至超自然，这种状态确实有可能出现。 量子叠加   一般而言，物理学家认为讨论量子系统在受观测之前的状态是没有意义的，比如自旋（spin）状态。有些人甚至认为，观测量子系统的行为会导致量子从不确定的模糊状态坍缩到你测量到的某种值（开或关，向上或向下）。虽然可能无法想象，但不能否认这种神秘的现象不仅真实存在，而且为提高解决问题的能力开辟出一个新维度，也为量子计算机奠定了基础。记住叠加的概念，我们稍后会介绍叠加是如何运用于量子计算的。   叠加存在的可能性不在本文的讨论范围内，但请相信它确实已经被证实了。如果你想要知道是叠加是如何产生的，你得先了解波粒二象性（ Wave/Particle Duality）的概念。     那么我们继续谈谈建造量子计算机所用到的另一个量子原理：量子纠缠。   众所周知，一旦两个量子系统开始相互作用，它们就会不可救药的成为纠缠的伙伴。自此，无论两个系统相距多远，一个系统的状态可以准确反映另一个系统的状态。真的，两个系统之间即使相距几光年，它们仍旧能够及时准确的反映彼此的信息。 这个现象让爱因斯坦都觉得不可思议。（爱因斯坦对此有个著名的描述，“幽灵般的超距作用”）。我们借由一个实例来展示这个现象。 量子纠缠 （ 纠缠的量子比特的状态无法独立来看）   假设有两个电子A、B，一旦让它们以正确的方式相互作用，它们的旋转就会自动产生纠缠效应。自此，如果A向上旋转，那么B就会向下旋转，就像两个小孩在跷跷板两端一样。但是A和B即使在地球两端，亦或是在银河两端，也是这样。无论中间相隔上万英里、几光年，A、B的自旋相反已经被证实。 但是需注意：这些系统的状态没有准确的取值，例如旋转的方向。它们在被测量之前以一种模糊叠加的方式存在。 所以在两个系统相隔几光年远的情况下，我们测量A的行为是否真的能导致B瞬间坍缩到相反的状态？如果确实如此，那么我们将面临另外一个问题：爱因斯坦告诉我们，在两个系统之间传递比如光信号这样的影响因素不可能超越光速。所以这个现象的根本原因是什么？老实说，我们真不知道。现在唯一已知的就是量子纠缠这个现象是真实存在的，而人类可以利用它创造奇迹。     量子计算中量子比特承担的任务就好比传统计算机中比特承担的任务：它是信息的基本单元。但是和量子比特币相比，比特就是彻头彻尾的无趣了。虽然在计算过程中，比特和量子比特都有两个状态（0或1），但是量子比特在计算结束之前能够同时处于0或者1的状态。这听起来有点像量子叠加对吗？这确实就是量子叠加。量子比特是量子系统中最突出的一个存在。 经典比特，量子比特   就像传统计算机建立在一个个比特、开或关的晶体管之上，量子计算机建立在一个个量子比特、上/下旋转的电子之上（如果能够观测到的话）。同样的，串联起来的开、关晶体管形成了逻辑闸，以供数字计算机进行传统方法的运算；而处于上/下旋转状态的电子串联起来，则形成了量子闸以供量子计算机进行量子运算。然而，要把单个电子串联起来（还有保持它们的旋转状态），做起来远比说起来难。   量子算法 图注： 1. 激发电子分化（通过创建2^n个状态的平等叠加态来激活机器） 2. 问题编码（利用逻辑闸给问题编码，把信息写入2^n个状态的相和振幅中） 3. 开启运算（通过物理干涉原理，机器放大正确答案的振幅，缩小错误答案的振幅，从而得到最终答案。有一些问题需要重复步骤2和3）   我们现在走到哪一步了？   在英特尔大量产出承载十多亿晶体管高度集成的传统芯片时，世界上最顶尖的实验计算机科学家还在努力把一小撮量子比特放到量子计算机的“芯片”上。为了体会出人类在量子计算这条路上还有多远的路要走，我们看一个例子： 。 尽管如此，量子计算机已经启程，如果量子计算机的发展也遵循诸如摩尔定律之类的定理，那么我们很快就能发明出有好几百个、甚至是上千个量子比特的“芯片”。十亿个？让我深吸口气冷静一下。 但是请注意，量子计算机其实无需这么多量子比特就能够让传统计算机在某些关键领域上望尘莫及，例如 。 无论如何，就现状而言，几乎每一台量子计算机都是花费上百万美元，几乎疯狂的科学家们通力合作的大项目。一般只有像IBM这样大型IT公司的研发部门，或者像麻省理工这样大型研究型大学的实验物理学专业，才有足够的能力研究量子计算机。 它们需要在接近于绝对零度的超低温下工作（这个温度甚至低于外太空的温度），并且在过程中需要使用精确频率的微波来与计算机中的每个量子比特建立联系。不必说，这种方法难以规模化。但是想想最初传统计算机所用的真空管也不能规模化，我们不要对初代量子计算机太过苛刻。     之所以量子计算机无法形成主流，最大的一个原因就在于顶尖科学家、发明家们还在努力解决错误率高、量子比特少的问题。我们解决这两个问题之后，就可以迅速提高计算机的“量子容量”。这是IBM提出的术语，用来描述每台量子计算机能进行的有效计算量。   量子计算机的运算能力不只取决于增加量子比特数。量子容量，方块体积的大小与有效量子计算量成正比。 图注： 图中x坐标轴：量子比特（递增） 图中y坐标轴：误差率（递减） 图中灰色箭头：减少误差率可以提高量子计算机运算能力 - 量子比特增加： 0 - 误差率减少：10x - 量子容量增加： 24x 图中红色箭头：在误差率高的情况下，提供量子比特数不能提高量子计算机运算能力 - 量子比特增加： 100 - 误差率减少：0 - 量子容量增加： 0 如果你想要用量子计算机来解决实际问题，它们需要在很大的量子状态空间中进行搜索。量子比特的数量很重要，误差率也同样重要。在实际设备中，误差率取决于每次操作正确与否，也取决于解决问题所需操作数量，以及处理器如何执行操作。这里我们提出“量子容量”这个数量术语，来整合上文提出的所有因素。可以将这个数量值视为代表机器可以有效搜索的问题域的大小。 简而言之，想要量子计算真正起飞、量子驱动的Macbook能够进入大众生活，我们需要更多的量子比特和更少的错误率。这需要一定的时间，但至少我们知道我们的目标，以及我们面临的障碍。   迷思还是解析   虽然量子计算机能够轻松完成传统计算机力不能及的事，但其实我们并不知道原理。如果这让你失望，想想我们确实发明了初代量子计算机，并且牢记这个词——“量子”。近一个世纪，人类已经利用量子力解决了许多问题，但我们确实不知道它们是如何做到的。 作为量子家族的一份子，量子计算同样扑朔迷离。《量子计算和量子信息》的作者Michael Nielsen 认为， 。毕竟，如Nielsen所言，如果能够有一个直观的解释来描述量子计算机是如何工作的（即你能想象出来的），那么传统计算机也能模仿这个范式。但是如果传统计算机也能模仿的话，那么这个模型就无法真正准确地描述量子计算机，因为我们对量子计算机的义就是，量子计算机能做到传统计算机无法做到的事情。 根据Nielsen的解释，量子并行是目前最受欢迎的量子计算假说。由于以后你将会听到很多量子并行的故事，所以暂且就先简单了解一下。量子并行最基本的一个论点就是， ，而数字计算机只能一个挨一个的读取。Nielsen 认为这部分解释大致合理。 然而，Nielsen极其反对后半段解释，即量子并行假说认为量子计算机能够在这所有的结果中选出最佳的一个。他坚持认为量子计算机在屏幕之下所做到的事情，和其他量子系统一样，是我们所不可能弄懂的。我们可以看到输入和输出，但是中间发生了什么永远将是谜团。   原文链接： https://towardsdatascience.com/the-need-promise-and-reality-of-quantum-computing-4264ce15c6c0 【今日机器学习概念】 Have a Great Definition 
103,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657848&idx=2&sn=4e5eee751890515ac1b0cbce37647fc5&chksm=bd4c31eb8a3bb8fd1f72abdece938e96bec5bca1edeee82c0a958fdcb552fae456ab75fb8549&scene=0,重磅译制 | 更新：牛津大学xDeepMind自然语言处理 第7讲（上）条件语言模型,大数据文摘重磅课程汉化《牛津大学xDeepMind自然语言处理》 本周更新至：Lecture 7 条件语言模型（1） 马上观看👇 点击文末 ，即可免广告观看 牛津大学Deep NLP是一门关于自然语言处理（NLP）的高阶课程。课程由 和 （AlphaGo的开发机构）联合开设，是牛津大学计算机系2017年春季学期最新课程。由Phil Blunsom主讲，同时邀请到多位来自DeepMind和NVIDIA的业界讲师来做客座讲座。 大数据文摘已联系课程主讲人取得翻译授权，并联合北京邮电大学模式识别实验室 组织了视频汉化， 发布。 课程视频【中文字幕】学习地址： （连载中，请收藏！点击文末 ，可直接加入学习） http://study.163.com/course/introduction/1004336028.htm 牛津大学课程页面（所有资料汇总）： https://github.com/oxford-cs-deepnlp-2017/lectures 本课时PPT精华 后台对话框内回复“ NLP ”获取本课时PPT 后台对话框内回复“ NLP ”获取本课时PPT 《MIT6.S094深度学习与自动驾驶》 课程 连载中 ，复制打开链接免费加入学习： http://study.163.com/course/introduction/1004938039.htm 《斯坦福CS231n深度学习与计算机视觉》课程已更新完毕，李飞飞与Andrej Karpathy（现任Tesla AI部门主管）主讲，已有近9万人参与学习，复制打开链接免费加入学习： http://study.163.com/course/introduction/1003223001.htm 本期工作人员 翻译 李楠  闵峰  乔一宁  张世平   刀哥  momo  无敌乔卡特 终校 彭俊逸  蒋宝尚 项目管理 龙牧雪  李楠 顾问 张闯  寒小阳  汪德诚 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 
104,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657870&idx=1&sn=3dac99aa2e157dbc1a8393c143987f46&chksm=bd4c311d8a3bb80b267199490f840da806b6e17ce448ba7aa6c24b0d7f3394c1e37d706b94bd&scene=0,为什么说去中心化很重要,"编译： 惊蛰、 、 小鱼 去中心化是与中心化相对的一个概念，简单的来说中心化的意思，是中心决定节点。节点必须依赖中心，节点离开了中心就无法生存。去中心化恰恰相反，在一个分布有众多节点的系统中，每个节点都具有高度自治的特征，每一个节点都是一个“小中心”。 随着网络服务形态的多元化，去中心化网络模型越来越清晰，也越来越成为可能。 互联网的前两个阶段 在互联网的第一个时代——也就是20世纪80年代到21世纪初，互联网服务建立在互联网社区控制的开放协议上。当了解到互联网固定的规则后，用户和组织就增加了他们在互联网中的存在感。同时期，包括雅虎，谷歌，亚马逊，Facebook，LinkedIn和YouTube在内的大公司都建立了大量的网络资产。在这个过程中，像AOL这样的集中式平台的重要性大大降低了。 在互联网的第二个时代，即从21世纪初到现在，盈利的科技公司中最有名的几家：苹果，Facebook和亚马逊（Google, Apple, Facebook, Amazon，即GAFA）构建了快速超越开放协议功能的软件和服务。 最终，用户从开放式服务迁移到这些更复杂的集中式服务上。即使用户仍然会用开放协议访问网络，他们也多半会通过GAFA四家公司提供的软件和服务进行访问。 这么做的好处是，通过出色的技术让数十亿人获得了非常好的体验，而且其中多数应用都可以免费使用。坏处是，初创公司、创业者和其他组织想在互联网领域分一杯羹就变得非常困难， 这一事实反过来又扼杀了创新趋势，使互联网不再那么有趣和活跃了。中心化系统也会造成社会紧张关系的普遍化，包括假新闻，系统机器人，没有用户言论自由的平台，欧盟隐私法和算法偏见等等。这些具有争议的情形在未来几年将会加剧。 互联网第三阶段：Web3 中心化系统的用途之一就是有利于政府对大型互联网公司施加监管。这样的监管建立在新出现的网络和过去的通讯网络（电话，广播和电视网络等）非常相似的基础上。但事实上，基于硬件的通信网络与新出现的基于软件的网络有本质上的不同。基于硬件的网络一旦建立，几乎无法重新架构，而基于软件的网络可以通过企业创新和市场力量进行重新架构。 互联网是基于软件的高级网络，其核心层相对简单，由数十亿个完全可编程的计算机组成。 连接到互联网的计算机都可以自由运行用户选择的软件。任何你想要表达的内容，加上正确的激励措施，都可以通过互联网迅速传播。所以说，互联网就是技术创新和设计碰撞产生火花的地方。 互联网仍处于发展初期：互联网核心服务在未来几十年内将进行重新架构。这一点将会通过加密经济网络（crypto-economic networks）实现。这种网络最开始在比特币中初步形成，通过以太坊的出现得到了进一步的发展。加密网络结合了互联网前两个时代的最佳特性：由社区管理的网络以及去中心化的分布式网络。最终，新型网络的功能将超过眼下最先进的中心化互联网服务。 为什么要去中心化？ 通常，大众对去中心化这一概念存在着广泛的误解。 例如有时会说，加密网络主张去中心化的原因是为了抵制政府审查，或者是因为自由主义的政治观点，然而这并不是去中心化如此重要的主要原因。 我们先来看看中心化平台的问题。这样的平台遵循着可预测的生命周期。最开始，互联网创业公司会尽其所能吸引用户和第三方人员，比如开发人员，企业和媒体组织，通过这种方式让他们的服务更有价值，因为“平台”的定义是具有多边网络效应的系统。在下图中，随着平台影响力的扩大使S曲线不断上升，这些平台对用户和第三方的掌控力也稳步增长。 当互联网创业公司的影响力到达S曲线的顶端时，他们与媒体、开发者等参与者的关系将从正和变为零和。最容易让公司继续升值的方法是从用户那里收集数据，并与竞争对手争夺潜在用户和利润。历史上曾有不少这样的先例，比如微软与Netscape，谷歌与Yelp，Facebook与Zynga以及Twitter与其第三方客户端。像iOS和Android这样的操作系统表现较好，虽然使用某些Apps仍需要支付30％的税费，但应用商店有权下架部分第三方的Apps，监管方面有绝对的话语权。 对于第三方来说，这种从合作到竞争的转变像是一场骗局。随着时间的推移，最优秀的企业家，开发商和投资者在中心化的平台上构建自己的网络时变得小心翼翼。现在数十年的证据已经表明，基于中心化的平台网络会以失望告终。另外，用户放弃隐私，下放私人数据的控制权，很容易受到来自安全漏洞的攻击。在未来，中心化平台的这些问题将更加明显。 进入加密网络时代 加密网络是建立在互联网基础上的网络，它具有两个特点，其一，加密网络使用诸如区块链的共识机制来维持和更新状态。其二，加密网络使用加密货币（比如coins 或者tokens）去激励分享共识的参与者（比如矿工/验证者）。以太坊等加密网络，就是一个通用的程序编写平台，可以开发各种用途的分布式应用。其他加密网络就有一些特殊用途，例如比特币主要用于电子储值，Golem用于执行计算，Filecoin用于分布式文件存储等等。 早期的互联网协议是由专门的团队或非营利组织创建的技术规范，而他们的生存则依靠互联网社区中的利益协调。 这种方法在互联网的早期阶段运行良好，但从20世纪90年代初以来，很少有新协议能够以上述方式进行普及。加密网络通过以令牌（token）形式向开发者，维护者和其他网络参与者提供经济激励，从而解决这些问题。加密网络在技术上也更加强大。例如，他们能够保持某种状态并对该状态进行任意转换，这是过去的网络协议无法做到的。 加密网络使用多种机制来确保它们在增长时保持中立，防止中心化平台的骗局。首先，加密网络和参与者之间的合同通过执行开源代码完成。其次，他们通过“退出—呼吁” 机制（“voice and exit”）进行网络检查。一方面，参与者通过社区治理获得呼吁，既可以是“链上”（通过协议）也可以是“链下”（通过协议周围的社会结构）。另一方面，参与者可以通过离开网络并出售他们的货币退出，或者在极端情况下通过分叉协议退出。 简而言之，加密网络让网络参与者一起努力实现共同目标 - 网络的扩大和令牌（token）的升值。这种一致性是比特币无视质疑一直保持繁荣的主要原因之一，像以太坊这样的新型加密网络都随其有了一定的发展。 如今的加密网络因对中心化网络产生过大的威胁而受到限制。其中最严重的包括对加密网络性能和可扩展性的限制。未来几年加密网络的发展主要是减少或者消除这些限制，并且构建组成加密堆栈基础结构层的网络。再往后，加密网络的主要任务将会是在这样的平台上建立应用程序。 去中心化的优势 说去中心化的网络会占据市场是一回事，如何占据市场就是另一回事了。 软件和Web服务是由开发人员构建的。世界上有几百万的高级开发者，但是他们当中只有小部分在大型IT企业工作，还有小部分专注于研发新产品。历史上许多最重要的软件项目都是由创业公司或独立开发者社区创建的。 “无论你是谁，大多数最聪明的人都会为别人工作。” - Bill Joy 去中心化网络可以赢得互联网的第三个时代，这与互联网当时胜出的原因是一致：赢得企业家和开发者的热情和想法。 在本世纪初，维基百科与Encarta等对手之间的竞争可以说明问题。在21世纪初，如果你比较这两种产品，Encarta其实做得更好，因为它主题覆盖范围更广，准确性更高。但维基百科改善的速度更快，因为它有活跃的志愿者贡献者社区。这些志愿者这种被分散的，去中心化的社区管理精神所吸引。到2005年，维基百科是互联网上最受欢迎的参考网站。Encarta网站于2009关闭。 从这个案例中得到的教训是，当比较中心化的和去中心化的系统时，需要将它们看作一个动态过程，而不是静态、生硬的产品。 中心化的系统通常在开始的时候表现良好，但它改善的速度完全取决于所属公司的员工。相比之下，去中心化的系统虽然开始不完善，但在适当的条件下，它们的特点会吸引大量新的贡献者，产品的表现也就会成倍增长。 加密网络中存在多个涉及各方人员的复合反馈回路，包括核心协议开发者，互补加密网络的开发者，第三方的应用开发者以及运营网络的服务提供商。这些反馈回路通过相关令牌（token）的激励进一步放大，正如我们在比特币和以太坊所看到的那样 - 可以提高加密社区发展的速度（不过有时会导致负面结果，比如挖比特币将消耗大量电力资源）。 去中心化或中心化系统是否会赢得互联网下个时代，其实可以归结为谁将构建最具吸引力的产品，简单来说就是谁能够获得更多高质量的开发人员和企业家。 GAFA四家公司有许多优势，包括现金储备，庞大的用户基础和运营基础设施。加密网络对开发人员和企业家在价值主张方面更具吸引力。 ”如果你在1989年问人们为了改善自己的生活需要什么东西，那他们不可能说使用超文本链接访问去中心化网络的信息节点。“ — Farmer & Farmer 中心化的平台通常会在推出应用程序时捆绑销售其他产品：Facebook具有其核心社交功能，iPhone拥有许多关键应用程序。相比之下，去中心化的平台通常开发出不完整，且用途不明确的应用案例。因此，这些案例需要经历两个产品—市场相适应的阶段： 平台与开发人员/企业家之间的产品市场匹配，他们将共同构建生态系统，完成平台搭建;  产品市场在平台本身和终端用户之间的匹配。 这个两阶段过程导致许多人 - 包括很有经验的技术人员 - 低估了去中心化平台的潜力。 互联网的下一时代 去中心化网络并不是一个能够解决互联网上所有问题的万能灵药。 但是，它们可以提供比中心化系统解决问题更好的方法。 我们可以比较一下垃圾推文和垃圾邮件的问题。自从Twitter关闭了第三方开发者的入口后，唯一能向用户发送垃圾推文的公司其实一直是Twitter本身。相比之下，有数百家企业试图通过数十亿美元的风险投资和企业融资致力于开发过滤垃圾邮件的业务。虽然过滤垃圾邮件尚未解决，但现在的情况已经有所改善，因为第三方开发者知道电子邮件协议是去中心化的，所以他们可以在此基础上建立业务，而不用担心后期这些规则会改变。 或者我们也可以考虑网络治理问题。如今，决定信息排名和过滤的往往是大型平台上那些不负责任的员工们，例如哪些用户该升级，哪些用户该禁止，以及其他重要的治理决策。在加密网络上，这些决策由社区制定，并且使用完全公开和透明的机制。正如我们的线下世界，民主制度虽不完美，但比其他替代方案要好得多。 中心化平台长时间地占据着主导地位，以至于许多人忘记了建立互联网服务还有更好的方法。 在互联网的第一个时代，我们看到了去中心化系统的价值。希望在互联网的下一个时代，我们会再次遇见它。 原文链接：https://medium.com/@cdixon/why-decentralization-matters-5e3f79f7638e 【今日机器学习概念】 Have a Great Definition "
105,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657819&idx=3&sn=c7fc00dd47cc054bb16ce32273df2a04&chksm=bd4c31c88a3bb8de2a9280ab823769f63496284069f5124cd77492915474aa4392072c87434e&scene=0,业界 | 裁判太嚣张？平昌之后，奥运会评分系统将引入AI技术,"平昌奥运会期间，在人类选手角逐较量的同时，八只机器人队伍也获得了参赛资格。2月12日，首届人形机器人滑雪锦标赛在威里山公园滑雪场开幕，这些装备传感器的8台机器人顺利完成比赛，给世界观众留下了深刻的印象。 你不禁会问：机器人能够参加比赛，那么也能够当裁判么？ ﻿国际体操联合会（The International Gymnastics Federation，简称 FIG）已经和日本通信技术公司富士通（Fujitsu）合作， 日本富士通公司去年发布的一段视频显示，该公司正在开发软件，利用3D传感器接收的数据分析鞍马和自由体操等体操项目。据报道， 为了开发这款裁判软件，富士通在2016年收集了职业体操运动员的3D数据，力图为运动员创造一种“骨骼结构模型”。软件能理解和数字模拟每个体操运动员的确切位置，然后将其与国际体操委员会的标准进行比较。 想象一下未来体操比赛的场景：灯光闪烁，提醒体操运动员开始比赛。运动员做完全套动作，然后转身向机器人裁判致敬。分数已经在奥运会场馆的大屏幕上出现，电视机前的数百万观众也能够看到，人工智能技术根据现场表现分析动作然后进行赋分，此过程完全没有人类裁判员的参与。 有人也质疑人工智能的评分能力。奥运冠军、罗马尼亚体操运动员纳迪娅·科马内奇（Nadia Comaneci）在世锦赛上接受《卫报》采访时说道：“运动员有可能会在竞赛中做出新的动作，假如这些动作的数据人工智能没有采集过呢？”  而且， 另外，人工智能的公平性与安全性也不是绝对的。专家警告：不仅这些测量数据可能会在评分过程中出现一些偏差， 伯克利网络安全中心的执行主任贝齐·库珀告（Betsy Cooper）告诉卫报：“如果这个算法被人操控，哪怕是一小部分人，也会影响到比赛的整个结果，而且很难被发现。” 不过即使如此，将人工智能引入奥运会评分系统依然是不可阻挡的趋势。因为体操、花样滑冰等评分标准“人性化”的项目都有过不可容忍的黑幕出现。 2014年索契冬奥会花样滑冰女单比赛结束，有失误的俄罗斯选手Adelina Sotnikova出乎意料地获得了金牌，结果受到了世界各大媒体的质疑，关注程度甚至超越了2002年盐湖城冬奥会丑闻。之所以会出现这个结果，外界传闻，是因为这位俄罗斯选手与裁判有不为人知的交易。 冬季运动会中最受欢迎的运动项目之一，花样滑冰早已饱受争议。根本原因在于其独特的评分标准——人工判断总是带有一定的主观性。更重要的是，奥运会裁判也被允许为来自自己国家的运动员评分。这就为“黑幕”提供了途径。 布鲁金斯学会的经济学教授Eric Zitzewitz15年来一直在评估国际滑冰比赛的成绩，他表示，通过数据可以观察到，包括美国在内的所有国家的裁判都偏向""自己人""。 人工智能技术的引入，在一定程度上，能够使评分系统更加的公正。 奥运会运动项目竞赛的背后，更多的是一个国家，一个民族风采的展示。过多的追求名次与荣誉，反而会失去举办奥运会的意义。 将人工智能技术引入奥运会，你怎么看？ 素材来源： https://qz.com/1202387/2018-winter-olympics%E2%80%AC-pyeongchang-2018-might-be-the-last-olympics-without-ai-judges/ https://www.nbcnews.com/storyline/winter-olympics-2018/think-olympic-figure-skating-judges-are-biased-data-says-they-n844886 https://www.cdstm.cn/theme/khsj/khzx/khqw/201711/t20171109_631745.html Have a Great Definition "
106,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657870&idx=2&sn=3b538c1468c218dc220c82876c3040ac&chksm=bd4c311d8a3bb80ba1fa256ffefa043f0abc8e2c46491b2d9521d410980fe60c1b5fb614cc78&scene=0,报名 | 2018全球AI芯片创新峰会@上海,经过4个多月的筹备，由智东西主办的GTIC 2018全球AI芯片创新峰会（以下简称GTIC 2018）进入大会开幕最后一周的时间，今天正式公布完整大会议程和嘉宾阵容。 作为中国第一场AI芯片产业峰会，以“走进AI世界 从芯看未来”为主题的GTIC 2018将于今年3月9日（下周五）AWE同期在上海卓美亚喜玛拉雅酒店举行。 
107,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657819&idx=1&sn=6bae69d67dbd94ecb276d41cc48e84e9&chksm=bd4c31c88a3bb8de99ddea9f7de0e296b7ea06b3a2b1311675ca394ac2b788071f4085f2be07&scene=0,一文打尽人工智能和机器学习网络资源，反正我已经收藏了！,"昨天，谷歌刚刚上线的机器学习课程刷屏科技媒体头条（点击查看 相关 评测 ）。激动过后，多数AI学习者会陷入焦虑： 入坑人工智能，到底要从何入手？ 的确，如今学习人工智能最大的困难不是找不到资料，更多同学的痛苦是： 为了节省大家的时间，我们搜遍网络把最好的免费资源汇总整理到这篇文章当中。 这些链接够你学上很久，而且你看完本文一定会再次惊叹：现在网上关于机器学习、深度学习和人工智能的信息真的非常多。 本文罗列了以下几个方面的学习资源，供大家收藏： 知名研究人员、人工智能研究机构、视频课程、博客、Medium、书籍、YouTube、Quora、Reddit、GitHub、播客、新闻订阅、科研会议、研究论文链接、教程以及各种小抄表。 许多著名的人工智能研究人员都在网络上有很强的影响力。下面我列出了20个专家，也给出了能够找到他们详细信息的网站。 Sebastian Thrun http://robots.stanford.edu Yann Lecun http://yann.lecun.com Nando de Freitas http://www.cs.ubc.ca/~nando/ Andrew Ng http://www.andrewng.org Daphne Koller http://ai.stanford.edu/users/koller/ Adam Coates http://cs.stanford.edu/~acoates/ Jürgen Schmidhuber http://people.idsia.ch/~juergen/ Geoffrey Hinton http://www.cs.toronto.edu/~hinton/ Terry Sejnowski http://www.salk.edu/scientist/terrence-sejnowski/ Michael Jordan https://people.eecs.berkeley.edu/~jordan/ Peter Norvig http://norvig.com Yoshua Bengio http://www.iro.umontreal.ca/~bengioy/yoshua_en/ Ian Goodfellow http://www.iangoodfellow.com Andrej Karpathy http://karpathy.github.io Richard Socher http://www.socher.org Demis Hassabis http://demishassabis.com Christopher Manning https://nlp.stanford.edu/~manning/ Fei-Fei Li http://vision.stanford.edu/people.html François Chollet https://scholar.google.com/citations?user=VfYhf2wAAAAJ&hl=en Larry Carin http://people.ee.duke.edu/~lcarin/ Dan Jurafsky https://web.stanford.edu/~jurafsky/ Oren Etzioni http://allenai.org/team/orene/ 许多研究机构致力于促进人工智能的研究与开发。下面我列出了一些机构的网站。 OpenAI（推特关注数12.7万） https://openai.com DeepMind（推特关注数8万） https://deepmind.com Google Research（推特关注数110万） https://research.googleblog.com AWS AI（推特关注数140万） https://aws.amazon.com/blogs/ai/ Facebook AI Research https://research.fb.com/category/facebook-ai-research-fair/ Microsoft Research（推特关注数34.1万） https://www.microsoft.com/en-us/research/ Baidu Research（推特关注数1.8万） http://research.baidu.com IntelAI（推特关注数2千） https://software.intel.com/en-us/ai-academy AI²（推特关注数4.6千） http://allenai.org Partnership on AI（推特关注数5千） https://www.partnershiponai.org 网上也有大量的视频课程和教程，其中很多都是免费的，还有一些付费的也很不错，但是在这篇文章中我只提供免费内容的链接。下面我列出的这些免费课程可以让你学上好几个月： Coursera — Machine Learning (Andrew Ng) https://www.coursera.org/learn/machine-learning#syllabus Coursera — Neural Networks for Machine Learning (Geoffrey Hinton) https://www.coursera.org/learn/neural-networks Machine Learning (mathematicalmonk) https://www.youtube.com/playlist?list=PLD0F06AA0D2E8FFBA Practical Deep Learning For Coders (Jeremy Howard & Rachel Thomas) http://course.fast.ai/start.html Stanford CS231n — Convolutional Neural Networks for Visual Recognition (Winter 2016) https://www.youtube.com/watch?v=g-PvXUjD6qg&list=PLlJy-eBtNFt6EuMxFYRiNRS07MCWN5UIA 斯坦福CS231n【中字】视频，大数据文摘经授权翻译 http://study.163.com/course/introduction/1003223001.htm Stanford CS224n — Natural Language Processing with Deep Learning (Winter 2017) https://www.youtube.com/playlist?list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6 Oxford Deep NLP 2017 (Phil Blunsom et al.) https://github.com/oxford-cs-deepnlp-2017/lectures 牛津Deep NLP【中字】视频，大数据文摘经授权翻译 http://study.163.com/course/introduction/1004336028.htm Reinforcement Learning (David Silver) http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html Practical Machine Learning Tutorial with Python (sentdex) https://www.youtube.com/watch?list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v&v=OGxgnH8y2NM YouTube上有很多频道或者用户都经常会发布一些AI或者机器学习相关的内容，我把这些链接按照订阅数/观看数多少列示在下边，这样方便看出来哪个更受欢迎。 sendex（22.5万订阅，2100万次观看） https://www.youtube.com/user/sentdex Siraj Raval（14万订阅，500万次观看） https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A Two Minute Papers（6万订阅，330万次观看） https://www.youtube.com/user/keeroyz DeepLearning.TV（4.2万订阅，140万观看） https://www.youtube.com/channel/UC9OeZkIwhzfv-_Cb7fCikLQ Data School（3.7万订阅，180万次观看） https://www.youtube.com/user/dataschool Machine Learning Recipes with Josh Gordon（32.4万次观看） https://www.youtube.com/playlist?list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal Artificial Intelligence — Topic（1万订阅） https://www.youtube.com/channel/UC9pXDvrYYsHuDkauM2fLllQ Allen Institute for Artificial Intelligence (AI2)（1.6千订阅，6.9万次观看） https://www.youtube.com/channel/UCEqgmyWChwvt6MFGGlmUQCQ Machine Learning at Berkeley（634订阅，4.8万次观看） https://www.youtube.com/channel/UCXweTmAk9K-Uo9R6SmfGtjg Understanding Machine Learning — Shai Ben-David（973订阅，4.3万次观看） https://www.youtube.com/channel/UCR4_akQ1HYMUcDszPQ6jh8Q Machine Learning TV（455订阅，1.1万次观看） https://www.youtube.com/channel/UChIaUcs3tho6XhyU6K6KMrw 虽然人工智能和机器学习现在这么火，但是我很惊讶地发现相关博主并没有那么多。可能是因为内容比较复杂，把有意义的部分整理出来需要花很大精力；也有可能是因为类似Quora这样的平台比较多，专家们回答问题更方便也不需要花太多时间做详细论述。 下面我会按照推特的关注数排序介绍一些博主，他们一直在做人工智能相关的原创内容，而不只是一些新闻摘要或者公司博客。 Andrej Karpathy（推特关注数6.9万） http://karpathy.github.io i am trask（推特关注数1.4万） http://iamtrask.github.io Christopher Olah（推特关注数1.3万） http://colah.github.io Top Bots（推特关注数1.1万） http://www.topbots.com WildML（推特关注数1万） http://www.wildml.com Distill（推特关注数9千） https://distill.pub Machine Learning Mastery（推特关注数5千） http://machinelearningmastery.com/blog/ FastML（推特关注数5千） http://fastml.com Adventures in NI（推特关注数5千） https://joanna-bryson.blogspot.de Sebastian Ruder（推特关注数3千） http://sebastianruder.com Unsupervised Methods（推特关注数1.7千） http://unsupervisedmethods.com Explosion（推特关注数1千） https://explosion.ai/blog/ Tim Dettmers（推特关注数1千） http://timdettmers.com When trees fall…（推特关注数265） http://blog.wtf.sg ML@B（推特关注数80） https://ml.berkeley.edu/blog/ 下面介绍到的是Medium上人工智能相关的顶级作者，按照2017年Mediumas的排行榜排序。 Robbie Allen https://medium.com/@robbieallen Erik P.M. Vermeulen https://medium.com/@erikpmvermeulen Frank Chen https://medium.com/@withfries2 azeem https://medium.com/@azeem Sam DeBrule https://medium.com/@samdebrule Derrick Harris https://medium.com/@derrickharris Yitaek Hwang https://medium.com/@yitaek samim https://medium.com/@samim Paul Boutin https://medium.com/@Paul_Boutin Mariya Yao https://medium.com/@thinkmariya Rob May https://medium.com/@robmay Avinash Hindupur https://medium.com/@hindupuravinash 市面上有许多关于机器学习、深度学习和自然语言处理等方面的书籍，我只列示了可以直接从网上免费获得或者下载的书籍。 机器学习 Understanding Machine Learning From Theory to Algorithms http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf Machine Learning Yearning http://www.mlyearning.org A Course in Machine Learning http://ciml.info Machine Learning https://www.intechopen.com/books/machine_learning Neural Networks and Deep Learning http://neuralnetworksanddeeplearning.com Deep Learning Book http://www.deeplearningbook.org Reinforcement Learning: An Introduction http://incompleteideas.net/sutton/book/the-book-2nd.html Reinforcement Learning https://www.intechopen.com/books/reinforcement_learning 自然语言处理 Speech and Language Processing (3rd ed. draft) https://web.stanford.edu/~jurafsky/slp3/ Natural Language Processing with Python http://www.nltk.org/book/ An Introduction to Information Retrieval https://nlp.stanford.edu/IR-book/html/htmledition/irbook.html 数学 Introduction to Statistical Thought http://people.math.umass.edu/~lavine/Book/book.pdf Introduction to Bayesian Statistics https://www.stat.auckland.ac.nz/~brewer/stats331.pdf Introduction to Probability https://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/amsbook.mac.pdf Think Stats: Probability and Statistics for Python programmers http://greenteapress.com/wp/think-stats-2e/ The Probability and Statistics Cookbook http://statistics.zone Linear Algebra http://joshua.smcvt.edu/linearalgebra/book.pdf Linear Algebra Done Wrong http://www.math.brown.edu/~treil/papers/LADW/book.pdf Linear Algebra, Theory And Applications https://math.byu.edu/~klkuttle/Linearalgebra.pdf Mathematics for Computer Science https://courses.csail.mit.edu/6.042/spring17/mcs.pdf Calculus https://ocw.mit.edu/ans7870/resources/Strang/Edited/Calculus/Calculus.pdf Calculus I for Computer Science and Statistics Students http://www.math.lmu.de/~philip/publications/lectureNotes/calc1_forInfAndStatStudents.pdf Quora已经成为人工智能和机器学习的重要资源，许多顶尖的研究人员会在上面回答问题。下面我列出了一些主要关于人工智能的话题，如果你想自定义你的Quora喜好，你可以选择订阅这些话题。记得去查看每个话题下的FAQ部分（例如机器学习下常见问题解答），你可以看到Quora社区里提供的一些常见问题列表。 计算机科学 (560万关注) https://www.quora.com/topic/Computer-Science 机器学习 (110万关注) https://www.quora.com/topic/Machine-Learning 人工智能 (63.5万关注) https://www.quora.com/topic/Artificial-Intelligence 深度学习 (16.7万关注) https://www.quora.com/topic/Deep-Learning 自然语言处理 (15.5 万关注) https://www.quora.com/topic/Natural-Language-Processing 机器学习分类(11.9万关注) https://www.quora.com/topic/Classification-machine-learning 通用人工智能(8.2万 关注) https://www.quora.com/topic/Artificial-General-Intelligence 卷积神经网络 (2.5万关注) https://www.quora.com/topic/Convolutional-Neural-Networks-1?merged_tid=360493 计算语言学(2.3万关注) https://www.quora.com/topic/Computational-Linguistics 循环神经网络(1.74万关注) https://www.quora.com/topic/Recurrent-Neural-Networks-RNNs Reddit上的人工智能社区并没有Quora上那么活跃，但是还是有一些很不错的话题。相对于Quora问答的形式，Reddit更适合于用来跟踪最新的新闻和研究。下面是一些主要关于人工智能的Reddit话题，按照订阅人数排序。 /r/MachineLearning (11.1万订阅) https://www.reddit.com/r/MachineLearning /r/robotics/ (4.3万订阅) https://www.reddit.com/r/robotics/ /r/artificial (3.5万订阅) https://www.reddit.com/r/artificial/ /r/datascience (3.4万订阅) https://www.reddit.com/r/datascience  /r/learnmachinelearning (1.1万订阅) https://www.reddit.com/r/learnmachinelearning/ /r/computervision (1.1万订阅) https://www.reddit.com/r/computervision /r/MLQuestions (8千订阅) https://www.reddit.com/r/MLQuestions /r/LanguageTechnology (7千订阅) https://www.reddit.com/r/LanguageTechnology /r/mlclass (4千订阅) https://www.reddit.com/r/mlclass /r/mlpapers (4千订阅) https://www.reddit.com/r/mlpapers 人工智能社区的好处之一是大部分新项目都是开源的，并且能在GitHub上获取到。同样如果你想了解使用Python或者Juypter Notebooks来实现实例算法，GitHub上也有很多学习资源可以帮助到你。以下是一些GitHub项目： 机器学习(6千个项目) https://github.com/search?o=desc&q=topic%3Amachine-learning+&s=stars&type=Repositories&utf8=✓ 深度学习(3千个项目) https://github.com/search?q=topic%3Adeep-learning&type=Repositories Tensorflow (2千个项目) https://github.com/search?q=topic%3Atensorflow&type=Repositories 神经网络(1千个项目) https://github.com/search?q=topic%3Aneural-network&type=Repositories 自然语言处理(1千个项目) https://github.com/search?utf8=✓&q=topic%3Anlp&type=Repositories 人工智能相关的播客数量在不断的增加，有些播客关注最新的新闻，有些关注教授相关知识。 Concerning AI https://concerning.ai his Week in Machine Learning and AI https://twimlai.com The AI Podcast https://blogs.nvidia.com/ai-podcast/ Data Skeptic http://dataskeptic.com Linear Digressions https://itunes.apple.com/us/podcast/linear-digressions/id941219323 Partially Derivative http://partiallyderivative.com O’Reilly Data Show http://radar.oreilly.com/tag/oreilly-data-show-podcast Learning Machines 101 http://www.learningmachines101.com The Talking Machines http://www.thetalkingmachines.com Artificial  Intelligence  in  Industry http://techemergence.com Machine Learning Guide http://ocdevel.com/podcasts/machine-learning 如果你想追踪最新的新闻和研究的话，种类渐增的每周新闻是一个不错的选择：其中大部分都包含相同的内容，所以订阅两三个就足够。 The Exponential View  https://www.getrevue.co/profile/azeem AI Weekly http://aiweekly.co Deep Hunt https://deephunt.in O’Reilly Artificial Intelligence Newsletter http://www.oreilly.com/ai/newsletter.html Machine Learning Weekly http://mlweekly.com Data Science Weekly Newsletter https://www.datascienceweekly.org Machine Learnings http://subscribe.machinelearnings.co Artificial Intelligence News http://aiweekly.co When trees fall… https://meetnucleus.com/p/GVBR82UWhWb9 WildML https://meetnucleus.com/p/PoZVx95N9RGV Inside AI https://inside.com/technically-sentient Kurzweil AI http://www.kurzweilai.net/create-account Import AI https://jack-clark.net/import-ai/ The Wild Week in AI https://www.getrevue.co/profile/wildml Deep Learning Weekly http://www.deeplearningweekly.com Data Science Weekly https://www.datascienceweekly.org KDnuggets Newsletter http://www.kdnuggets.com/news/subscribe.html?qst 随着人工智能的普及，人工智能相关的科研会议数量也在不断增加。我只提了几个主要的会议，没列所有的。（当然会议并不是免费的！） 学术会议 NIPS (Neural Information Processing Systems) https://nips.cc ICML (International Conference on Machine Learning) https://2017.icml.cc KDD (Knowledge Discovery and Data Mining) http://www.kdd.org ICLR (International Conference on Learning Representations) http://www.iclr.cc ACL (Association for Computational Linguistics) http://acl2017.org EMNLP (Empirical Methods in Natural Language Processing) http://emnlp2017.net CVPR (Computer Vision and Pattern Recognition) http://cvpr2017.thecvf.com ICCV (International Conference on Computer Vision) http://iccv2017.thecvf.com 专业会议 O’Reilly Artificial Intelligence Conference https://conferences.oreilly.com/artificial-intelligence/ Machine Learning Conference (MLConf) http://mlconf.com AI Expo (North America, Europe, World) https://www.ai-expo.net AI Summit https://theaisummit.com AI Conference https://aiconference.ticketleap.com/helloworld/ 你可以在网上浏览或者搜索已经发布的学术论文。 arXiv.org的主题类别 arXiv 是较早的预印本库，也是物理学及相关专业领域中最大的，该数 据库目前已有数学、物理学和计算机科学方面的论文可开放获取的达50多万篇。 Artificial Intelligence https://arxiv.org/list/cs.AI/recent Learning (Computer Science) https://arxiv.org/list/cs.LG/recent Machine Learning (Stats) https://arxiv.org/list/stat.ML/recent NLP https://arxiv.org/list/cs.CL/recent Computer Vision https://arxiv.org/list/cs.CV/recent Semantic Scholar内搜索 Semantic Scholar是由微软联合创始人保罗·艾伦创立的艾伦人工智能研究所推出的学术搜索引擎 Neural Networks (17.9万条结果) https://www.semanticscholar.org/search?q=%22neural%20networks%22&sort=relevance&ae=false Machine Learning (9.4万条结果) https://www.semanticscholar.org/search?q=%22machine%20learning%22&sort=relevance&ae=false Natural Language (6.2万条结果) https://www.semanticscholar.org/search?q=%22natural%20language%22&sort=relevance&ae=false Computer Vision (5.5万条结果) https://www.semanticscholar.org/search?q=%22computer%20vision%22&sort=relevance&ae=false Deep Learning (2.4万条结果) https://www.semanticscholar.org/search?q=%22deep%20learning%22&sort=relevance&ae=false Andrej Karpathy开发的网站 http://www.arxiv-sanity.com/ 我另外单独有一篇详细的文章涵盖了我发现的所有的优秀教程内容： 超过150种最佳的机器学习、自然语言处理和Python教程 https://unsupervisedmethods.com/over-150-of-the-best-machine-learning-nlp-and-python-tutorials-ive-found-ffce2939bd7        和教程一样，我同样单独有一篇文章介绍了许多种很有用的小抄表： 机器学习、Python和数学小抄表 https://unsupervisedmethods.com/cheat-sheet-of-machine-learning-and-python-and-math-cheat-sheets-a4afe4e791b6 通读完本篇文章，是不是对于如何查找关于人工智能领域的资料有了清晰的方向。资料很多，大多都是国外的网站，所以大家需要科学上网哟~~~ 原文链接： https://unsupervisedmethods.com/my-curated-list-of-ai-and-machine-learning-resources-from-around-the-web-9a97823b8524 Have a Great Definition "
108,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657819&idx=2&sn=bc70d58d2454ba495c08ddeb743d771c&chksm=bd4c31c88a3bb8de107e759d668c4bc1e79f8ff01827c9eb4f3be9d048bf503078797bbf0ac2&scene=0,BlockChange | 这些热门案例让你一下子搞懂区块链！,太多文章在解释区块链技术的原理，但是大家对区块链怎么用以及怎么造福经济和社会还摸不着头脑。 本文作者着重讲了区块链运用的实例，结合具体的运用场景可以给你更直观的感受。   区块链的应用 我是区块链！我是无敌的，因为我在多台电脑上复制了自己。对！就像复仇者联盟里的超级反派奥创。你无法破坏我。虽然比特币和以太坊是我的首次应用，但我的真正力量还没有被释放。   来源：xkcd 身份   让我从身份证，徽章和其他身份标记说起吧。不管设计得多么巧妙，它们总能被复制。你知道3D打印吧？如何去验证它们呢？有一些组织提供在线验证服务。你可以扫描卡片或者输入验证码去鉴别真伪。但这项服务的成本可能非常高，你需要支付云端服务的费用。而使用区块链，你不需要构建自己的身份构架，你可以用以太坊的开源区块链来存储详细的身份信息。任何需要验证的人只需要查询公开区块链即可。 公证 你的大部分所有权记录都在纸质账本中。这些记录是可以被篡改的。而储存在区块链中的数据却无法更改。一个区块链中包含两个成分，区块和链。在高层面上讲，它本身只是一连串的区块。其中数字信息被分配到不同的区块中，然后连接在一起。举个例子，我们有一些区块，每个区块代表一个国家，包含该国家城市的名字。 每个区块又都含有一个叫做散列的东西。散列是一组字符（例如：“1hi515AHA5H”）。散列来源于区块中存储的信息。代表美国的区块中有纽约、洛杉矶和芝加哥。所以散列是“NYLAC”（虽然从技术角度上讲，情况并非完全如此，但这样解释你就会大概明白）。 每个连续的区块都包含前一个区块的散列信息。就是这个联系把各个区块捆绑在一起（区块链的超能力）。如果有人篡改了第一个代表美国的区块，添加了“波士顿”，新的散列信息将变成“NYLACB”。然而，与美国相连的区块印度所存储的散列信息是“NYLAC”。这一环的信息不匹配将打破区块间的链接。所以，散列的目的在于确保没人能篡改区块的内容。我想要强调的是：你不可以篡改我的记录。一旦你篡改，我就会发现。 数字资产 希望你听过“首次代币发行”（ICO）（参见TravelChain）。这是一种募集资金的新形式。不论你是谁，不论你身在何方，都可以成为一名投资人。当有人投资了你的公司，你应该回报他们吧？比如股票或股份？ICO提供的是一种称为“代币”的数字资产。这些“代币”会存储在你的区块链钱包中。你可以用它们支付公司服务费，甚至可以等日后“代币”增值时再进行交易。 智能合约   Mark已经拖欠了五个月房租了。每当房东Sara问起，他总是保证之后会付的。Sara很无助。她请不起律师。法庭强制执行也要等八个月甚至将近一年的时间。唯一的选择就是说服Mark。     Joe是个商人。他经常和不同的公司做生意。几个月前，他与零售商签订了一份合同。虽然Joe履行了合约。但对方却拒绝付款。这些人钻法律的空子，劝说Joe允许他们少付钱。Joe之前有过这样的经历，也去过法庭，可他在法庭花费的时间和金钱基本等于他一单生意的利润了。     区块链的解决方案就可以用在这个案例中。在Sara的故事中，我们需要让Mark每月支付房租。这是一个基于时间的触发点。你的日历应用根据这个触发点推送预设的事件提醒。   在Joe的案例中，一旦合约条款履行，对方就必须付款。这是一个基于条件的触发点。想想你上一次在亚马逊上买电子书。亚马逊只会在确认你付款后发货。   关键在于，计算机程序能够坚决执行指令。比如你现在点开这篇文章，向下滑动页面，计算机程序就正在执行你的指令。所以为了帮助Sara，我们需要把租房合约转换成代码的形式。     如果今天是30号并且房租还没付，那么从Mark的账户中转款500美元到Sara的账户，但是我们应该把代码配置到哪里呢？代码应该配置到合同参与方的电脑上。Sara和Mark的银行也会参与这个私有区块链网络。Joe和Sara将各签署一份代码合同（即智能合同）。然后合同将被配置到区块链网络中，Mark和Sara各自的银行都会得到一份合同副本。每月30日，当指针走到12点时，约定好的金额将会从Mark的账户转入Sara的账户。Joe也开始使用智能合约强制他的客户支付事先同意的金额。   Sara高兴了，因为她不用再依赖Mark的同意就能得到房租。Joe也很满意，因为他再也不用去法庭寻求正义。现在Joe可以把这些精力放在拓展生意上。   数字选举   还记得上次你为了投票站在人群中大排长队吗？如果能在家投票呢？在线投票的最大问题就是安全。选票可能被篡改或者黑客们可以找出你投给了谁。区块链可以提供条件，让你更安全地匿名投票。由于美国选民投票率低，数字投票可以带来更多参与者。   分配存储空间   当你使用Google Drive，Dropbox等服务存储你的文件时，最大的问题是你不得不相信服务供应商不会窥视你的数据。政府可能强制要求他们披露数据。在区块链中，数据是去中心化的，并且以高度加密的形式被存储在网络中不同的电脑里。 这种方式也可以减少存储成本，当你需要使用的存储空间超过了电脑的配置，你可以租用存储空间。Storj就是一个例子，就像一个提供数据存储服务的Airbnb或Uber。   原文链接： https://hackernoon.com/popular-use-cases-of-blockchai n-technology-you-need-to-know-df4e1905d373   【今日机器学习概念】 Have a Great Definition 
109,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657797&idx=1&sn=976e4ec8a5e426b02225037e5c2365f0&chksm=bd4c31d68a3bb8c0b93bb7195c69fd28fff5c977897875b98838f6e3e27ae12b385aa7c3c9a4&scene=27,谷歌上线自带中文的机器学习免费课程，我们带你做了个测评,大数据文摘编辑组 谷歌刚刚为全球的机器学习者们带来了一份大礼。 作为向人工智能教育领域迈出的第一步，谷歌的人工智能学习网站Learn with Google AI在今天上线，并重磅推出了一门机器学习速成课（Machine Learning Crash Course ，MLCC），提供交互式教学视频和练习，免费教授机器学习概念。 课程网站： https://developers.google.cn/machine-learning/crash-course/ 在本次发布中，谷歌提供了英文，西班牙文，法文，韩文和普通话五种版本，以突破语言障碍，造福全球的AI学习者。 作为一门机器学习课程，这门课本身也有非常多的AI元素。课程全套中文音频和中文PPT都由机器学习技术生成，还全部内嵌到了课程视频里，颇为用心良苦。 这门课程内容基于谷歌内部为期两天的训练课程，旨在帮助谷歌工程师学习机器学习概念。据介绍，之前已有超过10000名谷歌工程师学习过相同课程。 谷歌称，通过该课程的培训，谷歌工程师得以在AI领域有更多创新：比如加强Daydream设备的摄像机校准，为Google Earth创建虚拟现实，并提高YouTube的流媒体质量。“MLCC在谷歌的成功激励我们向所有人开放这些培训课程。” MLCC也是谷歌打算通过新的ai.google网站提供的许多课程和资源中的第一个，更多的课程和资源即将到来。 谷歌希望这一网站成为机器学习和人工智能的存储库，并成为所有机器学习者的“大本营”，吸引从高级研究人员到初学者的所有级别人工智能爱好者。 机器学习速成课时长约15小时，包括互动课程，谷歌研究人员的讲座以及40多个练习。  文摘菌也对本课程进行了简单测评，总体来看， 。  那么对于初学者，到底如何选择最新入手的课程呢？ 对比吴恩达新上线的deeplearning.ai深度学习系列课程，谷歌这门课显然更加偏向机器学习入门，具备编程基础的学习者能通过这门课迅速了解机器学习相关概念并上手，这对于广大编程者来说无疑是个好消息。 对于深度学习中的计算机视觉、自然语言处理等方向，这门课都没有涉及。同时，你也只能学到谷歌自家的TensorFlow框架。不过如果目标是能上手，学这些就足够了。 去年在I / O开发者大会上，谷歌宣布在网站上新增教育项目。近年来，谷歌一再表示， 。这一课程显然是重要一步。 先来看看谷歌官方如何描述这一课程旨在解决哪些问题： 机器学习与传统编程有何不同？	 什么是损失，如何衡量损失？	 梯度下降法的运作方式是怎样的？ 如何确定我的模型是否有效？	 怎样为机器学习提供我的数据？	 如何构建深度神经网络？ 谷歌建议学习者掌握入门级代数，熟练掌握编程基础知识和Python。 官网对课程的学习者有如下要求： 掌握入门级代数知识。 你应该了解变量和系数、线性方程式、函数图和直方图（熟悉对数和导数等更高级的数学概念会有帮助，但不是必需条件）； 熟练掌握编程基础知识，并且具有一些使用Python进行编程的经验。  机器学习速成课程中的编程练习是通过TensorFlow并使用Python进行编码的。你无需拥有使用TensorFlow 的经验，但应该能够熟练阅读和编写包含基础编程结构（例如，函数定义/调用、列表和字典、循环和条件表达式）的Python代码。 再来看看课程目录： 机器学习概念： 机器学习简介（3分钟） 框架处理（15分钟） 深入了解机器学习（20分钟） 降低损失（60分钟） 使用TF的基本步骤（60分钟） 泛化（15分钟） 训练集和测试集（25分钟） 验证（40分钟） 表示法（65分钟） 特征组合（70分钟） 正则化：简单性（40分钟） 逻辑回归（20分钟） 分类（90分钟） 正则化：稀疏性（40分钟） 神经网络简介（55分钟） 训练神经网络（40分钟） 多类别神经网络（50分钟） 嵌入（80分钟） 机器学习工程： 生产环境机器学习系统（3分钟） 静态训练与动态训练（7分钟） 静态推理与动态推理（7分钟） 数据以来关系（14分钟） 机器学习现实世界应用示例： 癌症预测（5分钟） 18世纪文学（5分钟） 现实世界应用准则（2分钟） 从目录看来，这是一门机器学习尤其是TensorFlow入门课。正如这门课的英文名称，Crash Course。但这门课的亮点在于， 课程视频页面 一开始打开网页时，文摘菌并没看到中文，这时只要在页面左下角选择语言为中文即可。 谷歌最牛逼之处可能是，使用机器学习技术给课程生成了全套中文音频和中文PPT，还全部内嵌到了课程视频里。神奇！文摘菌从来没见过这种操作。 也就是说，上方视频里大叔说的中文竟是AI给配音的！ 让我们再来看看课程的配套练习。 下图是练习题所使用的ipython notebook云平台。学习者可以在浏览器内按照教程的提示直接运行代码，非常方便。同样的，页面可以在中英文之间随意切换。对比英文和中文界面，简直毫无机器翻译痕迹。 配套练习英文界面 配套练习中文界面 谷歌还提供了一份中英文对照的机器学习术语表，也是非常贴心了。 还在等什么呢？快打开链接学习吧！记得和文摘菌分享心得！👇 https://developers.google.cn/machine-learning/crash-course/ Have a Great Definition 
110,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657797&idx=2&sn=0d0f7ba8b64c3776e6a5195bb17ec190&chksm=bd4c31d68a3bb8c050b670db6cd3a87e6c762864f159e5e3edb2beace9103cb9a41eeaaa3c1b&scene=27,BlockChange | 区块链领域的Kaggle？反正谷歌已经投资了,大数据文摘作品 除了去Kaggle打比赛，机器学习的研究者刚刚为其算法能力找到了另一个更高效透明的买单者。 这个买单者支付的还是最近火到不行的虚拟货币——以太币。 本周二，算法公司Algorithmia新推出了一项基于区块链的机器学习合约——DanKu。 这一协议以区块链为基础，允许非专业人员将数据发布在以太坊上，并且寻找器学习研究者为其创建数据模型。 DanKu是一个可以评估被提交模型的神经网络，并用以太币奖励获胜者。 不太了解的读者可以先了解一下区块链的运作原理，点击阅读大数据文摘相关报道 Algorithmia，这家西雅图的初创公司一直致力于经营一个机器学习算法商店。简单来说， 迄今已有超过45000名开发人员在使用该“算法商店”，并有3500个算法“上架”。 Algorithmia 的创始人Diego Oppenheimer认为，Algorithmia存在的意义是为了「对抗AI 霸权」，而霸权拥有者就是诸如Google、Facebook 等巨头公司，它们集中了最多的AI科学家，发明新算法、攻破难题，主宰着人工智能的世界。 这样的算法社区模式听起来好像和Kaggle异曲同工。 去年3月被谷歌收购，Kaggle专注数据科学、机器学习竞赛的举办，很快吸引了大量数据科学家、机器学习开发者的参与。 而Algorithmia在自己的社区中引入了区块链技术和虚拟货币的奖励。 DanKu协议的工作原理图：如何使用区块链来训练机器学习模型的算法。  虚拟货币的奖励也能够鼓励研究人员参与到这一项目中，并使用机器学习知识推进技术民主化。 该公司在一篇博客文章中表示，“这将激励人们更好地训练机器学习模型，推进人工智能在业内的使用。” 第一个公开的DanKu合约项目已创建完成：根据2016年选举的数据，预测民主党／共和党是否有可能赢得某个美国县的选举。DanKu将在提交模型时评估模型，并奖励获奖模型5枚以太币（本文写作时价值约4360美元）。这个比赛将持续60天。提交最准确模型的第一支队伍将是胜利者。 这场比赛实际上是一个系统的概念验证测试，任何人都可以创建自己的智能合约，并征求定制机器学习模型来解决特定问题。 Algorithmia的方法不要求参与者互相信任（因为所有组件都由协议控制），并自动支付奖励。 Algorithmia已经获得了众多大的AI公司的密切关注，谷歌的人工智能投资部门去年领投了1050万美元的A轮融资。除了算法市场，该公司还提供基于无服务器计算原则的AI服务，让复杂的AI模型更容易启动和运行。 原文链接： https://www.geekwire.com/2018/algorithmia-launches-blockchain-based-protocol-machine-learning-algorithm-shoppers/ Have a Great Definition 
111,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657797&idx=3&sn=fc6078536763b0743e5b22d78ce9aae0&chksm=bd4c31d68a3bb8c0809f45d3ae86f705b88de97dd4a889058d3cbbee2466ef78556ec670d35c&scene=27,AI角 | 吴恩达李飞飞西瓜书课程学习打卡开启，追随superstar，搞定AI核心知识！,在刚刚过完的7天年假里，大数据文摘和184位小伙伴一起学习了吴恩达《Deep Learning Specialization》和李飞飞《CS231n：Convolutional Neural Networks for Visual Recognition》部分课程， 。 经过一周短暂的休整和总结，第二期课程打卡学习活动开启啦！ 先来看看第一期大家提交的精彩笔记： 加入我们，将有机会和笔记分享者一起学习哦。 当然，免费为大家提供学习机会的文摘菌也希望大家的学习可以真的有效率，所以社区内会有严格的打卡制度，奖惩机制。 吴恩达《Deep Learning Specialization》 由 deeplearning.ai 出品，网易引进的正版授权中文版深度学习工程师微专业课程，让你在了解丰富的人工智能应用案例的同时，学会在实践中搭建出最先进的神经网络模型，训练出属于你自己的 AI。 课程官方链接： https://www.coursera.org/specializations/deep-learning 李飞飞《CS231n：Convolutional Neural Networks for Visual Recognition》 课程内容安排合理，由浅入深。主要介绍了深度学习（尤其是卷积神经网络和与其相关的框架）在计算机视觉领域的应用，内容涵盖多种神经网络具体结构与训练应用细节，以及针对大规模图像识别，物体定位，物体检测，图像风格迁移，图像理解描述与视频内容识别等问题的前沿解决思路。从一个简单的cifar10数据集和最简单的KNN算法开始介绍，慢慢引入深度学习相关的知识点。比如dropout、batchnormalization等。最后介绍了一些深度学习经典的范例，比如RNNs， LSTMs ，GAN等。 课程官方链接： http://cs231n.stanford.edu/ 大数据文摘授权翻译汉化版课程： https://study.163.com/provider/10146755/index.htm 吴恩达《Machine Learning》 人工智能的发展到已经进入了一个瓶颈期。近年来各个研究方向都没有太大的突破。真正意义上人工智能的实现目前还没有任何曙光。但是，机器学习无疑是最有希望实现这个目标的方向之一。斯坦福大学的“Stanford Engineering Everywhere ”免费提供学校里最受欢迎的工科课程，给全世界的学生和教育工作者。得益于这个项目，我们有机会和全世界站在同一个数量级的知识起跑线上。 课程官方链接： https://www.coursera.org/learn/machine-learning 周志华《机器学习》 本书尽可能从材料的“原生态”出发讲述，仅在少数地方简略点出联系。 需说明的是，作者试图以相近深度讲述主要内容。读者若感到在某些地方“意犹未尽”，也可借助本书对其他内容的初窥优先于此处的进一步深究。另外，机器学习飞速发展，很多新进展在学界尚无公论之前，作者以为不适于写入入门级教科书中。但为了不致于与学科前沿脱节，本书也简略谈及一些本领域专家有初步共识的相对较新的内容。 书籍官方介绍： https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/MLbook2016.htm 所有课程/书籍将分为几期完成，每期有各自的打卡日程安排 每天至少完成规定视频/书籍内容的学习，并记录【学习笔记】，笔记形式不限、内容多少不限，但应满足一定的内容覆盖度 每天建议学习时间：1个小时-1.5个小时 每个微信群限额20人，每名参与者缴纳66元人民币 16元用于交付运营志愿者的组织与记录薪酬，50元加入奖金池 坚持完成一期打卡的学员，均分微信群内所有奖金（1000元） 深度学习入门： 我们推荐吴恩达《Deep Learning Specialization》课程 机器学习入门： 我们推荐吴恩达《Machine Learning》课程 机器学习进阶： 我们推荐周志华《机器学习》（西瓜书） 计算机视觉专项学习： 我们推荐《CS231n：Convolutional Neural Networks for Visual Recognition》课程 扫描二维码，添加ai_learner好友 备注“ ”参与《Deep Learning Specialization》课程打卡； 备注“ ”参与《Machine Learning》课程打卡； 备注“ ”参与《机器学习》（西瓜书）打卡； 备注“ ”参与《CS231n：Convolutional Neural Networks for Visual Recognition》课程打卡； 如果希望能组织、督促并激励所在群的小伙伴一起学习，并拿到一组的运营志愿者薪酬，也请在申请时一并说明哦！ AI热潮风起浪涌、资料信息层出不穷，如果你时常为选择学习什么而焦虑的话，请加入我们的打卡学习联盟。 最著名的免费课程、活跃的学习社区、明确的奖惩机制、负责的运营志愿者，合力推动你沉下心去了解机器学习、深度学习和计算机视觉，真的了解领域知识的内在逻辑，明白关键术语的含义。 推开浮光掠影的泡沫，让我们一起给成长时间和信心！第2期打卡，我们在群里等你！ 2018年，让我们变成更厉害的人！ 【今日机器学习概念】 Have a Great Definition 
112,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657740&idx=3&sn=86165d2b9400cde32153211ef8d06a84&chksm=bd4c319f8a3bb8896e2aae3eebd3e926cd840a8fa36c1c3cc0717242e43bf140f9493d47408d&scene=27,业界 | 谷歌智能摄像头Clips开卖啦！能识别宠物动作生成小视频,你觉得一个摄像头能干啥？ 生活记录、动作捕获、安全监控…… 谷歌新上市了一款“智能摄像头”Google Clips， 瞄准了父母们和宠物主们——利用脸部识别技术，只要你的家人或宠物出现在镜头里，谷歌就会自动抓取7秒最佳画面。 早在去年10月份的硬件发布会上，谷歌就已发布这款摄像头。 售价为249美元 ， 消费者可以通过Google Store，Best Buy，B＆H和Verizon等零售商购买。 “智能”体现在哪里？谷歌称，为了使设备体验尽可能的友好，该摄像头集成了很多复杂的人工智能和机器学习技术。Clips内置了英特尔旗下的Movidius Myriad 2 VPU视觉处理芯片，无需联网，在终端即可实现图像计算与脸部识别。 摄像头录下的画面 让我们看看谷歌的官方介绍： Clips是一种新型摄像头， 它并不是要取代智能手机摄像头或数码单反相机。设备上嵌入的机器学习算法将能记录你生活中的人和宠物有意思的面部表情，比摆好姿势自拍的照片更加生动。不需要使用视频编辑软件，你就可以将这些表情做成小视频。 是的，不仅能识别人脸，人工智能还能识别猫、狗，甚至还有兔子🐰！ 作者用Clips拍摄的动图 谷歌对Clips的定义是， 既可以固定在某处拍摄照片或视频，也可以直接拿在手中随时使用。家里的狗狗在糟蹋花盆里的花，小baby在学走路，孩子在公园玩……用这个摄像头都能方便地拍下来。 Clips 采用了一颗130°广角的摄像头，像素1200万，光圈值F/2.4，重约60.5克，可提供长达3小时的拍摄， 适配Android和IOS系统。依靠人工智能，摄像头将识别熟悉的脸部并选择画面中的7秒最佳时刻进行拍摄记录，这些视频可以存储为静态图像或共享为Apple Live Photo，Google Motion Photo或者更直接的，存成GIF动图。 作者用Clips拍摄的动图 你不在家的时候，家里的阿猫阿狗在干嘛，这下一目了然啦。 素材来源： https://techcrunch.com/2018/02/27/googles-ai-powered-clips-smart-camera-is-now-available/ https://techcrunch.com/2018/02/27/google-clips-review/ 【今日机器学习概念】 Have a Great Definition 
113,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657740&idx=2&sn=d3a061858043b53b40de54dfba7fd737&chksm=bd4c319f8a3bb8892882f12d187701d10ef0bee8f2d3f09fa1548629053e438b3bcb70574910&scene=27,Reading Club | 算法和人生抉择：午饭到底吃什么？,大数据文摘作品 午饭吃什么？去拔草楼下新开的餐厅，还是去对面那家常去的小馆子？ 这可能是很多人每天面临的亘古选择题，也是我们每一天都在做一类特定的选择：选择已知的最爱还是未知的可能？ 如何平衡这个选择不仅是我们纠结的日常，也是计算机学家半个世纪以来的研究对象。 春节前，大数据文摘启动了最新音频栏目——Data Reading Club，我们为大家推荐的书籍是Algorithm to Live by（生活中的算法），上一期我们跟大家探讨了算法与人生伴侣的选择——神奇的37%法则 。 本周，我们继续聊聊【选择】这个人生中的重大话题。由来自杜克大学美女主播段天霖与大家分享：在选择时，如何衡量“坚守已知（exploit)”或者“探索未知(explore)”。 点击收听👇 就像读书会小蒋所说：对于计算机来说，explore代表收集信息，而exploit是运用这些信息来达到一个确定的理想结果；在生活中，explore是我们对未知世界的探索，而exploit是享受已知的美好。 从这个意义上讲，认识一个新朋友、听一首新歌是explore，与家人团聚、听一首循环无数次的老歌就是exploit。仔细想想，生活中这两者总是共存的，但他们之间的平衡却是因人而异的。那么从算法的角度，这个命题是否存在一种最佳解法呢？ 要回答这个问题，我们还是要从它的起源说起。 虽然，计算机科学家对于午饭吃什么有种有啥吃啥的佛系心态，但是，他们对于幻想怎么在赌场赚最多的银子倒是有极大的热情。 假设赌场中有一排未知预期收益的老虎机，只能靠投钱来以身试法，你要花多久时间来收集信息，又该在什么时候锁定目标发家致富呢，这就是Explore-Exploit的最经典案例，multi-armed bandit，多臂老虎机问题。 让我们从这个经典案例说起，看看历史上，不同科学家是如何选择的。 也许你可以随机挑选一台老虎机，只要你在赢就一直盯住它，一旦输了就转投另一台，以此循环。 这是由哥伦比亚大学的数学家Herbert Robbins针对多臂老虎机问题提出的第一个解法: Win-Stay Lose-Shift。 这个解法中Win-Stay的逻辑很直观：如果你已经选择一台机器，那么如果它让你赢了，那只会让你更有可能继续选择这台机器；但Lose-Shift就有待推敲了：试想你认准的机器让你连赢10次，但在第11次输了，你真的会因为这一次的结果而彻底改换一个尝试对象吗？ 就像你最爱的那家餐厅，你真的会因为某一次的某道菜没有那么好吃就不再去了吗？ 假设我们考虑的时间是一个有限的区间，探索的价值是逐日递减的，且不说你新发现的选项到底是不是比你目前的最爱更好，就算你找到了新的最爱，已经用来explore的时间也意味着起码这一次留给你exploit的时间没有多少了。 反过来，有限时间里exploit的价值却是递增的。你截止这个月为止最爱的餐厅by definition就一定和你上个月之前所尝试过的餐厅一样好或更好。 所以时间的维度决定了我们的策略应当根据剩余时间而定： 现在我们知道了interval是平衡explore/exploit的关键，同时它并不一定是一个具象甚至有界的期限，那么我们该如何将这种对于interval的认知融合到算法中呢？ Gittins Index回答了这个问题。 要理解Gittins Index 基廷斯系数，我们要先介绍一个经济学中常见的概念：time discounting，Gittins认为这种单位回报是呈几何递减的。 以选择餐厅为例，如果你认为你有1%的可能性某天会离开这座城市，那么一顿第二天晚餐的价值就应该是今天晚餐价值的0.99，依次递推。基于目前所收集的信息，Gittins Index为每一种情况都赋予了一个系数。 因此，你的众多选择瞬间变成一个明确的定量比较——谁系数高就选谁。 1985年，提出Win-Stay Lose-Shift的那位哥大数学家Robbins时隔多年又带着加强版解法归来了。 这一次他提供了另一个看待这类问题的思路：在你做一个选择时，你不必纠结任何一个选项会给你带来什么，而是扪心自问， Robbins的新算法所做的将后悔量化，定义为实施某一特定策略所得到的回报与最大可能的回报之间的差值，就是选择那个将你的后悔值最小化的策略。 不过人和机器终究还是不同的，我们并不会、也不需要总按照最佳策略生活。 面对这变幻不息的世界，我们能从这些算法中学到的，或许并不只是某一种策略，而更是一种新的看待选择与变化的方式： 人生的旅程中，刚刚启程的孩子正该尽情探索属于他们的无限可能，而年纪渐长的父母老人在我们眼里的固执己见，又何尝不是一种看过更多人生风景后的积累与沉淀。 二月已过、三月将来，新春伊始，不如就从今天起将这些新的体会付诸实践：探索一家新的餐厅，也挑战踏出你的舒适圈，或许渐渐你会发现，生活真的一天比一天更美好。 以上就是Algorithm to Live by第二章的内容主要内容，点击 收听大数据文摘喜马拉雅专栏音频 。 在这个崭新的专栏中，我们将陆续探讨这些你在生活中将要用到的算法。这些算法和观点将主要来自一本算法书籍Algorithm to Live by（生活中的算法），这本书被称为“the computer science of human decisions（人生抉择中的计算机科学）”。主播段天霖告诉我们，在杜克大学和斯坦福大学等学府的统计学和计算机系，这本书几乎人手一本，是一本难得引人深思的好书。 在这个新的栏目里，我们将从这本书出发，探讨算法和人生的关系。当然，其中所涉及的并不只是计算机科学，它与数学、工程学、认知科学、心理学、经济学都通通相关。 本书的两位作者除了本专业，也都在这些方面各有建树：Brian Christian是位布朗大学计算机与哲学双学位毕业的作家和诗人，Tom Griffith则是斯坦福统计与心理学毕业的加州伯克利教授，专攻computational cognitive science，计算认知科学。 不仅如此，这两位大神还专门找到当初设计这些计算机算法的科学家们，了解这些算法背后的故事。接下来的一段时间，我们将在这个新栏目中，跟随他们的脚步，探讨一些人类和计算机所共同面临的难题： 如何分配有限的空间、时间、注意力；如何应对不完整的信息和无限的未知......我们将了解到计算机是如何尝试优化这些问题的，而我们作为人类可以如何借鉴，又面临着哪些独特的挑战。 最后，希望这本书的旅程能让你我都能有所收获，并带着一种新的视角来审视取舍与抉择，这个人生中永恒的主题。  当然，我们也欢迎对这本书和我们的栏目感兴趣的读者，加入我们的reading club，和我们一同阅读本书，发表你的评论，探讨相关话题。 如果你想要加入我们的读书会，和我们一起阅读探讨这本书，我们希望你： 1、有还不错的英文水平： 这本书目前在国内还没有正式的中文译本，所以我们的阅读以英文原著为主； 2、对阅读和表达有热情： 我们会规定一个固定的时间段（通常是一周时间）与大家分享一个章节，并要求你在固定的时间之前，在群里表达相关心得（可以是读书笔记、思维导图、甚至一段语音）； 3、对自己有一定的要求： 每个群限额50人，无法按期完成阅读量或不及时反馈的读者将被清除。 如果读到这里，你依然对这本书以及我们的节目充满期待，那么欢迎扫描二维码，添加 ai_learner 好友，备注“ ”，加入我们。 Have a great data! 回复 “ ”加入我们 
114,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657740&idx=4&sn=755d7d84fb77003e6bc29ff61961ed37&chksm=bd4c319f8a3bb88982a3dee19bbcc459bdeb0d6dbeef673e4282eb215fda75e8be330c7209d5&scene=27,快讯 | 超越美国！中国AI启动资金数额占全球48%，重点投资人脸识别和芯片,大数据文摘作品 编译：蒋宝尚 中国的人工智能启动资金数额超过美国，重点投资领域是面部识别和芯片。 经过近十年的发展，计算机的算力和处理数据的能力取得了重大的突破。人工智能领域因此迅猛发展。 中美两国在人工智能方面展开竞赛，两方各有千秋。在美国， 自然语言处理，机器学习应用，以及计算机视觉与图像 入列AI创业公司的三甲。而中国排名前三的领域为：计算机视觉与图像，智能机器人以及自然语言处理。 人工智能各领域企业数量分布 中国和美国在人工智能开发方面的竞争很难量化，虽然有些指标可以初步评估AI的发展能力，但是没有指标可以全面评估。 根据CB Insights的数据，在对AI初创公司的资助上，中国已经超越美国成为世界第一大国。 但是，这并不意味着在中国在这场竞赛中取得完胜。虽然就个人交易数量而言，美国仅占总数的9%，而美国在人工智能初创企业的总数和总体融资总额方面均居榜首。但是，在人工智能创业融资的美元价值方面，中国处于领先地位，CB insight表示：“中国正在积极执行一个影响深远的AI愿景”。 中国在人工智能方面具有天然的优势。与美国相比，它拥有庞大的人口(十四亿)，这为人工智能企业提供了丰富的数据和机会。中国的人工智能行业也得到了中央政府的支持，相对于缺乏行动的白宫而言，中央政府能够迅速转移资源，而国家对数字监管的宽松做法意味着企业可以更自由地进行实验。 中国的在人工智能上投入的资金， 。这种技术的应用很普遍，从识别乱穿马路的行人到分配厕纸，无所不包。更重要的是，它也被视为监视和跟踪的工具。这是美国公民可能不想复制，也无法复制的技术优势。 识别不守交通规则的行人和司机 除了人脸识别，CB Insights还指出， 。像寒武纪科技（ 去年8月募资1亿美元） 这样的初创企业正在开发处理器，以满足机器学习的需求。这种巨额资金的投入是有价值的，因为，尽管人工智能芯片的很多投资资金流向中国的初创公司，但在美国，高通(Qualcomm)、英伟达(Nvidia)和英特尔(Intel)等老牌公司正在将资源投入到同样的事业中。显然，中国不希望被牵着鼻子走。 在美国和中国的人工智能竞赛中，鹿死谁手尚不明确，但是中国在人脸识别和芯片技术方面已将美国甩在身后了。 素材来源： https://www.theverge.com/2018/2/22/17039696/china-us-ai-funding-startup-comparison http://www.askci.com/news/chanye/20170803/144016104531_7.shtml 【今日机器学习概念】 Have a Great Definition 
115,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657697&idx=2&sn=d616c5f5b7c1fa8f4592ffbde4f1f8c6&chksm=bd4c32728a3bbb649ce23f710a1bc82ffb83062003231cdd16263ac1044bdc81385a89ae246e&scene=27,快讯丨斯坦福等高校联合研发的律政界AlphaGo，刚刚战胜了20名顶级律师,大数据文摘作品 编译：蒋宝尚、小鱼 在一场与人工智能比赛解释合同的竞赛中，20名顶尖律师输了。 法律AI平台LawGeex与斯坦福大学、杜克大学法学院和南加州大学的法学教授合作进行了一项新的研究，让20名有经验的律师与训练好的法律AI程序相互比赛。 比赛内容是四小时审查五项保密协议（NDA），并确定30个法律问题，包括仲裁，关系保密和赔偿。如何准确界定每个问题是比赛的得分要点。 人类律师的平均准确率达到了85％，而AI的准确率达到了95％。 另外，AI在26秒内完成了任务，而人类律师平均需要92分钟。值得注意的是，人工智能在这些合同中最高可以达到100％的准确率，而其中人类律师的最高得分仅为97％。简而言之，人类律师完败。 知识产权律师Grant Gulovsen是比赛参与者之一，他表示这项任务与许多律师每天所做的工作非常相似。 “大多数文件，无论是遗嘱，公司运营协议，还是NDA等，他们的内容都非常相似，”Gulovsen说。 那么这是否意味着律师这个职业的终结？完全不是。相反，使用AI确实可以帮助律师加快工作速度，以便他们能专注于那些仍需要人脑的任务。 “让AI作为一个律师助理对NDA进行初次审查，将为律师腾出宝贵的时间，专注于客户咨询和其他更高价值的工作，”杜克大学法学院临床教授Erika Buell说。 这项技术绝不会完全取代律师这个职业，但是律师们可以利用这项技术找到他们要讲的故事中最重要的部分，提高他们工作的效率。 “我坚信，法律专业的学生和初级律师需要理解这些人工智能工具和技术，这将有助于他们成为更好的律师，以便未来在法律方面有更好的建树，”Buell说道。 “如果律师们能用这些工具更有效地处理法律问题，那么这类新工具将会非常受欢迎。” 这场“对决”的组织者LawGeex将人类与AI双方的详细介绍、评分标准、技术内核写成了一篇详尽的报告。 后台对话框内回复  “律师” 即可下载报告，进一步了解这场比赛。 原文链接： https://mashable.com/2018/02/26/ai-beats-humans-at-contracts/?from=singlemessage&isappinstalled=0#NQSAXAlXWkqd Have a Great Definition 
116,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657697&idx=3&sn=35cf966e931d997b79bd91dea13527e7&chksm=bd4c32728a3bbb6419e0dff18225c2ed5de9c45478f27cb2712a93fdf5f7924409520548179e&scene=27,AI大事件丨中国的AI启动资金超过美国，JupyterLab上线，用少量样本实现语音克隆,"呜啦啦啦啦啦小伙伴们大家好呀，沉寂一个春节的AI大事件又开始更新啦！过去的一周中AI圈都发生了什么？大佬们讨论了哪些问题？研究者们发布了哪些值得一读的论文？又有哪些开源的代码和数据库可以使用了？快快跟随文摘菌盘点过去一周AI大事件！ 新闻 来源： BLOG.JUPYTER.ORG   JupyterLab是面向研究人员和数据科学家的流行笔记本工具Jupyter的下一代基于Web的界面。随着最新版本的发布，JupyterLab现在可以用于日常研究工作。 来源： WWW.THEVERGE.COM   链接： https://www.theverge.com/2018/2/22/17039696/china-us-ai-funding-startup-comparison?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 根据CB Insights的数据，在对AI初创公司的资助上，中国已经超越美国成为世界第一大国。2017年中国占全球人工智能启动资金总额的48％，而美国仅为38％。 来源： MALICIOUSAIREPORT.COM 链接： https://maliciousaireport.com/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 该报告调查了可能的恶意使用人工智能技术带来的潜在安全威胁，并提出了预测、预防和减轻这些威胁的方法。它的内容主要来自于2017年2月在英国牛津举行的为期2天的研讨会。 。 来源： ENG.UBER.COM 链接： https://eng.uber.com/uber-ai-residency/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI Uber AI Residency是一项为期一年的研究强化培训项目，预计将于今年夏天开始。Uber人工智能实验室从类似的计划中获得了灵感并创建了Uber人工智能居住系统，以帮助即将到来的研究人员加速他们在机器学习和人工智能研究和实践方面的职业生涯。 文章&教程 来源：RESEARCH.GOOGLEBLOG.COM 研究者们使用深度学习算法对来自284,335名患者的数据进行训练，该算法最终能够从12,026和999名患者的两个独立数据集中以惊人的高准确度预测来自视网膜图像的心血管危险因素，并且可以在71％的时间内将吸烟者的视网膜图像与非吸烟者的视网膜图像区分开来。 来源： WWW.ABIGAILSEE.COM 链接： http://www.abigailsee.com/2018/02/21/deep-learning-structure-and-innate-priors.html?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI Yann LeCun教授和Christopher Manning教授进行了一次有趣的讨论：“我们应该在深度学习系统的体系结构中建立什么先验知识？” 来源： BLOG.ACOLYER.ORG   链接： https://blog.acolyer.org/2018/02/22/dynamic-word-embeddings-for-evolving-semantic-discovery/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这篇文章实践了用于语义发现的动态词嵌入，这种技术可以让使用者跟踪词的含义，并观察语义随时间的变化。 来源： RESEARCH.BAIDU.COM 链接： http://research.baidu.com/neural-voice-cloning-samples/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 百度的发布的新成果试图从少数语音中学习说话人的特征，通常称为“语音克隆”。 代码，项目&数据 来源： GITHUB.COM 链接： https://github.com/openai/maddpg/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这是实现论文 Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments 提出的MADDPG算法的代码：它被配置在多代理粒子环境（MPE）中运行。 来源： GITHUB.COM 链接： https://github.com/deepmipt/DeepPavlov?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这是一个开源会话AI库的Alpha版本，建立在TensorFlow和Keras之上，专为NLP、对话系统和复杂对话系统的实现和评估而设计。 爆款论文 来源： ARXIV.ORG 链接： https://arxiv.org/abs/1802.07740?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI ToMnet通过单独观察代理的行为和使用元学习来构建它所遇到的模型。通过这个过程，它获得了一个强大的行为人先验模型，以及仅使用少量行为观察就能够丰富地预测行为人特征和心理状态的能力。作者将ToMnet应用于在简单的gridworld环境中运行的代理，表明它学习了来自不同人群的模型随机性、算法和深度强化学习代理。 来源：SITES.GOOGLE.COM 这篇文章介绍了一种方法，通过使用最大熵策略实现最大化信息理论目标来在没有奖励功能的情况下学习有用技能。作者表明，在各种模拟机器人任务中，这个简单的探索目标可以导致无监督地出现各种技能，如步行和跳跃 来源： ARXIV.ORG 链接： https://arxiv.org/abs/1802.08294?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 在研究领域中，一些真实世界的领域最好被描述为一个单一的任务，但对其他人来说，这个观点是受限的。相反，一些任务的复杂性与代理人的能力不断增加。在持续学习中（也称为终身学习）没有明确的任务边界或课程。作者提出了一种称为Unicorn的新型代理体系结构，该体系结构表现出强大的持续学习能力，并且在建议的3D域上胜过了几个标准代理。代理通过联合表示和学习多项策略来实现这一目标，即使用并行的关闭策略学习设置。 来源： ARXIV.ORG 链接： https://arxiv.org/abs/1802.08395?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 作者在他的论文中介绍了关于口语理解的端到端学习系统的研究。采用这种方法，可以直接从音频特征推断语义，而不需要文本表示。这项研究表明，训练出来的模型可以取得相当好的结果，并证明该模型可以直接从音频特征中捕获语义。 Have a Great Definition "
117,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657660&idx=1&sn=0112ec97739fb107de7d26083c176f9c&chksm=bd4c322f8a3bbb39352f8465cbeb93068ef541d23cdd7fdc02058c2904d04c3a6f6d429f347f&scene=27,文本分析了4000万条Stack Overflow讨论帖，这些是程序员最推荐的编程书（附代码）,"程序员们都看什么书？他们会向别人推荐哪些书？ 本文作者分析了Stack Overflow上的4000万条问答，找出了程序员们最常讨论的书，同时非常慷慨地公开了数据分析代码。让我们来看看作者是怎么说的吧。 寻找下一本值得读的编程书是一件很难，而且有风险的事情。 作为一个开发者，你的时间是很宝贵的，而看书会花费大量的时间。这时间其实你本可以用来去编程，或者是去休息，但你却决定将其用来读书以提高自己的能力。   所以，你应该选择读哪本书呢？我和同事们经常讨论看书的问题，我发现我们对于书的看法相差很远。 幸运的是，Stack Exchange（程序员最常用的IT技术问答网站Stack Overflow的母公司）发布了他们的问答数据。用这些数据，我找出了Stack Overflow上 4000万条问答里， 被讨论最多的编程书籍，一共5720本。 在这篇文章里，我将详细介绍数据获取及分析过程，附有代码。 我开发了dev-books.com来 展示书籍推荐排序 让我们放大看看这些最受欢迎的书 “被推荐次数最多的书是Working Effectively with Legacy Code ，其次是Design Pattern: Elements of Reusable Object-Oriented Software 。 虽然它们的名字听起来枯燥无味，但内容的质量还是很高的。你可以在每种标签下将这些书依据推荐量排序，如JavaScript, C, Graphics等等。这显然不是书籍推荐的终极方案，但是如果你准备开始编程或者提升你的知识，这是一个很好的开端。” ——来自Lifehacker.com的评论 获取和输入数据 我从archive.org抓取了Stack Exchange的数据。（https://archive.org/details/stackexchange） 从最开始我就意识到用最常用的方式（如 myxml := pg_read_file(‘path/to/my_file.xml’)）输入48GB的XML文件到一个新建立的数据库（PostgreSQL）是不可能的，因为我没有48GB的RAM在我的服务器上，所以我决定用SAX程序。 所有的值都被储存在<row>这个标签之间，我用Python来提取这些值： 在数据输入进行了三天之后（有将近一半的XML在这段时间内已经被导入了），我发现我犯了一个错误：我把“ParentId”写成了“ParentID”。 但这个时候，我不想再多等一周，所以把处理器从AMD E-350 (2 x 1.35GHz)换成了Intel G2020 (2 x 2.90GHz)，但这并没能加速进度。 下一个决定——批量输入： StringIO让你可以用一个文件作为变量来执行copy_from这个函数，这个函数可以执行COPY（复制）命令。用这个方法，执行所有的输入过程只需要一个晚上。 好，是时候创建索引了。理论上，GiST Indexes会比GIN慢，但它占用更少的空间，所以我决定用GiST。又过了一天，我得到了70GB的加了索引的数据。 在试了一些测试语句后，我发现处理它们会花费大量的时间。至于原因，是因为Disk IO需要等待。使用SSD GOODRAM C40 120Gb会有很大提升，尽管它并不是目前最快的SSD。   我创建了一组新的PostgreSQL族群： 然后确认改变路径到我的config服务器（我之前用Manjaro OS）： 重新加载config并且启动postgreSQL： 这次输入数据用了几个小时，但我用了GIN（来添加索引）。索引在SSD上占用了20GB的空间，但是简单的查询仅花费不到一分钟的时间。   从数据库提取书籍 数据全部输入之后，我开始查找提到这些书的帖子，然后通过SQL把它们复制到另一张表： 下一步是找的对应帖子的连接： 但这时候我发现StakOverflow代理的所有链接都如下所示: 于是，我建立了另一个表来保存这些连接和帖子： 我使用常用的方式来提取所有的ISBN（国际标准书号），并通过下图方式提取StackOverflow的标签到另外一个表： 当我有了最受欢迎的标签并且做了统计后，我发现不同标签的前20本提及次数最多的书都比较相似。 我的下一步：改善标签。 方法是：在找到每个标签对应的前20本提及次数最多的书之后，排除掉之前已经处理过的书。因为这是一次性工作，我决定用PostgreSQL数组，编程语言如下： 既然已经有了所需要的数据，我开始着手建立网站。   建立网站 因为我不是一个网页开发人员，更不是一个网络用户界面专家，所以我决定创建一个基于默认主题的十分简单的单页面app。 我创建了“标签查找”的选项，然后提取最受欢迎的标签，使每次查找都可以点击相应选项来搜索。 我用长条图来可视化搜索结果。尝试了Hightcharts和D3（分别为两个JavaScript数据可视化图表库），但是他们只能起到展示作用，在用户响应方面还存在一些问题，而且配置起来很复杂。所以我决定用SVG创建自己的响应式图表，为了使图表可响应，必须针对不同的屏幕旋转方向对其进行重绘。 网页服务失败 Nginx 还是 Apache？   当我发布了 dev-books.com这个网站之后，它有了大量的点击。而Apache却不能让超过500个访问者同时访问网站，于是我迅速部署并将网站服务器调整为Nginx。说实在的，我对于能有800个访问者同时访问这个网站感到非常惊喜！   如果你有任何问题，可以通过twitter（https://twitter.com/VLPLabs ）和Facebook（https://www.facebook.com/VLP-Labs-727090070789985/）联系作者。 原文链接： https://medium.freecodecamp.org/i-analyzed-every-book-ever-mentioned-on-stack-overflow-here-are-the-most-popular-ones-eee0891f1786 Have a Great Definition "
118,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657740&idx=1&sn=4f92ecbdb46cd6097cd35a60cb19907e&chksm=bd4c319f8a3bb8891c01a37a39752142741f5b113086224db189cb4be35b7d83d39dcfcb8045&scene=27,手把手：自然语言处理太难？按这个套路走，就是砍瓜切菜！（附Python代码）,"大数据文摘作品 小饭盆、 周佳玉、 笪洁琼、钱 天培 豆瓣水军检测、《权游》续写、越来越神的谷歌翻译...... 最近 自然语言处理（NLP）的各路应用可是被玩得风生水起。 这些NLP应用看起来炫酷到没道理，但其实背后的原理并不难理解。 今天，文摘菌就来扒一扒最常用的自然 语言处理技巧和模型，手把手教你做一个简单神奇的小应用。 不吹不黑，90%的NLP问题都能用类似方法解决。   今天这个教程从数据处理的三大阶段教你自然语言处理： 收集，准备、检查数据 建立简单的模型（包括深度学习模型）  解释、理解你的模型 整篇教程的Python代码都在这儿啦： https://github.com/hundredblocks/concrete_NLP_tutorial/blob/master/NLP_notebook.ipynb   赶紧开始吧！ 第1步：收集数据 自然语言数据的来源太多啦！ 淘宝评论、微博、百度百科等等。 不过今天呢，我们要处理的数据集来自推特 “社交媒体上的灾难”数据集（ Disasters on Social Media dataset）。 我们将使用由CrowdFlower慷慨提供的一个名为“社交媒体灾难”的数据集。 其中一部分推特确实描述了灾难事件，而剩下的则是影评、笑话等等奇怪的东西=。=   我们的任务将是检测哪些推文是关于一个灾难性的事件，而不是一个不相关的话题，如电影。 为啥要这么做呢？有关部门就可以用这个小应用及时得到灾难事件信息了嘛！ 接下来，我们将把有关灾难的推特称为“disaster”，并将其他推文称为“irrelevant”。 Labels标签 注意哦，我们用的是有标签的数据。正如NLP大神Socher所说，与其花一个月用无监督学习处理一堆没有标记过的数据，还不如花个一周时间标记一点数据，整一个分类器。 第2步：清洗数据 我们遵循的第一原则是：“再好的模型也拯救不了shi一样的数据”。 所以，先来清洗一下数据吧！ 我们做以下处理： 1. 删除所有不相关的字符，如任何非字母数字字符 2. 通过文本分隔分成单独的单词来标记你的文章 3. 删除不相关的字词，例如“@”推特或网址 4. 将所有字符转换为小写字母，以便将诸如“hello”，“Hello”和“HELLO”等单词看做相同单词 5. 考虑整合拼写错误或多种拼写的单词，用一个单词代表（例如“cool”/“kewl”/“cooool”）相结合 6. 考虑词形还原（把“am”，“are”，“is”等词语缩小为“be”这样的常见形式） 按照这些步骤并检查其他错误之后，我们可以开始使用干净的标记数据来训练模型！ 第3步：找到一个好的数据表示方式 数据清理完了，我们还得把这些文字转换成数值——这样机器才看得懂嘛！ 例如，在图像处理中，我们就需要把图片转换成一个表示像素点RGB强度数字矩阵。 一个笑脸代表着一个数字矩阵 自然语言处理中的表示稍微复杂一点。我们会尝试多种表示方法。 独热编码（词袋） 表示计算机文本的一种自然方法是将每个字符单独编码为一个数字（例如ASCII）。  例如，我们可以建立数据集中所有唯一字的词汇表，并将唯一索引与词汇表中的每个单词相关联。然后，每个句子都被表示为一个与我们词汇表中唯一字数量一样长的列表。在这个列表中的每个索引处，我们标记给定词语出现在我们句子中的次数。这就是所谓的词袋模型，因为它是一个完全忽略我们句子中单词顺序的表现形式。如下所示。 代表句子作为一个词袋。左边为句子，右边是其表示形式。向量中的每个索引代表一个特定的词 可视化嵌入 在“社交媒体的灾难”这个例子中，我们有大约2万字的词汇，这意味着每个句子都会被表示为一个长度为2万的向量。该向量将包含大部分0，因为每个句子只包含我们词汇的一个很小的子集。 为了了解我们的表示是否捕获与我们的问题相关的信息（即推文是否与灾难有关），让我们将它们可视化并查看这些类是否看起来很好地分离是一个好主意。由于词汇通常非常大，并且不可能在20,000维度上显示数据，所以像PCA这样的技术将有助于将数据投影到两个维度。如图所示： 可视化   这两类看起来不太好分开，这可能是我们嵌入的一个特征，或者仅仅是由于我们的维度降低。为了看看词袋特征是否有用，我们可以根据它们来训练一个分类器。 第4步：分类 首先遇到问题时，一般的最佳做法是从最简单的工具开始解决问题。每当涉及到对数据进行分类时，基于通用性和可解释性的一个普遍喜好是Logistic回归。训练非常简单，结果可以解释，因为你可以轻松地从模型中提取最重要的系数。 我们将数据分成一个用于拟合模型的训练集和一个用于评估模型泛化能力的测试集，以此来推广到不可见的数据。训练结束后，我们得到了75.4％的准确度。还不错哦！如果我们简单地猜测最频繁的类（“irrelevant”），准确率只能达到57％。但是，即使75％的精度足够满足我们的需求，我们也不应该在不尝试了解它的情况下，发布一个模型。 第5步：检查 第一步是了解我们模型的错误类型，以及哪种类型的错误是最不可取的。在我们的例子中，假阳性划分为irrelevant，事实上是diasaster，而假阴性实际是disaster，而归类为irrelevant。如果要优先处理每一个潜在的事件，我们会想要降低我们的假阴性。然而，如果我们受到资源的限制，我们可能会优先考虑较低的假阳性来减少误报。 将这些信息可视化的一个好方法是使用混淆矩阵，它将我们的模型的预测与真实标签进行比较。理想情况下，矩阵将是从左上角到右下角的对角线（预测和实际完美匹配）。 混淆矩阵（绿色是高，蓝色是低） 相对于假阳性来说，我们的分类器按比例产生更多的假阴性。换句话说，我们模型最常见的错误是将disaster归类为irrelevant。如果假阳性导致高的执法成本，这使我们的分类器可以有一个很好的bias（偏差）。        为了对我们的模型进行验证并分析它预测的准确性，我们需要看它通过使用哪些词来做决定，这是十分重要的。如果我们的数据存在偏差，那么分类器将只能在样本数据中做出准确预测，而这个模型在现实世界中则不能很好地推广。在此，我们分别为disaster和irrelevant绘制了“最关键的词”的表。由于我们可以对用于预测的模型的系数进行提取和排序，使用词袋和逻辑回归来计算单词的重要性其实很简单。 词袋：关键词     我们的分类器正确地采取了一些模式（如hiroshima广岛、massacre大屠杀），但这其中也显然有一些看似无意义的过度拟合（heyoo蓝调摇滚，x1392话题简称）。现在，我们的词包模型正在处理包含各种不同单词的巨大词汇表，并且平等地对待所有单词。然而，这其中的一些词语出现的非常频繁，只会对我们的预测产生影响。接下来，我们将尝试一种新方法来表示能够统计单词频率的句子，看看能否从我们的数据中获取更多的信号。 第6步：统计词汇结构 为了使我们的模型更多的专注于有意义的单词，我们可以在词袋模型顶部使用TF-IDF评分（术语频率、逆文档频率）。TF-IDF通过在数据集中的出现频率来确定词权重，减少出现过于频繁的词的权重而增加到噪音干扰上。下图是对我们新嵌入数据的PCA预测。 TF-IDF嵌入可视化     从上图可以看出，在这两种颜色之间有一个相对清晰的分界。这将会使我们的分类器更容易将其分为两组。让我们来看看这是否会带来更好的表现吧！接下来在我们新嵌入的数据上训练另一个Logistic回归参数，我们得到了76.2％的准确性。    这是一个非常细微的改进。我们的模型是否已经开始采用更关键的词？如果我们在防止我们模型“作弊”的同时取得了更好的效果，那么我们就可以真正认为这个模型实现了一次突破了。 TF-IDF：关键词    模型所采取的词看起来更相关！尽管我们测试集的指标只是略有增加，但是我们对模型使用的术语将会更有信心，所以将其应用在与客户交互的系统中会感到更加舒适。 第7步：巧妙利用语义     我们的最新模型设法采取具有高信号的词。然而，如果我们配置这个模型，很可能会遇到我们之前在训练集中没有看到的词。然而即使在训练中看到非常相似的单词，以前的模型也不能准确辨别这些干扰。     为了解决这个问题，我们需要捕捉词的语义，这意味着我们需要理解“好”和“积极”等词比“杏”和“大陆”更相近。我们将用名为 这个工具帮助我们捕捉语义。    Word2Vec是一种实现连续词嵌入的技术。它通过阅读大量的文字来学习，并记忆哪些词倾向于出现在相似的语境中。在训练足够多的数据后，它会为词汇表中的每个词生成一个300维的向量，意思相近的词彼此则会更接近。      本文的作者开源了一个模型，它在一个非常庞大的语料库上预先训练好，我们可以利用这个语料库将一些语意知识纳入到我们的模型中。预训练的向量可以在与这篇文章相关的知识库中找到。      为我们的分类器获得句子嵌入的一个快速方法是：平均句中所有词的Word2Vec得分。这跟以前一样也是一个词袋的方法，但是这次我们只丢掉句子的语法，而保留一些语意信息。 Word2Vec句嵌入      下图是使用先前技术获得的新嵌入可视化： Word2Vec嵌入可视化      两组颜色的分界看起来更加明显，我们的新嵌入技术一定能帮助我们的分类器找到两个类之间的分离。第三次（使用Logistic回归）训练同一个模型后，我们得到了77.7％的精准度，这是我们到目前为止得到的最好的结果！接下来该检查我们的模型了。      由于新嵌入技术没有像我们以前的模型那样以每个单词一维向量来表示，所以很难看出哪些单词与我们的分类最为相关。虽然我们仍能使用Logistic回归的系数，但它们只与我们嵌入的300维度相关，而与词汇索引没有关联。     对于如此低的准确度，失去所有可解释性似乎是一个艰难的权衡。然而，对于更复杂的模型，我们可以利用LIME等黑盒解释器来深入了解分类器的工作原理。   Github通过开源软件包提供LIME。黑盒解释器允许用户通过干扰输入（在我们例子中即去除句子中的单词）来解释任何分类器的决定，并查看预测的变化。      接下来让我们一起看看我们数据集中的几个句子的解释。 然而，我们并没有时间去探索数据集中的数千个案例。我们应该做的则是在测试案例的典型范例上继续运行LIME，看看哪些词的占有率仍能位居前列。通过这种方法，我们可以获得像以前模型那样的单词的重要性分数，并验证模型的预测。   Word2Vec：关键字   模型似乎能提取高度相关的词，这意味着它也许能做可理解的决定。而这些看起来像是以前所有模型中最相关的词，因此我们更愿意将其配置到实际操作中。 第8步：使用端到端的方法来巧妙利用语义     我们已经介绍了快速有效的方法来生成紧凑的句嵌入。然而，通过省略词序，我们放弃了句子的所有句法信息。如果这些方法不能提供充分的结论，则可使用更复杂的模型，将整个句子作为输入并预测标签，而不需要建立中间表示。一种常见的方法是 ，使用Word2Vec或更新的方法，如GloVe或CoVe。这就是我们将在下面做的。 高效的端到端体系结构（源）    用于句子分类的卷积神经网络训练非常迅速，并且作为入门级的深度学习体系能够很好地完成任务。虽然卷积神经网络（CNN）主要因其在图像数据上的性能而闻名，但它们早已在文本相关任务上提供了优异的结果，并且通常比大多数复杂的NLP方法（例如LSTM和编码器/解码器体系结构）能更快地训练。这个模型保留了词序，并且学习了关于哪些词序列可以预测我们目标类的有价值的信息。与之前的模式相反，它是可以区分“亚历克斯吃植物”和“植物吃亚历克斯”的不同。     训练这个模型不仅不需要比以前方法更多的工作（详见代码），而且给了我们一个比以前方法更好的模型，准确率达到了79.5％！与上述模型一样，下一步应该是继续使用我们描述的方法来进行探索和解释预测，以验证它确实是配置给用户的最佳模型。现在，你应该能自己上手处理这个问题了。 小结     从一个简单快捷的模型开始 解释其预测 了解它正在犯的错误类型 利用这些知识来确定下一步工作：模型对数据是否有效，还是应该使用更为复杂的模型 这些方法被应用于特定的案例，如理解和利用诸如推文之类的短文本模型，但实际上这些思想广泛地适用于各种问题哦！ 就像开头文摘菌说的，90%的自然语言处理问题都可以用这个套路解决，那还不是砍瓜切菜！   原文链接： https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e?gi=6fefa8b6c671 【今日机器学习概念】 Have a Great Definition "
119,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657660&idx=2&sn=5f3764ddc43577004ac4ce0117db6295&chksm=bd4c322f8a3bbb39b71d40fe1f73e89b438a64e7e052a6e9918af7a5cd2cdeba17451ea9da76&scene=27,BlockChange | 虚拟货币也有评估框架啦！资深风投教你用6大关键维度冷静选择,"玲琅满目的虚拟货币中，你如何选择哪种货币进行投资？在狂热大潮中如何保持冷静的分析头脑？定性的衡量标准在这个时候尤其重要。 最近虚拟货币带来了无与伦比的致富机会，基本上所有人都参与了这项疯狂的游戏。然而，尽管市场上到处都是热烈的讨论，却很难找到可靠的投资框架来评估新上市的虚拟货币。 在同虚拟货币专家交流之后，我们惊讶的发现很多专家依靠主观判断来做决策——比如团队背景、报告质量以及作为区块链平台的可行性。 以上所有的特征都具有无可否认的重要性。但是，虚拟货币的迷人之处在于大部分项目都是开源的，在Github（代码托管平台）上可以查到源码。而且，在很多社交媒体比如推特、Reddit（社交新闻站点）、BitcoinTalk（虚拟货币论坛）和Telegram（中文名电报，功能类似微信）上都有大量的虚拟货币讨论。我们相信这些数据可以用来评估一个虚拟货币的合理性。 于是我们开发了一个专门利用定量和定性指标来总体评估虚拟货币的框架。 首先，我们确定了 ，货币目标排序是在每个指标上按低中高三个等级的顺序来打分。为了找出每个指标的基准，我们按照市值（2018年1月26日的市值）和汇总分数高低，选取了TOP50种虚拟货币。 大部分的定量指标是从Github、CoinGecko（币虎数字货币排名应用程序）、CoinMarketCap（加密货币市值排名网站）、BitInfoCharts（虚拟货币对比网站）等网站抓取获得，而定性的数据则是从公司的官网、报告和如Reddit、Twitter、Telegram等在线交流站点上获取。汇总的数据在我们的表格里 ，定量指标的汇总如下所示： 表格链接： https://docs.google.com/spreadsheets/d/1gArufBuDdoV561w7byxvW-UieQxZhjv9jDq6aOAUwQM/edit#gid=353840556 本文分析的主要应用于山寨币（除比特币、以太币之外的虚拟货币）。 下面我们运用六大关键维度以及其中的指标和举例来说明我们将如何进行虚拟货币的评估。 在这个分类里，比特币可以拿到9分到10分（满分12分）。其中，翔实的白皮书可以拿3分。有很多竞争者，他们诟病比特币的很多技术缺陷，但是很明显比特币仍然有很大的市场份额（3分钟可以拿到2分，还可斟酌）。目前出块时间在8分钟左右（得1分）。区块链技术是其匿名性、去中心化和全球交易的核心技术（得3分）。 我们认为出块时间对于主要用于保值的虚拟货币来说并没有作为交易媒介的虚拟货币那么重要。但是，由于很多虚拟货币都声称能够灵活满足经常性交易，所以我们把更短的出块时间作为加分项。 在这个分类里，Decred（一种山寨币）可以得到11分（总分12分）。Reddit（得3分）和Telegram（得2分）社区的规模和币的市值非常匹配。李启威担任顾问（得3分），推特呼声（下图可以看到）非常积极，非顾问的影响者如 Tai Zen 和 Garry Tan 公开表示支持（得3分）。 Tai Zen： https://twitter.com/HeyTaiZen%20/t%20_blank Garry Tan： https://twitter.com/garrytan/status/920167450498363393%20/t%20_blank 推特是另外一个讨论虚拟货币的重要场所。但是由于存在大量的伪造和虚假用户，所以我们不参考货币推特社区的大小和发帖的频率来评估其价值（至少在“社区”维度不会，我们会在“人脉”维度考量）。同时我们决定评估Reddit和Telegram社区作为市值的参考，而不是作为基础数据。因为我们认为这样惩罚那些还不是很知名（市值小），而且社区比较小的货币并不公平。 在这个分类里，比特股（BitShares）可以拿到满分12分中的8分。大部分的开发者都是匿名的，并且官网中的团队介绍已经失效（得1分）。GitHub有5212次更新来自79位开发者（得3分）。过去一个月有20位开发者共提交了78次代码，代码关闭和新增比例为2.3（得3分）。但是，单个开发者提交占比最高为43%（得1分）。 在代码提交方面过度集中于某一个开发者并不一定是扣分项。但是，考虑到很多货币都处于开发初期，如果过分依赖某一个开发者会有很大风险。所以我们认为过度依赖某个开发者对评分有负面影响。 这个维度里,Omise（一种山寨币）可以拿到9分里的8分。由于是风投公司的产品，所以已经上线但是没有公开代码（得2分）。目前在东南亚为超过6000个批发商（3分）每天处理相当于百万美元级别的交易，包括为泰国240家麦当劳提供支付业务（3分）。 我们知道每小时5000次的交易能力是一个相当一般的量。但是我们尝试区分经常使用在交易里的货币和那些较难使用或者未经证实的货币。所以参考前50种虚拟币的交易能力，每小时5000次交易量还是一个挺合理的门槛。 在这个维度里，Augur（一种虚拟币）可以拿到12分里的10分。过去一个月币价掉了2%（得3分），但过去一年涨了18.76倍（得3分）。登陆了2家排前五名的交易所（得2分）。代币额度为1100万，几乎所有的代币都在2015年进行了众筹——20%留给创始团队和Augur基金会（兑现计划未公布），因此代币发放得2分。 我们认为从短期收益来看近期的高额回报是扣分项。在接下来几个月或者几年里，有很多低价格的虚拟币（价格低于1美金），有些有机会成为百倍币、千倍币甚至万倍币。已经大幅升值的货币不太可能再次暴涨。 从短期收益的角度来看货币所登录的交易所。如果还没有上过主流交易所，我们可以期待在登录大交易所后币价的大幅提升且更容易购买。但是长远来看，更容易买到的币发展会更好，所以1-3的标准会反过来。关于表中一个月和一年的回报率也会根据TOP50虚拟货币的平均情况进行调整。 我们相信中长期来看，一个虚拟币的成功很大程度上依赖于人脉效应。更多的人拥有某个币，这个币就更容易获得认可并被广泛接受，也就更难下跌。我们会着重介绍为什么这一点十分重要，通过上面的标准我们其实就是想得到有多少人持有、关注或者知道某种虚拟币。 这个维度里，百特币（Bytecoin）能得7分（满分12分）。过去30天里它有7200个推特提及数（得2分）和317个新闻提及数（得2分），同时有9600个Reddit读者和2.93万个推特关注者（得1分）。并且过去一年谷歌趋势得分（同比特币对比）为0.06（得2分）。 你需要记住的虚拟货币人脉效应的例子： 交易： 基本上所有山寨币交易所都是要求用比特币或者以太坊进行交易——你不可以用信用卡或者Paypal来买。作为交换媒介的虚拟币将会从投资者的购买（潜在持有）用于交易其他山寨币来获得升值。 机构兴趣 ：机构投资者会投入重金到某种虚拟货币，但是会担心诸如合理性、流动性以及币价稳定性。市值更大的虚拟货币一般会被认为更加合理，有足够的流动性来维持大量的投资而不会出现价格暴涨。需要多说一点的是，币价一般更加稳定，所以有更多的投资者对避免大幅贬值感兴趣。 安全： 被广泛接受的币种自然有更好的安全性——流通群体越大就越难被攻击，同时有更多的开发者来发现和修补潜在的漏洞和缺陷。投资者期望购买建立在更加安全平台上的虚拟货币，更好的安全性会给虚拟货币带来更多的资本流入。 媒体： 面对大量的虚拟货币，媒体会主要关注接受度最高的币种。很多个人投资者会考虑购买他们在媒体上经常听到的币种，这样就会产生良性循环，某种币的交易量越大受媒体曝光的机会也更多。目前对很多人来说，比特币实际上已经成了虚拟货币的代名词。 交易方式： 最大型的货币很可能最早被零售商购入（比如Overstock.com接受比特币），于是会有更多的人对使用虚拟币交易感兴趣并且大部分的零售商都希望限制初次发售。因为货币被大量零售商接受，因此可以预测会吸引更多散户持有货币，进而吸引更多零售商。 监管合法性： 相对只有少量投资者的虚拟币，监管者更难关闭有成千上百万用户的大型虚拟货币。监管者更倾向于同被最广泛接受的货币合作，而小型的山寨币则会面对更加不利的监管。 原文链接： https://hackernoon.com/a-framework-for-evaluating-cryptocurrencies-e1b504179848 【今日机器学习概念】 Have a Great Definition "
120,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657660&idx=3&sn=3d2c358f9ef3165c0ef08bf0878d8acb&chksm=bd4c322f8a3bbb39468c2d8f7cd4a8396fc9b79d29f3289386293ad7d7807286206e9459f3b4&scene=27,184名同学与李飞飞吴恩达一起欢度春节：七天打卡活动圆满结束,狗年春节前，大数据文摘发布了春节打卡学习的召集令 ，组织运营志愿者和打卡学习者进行吴恩达《Deep Learning Specialization》和李飞飞《CS231n：Convolutional Neural Networks for Visual Recognition》部分课程内容的笔记打卡学习。说实话，当时的文摘菌并不敢有特别高的期待，毕竟春节学习要面临的困难太多了：往返路程的颠簸、各种聚会的影响，还有熊孩子和亲戚们的持续打扰。 但是，很显然文摘菌低估了读者们的执行力和学习热情，本次的打卡活动进展无比顺利！活动结束后，文摘菌给大家做一个简单的活动总结，看看我们都收获了哪些成果。 和全世界的AI-Learner一起学习 本次活动，我们吸引了身处美国、悉尼、加拿大和台湾等地小伙伴。一位来自台湾的朋友在支付时遇到了困难，最后在文摘菌的帮助下，这位台湾朋友顺利进入学习社区！ 我们也经常在深夜收到时差党小伙伴们的打卡，跨越时区的学习热情，真是挡也挡不住啊！ 不得不感叹，想学习的小伙伴即便跨过千山万水也愿加入我们~所以，这么好的学习机会就摆在你眼前时，千万不要错过哦。 在我们的学习社区中，也潜伏了很多深度学习领域的大咖，时常进行课程内容的讨论和扩展。这种互动式的学习氛围，对于刚入门的小白和进阶中的学习者，都非常有帮助！ 收获了高质量的学习笔记 社区呈现出了非常多优质的学习笔记，以下为大家展示一小部分。感谢作者的授权！ 课程： 吴恩达《Deep Learning Specialization》，第一门课 作者：Neptune 笔记软件：Xmind 后台回复“打卡笔记”，可获取高清原文件 课程： 吴恩达《Deep Learning Specialization》，第一门课 作者：沈晶 手写笔记 后台回复“打卡笔记”，可获取高清原文件 课程： 吴恩达《Deep Learning Specialization》，第一门课 作者：Wan Baosi 笔记网站：https://coggle.it/ 后台回复“打卡笔记”，可获取高清原文件 课程： 吴恩达《Deep Learning Specialization》，第一门课 作者：高天翔 笔记软件：笔记使用Latex，Editor为TeXstudio 后台回复“打卡笔记”，可获取高清原文件 课程： 李飞飞 CS231n，第一部分 作者：Karen 笔记软件：Mindnode 后台回复“打卡笔记”，可获取高清原文件 解锁了多种多样的笔记软件 活动进行过程中，大数据文摘在微信工作号 AI学习者（微信号：AI_Learner）的朋友圈展示了部分优秀笔记，收到了很多点赞和回复！有小伙伴表示没有晒到自己的笔记很忧伤~嗯，不难过不难过，后期我们会多发一些朋友圈的！ 小助手会多给笔记出镜机会的！ 经过记录和围观大家打卡的笔记，文摘菌第一次解锁了形形色色的软件，有颜值又实用！下面和大家分享部分笔记软件： Xmind 幕布 Mindnode Coggle Jupyter Markdown Typora intellij 有道云笔记 OneNote 印象笔记 石墨文档 简书 你平时用哪款软件呢？列表中的哪款是你的心头好呢？ 打造了非常活跃的学习社区 本次打卡活动共建立了10 个学习小组，其中包括7个吴恩达深度学习小组和3个李飞飞机器视觉学习小组。每天，每个学习小组内有关学习课程内容的讨论聊天记录就有280多条，包括软件安装、课程细节内容讨论及学习时遇到的问题，我们志愿者也在能力范围内给予了耐心细节的回复。 结识了认真负责的志愿者们 这次打卡我们共成立了10个微信群，为了保证质量，每个群中都至少配备2位大数据文摘专业运营同学和2位运营志愿者，在春节假期中，是这些运营同学的努力和负责，让整个活动得以顺利进行，让我们对此表示衷心感谢！ 本次活动开始后，志愿者们负责记录打卡笔记、解答群内问题，并积极分享好的学习资料，鼓励大家完成编程作业、更好地掌握课程内容。在春节休息期间，尤其是每天打卡结束前，志愿者们熬夜工作，尽职尽责，非常辛苦！为我们如此优秀的志愿者们打call！ 本期志愿者名单：游弋阳 、龚鹤扬@lthl、阴存翊、道义、ywainxiao、郝孝帅、DV、Jiakun、Karen、陳素Mer。 度过了一个有意义的年假 活动结束后，顺利完成打卡任务的小伙伴平分了奖金池的奖金： 大数据文摘也受到了大家的好评和鼓励，我们会继续努力为大家打造更好的学习社区！ 文摘菌也收集了一些顺利完成打卡活动小伙伴的心声： “感谢志愿者，打卡激励我在任何情况下坚持，感谢，希望能够跟上编程的步伐，再接再厉！” “感谢各位志愿者和大数据文摘提供的服务！” “谢谢！感觉这个假期特别珍贵” “辛苦啊 好仔细啊@文摘-运营志愿者 感谢感谢！” “这段时间收获颇多，希望接下来还能和大家一起学习” 为了和大家共同建设一个良好的学习社区，活动结束后，我们也对本次活动做了问卷反馈，还收到了不少有意思的反馈： “感觉今年春节过的特别充实，每天7点左右就起床，还要错开走亲访友的时间。” “大年三十找个借口在房间里学习” “春节饭局多，但是心里总惦记打卡，有种久违的学习紧迫感” “过年聚会喝完酒已经晕了，想起没打卡，冲个澡赶紧学习” 这种精神值得表扬！ “我家小宝宝刚出生，过年这几天哪也不能去，只能陪着他，这次打卡也给我的假期添加了一些乐趣和成就感。很高兴自己认真完成了这期课程，我算是有一些机器学习的基础，但是对于深度学习一直没有投入，我相信自己完成花费的时间远多于课程本身的时间，真的理解要思考很多。组织者还不错的，我认为比学员在这方面都有更多的学习和了解。谢谢你们~” “学习是可以互相激励的，回老家打卡断了，我虽然没有完成打卡，但过程中还是很有收获。” “一直都在坚持，从第一天到最后一天，最后一天的CS231N的卡忘记打了，笔记倒是写完了，连朋友圈都发了，最后笔记的时间都能证明我学完了，但是规则就是规则，既然错了，就要反省自己来改正，惩罚自己在最后一刻松懈！” 为你的坚持点赞！ “大家的笔记做的都很认真，组织形式也不同，学习到了很多记笔记的方法，很赞” 看到大家对本次打卡活动给出如此高的评价，春节加班的大数据文摘工作人员也很感动，感谢大家的积极参与！ 后续课程更精彩 请持续关注大数据文摘活动～ 【今日机器学习概念】 Have a Great Definition 
121,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657697&idx=1&sn=9d708f2c5595eef76de0268de764a5ea&chksm=bd4c32728a3bbb64085aeda90168014b754da391319d9cb23341da14f99d12d60de42ca2564a&scene=27,密码学家百年来无法辨认，500年前古怪手稿的加密希伯来语被AI算法破译,"大数据文摘作品 编译：Niki、丁慧、龙牧雪 几个世纪以来，伏尼契手稿（Voynich manuscript）一直是本人类无法理解的书，但现在我们终于可以读懂它了——这要归功于我们在手稿写成的500年后发明的机器智能。 伏尼契手稿通常被称为“世界上最神秘的书籍”，它是一份 。它由复杂、未知语言书写的神秘文本组成，并附有奇怪的图表和插图，包括植物、裸体人像和天文符号。它甚至有折叠页面，非常漂亮。 然而，没人知道手稿上面到底写了什么。这些文字的意义，被铭刻在古代的牛皮纸上，几百年来一直没有人能理解。 这份手稿一直被炼金术士和皇帝所拥有，直到1912年，一位名叫Wilfrid Voynich的波兰书商偶然发现了这份手稿，于是手稿便以Voynich的名字命名。 手稿有些页面已经丢失，剩余约240页。1969年，手稿由Hans P. Kraus捐赠给耶鲁大学Beinecke稀有书籍和手稿图书馆（即本文所有图片来源）。 大量密码学家和语言学家都试图揭开手稿的秘密，包括第一次世界大战和第二次世界大战期间的美国和英国密码破译者，但其页面中包含的晦涩难懂的代码、植物、符号和沐浴中的女性的奇怪图画没人能解释得通。它已成为密码学和语言学上的一个世界性难题。 手稿的意义和起源的奥秘激发了大众的想象力，使手稿成为小说和猜测的主题。在过去的一百年中提出的许多假设都没有得到验证，这其中包括半随机加密机制生成手稿；回文构词法；或是书面语中的元音被移除等等。有些理论甚至说这部手稿是一个精心制作的骗局。 现在，多亏了加拿大的计算机科学家，我们取得了新突破。 阿尔伯塔大学的研究人员使用人工智能来解码古代手稿的各个部分，使用一种称为 的技术来揭示隐藏在这本奇怪书籍背后的潜在加密语言。 “伏尼契手稿是用一种未知语言编写的，这是一种最具挑战性的解密问题。” 阿尔伯塔大学研究团队在他们的论文中解释说。 研究成果发表于2017年ACL大会 后台对话框内回复“手稿”即可下载 通过在《世界人权宣言》的380种不同译文中测试算法，并用AI寻找模式， 识别一篇文章中的语言时， AI系统能够达到97％的准确率。 接下来，他们将AI集中应用在伏尼契手稿上。此前，多数观点认为手稿可能是用阿拉伯语写成的。 但是，AI否定了这一看法。 AI的结论是， 。 如何解密？ 研究员们采用了先前研究中所提出的一个假设——手稿是由字母表所创建，也就是说，文本中的单词字母按照字母顺序表的先后顺序重新排列（例如，变位词GIZMODO被读成DGIMOOZ）。在已经知道这些文字来源于希伯来文的前提下，研究员们设计了一种能够 。 “结果显示，超过80%的单词都可以在希伯来文字典中查到，但我们还不知道这些单词组合在一起是否真的代表了某种含义。”计算机语言学家Kondrak说。 由于没有找到任何希伯来学者可以帮助验证他们的发现，研究人员最终使用谷歌翻译来把手稿译成英语。他们承认此过程中涉及一些猜测，但总体上手稿中的图片似乎与AI解读出的文本相匹配。 在手稿的“草药”章节的开头部分，包含几种植物的图画，出现了许多植物学相关术语 ，包括农民、光线、空气和火焰。 巧合？也许不是。 这本世界上最神秘的书又是如何开头的？ 根据AI的说法， 她向牧师、家中的人、我和人们提出了建议 （She made recommendations to the priest, man of the house and me and people） 是伏尼契手稿的第一句话。 “它提出了一个语法上的句子，你可以解释它，”Kondrak说。“这是一个奇怪的句子，但它绝对有道理。” 也许这本书的内容是有关草药植物的建议？研究团队并不能确定。他们表示，需要古希伯来历史学家的协助来进一步解码。 “无论如何，对噪音输入进行算法解密的结果只能是起点，之后需要熟悉特定语言和历史时期的学者参与研究。” 这种破译长达240页手稿的方式其实并不多见，但结果所得到的语句的确都讲得通。重要的是， 。整部手稿的翻译要等研究古希伯来语的历史学家们去研究才能知晓。 不管怎样，AI在人文与社会科学学科中的应用结果仍令人兴奋。该团队正计划应用这一新算法去破译其他古老的手稿，凸显人工智能解决几个世纪来一直困扰人类的种种难题的潜力。 素材来源： https://gizmodo.com/artificial-intelligence-may-have-cracked-freaky-600-yea-1822519232?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI https://www.sciencealert.com/ai-may-have-finally-decoded-the-bizarre-mysterious-voynich-manuscript https://transacl.org/ojs/index.php/tacl/article/view/821 后台对话框内回复 即可下载手稿研究论文。 Have a Great Definition "
122,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657632&idx=2&sn=cda6aa0f9ca992e65db2f1f8e52ca337&chksm=bd4c32338a3bbb25b7c16712325542b440317ee28cf9f77b64ba60e3fb91a8edd09d5701f710&scene=27,重磅译制 | 更新：MIT 6.S094自动驾驶课程第2讲（1）深度强化学习,大数据文摘重磅译制：最In的无人车课程视频+中文字幕！ 本周更新至：第二讲（1） 深度强化学习-运动规划 Deep Reinforcement Learning for Motion Planning 时长30分钟 带有中文字幕 点击文末 ，即可免广告观看 这门【深度学习与自动驾驶】课程由麻省理工MIT开设，话题前沿且实践性质很强。课程首先引导大家了解深度学习，之后大家可以自己“造”一辆无人车（的算法🌚）！ 课程面向机器学习 ，但已经有大量经验的研究人员也能从课程提供的从实践出发的深度学习方法和应用中受益。 课程主讲Lex Fridman与TA团队 大数据文摘已取得课程翻译授权，将以连载的形式发布后续课程内容，请大家继续关注我们，随时给予好评🌚 课程视频 【中文字幕】 学习地址： （连载中，请收藏！） http://study.163.com/course/introduction/1004938039.htm MIT深度学习与自动驾驶课程页面（所有资料汇总）： https://selfdrivingcars.mit.edu/ 《牛津大学xDeepMind深度学习与自然语言处理》汉化视频 ，复制打开链接免费加入学习： http://study.163.com/course/introduction/1004336028.htm 《斯坦福CS231n深度学习与计算机视觉》课程已更新完毕，李飞飞与Andrej Karpathy（现任Tesla AI部门主管）主讲，已有8.6万+人参与学习，复制打开链接免费加入学习： http://study.163.com/course/introduction/1003223001.htm 本课时PPT精华 ▼ 北京邮电大学模式识别实验室 李琦、李子凡、刘冠群 刘家铭、慕宗奇、祁星群 吴灵境、肖思瑶、杨紫都、张文源 （按拼音排序） 寒小阳、龙牧雪 刘家铭、龙牧雪 张闯、汪德诚 Have a Great Definition 戳 假期余额不足啦 快上车 ▼▼▼ 
123,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657632&idx=1&sn=be181c40fd11f5ffba3fd37239301e74&chksm=bd4c32338a3bbb25cb107d6b8f8f8db1d2d0879f8d1a01e48b5e32d2d451751baee8a934b4ff&scene=27,一位16岁CEO教你如何在高中阶段入门人工智能,大数据文摘作品 编译： 冯琛、龙牧雪 What? 高中生也可以？ 人工智能、大数据已经被纳入了我国高中“新课标”，但估计大多数高中生要是真想了解这一学科恐怕是一头雾水：高数没学过，编程也不会，老师也不教，这怎么学人工智能？ 新加坡有位高中生Karan Jaisingh已经学习人工智能和机器学习一年了。不久前，他在GitHub发出了一篇长文，专门教广大高中生 （以及高中老师、高中生家长、准高中生、准高中生家长……） 入门人工智能。 不看不知道，他的LinkedIn显示他还是个CEO！他正在开发一个错题集和期末复习相关的App😱 文摘菌不禁惦记起了广大想入行的本科生、硕士生、博士生……告诉我，春节假期余额严重不足了，你计划要看的书翻开了吗？如果没有，可以参考 下面这篇入门指南， 。 这份指南中整合的内容，是为打算在机器学习和人工智能这个新兴领域内有所建树的高中生准备的。 目前在这个领域还没有适合高中生的学习路径。 如果你能够定期按照这个路径学习，我相信在短短三个月内你会进步飞速。 接下来我们就正式开始吧。 我强烈推荐Python，不仅仅因为它超容易上手，还因为它提供了机器学习会用到的几乎所有好用的函数库。R也很好用，但是我认为Python更适合高中生。除了基础的编程，Numpy、Pandas和Matplotlib是机器学习中最有用的几个函数库。  如果你没有任何编程经验，我推荐你上一门多伦多大学的免费课程。多伦多大学是目前在机器学习和人工智能方面水平最高的大学之一。这门课耗时数周，但它值得你花费时间。你在这门课程中学到的大多数知识都能应用于任何其他的编程语言，唯一不同的只有语法。 课程链接：  https://www.coursera.org/learn/learn-to-program?siteID=SAyYsTvLiGQ-rs4V8qoewjp3oL7Nr.r_Fw&utm_content=10&utm_medium=partners&utm_source=linkshare&utm_campaign=SAyYsTvLiGQ#  如果你有除Python之外的编程经验，可以直接浏览以下语法教程，这最多耗时一天。 教程链接： https://www.tutorialspoint.com/python/python_basic_syntax.htm 学习了Python的基本知识后，你需要了解 Numpy、Pandas 两个函数库（Matplotlib可以之后再说）。Numpy数组和Pandas用于调用和更改数据，Matplotlib用来制作图表将数据可视化。下面两个课程只需要几天时间就能完成： Numpy: http://cs231n.github.io/python-numpy-tutorial/ Pandas: https://pandas.pydata.org/pandas-docs/stable/10min.html 文摘菌备注：这篇Numpy教程是斯坦福CS231n的配套练习，想同步学可以看大数据文摘翻译的视频+笔记 http://study.163.com/course/courseMain.htm?courseId=1003223001 如果要说一门通用的机器学习课程，那非吴恩达（Andrew Ng）的课程莫属。对于高中学生来说，这门课程可能有点难度，因为它涉及到偏导数等概念（尽管这些概念不是必须的）。建议反复观看第3至5周的课程。 我鼓励每个人都学学这门课并做笔记，虽然 基于Matlab的 编程相关的教程和练习不是必须的，而且根据我的经验，这个课程对于高中生来说难以掌握。但不用担心，我们将用更短的时间在Python中完成相同（甚至更先进）的算法。 课程链接： https://www.coursera.org/learn/machine-learning 在没有通用数学基础的情况下想要理解机器学习算法，理论上讲是很难的。但是一个澳洲团队解决了这个问题。 来自SuperDataScience团队的Kirill Eremenko和Hadelin de Ponteves，特别擅长在现实生活中寻找实现简单算法的途径。更厉害的是，这让没有复杂数学背景的高中生可以轻松理解。 他们的课程包括Python和R，不用担心R的部分，只需要看Python的教程就可以了。如果你觉得他们的课有点慢，可以用1.25倍速播放。 他们的课在Udemy上，是付费的，但Udemy一般都给他们的课90%的折扣。在这可以找到课程，通常只要花费10美元。 课程链接： https://www.udemy.com/machinelearning/learn/v4/overview 该课程涵盖了从基本回归分析到深度卷积神经网络。如果你还想探索更深的领域，机器学习课程的最后提供了他们的深度学习课程，有90%的折扣。但是，因为第二个课程太新了，其中的概念可能有点超前并缺乏合适的分类整理。 如果你不愿意花钱学，你可以看看谷歌的免费深度学习课程，或者密西根大学的免费课程。但是这些课程都与SuperDataScience的课程相差甚远。 谷歌的免费深度学习课程： https://www.udacity.com/course/deep-learning--ud730 密西根大学的免费课程：  https://www.coursera.org/learn/python-machine-learning 对于这些课，做笔记不是必须的，网上有很多算法小抄，你一下就能看明白这些算法是怎么运作的。 小抄链接： https://www.analyticsvidhya.com/blog/2017/02/top-28-cheat-sheets-for-machine-learning-data-science-probability-sql-big-data/ 现在你掌握了广泛的机器学习概念，并且学到了大量的技能。是时候在这些基础项目上小试牛刀啦。我建议上Kaggle或者UCI机器学习库，找个你感兴趣的数据集，对它进行建模解决一些问题。尝试各种不同的算法，尝试去不断优化模型表现。 Kaggle： https://www.kaggle.com/ UCI机器学习库： http://archive.ics.uci.edu/ml/datasets.html 确保你用的数据集简单明了，它们不应该需要太多的预先处理和修改。一些我能想到的简单数据集：鸢尾花数据、葡萄酒数据、威斯康星州乳腺癌数据、自闭症筛查数据、国会投票数据、MNIST手写数字数据和MNIST时尚数据。 如果你遇到障碍，Stack Overflow是你的好朋友，上面有你所有问题的答案。如果没有，发布一个问题，几个小时内就能得到解答。 Stack Overflow链接： https://stackoverflow.com/ 现在你已经有了对全部基础知识有了很好的广泛了解。我建议你在机器学习的范围内寻找一个感兴趣的领域，并且深入了解它。在高中阶段，你可能没有时间成为所有领域的专家，但可以尝试去征服一个或两个领域。 计算机视觉 应用一种特殊的神经网络使计算机观察并理解事物，这应该是当下机器学习及人工智能最热门的领域。斯坦福大学发布了相关在线课程，讲义、课堂笔记和作业都公开。尽管课程涉及的数学有些复杂，不要担心，试着去学习一下，该课程只是为了加深你的知识。另外，你还可以看看OpenCV，这是一个计算机视觉库，它可以为你处理很多复杂的东西。这是一个很好的教程。当你完成上述这些，就去Kaggle和UCI上找更多的高级图像数据集，或者参加Kaggle的竞赛。 斯坦福CS231n在线课程： http://cs231n.stanford.edu/ OpenCV教程： https://www.youtube.com/watch?v=Z78zbnLlPUA&list=PLQVvvaa0QuDdttJXlLtAJxJetJcq mqlQq 斯坦福CS231n中文字幕视频+笔记： http://study.163.com/course/courseMain.htm?courseId=1003223001 自然语言处理 了解计算机如何学习说话也是当下的一个突出话题。斯坦福大学又提供了一个在线课程。如果你不了解其中的一些数学概念，不要担心，只需要了解这个领域的工作原理。对于实现NLP应用，你可以学习Udemy课程。你也可以选择Siraj Raval的视频。如果你已经完成了这些，可以尝试开始做简单的众所周知的项目，比如创建聊天机器人，情感分析或为歌曲创建歌词。 斯坦福CS224n在线课程： http://web.stanford.edu/class/cs224n/ Udemy课程： https://www.udemy.com/data-science-natural-language-processing-in-python/ Siraj Raval的视频： https://www.youtube.com/watch?v=9zhrxE5PQgY 大数据文摘经授权译制Siraj Raval多个视频， 强化学习 该领域专注于机器如何以特定方式学习，其最受欢迎的应用程序是在电玩领域。 Siraj Raval在这方面又有了一个不错的视频集合，另外David Silver的UCL课程非常棒，虽然初学者可能会觉得有点难 。一旦你完成了这些工作，就可以开始从网上下载基础项目，并添加人工智能元素来改进他们的行为模式。 Siraj Raval： https://www.youtube.com/watch?v=i_McNBDP9Qs&list=PL2-dafEMk2A5FZ-MnPMpp3PBtZcINKwLA David Silver的UCL课程：http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html 这是一个萌芽的领域，有许多令人兴奋的工作机会。我建议你学习SuperDataScience的付费课程或加州大学圣地亚哥分校基于Python的免费课程。你还必须学习SQL以及Matplotlib。在学生时期学习的优势在于找工作——我有高中的朋友拿到了数据科学实习的offer，因为从他们的工作中获得的数据可以立即被公司拿去盈利。公司总是很需要数据科学家。 SuperDataScience的付费课程： https://www.udemy.com/datascience/ 加州大学圣地亚哥分校的免费课程： https://www.edx.org/course/python-data-science-uc -san-diegox-dse200x SQL： https://www.khanacademy.org/computing/computer-programming/sql Matplotlib： https://www.youtube.com/watch?v=q7Bo_J8x_dw 还有像代表性学习（用于推荐系统）、Adversial Networks（AI改进AI）和遗传算法（以与自然进化类似的方式改进解决方案）等领域，但在我看来，对于大多数高中学生来说，这些是延伸学习。因为这些领域目前没有盈利空间，他们不像其他领域被学习和发掘得那么全面。如果你对其中某个领域特别感兴趣，也可以尽情去探索。 如果你想要长期在这个领域中工作，了解它是什么、有什么突破性进展以及它对社会的影响至关重要。 高中生应该做如下几件事来加深对该领域的了解、增长见识： 开始阅读研究论文：它们不像你想象的那么有挑战性。即使只有高中数学水平也可以读懂很多论文。如果你读到一篇不理解的，放下它不用读了，还有很多其他的替代选择。 https://www.kdnuggets.com/2017/04/top-20-papers-machine-learning.html 关注领域内的先驱：像吴恩达、Ian Goodfellow和Yann LeCunn都经常接受采访，他们给出了这一领域内专家对于人工智能课题的权威观点。 https://www.youtube.com/user/Maaaarth/videos         与时俱进：Wired是科技达人的最佳平台之一。它每天发布多个与AI相关的故事。这是个方便快捷了解实时趋势的好途径。另外，订阅TechCrunch的Facebook Messenger机器人 - 它通常会每天推送与人工智能相关的有趣文章。 https://www.wired.com/tag/artificial-intelligence/ 了解内涵：没有比看TED更好的方式了。他们的发言人在这个领域非常权威，并且在发言中越来越强调人工智能。 https://www.youtube.com/user/TEDtalksDirector/videos 了解哲学：人工智能有支持者也有反对者。然而，它背后的哲学是有趣的。推荐一些我喜欢并且适合高中生阅读的探究该领域的书籍，包括Ray Kurzweil的《如何创造心灵》和Max Tegmark的《生活3.0》。 http://s3.amazonaws.com/arena-attachments/1446178/cffa5ebc74cee2b1edf58fa9a5bbcb1c.pdf?1511265314 做贡献：如果你喜欢从他人的经验中学习，看看脸书上的人工智能和深度学习小组。或者，如果你更喜欢对话，看一下Reddit上的人工智能相关问题。 https://www.reddit.com/r/artificial/ 并不是每个人都要遵循这一条路径，你也可以寻找自己的学习路径。机器学习和人工智能是一个新领域，一般是研究生在学习相关课程。但这并不是说此领域晦涩难懂，只要掌握学习方法，什么时候学习都不算晚。 你觉得几岁开始学习人工智能比较合适？欢迎留言讨论~ 原文链接：https://github.com/kjaisingh/high-school-guide-to-machine-learning/blob/master/README.md 【今日机器学习概念】 Have a Great Definition 
124,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657417&idx=2&sn=27f97ac9bf10b6a50c06e83282a49655&chksm=bd4c335a8a3bba4c4b864f6e3cda43ad5efa5310ca4b9ef2938e2f4232fe742dbbd8cf9bd4d9&scene=27,学界 | Ian Goodfellow最新论文：是猫还是狗？不光神经网络识别不了，你也能被忽悠,上面这张图里，是猫还是狗？再好好想想，你能肯定吗？ 根据胡子、鼻子较短判断，左边的似乎是猫。但是再看看右边，这明显是只狼狗吧（诡异的戴着蝴蝶结的狼狗orz）。但是这明明是一张图啊？怎么回事？ 都是深度学习搞的鬼。 这是Ian Goodfellow大神2月22号最新论文里的成果。对抗性干扰，既能骗过神经网络，也能骗过人眼了。 先回忆一下我们是怎么忽悠神经网络的。 不久前，文摘菌发布过一篇关于如何利用一个小贴纸，让各大著名图像识别算法纷纷破功的文章（ ）。 加上这个五彩缤纷的小贴纸后，不论是什么图片，都会被神经网络识别成“烤面包机”。 原理其实很简单，我们在对图像处理时，为了简化图像本身的数据量，提取了图像的关键特征进行识别。当这个小贴纸加入后，它所携带的像素数据严重影响到了原来图像的关键特征，从而扰乱已经训练好的神经网络，导致识别结果错误。 在Ian Goodfellow的最新论文里，这种缺陷除了扰乱图像识别算法，还可以加以利用，生成一些人眼都无法辨识的图片。 论文地址： https://arxiv.org/abs/1802.08195 在大数据文摘公众号后台对话框内回复 “ 即可下载这篇论文~ 以下是论文部分内容： 机器学习模型很容易受到对抗特征的攻击，稍微将待识别的图像进行改动，识别结果就大相径庭。然而，人类处理这种问题十分容易而且准确率极高。那么人脑是如何识别图像的呢？我们利用最新的技术，将对抗特性从计算机视觉现有的模型及参数转移到还未开发的模型中去，通过修改这种模型去接近人类视觉系统的处理原理。研究结果表明，通过人为转移计算机视觉模型中的对抗特性生成的图片，在有限时间里，会影响人类的识别结果。 实验采用的数据集来自ImageNet，研究人员筛选了三组进行分析： 宠物类（猫和狗） 危险动物类（蜘蛛和蛇） 蔬菜类（西兰花和卷心菜） 研究者使用了K个CNN网络，每个模型包括以下架构： Inception V3 Inception V4 Inception ResNet V2 ResNet V2 50 ResNet V2 101 ResNet V2 152 生成对抗图像的目的：给图像添加干扰，使模型将图像A识别成图像B，同理，对图像B也做相同处理，针对每个图像构造不同的干扰，干扰的大小取决于最大干扰值。 原理： 式中，Xn是原始图像数据，ytarget是目标分类结果，Xadv是添加扰动后的图像，α是梯度下降的步长，eps是扰动值。对X执行迭代梯度下降获得Xadv。 对于每组图像分别用以下四种方式显示： 原图 生成的对抗图像 对抗翻转图像 误分类图像 图中，使用了不同模型来生成对抗图像。从左往右，随着训练模型的数目不断增加，图像中的猫看上去更像狗。eps代表图像中添加的对抗扰动值，即便当eps=8的时候，图像中的猫看起来也更像一只狗。 常见生成具有对抗特性图片的方式： 纹理修饰 修改对比度 边缘增强 边缘破环 用这种方式生成的对抗图像，由于人们明白其产生原理，因此需要加入更大的干扰才会对人类的辨识产生影响。 常见的生成对抗图像的方式 结论 1、在有限时间内，生成的对抗图像使人难以辨认 2、这种生成对抗图像的方式可以用在音频、视频，会给人类社会带来一定的风险 3、生成的对抗图像可以用在某些场合，作为一种醒目的提示 4、但是这种图像，对于人来说，可能刚开始看上去难以辨认，经过一定时间的反复观察和思考，人眼还是可以正确识别出图像中的物体（比如是猫还是狗）。从而引发思考，机器学习中是否可以加入这种反馈和动态递归以提高分类准确率？ 在大数据文摘公众号后台对话框内回复 即可下载这篇论文~ Have a Great Definition 
125,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657417&idx=1&sn=87c24739c18f5c0551c950e48560a8fc&chksm=bd4c335a8a3bba4cbfa0ca8a97de43ad791993f5591f71f531d447bab8da4ae3999b24e4cbfe&scene=27,别错过这张AI商用清单：你的难题可能被一个应用解决（终篇）,大数据文摘作品 编译：小饭盆、肖依月、蒋宝尚 千呼万唤始出来，终于， AI清单我们更新到了最后一部分。本系列共有四个部分，另外三个分别是： 决 在本篇文摘菌介绍一些针对特定行业的商用AI。这些应用针对性极强，如果你看完了前三部分，文摘菌建议也一定不要错过这最后一部分。 Exa - 通过语音自动化解决方案来帮助并取悦客人。 Datacratic  - 帮助你将数字广告投放到合适人群。 TNAB - 个性化展示并插入广告的一种方式。 Abundant Robotics  - 机器人解决农业困难的工作 AgriData - 农业专用绘图软件 Blue River Technology  - 农业机器人公司 （译者注：约翰迪尔3亿美元收购了农业机器人公司BlueRiver Technology，约翰迪尔(John Deere)是全球知名农业机械设备生产商 Descartes Labs  - 收集卫星图像，用以使用和分析 Grojo- 种植房间控制器和监控系统 Mavrx  - 航空影像，提供对作物的深刻理解 Peat - 植物损害的自动图像识别 Pivot Bio - 作物土壤与微生物健康管理 Prospera Technologies - 监测和分析植物健康 TerrAvion – 通过航拍图像了解作物健康和以及其他 Trace Genomics - 帮助测量土壤健康和营养状况 Tule - 远程作物水分监测和灌溉控制 UDIO - 帮助管理用水量 Atomwise - 用于新型小分子的发现 Citrine  - 更好的材料信息 Color - 帮助您了解常见遗传性癌症的遗传风险 Deep Genomics  - 预测DNA改变时细胞内会发生什么 Embryonic by BioTime  - 在线识别样本的胚胎评分（好坏） Ginkgo Bioworks - 我们为范围市场设计定制的微生物 Grail - 早发现癌症，以便可以治愈 iCarbonX - 个人健康数据收集和组织平台 Mims - 帮助生物信息科学家 Nanotronics  - 非常先进的显微镜 Numerate - 革命性的小分子药物设计 Recursion Pharmaceuticals - 药物发现 SciAi - 以语义格式写生物医学论文 Verily - 开发用于收集和组织健康数据的工具 Whole Biome - 开发微生物干预的平台 Zymergen - 设计更好的微生物 Cybel Angel - 预防和实时检测网络事件 Cylance - 预测，防止和免受威胁的网络安全 Darktrace - 在发生黑客行为之前，预防黑客行为，防止网络犯罪 Deep Instinct - 零日攻击保护端点和移动 Delphi - 针对恶意软件和恶意网络活动的安全性 Demisto - 结合了安全业务流程和事件管理 Drawbridge Networks - 安全即服务 Emergent - 帮助预测黑客攻击的地点 Graphistry - 帮助团队快速轻松地调查网络威胁 LeapYear - 从敏感数据中提取威胁洞察 Pelican - 更智能，更安全的付款，合规和银行业务 SentinelOne - 预测，预防，检测并响应威胁 Shift Technology - 帮助减少保险欺诈 SignalSense - 评估网络内部发生的威胁的流量 Sift Science – 防止欺诈和滥用您的网络规模的业务 SparkCognition - 帮助企业预测数据泄露 Versive - 支持网络安全团队的自动化威胁搜索 Zimperium - 实时防护手机和应用程序 Basket - 电子商务购物车的聊天机器人 Choice.ai - 在几秒钟内创建和部署令人惊叹的UI元素和小部件 Cody.ai - 面向电子商务的智能代理 Contented - 为您的内容进行优化的动态页面/网站/电子邮件布局 Firedrop - 自动设计的网站，只需添加内容，并发布 Millions.ai  - 扔给它内容，它会为你建立一个网站 Prix - 有助于优化定价 Oly  - 选择并帮助您将内容发布到您的社交媒体 Sentient - 自动进行网站设计更改，以提高利润率 Signature - 使用您的社交媒体内容创建简洁的登录页面 TheGrid - 只需添加内容即可自动构建网站 AltSchool - 一个提高学习能力的平台 Content Technologies (CTI)  - 研发公司 Coursera - 来自顶尖大学的在线课程 Gradescope - 简化了分级的繁琐部分 Hugh - 帮助图书馆用户快速找到书籍 Ivy.ai - 为高等教育客户服务的聊天机器人 Knewton - 针对中小学的个性化学习 Volley - 使训练和发展更有吸引力和高效 AlphaSense - 高度智能的搜索功能 Alta5 - 为您的网上经纪账户编写交易自动化程序 Analytic.ai - 套期保值和套利的保护 AppZen - 实时审核您的旅行娱乐费用并削减您的费用 Cerebellum Capital - 由统计机器学习驱动的投资管理公司 Darwinian Capital - 使用AI来建立投资产品 iSentium - 将非结构化社交内容量化为情感指标 Kasisto - 通过聊天管理您的银行业务 Numerai - 一种新型的对冲基金 Kensho - 为政府和商业提供的可扩展的机器学习（由中央情报局支持） Origin - 交易股票和预测价格 Pit.ai - 矿业交易策略和管理 Pitchbot.vc - 如果你不是专业的投资者，通过对话学习 PrecisionLender - 为银行家提供可实施的财务见解 Quandl - 在核心财经数据上提供备选数据集 Sentient - 有助于财务策略和投资选择 Kythera - 游戏AI有助于游戏工作室开发 Atomwise - 用于新型小分子的发现 Babylon - 使用AI进行在线医生咨询 BuddiHealth - 通过RCM帮助改善流程，支付系统和成本 Behold.ai - 医疗帐单，编码和理赔软件 BenevolnentAI - 帮助发现新药 Calico Labs - 试图解决老龄化和疾病的问题 CareSkore - 用于预测结果和趋势的病人档案软件 CloudMedx - 帮助临床治疗和节省资金的平台 CUDL - 安全地共享临床数据并简化超声波的理解 Deep6 Analytics - 帮助更快找到更好的临床试验患者 Diagnostics.ai - 使医疗诊断测试准确和安全 DreamUp Vision - 帮助眼科医生筛查视网膜疾病 Emr.ai - 将医疗报告转换为国际标准代码 Embryonic by BioTime - 在线识别样本的胚胎评分 Enlitic - 使医生更快，更准确 Freenome - 非侵入性医学筛查来治疗癌症和其他疾病 Healthcare.ai - 开放源代码工具，帮助增加医疗保健方面的ML IBM Watson Health - 医疗机构的高级功能 Lunit Inc. - 医疗数据分析和解释 Lytics - 医学心得工具 MD.ai - 协作医学研究 Numerate Medical - 革命性的小分子药物设计 Oncora - 精准的放射肿瘤学，进行个性化治疗 Pharma AI - 支持制药研究和开发 pulseData - 提前对不良且昂贵的健康结果进行预测 Qure - 诊断核磁共振，CT扫描和X-射线 Sentrian – 发现慢性病防止病人恶化 twoXAR - 加速药物发现 Umps Health - 帮助检测老年人紧急情况的需求 Viz - 通过医疗成像帮助医生更快地治疗患者 Zebra Medical Vision - 医学成像，以帮助医生和从业人员 Zephyr Health - 帮助生命科学公司连接合适的人 3Scan - 提高解剖病理学的准确性和效率 Arterys - 帮助管理医学影像的平台 Bay Labs - 开发心血管成像工具 Butterfly Network - 世界上每个人都可以使用的医学影像 Cortexica - 一系列不同的高级影像产品 Google DeepMind – 这就不用介绍了吧 Imagia - 有助于及早发现癌症的变化 Kuznech - 计算机视觉产品范畴 Lunit Inc. - 一系列医疗影像软件 Zebra Medical Vision - 医疗成像，以帮助医生和从业人员 Doxel - 工作现场的可视化人工智能 Flywheel - 建设性能平台 OJO Home - 帮助房地产经纪人把潜在客户变成生活中的客户 Cape Analytics - 在保险业规模上鉴定财产属性 Underwrite.ai - 信用风险的动态建模 ZestFinance - 改善保险公司的承保 Beagle - 帮助律师事务所在法律文本中找到深藏的见解 Blue J Legal - 使税务专业人员加强他们的课税情况 Equivant - 帮助对坚信的东西做出决策 Kira - 加快对合同的鉴定和分析 Legal Robot - 帮助理解法律语言并发现错误 Premonition - 根据他们的统计数据帮你找到律师 Peter - 帮助合法的契约和时间戳 Ravel Law  - 通过深刻的见解，提高律师的法律能力 ROSS Intelligence - 通过深刻的见解，提高律师的法律能力 Seal - 合同发现和分析 Eigen Innovations - 帮助制造商优化生产效率 Raven - 解读车间数据并向操作员反馈操作指令 Dataminr - 快速发现具有强影响力的时间和新闻 Maxima - 声称致力于通用人工智能 makeAvatar.ai - 瞬间将自拍创造出3D画像（3D avatars） Harmony.ai - 一个利用领先的设备和平台的IIoT生态系统 Hugh - 帮助图书馆的用户快速找到想要的书 PETRL - 促进算法的道德考量 Purple - 通过用户WiFi使用的行为数据，更加了解他们 Personalised Privacy Assistant Project - 了解用户的隐私偏好，让他们拥有自主控制自己的信息的能力 TARA - 帮助您管理项目 Ulzard - 将UI截图转换为工作代码 Vue - 流行趋势 Betterment - 个性化的退休计划 Earnest - 用未来收入预测贷款融资的替代选择 Lendo —服务于没有信贷准入人群的一种信用评分新方法 Mirador - 借贷人进行借贷时，提供改善、帮助和快速决策建议 Tala (a InVenture) - 一种利用智能手机数据进行信用评分的新方法 Playment - 为企业提供培训数据、图像标注等更多服务 Prix - 帮助优化定价 Alive.ai - 无人驾驶飞机应用于农业、公共紧急情况等更多的场所 Irvine Sensors - 对外来的以及故意放置的物品进行安全性检测 Arena - 运动成绩预测与分析 Acerta - 有助于更好地理解车辆数据以发现根本故障原因 Aerea - 供应链管理、制造与预测 Alloy - 分析以及提供供应链管理软件 Armada - 帮助跟踪和改进供应链成本和效率 Captain - 餐厅的智能配送软件 ClearMetal - 帮助预测物流问题并降低成本 Marble - 创建智能快递机器人组 PitStop - 提供检测和纠正PDF文件中错误的最快方法 Preteckt - 在您的卡车遇到故障之前，进行预报 Routific - 实时改进和规划地方物流路线 Preteckt - 帮助诊断和预测卡车故障 Seldin - AI供电供应链 SupplyAI - 帮助预测顾客是否有可能退货 Mezi - 帮助预订航班、酒店、餐厅预订等 Voya - 帮助预定事务以及管理商务行程 Drop - 我只是被他们的网站吸引住了… Achron - 自动无人机操作 Airware - 工业用无人机 Alive.ai - 无人驾驶飞机用于农业、公共紧急情况和更多 DJI - 每个人都拥有这个无人机 DroneDeploy - 无人机测绘软件平台 Fathom - 提供快速原型，检测深度神经网络（DNN）以及计算机视觉（CV）无人机 Lily - 跟随您的无人机 Mavrx - 提供对农作物深刻了解的航空成像技术 Shield - 民用和国防自主无人系统 Skycatch - 把无人机航拍照片转换为3D模型 Skydio - 建立新一代人工智能无人驾驶飞机   Aeye - 安全可依赖的自动驾驶 AIMotive - 自动驾驶软硬件 Area17 - 自动导航 Autonomic - 构建拥有自主驾驶能力的汽车 Auro Robotics - 校园以及企业园区内的自动驾驶摆渡车 Comm.ai - 帮助构建您的汽车的自驾兼容性 Drive.ai - 创建自动驾驶车辆的大脑 Dryvless.ai - 全自动对等运输物流网络 Five AI - 在任何地方都可以使用的自动驾驶系统 Mobileye - 工业用自动驾驶车辆 Nauto - 赋予你的驾座自动驾驶能力 译者注（作为一个成立仅2年的科技公司，目前的Nauto主要面向后装ADAS市场） nuTonomy - 无人驾驶舰队软件 PlusAI - 致力于4/5级自动驾驶汽车（半-全自动） Shield - 民用和国防自动无人驾驶系统 Tesla - 最好的自动驾驶引导以及自动驾驶能力 Uber - Uber提出的自动驾驶计划 Waymo - Google的自动驾驶项目 Airware - 工业用无人机 Anki - 致力于将消费者机器人技术引入到日常生活 Clearpath Robotics - 为不同的用途而研发自主机器人 Corva - 为气体和石油（提炼）提供钻井分析和其他见解 Fetch Robotics - 优化仓库（库存管理）以及物流运作 Graphcore - IPU芯片带来10倍到100倍的效率提升以及成本下降 Harvest Automation - 一系列在工业环境下使用的机器人 Jaybridge Robotics - 研发重装车辆的自动化 Kindred AI - 探索让机器人能够参与到我们世界中的系统 Mov.ai - 工业自主机器人 Ortelio - 帮助机器人做他们所做的软件 Osaro - 一系列自主车辆和机器人 Rethink Robotics - 促使Baxter与Sawyer合作的幕后黑手 Roboy - 一种希望拥有人类能力的人形机器人 Spoon - 一种机器人（我无法描述它的用途，但听起来很酷） SoftBank - 拥有机器人技术以及其他先进技术的公司 Tend - 从无死角监控和控制生产线 Yandex Data Factory - 提供基于人工智能的解决方案：直接提升生产率，降低成本，提高使用能源效率 Cogitai - 开发持续的共享学习型人工智能 IBM Q - 为商业和科学构建通用量子计算机 Isris - 人工智能提供科学文献以找到解决方案 Kimera - 发展AGI技术，去帮助治愈癌症以及治疗其他疾病 Meta - 帮助研究人员关注科学界的最新动态并向他们展示科学研究的走向 NNAISENSE - 建立大规模神经网络解决方案 OpenAI - 发现和制定道路安全的强人工智能（AGI） Swarm Insight - 来自团体的高效、优质反馈 Aitia Amplify Applied AI Blindspot Solutions Cogent Crossing Minds DSP Expert Systems Explosion Minds.ai Nebula Nous.ai Ignition Iv.ai Plum Vital.ai Symbol.ai Symphony Amazon DSSTNE Apache Spark Azure ML Caffe Chainer DeepLearning4j DM LCH2O.ai Keras Microsoft CNTK Microsoft DMTK MLlib MLDB MXNet Nervana Neon PaddlePaddle OpenAI Gym scikit-learn TensorFlow Theano Torch7 Weka spaCy 1026 Labs Armada Cadence Cirrascale Comm.ai Google TPU Graphcore Hugh Intel Isocline KNUPATH MATRIX Lab Preteckt sNVIDIA DGX-1/Titan X Qualcomm Tenstorrent Tensilica Allen Institute for Artificial Intelligence Association for the Advanced of Artificial Intelligence AI•ON - Artificial Intelligence Open Network AI Impacts EXI - Exropy Institute Future of Life Institute Humanity+ Institute for Artificial Intelligence - Franklin College of Arts & Sciences Partnership on AI - to benefit people and society Singularity Institute Stanford - One Hundred Year Study of Artificial Intelligence UC Berkeley - Center for Human-Capital AI Vector Institute for Artificial Intelligence PETRL - 促进算法的道德考量 Facebook AI Research 隐私以及社会影响 AI Now Initiative - 研究跨学科的研究倡议，以了解人工智能的社会和经济影响，确保未来更加公平。 Personalised Privacy Assistant Project - 了解用户的隐私偏好，让他们拥有自主控制自己的信息的能力，哪部分是对他人可见的。 【今日机器学习概念】 Have a Great Definition 精品课程推荐 数据科学实训营第5期 感谢数据科学训练营，我已经顺利从某制造业国企转行互联网，实训营是我见过最负责任的培训班。在这里不仅教会我怎样快速入门数据科学领域，还认识了很多志同道合的小伙伴，希望大家来这里一起学习，一起进步! —— 
126,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657379&idx=2&sn=84c3294638314a1707f9f2713483211a&scene=0,手把手 | 20行Python代码教你批量将PDF转为Word,大数据文摘作品 投稿作者 ｜ 在日常工作或学习中，经常会遇到这样的无奈： “小任，你把这个PDF中的文件码出来发我” 艹，倒霉，2M的PDF12点也完不了啊！ 很多时候在学习时发现许多文档都是PDF格式，PDF格式却不利于学习使用，因此需要将PDF转换为Word文件，但或许你从网上下载了很多软件，但只能转换前五页（如WPS等），要不就是需要收费，那有没有免费的转换软件呢？ so，我们给各位带来了一个免费简单快速的方法，手把手教你用Python批量处理PDF格式文件，获取自己想要的内容，存为word形式。 在实现PDF转Word功能之前，我们需要一个python的编写和运行环境，同时安装好相关的依赖包。 对于python环境，我们推荐使用PyCharm。 在本地电脑环境，anaconda提供了非常便利的安装和部署。 PDF转Word功能所需的依赖包如下： PDFParser（文档分析器） PDFDocument（文档对象） PDFResourceManager（资源管理器） PDFPageInterpreter（解释器） PDFPageAggregator（聚合器） LAParams（参数分析器） 说明：本文是在Windows7下使用python最新的3.6版本 1.安装pdfminer3k模块 安装anaconda后，直接可以通过pip安装 2.若安装不成功，可以试试下面方法 首先下载pdfminer3k：https://pypi.python.org/pypi/pdfminer3k；然后安装pdfminer， 将下载好的pdfminer3k解压到D:或其他合适的盘符，通过win+r 打开运行窗口，输入cmd；输入D:切换到D盘，cd pdfminer3k(pdf解压的文件夹)，输入setup.py install安装软件。 最终显示Finished，则代表成功 1.导入相关包 整体思路为：构造文档对象，解析文档对象，提取所需内容 构造文档对象 构造解释器 2.导入需要解析的PDF文件 将所需解析的文件与执行代码放到同一个目录下，如图： test.pdf内容 3.具体代码如下： 最终得到的test.txt结果如下： 对于Python批量PDF转Word的操作介绍就到此，本文仅仅作为一种运用库展示代码编写过程，具体技术还需要有兴趣的朋友，与我一起讨论专研，互相学习进步。 本文为投稿作品，仅代表个人观点。 【今日机器学习概念】 Have a Great Definition 
127,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657379&idx=1&sn=5bb6ab6c16cb76c2df681f69d1a2185e&scene=0,Elon Musk又一太空雄心起航：12000颗卫星上天，5G服务全球覆盖,大数据文摘作品 作者：魏子敏 改期6次，Elon Musk和SpaceX这一名为「PAZ MISSION」的发射任务，终于在两个小时前，顺利完成。 搭载着两颗网络星座测试卫星的Falcon 9火箭，在当地时间22日凌晨6点17分，从加州范登堡空军基地发射并成功飞向轨道。 就在前一日原定发射前一小时，SpaceX因为大风将发射计划推迟了24小时。 而这次的 推迟显然是值得的，今日的加州清晨天气难得的平静。 凌晨6点的加州依然一片漆黑， 夜幕下的Falcon 9火箭显得异常壮观。 当地时间6点17分， Falcon 9按照原定计划准时升空。整个过程历时近15分钟，三个阶段顺利完成，卫星成功部署到低地球轨道。 SpaceX在YouTube全程直播了这一发射过程。点击查看新鲜出炉视频👇 这一看似普通的发射任务实际上酝酿已久，且后续长足。 本次发射搭载的两颗测试卫星MICROSAT-2A/2B隶属Elon Musk一个庞大的计划Starlink，旨在在全球范围内带来5G级的通信服务。 两颗测试卫星将在地球上空约700英里的轨道上行驶，和Starlink计划中的其他卫星部署高度一致。 SpaceX在去年为Starlink申请了商标名称，这是Musk又一个关于太空的雄心壮志。 从2015年开始酝酿，SpaceX的目标是在2019年开始建造自己的4425颗宽带卫星，完成之后再建7518颗，总计近12000颗。 这么多颗卫星是什么概念呢？ 这些卫星均采用标准产品化设计，且用同一款火箭猎鹰9号发射。 这是人类历史上第一次真正意义上实现火箭和卫星的量产，预计未来三十年太空业将迅速发展，将对整个行业成本带来颠覆性的影响。 美国联邦通信委员会（FCC）文件显示，SpaceX将于2019年发射一个提供4425 Ka/Ku频段的低轨卫星群，一旦部署卫星超过800颗，该系统即可投入使用。 Starlink将卫星将为消费者提供新的无线连接，而不需要再通过现有系统的信号再分配。目前的宽带卫星通信技术，如DirecTV和Dish Network等，信息收发的延迟时间高达约600毫秒 - 比SpaceX预计提供的25到30毫秒的延迟时间慢许多倍。 Elon Musk一直极力宣扬Starlink的影响力，称它可以为全球数十亿人带来5G服务，同时还可以在各种拥挤地区增加流量。 多方阻力，前进道路仍艰难 SpaceX目前市值约215亿美元，并已得到谷歌母公司Alphabet和Fidelity至少10亿美元的投资。 SpaceX曾公开表示， 在其即将发布的发行清单中拥有超过100个任务，和价值超过120亿美元的合同。 尽管手握巨额资金，Starlink计划要想达成，仍面临着巨大的困难。 SpaceX的一个竞争对手OneWeb以日本SoftBank为后盾，筹集了超过10亿美元的资金，用于建造720个Ku波段卫星群，并计划于2019年在低轨道上飞行约750英里。去年，FCC批准了OneWeb的请求。 另一个卫星运营商Telesat称，希望在2021年前建造一个能提供120Ka带宽的卫星群。Telesat的卫星主要供美国军方使用，其在1月份发射了卫星来测试宽带服务。 除了公司，包括中国在内的各国政府也都在开展类似项目研发。 中国航天科技集团计划2020年建成“鸿雁卫星星座通信系统”。该系统将由60颗低轨道小卫星及全球数据业务处理中心组成；中国航天科工集团推出的商业航天系列工程“行云工程”旨在建立中国首个低轨窄带卫星通信星座系统。采用“星地微波通信＋星间激光通信”技术方案。 同时，在打开全球市场方面，Musk同样面临重重困难。 这里面涉及到各国电信产业的行业保护以及网络安全等问题，类似于北斗之于GPS。 此前，Musk也承认，SpaceX需要各国政府的许可才能为当地提供网络服务，然而获得许可会是一个艰难且缓慢的过程。 对商业航空的发展意义重大 在探索太空领域的过程中，很多公司都曾进行过尝试，但结果却不尽如人意。 早在2015年，Facebook决定不再花费高达10亿美元去建造和发射卫星，而是选择租用SpaceX公司的AMOS-6卫星来提供宽带，主要用于向非洲和其他落后地区提供互联网服务。然而在2016年，SpaceX Falcon 9号火箭发射前加油时发生爆炸，该卫星也被摧毁。 2017年2月19日，SpaceX Falcon 9号火箭从佛罗里达州卡纳维拉尔角肯尼迪航天中心的发射台39A向国际空间站供应任务，本次发射的卫星也搭载同一火箭升空。（图片来自路透社） 微软创始人比尔盖茨曾资助Teledesic，致力于研发提供互联网服务的低轨卫星。 然而Teledesic在把90亿美元花光之后，于2002年倒闭了。 “SpaceX的成本结构和比尔盖茨所投资的公司相比要好得多，”古根海姆合伙公司分析师Paul Gallant在接受CNBC采访时曾说， SpaceX通过其Falcon系列火箭大大降低了进入太空的成本，虽然此次发射成本高达数千万，但与竞争对手花费的数十亿美元相比，成本已降低不少。  随着卫星互联网业务的发展，Musk很可能已经为SpaceX找到了一个主要业务，来帮助他实现火星殖民地的梦想。 Starlink和SpaceX的这一尝试对于正处在风口上的商业航天企业无疑将是极大的利好。 未来将会有更多的小卫星亟待上天，也给SpaceX或者国内像零壹空间这样的民营商业火箭公司提供了市场机遇。 零壹空间相关负责人告诉大数据文摘，作为天基互联网，Starlink是太空经济领域划时代的里程碑，极大拉近了航天与人类日常生活的相关性。 “我们完全可以期待，在新一代通信卫星组网运行以及更便宜的组网运行方案实施以后，会有个通讯速率更快，容量更大，成本也更低的空天互联网，这样人人都能在天上流畅便捷地上网了，这块市场的想象空间也是非常大的。” 【今日机器学习概念】 Have a Great Definition 
128,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657362&idx=2&sn=061b3551f7bcc92378d11244b615d173&chksm=bd4c33018a3bba17ccbb0ffc0902ddc10b3d4916005f4146461cda8b76c9ee2d04bbf04625b0&scene=27,前沿报告 | 牛津、剑桥、OpenAI联合发出AI预警《人工智能的恶意使用》（附下载）,作者：龙牧雪 无人车、无人机、视频生成……这些AI应用在让我们激动万分的同时，也有可能带来前所未有的灾难——如果无人车队被恶意操纵来撞你，该怎么办？这次让我们看看AI政策研究学者怎么说。 2月20日，26位来自牛津大学、剑桥大学、OpenAI、电子前沿基金会（一个非营利数字版权组织）、新美国安全中心（一家美国智库）等多个研究机构的研究人员发布了一份AI预警报告，针对AI的潜在恶意使用发出警告，并提出相应的预防及缓解措施。 报告作者之一、来自牛津大学人类未来研究所的Miles Brundage在推特上发布报告 报告链接： https://maliciousaireport.com/ 在大数据文摘公众号后台回复“预警”即可下载报告PDF全文 新兴技术对人类安全的影响一直是个热门话题。牛津、剑桥、OpenAI这些重量级研究所此次发布的这份报告名为《人工智能的恶意使用：预测、预防和缓解》，预测了 报告也建议采取以下干预措施以减轻恶意使用人工智能造成的威胁： 政策制定者和技术研究人员现在需要共同努力来理解和为应对恶意使用人工智能做出准备。 人工智能有许多积极的应用，但是是一把双刃剑，人工智能研究人员和工程师应该注意并积极预测其滥用的可能性。 人工智能应该从具有较长的处理风险的历史的学科（如计算机安全）中学习。 积极扩大参与预防和减轻恶意使用的利益相关者范围。 这份长达100页的报告关注与恶意使用人工智能特别相关三个安全领域：数字安全（digital）、物理安全（physical）和政治安全（political）。它表明，人工智能会破坏规模（scale）和效率（efficiency）之间的权衡，并使大规模、精细目标和高效的攻击成为可能。 例如，自动黑客攻击，用于模拟目标的语音合成，使用从社交媒体获取的信息的精确目标垃圾邮件，或利用AI系统本身的漏洞等新型网络攻击。 同样，无人机和网络系统的扩散将允许攻击者部署或重新调整这些系统用于有害目的， 例如让自动驾驶车队相撞，将商业无人机变为可以定位目标的导弹，或劫持重大基础设施以索要赎金——自主武器系统在战场上的崛起可能会导致失控。 在政治领域，借由详细的分析、有针对性的宣传、便宜且高度可信的虚拟视频，可以操控公众舆论，而这种操控的规模在以前是无法想象的。 利用人工智能，可以大规模聚集、分析和处理个人信息，这可以实现监控，可能侵犯隐私，并从根本上改变个人、企业和国家之间的权力。 为了减轻这些风险，报告作者探索了几种干预措施，以减少与AI滥用相关的威胁。这些措施包括重新思考网络安全，探索信息共享的不同开放模式，促进责任文化，制定有利于安全防御的政策和技术。 报告作者之一， 剑桥大学生存风险研究中心执行主任Seán Ó hÉigeartaigh博士说道： 人工智能是一个改变游戏规则的机器，这份报告已经想象出未来五到十年内世界会变成什么样子。 我们所生活的世界可能变为一个充满因滥用人工智能而导致的危害的世界，我们需要处理这些问题，因为风险是真实存在的。 我们现在需要做出选择，而我们的报告号召全球政府、机构和个人的行动。 几十年来，人工智能和机器学习方面的宣传超过了事实。但现在不再是这样了。这份报告着眼于那些不再适用的做法，并提出了一些可能有所帮助的方法：例如，如何设计不易被攻击的软件和硬件，以及可以采取什么类型的法律和国际法规。 不过，在报告开篇，作者也承认： 网络上也存在着批评的声音。GigaOm评论员Jon Collins指出，对于所有提出的风险，报告并没有定量描述，而只是以“可能出现（plausibly）”的字眼概述，这不是对风险的科学描述方式。风险有多大？我们也不得而知。此外，报告中的许多地方也明确表示，“报告的多位作者对此持有不同观点”。所以就此看来，报告起到的唤醒作用可能远大于对实际操作的指示。 在大数据文摘公众号后台回复“预警”即可下载报告PDF全文 素材来源： https://www.cser.ac.uk/news/malicious-use-artificial-intelligence/ https://gigaom.com/2018/02/21/whats-missing-from-the-malicious-use-of-artificial-intelligence-report/ 【今日机器学习概念】 Have a Great Definition 
129,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657318&idx=2&sn=7d226f7308aac86e15c739e371068856&chksm=bd4c33f58a3bbae3539c6c9319ba1f9116612684a899430e0982495b32511acc4bb77d6c349a&scene=27,BlockChange | 从代码入手，如何理性为虚拟货币估价,大数据文摘作品 作者：Fabian Blank 编译：Niki、笪洁琼、Yawei Xia 
130,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657318&idx=1&sn=4c54466814cdd7f23696bc23ab4c56c3&chksm=bd4c33f58a3bbae3cfa46d477e0d8febbe9732ee9bad503a61237ebc7d604e5e0fb6d1f17de7&scene=27,吴恩达深度学习系列课程完结，第五部分学霸笔记了解一下？,"吴恩达深度学习系列课程的第五部分更新后，整个课程终于完结。紧随吴老师的步伐，文摘菌邀请到了两位对该领域颇有研究的学者，为大家赶制了课程第五部分内容的笔记，趁着学习热情还未退去，尽快拿下这门课程！ 自2016年8月份，吴恩达的初创公司deeplearning.ai通过Coursera提供深度学习的最新在线课程，到今年2月份，吴老师更新了课程的第五部分（ ）前后共耗时半年时间。 让我们先来回顾一下第五部分课程内容简介： 第一周：循环神经网络RNN RNN Gated Recurrent Unit(GRU) LSTM 第二周：自然语言处理和词嵌入 Word2Vec GloVe 第三周：序列模型和注意力机制 Beam Search 语音识别 与内容相对，我们的笔记也按课程安排分为三个部分，分别是RNN相关理论介绍、结合Word2Vec和GloVe的应用以及RNN在机器翻译和语音识别等方面的应用。 序列模型, 普遍称为RNN(递归神经网络 - Recurrent Neural Network), 做为深度学习中非常重要的一环，有着比普通神经网络更广的宽度与更多的可能性，其应用领域包括但不限于“语音识别”， “自然语言处理”， “DNA序列分析”，“机器翻译”， “视频动作分析”，等等等等... 有这样一种说法，也许并不严谨，但是有助于我们理解RNN，大意是这样的： 普通神经网络处理的是一维的数据，CNN处理的是二维的数据，RNN处理的是三维的数据。 最直观的理解是在CNN对图片的分析基础上，RNN可以对视频进行分析，这里也就引入了第三维“时间”的概念。 RNN模型可以用下图表示： 鉴于微信呈现方式有限，我们在本文文末仅用图片形式发布部分笔记，希望查看更完整的笔记请点击以下链接前往收藏： 大数据文摘GitHub专栏： https://github.com/theBigDataDigest/Andrew-Ng-deeplearning-part-5-Course-notes-in-Chinese 大数据文摘CSDN专栏： http://blog.csdn.net/BigDataDigest 还不了解这门课程的同学可以戳下面的链接学习哦： Coursera课程链接： https://www.coursera.org/learn/nlp-sequence-models 目前网易云课堂的汉化版已经 完整放出， 相关链接： http://study.163.com/provider/2001053000/index.htm 大数据文摘也总结了一些大牛们写出的前四课的课程笔记给大家，可以点击查看： 最后，让我们感谢本次作业的两位作者，迅速高效地完成了课程学习，并无私分享如此详细的笔记。 作者简介： 于乐源，加拿大阿尔伯塔大学计算机系研究生在读，本科从阿尔伯塔大学毕业后做了三年的程序员突然在某一天发现了自己对深度学习的兴趣，决定回炉重造。现在在albertaai.org担任Academic Officer 我的心愿是 - 这个冬天不太冷 :) 杨佶，在加拿大阿尔伯塔大学取得计算机荣誉学士学位后，继续在本校攻读计算机科学硕士学位。主要的研究兴趣和方向是强化学习和计算机视觉，但在业余时间也会关注和研究深度学习，机器学习的其他发展方向。现在在 albertaai.org 担任 Vice President Education。 笔记截图如下： 【今日机器学习概念】 Have a Great Definition "
131,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657291&idx=1&sn=91ae288f32791952b4ac27f8d03797b1&chksm=bd4c33d88a3bbaceb464f2f482f6e653629f511eef4873d77e18dc1437b55cb9a00016a387a4&scene=27,别错过这张AI商用清单：你的生产难题可能被一个应用解决（续篇）,大数据文摘作品 作者：Liam Hänel  编译：S 在年前，文摘菌分享了一份商用AI清单，从语音识别到商业分析应有尽有。（点击阅读 ） 过了个年，文摘菌又整理出了一份最新清单。涵盖了以下这些AI应用： 对话界面和聊天机器人 客户关系管理、客户研究、客户支持 市场营销 智能招聘 团队协作等等 如果你真怕被AI抢走饭碗，所谓知己知彼，赶紧要来了解AI在业界的具体应用。 如果你是企业负责人，更是别错过这张清单——或许你的生产运转难题就可以被其中的某一个AI应用解决！ API.ai  —用于构建对话式用户界面的 高级工具 Chatfuel  —无需编码创建一个Facebook聊天机器人  Comm.ai  — 为网站和应用增添语音和聊天应用接口 Conversica  — 帮助达成更多销售的聊天界面 EDDI  — 创立、测试、部署聊天机器人 FPT AI Platform  — 与终端用户进行自动化交互 Golem.ai  — 供开发者使用的自然语言理解工具 Gong  —分析、提升销售谈话与客户访问电话的质量 Kasisto  — 金融行业的会话式AI平台 KITT.AI  — 利用一个可视界面创建会话代理人 Maluuba  —教会机器如何思考、推理与沟通  Massively  — 搭建商业用途的聊天机器人 Meya  —在一个平台上 建立、培训和托管机器人 MindMeld  — Siri的升级版本 Mobvoi  —语音集成的智能手表  Motion AI  — 聊天机器人让你事半功倍 msg.ai  — 带有管理仪表盘的聊天机器人 Octane AI  —帮助实现营销自动化 的消息回复软件 OpenAI Gym  — 适用于强化学习任务的开源用户界面 Orbit  — 可以将会话式人工智能自动化的工具 Pool  — 帮助你完成更多工作的私人助理 Recast  — 一个可以建立、培训、部署智能机器人的协作平台 Reply.ai  — 可以建立并管理你的会话策略的平台 Semantic Machines  — 用于工作、旅行、购物及娱乐的会话AI Snips  — 在你的互联设备上增加一个语音助理 Servo  — 全端机器人以及整合现有系统的语音 Smartly.ai — 一站式语音和聊天机器人平台 UNU.ai  — 使用了集群智能（Swarm Intelligence）的聊天机器人 Unify  — 电子商务聊天机器人 uTu  — 多渠道机器人分析及数据管理 Wit.ai  —为指定平台轻松创建基于文本或语音 的机器人 Wysh  — 支持支付功能的企业级规模聊天机器人 Zero AI  —有助于理解意义、目的和事件背景的 语音界面 Pez.AI  — 支持基于语音聊天的业务 Nucleus.ai  — 针对会话式AI的白标方案 Myra  — 在网站上提供即时的客户服务 Ivy.ai  — 高等教育领域的客户服务聊天机器人 Init.ai  — 通过对话改善客户体验 Hatch  — 通过Facebook Messenger实现自动化电子商务 Clinc  —企业级AI会话平台 Botco.ai  — 在大多数消息传送渠道上使用聊天机器人 Boost.ai  —坚实可靠的虚拟商务 伙伴 Bitbot.ai  — 建立Facebook聊天机器人 NLU Lab  — 建立不同类型的聊天机器人 Converse  — 创造智慧型聊天机器人 Basket  —电子商务购物 聊天机器人 IBM Watson NLP  —适用于 高级文本分析的自然语言处理 Brndstr  — 聊天机器人开发者工作室 Artificial Solutions  —实现企业级别的自然语言处理与分析  Botsify  — 无需编写程序即可创建聊天机器人 Hound  —通过语言处理 来实现产品语音功能（译者注：智能语音助手） Kriya.ai  —帮助你按需雇佣人才 Pandorabots  — 快速建立聊天机器人 DataFox  — 更好的客户关系管理 Dynamic Yield  — 一站式电子商务个性化平台 Jetlore  —将消费者行为匹配至结构化的可行动数据  Kasisto  — 金融行业对话式AI平台 Reifier  — 管理客户、供应商及产品的主数据 Rep.ai  — 跨平台的所有客户数据的中央枢纽 Takt  —帮助你更全面地了解客户 Dynamo  — 即时生成关于所有客户账户的见解 Augur  —帮助识别使用不同设备的各类顾客 Audience.ai  — 利用公开的社交媒体数据，帮助拓展受众群体 OpenDNA  —生成和构建用户的心理图表和行为图谱  Maia  — 去除了大数据的麻烦 Cogito  — 在电话中侦查人类信息，提供在线的行为指导，以促进每一次交互的质量。 Remesh  — 通过规模化的对话与客户构建连接 Tanjo  —以动画形式实时展现人物角色以及对客户进行细分 Aaron  — 客户服务机器人 ActionIQ  — 一个帮助市场营销人员分析数据的平台 Brain  —一个聊天机器人管理套件 Clarabridge  —根据文本和反馈信息生成可执行的消费者洞察 DigitalGenius  —在你的联络中心添加一层AI层（译者注；结合人工与智能的客服平台） Eloquent Labs  —将自助支持页面转化为对话形式，以减少工作量 Presence AI  — 一个可以帮助处理顾客消息的、便捷的仪表盘 Spin  — 保密的顾客反馈 Smith  — 真实的接待员+基于机器学习过滤垃圾邮件、销售、不受欢迎的致电 Rep.ai  — 跨平台的所有客户数据的中心枢纽 Wise.io  — 减少票务、缩短回复时间，为代理人腾出更多时间 Zendesk  — 创建有助于客户关系发展的软件 NEVA  — 自动化客户服务与支持 Alterra.ai  — 借助虚拟助理来增强联络中心话务员的能力 Agent.ai  — 将客户支持工具以及数据库中心化 Bottlenose  — 以更少的时间管理数据、花更多的时间获取洞见 CB Insights  — 为决策过程提供支持的预测行为 Enigma  — 整合内外部数据 Intelligent Layer  — 通过利用未发掘数据促进商业运营 Mattermark  —帮助你在正确的公司里找到合适人选 Predata  — 帮助你将媒体信息转化为投资的风险评估与预测 Premise  —促使大公司做更有影响力的投资  Quid  — 对市场规模、增长、投资首选机会的鸟瞰 Tracxn  —帮助VC记录不同行业的初创企业所在的生态系统  Appier  — 通过交叉屏幕营销提高营收 Dataminr  — 即时发现有重大影响力的事件和新闻 AirPR  —帮助管理PR工作及媒体活动  Albert  — 帮助你更好地开展市场营销活动 Amplero  — AI驱动的B2C市场营销平台 Automat  — 个性化、一对一地与批量客户交谈 BrightFunnel  — 优化全流程客户体验之旅 CogniCor  — 自动化产品查询、客户账户建立以及更多 Crystal  — 为你的社交媒体和内容营销提供实时建议 Datorama  — 机器学习驱动的数据整合以及AI驱动的营销情报 Lattice  — 促使你发现未开发市场和潜在客户 LiftIgniter  — 针对每一个用户的网页内容和电子商务进行个性化 Lucep  — 帮助销售代表管理销售线索 Maik  — 优化你的营销活动 ManyChat  — 为你的市场、销售及支持活动创建Facebook Messenger机器人 Mintigo  — 帮助预测销售机会并促进销售额增长 msg.ai  — 一块用于管理社交平台消息显示的单一展示面板 Persado  — 一个生成语言的内容平台，其语言具有激发行为的特性 Questions  — 更快速、非侵入式的问卷调研 Radius  — 帮助你在社交渠道上寻找潜在客户，与其互动，并转化为买家 ReSci  — 帮助客户维护 Rock Fuel  — 带来个性化广告的预测性市场活动 Prizma  — 媒介内容的优化、受众分析 Creativity.ai  — 360度的产品概览 Cosmos  — 帮助你更好地了解客户 ATP  — 提高营销绩效并简化工作流程的市场工具 Purple  — 通过用户的wifi使用情况更多地了解你的客户 Boxever  — 帮助生成内容并且在正确的时刻给到客户 6sense  — 为客户清单添加一层预测性的关于行为方面的洞见（译者注：通过分析人群的高时效性的行为数据，辨别潜在客户，同时针对既有客户群按照购买意愿做出分级，借此协助商户优化销售和市场事务，增长销售额） Aviso  — 做出可以促进销售增长的知情决策 BloomReach  — 提供对在线购买者的见解（译者注：BloomReach 出品的SNAP软件把用户心仪的商品直接推送到电商主页） Chorus.ai  — 记录、总结在线会议以帮助完成项目结尾 Clari  —精准预测并告知销售团队应该聚焦何处来达成目标 Collective[i]  —帮助获取更高销售绩效的预测性AI Enquire  — 更好的电子商务搜索 Fusemachines  — 自动勘探潜在客户、选择机会，以及更多 Eye.ai  — 得到关于如何提高你的网站UX/UI设计的建议 InsideSales  — 获取更相关的销售机会 Nova AI  — 帮助你从客户身上获得有意义的、有用的洞见 One.ai — 由AI驱动的、基于云的CRM软件 People.ai  —给予销售部门领导关于销售活动及其绩效的分析 Personify.ai  — 轻松创建机器人 Roof AI  — 生成房地产销售机会的聊天机器人 Salesforce Einstein  —优化商业流程和促进客户交互 Sales Decision Engine  — AI驱动的销售支持工具套装 Sudo  —从客户数据中寻找有意义的信号 Spin  — 保密的客户反馈 Tethr  — 从客户电话交谈记录获取洞见 TACT  — 再也不需要登录一款客户关系管理软件 Transformation  —跟踪、匹配、理解用户体验 xiQ  — 帮助加速销售增长，监控竞争活动，以及更多 Zensight  — 针对专业销售人士的AI Init.ai  —  通过对话改善客户体验 Hydra.ai  — 帮助销售领导者以最佳状态运营他们的团队 Hatch  — 通过Facebook Messenger实现自动化电子商务 Pathlight  — 永远联机、基于数据的，对销售运营团队的分析 Conversica  — 从邮箱和其他沟通渠道里发现你的最佳销售机会 Sentient  —自动调整网站设计以提高ROI Entelo  —整合来源于不同网站的职位候选人信息，并从中推荐合适候选人 Glider  — 自动检索，匹配，评估 HiQ  —提供如何与员工互动的见解和建议 HireVue  — 使用面部识别来帮助你挑选合适候选人 Olivia  — 优化的求职及招聘体验 Rai  —帮助你联系并招募到合适候选人 Rey  —将你介绍给你真正需要认识的人（工作与娱乐） Talent Sonar  — 使用一系列AI和包含其他相关手段的招聘平台 Textio  — 帮助优化你的招聘广告的书写 Uncommon  — 一个优化了的候选人搜寻及广告创建平台 Wade & Wendy  — 帮助你找寻合适的工作和人选 Recruiting.AI —帮助招聘   Aviva  — 使得工作场所的沟通条理化 Butter.ai  — 让你的全部公司知识触手可及 Cyclops  — 视频会议，包括书写白板 Deckard.ai  — 帮助预测项目进度 Howdy  — 一个友善的、可培训的，能帮助Slack团队工作的机器人 Knowmail  — 一个可以帮助你聪明地管理收件箱的邮箱助理 Plato  — 团队协作平台 Talla  — 自动化内部问题，管理员工需求并进行优先排序 Soapbox  — 通向组织群体智慧的入口 x.ai  — 会议议程规划助理 Yva.ai  — 帮助你跟踪管理重要工作任务的私人助理 Entropy  —帮助测量、提升员工的情商 ConferAI  —促使员工对项目与会议有效性给出反馈 Collaboration.ai  —帮助提高团队协作与绩效 Cerb  — 帮助管理共享收件箱 Butterfly.ai  —将员工反馈意见转化为个性化的管理者领导力培训 Butter.ai  — 让你的全部公司知识变得触手可及 Brand.ai  — 消除在设计与开发工作流程中的通信费用与版本冲突 原文链接： https://medium.com/imlyra/a-list-of-artificial-intelligence-tools-you-can-use-today-for-businesses-2-3-continued-21bf14280250 【今日机器学习概念】 Have a Great Definition 课程推荐 
132,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657362&idx=1&sn=39dbb35dc240fd0fd3bb04bf52cf0b70&chksm=bd4c33018a3bba178174ca5f960f026404d2bfd25495a4936d848d9b7b6867cc89da01f80ffb&scene=27,手把手：AlphaGo有啥了不起，我也能教你做一个（附Python代码）,大数据文摘作品 编译：叶一、Chloe、彭湘伟、钱天培 在2016年3月，Deepmind研发的AlphaGo以4:1的成绩，击败了曾荣获18次世界冠军的围棋选手，李世石(Lee Sedol)。超过2亿观众见证了这一历史时刻。一台机器已经学会了一种超越人类的围棋策略。这在以前被认为是一项不可能完成的任务，或者至少需要十年之功。 AlphaGo与李世石的第3场比赛 这已是一项了不起的成就。然而，在2017年10月18日，DeepMind又再次取得了突破。 论文《无需人类知识就能称霸围棋》（Mastering the Game of Go without Human Knowledge），揭示了一种新的算法——AlphaGo Zero，它以100:0的惊人成绩打败了AlphaGo。 仅48天后的2017年12月5日，DeepMind又发布了另一篇论文《通过一种通用的强化学习算法称霸国际象棋和日本象棋》（Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm），它展示了AlphaGo Zero如何能够学会国际象棋（StockFish和Elmo）和象棋。整个学习过程，从第一次参与游戏到成为世界上最厉害的计算机程序，只用了24小时。 就这样，AlphaZero华丽丽地诞生了——它无需储备任何人类棋谱，就可以以通用算法完成快速自我升级。 关于这个成就，有两点最让人称奇: AlphaZero对人类游戏经验根本就不需要 这点的重要性怎么说都不过分。也就是说，对于任何有充分信息的游戏（对阵双方对游戏状态都全程掌握），AlphaGo Zero的方法论都可以得到完美应用！因为除了游戏规则之外，人类任何游戏经验值都是不需要的。 AlphaGo Zero的基础方法可以应用于任何具有完美信息的游戏(游戏状态在任何时候，双方玩家都完全知道的)，因为在游戏规则之外，不需要事先的专家知识 。 这就是DeepMind能在发表AlphaGo Zero论文48天后，马上就能发表第二篇论文。毫不夸张地说，所需要改变的仅仅是新游戏规则，及与神经网络和蒙特卡罗树搜索相关的超参数。 即便AlphaZero使用的是世界上只有极少数人能够看懂的超复杂算法，它仍然是项了不起的成就。同它相比，之前的算法可谓不复杂不成活，这才是它真正的魅力。 脑补各种场景，挑能赢的路走，想想别人会怎么应对，并不断探索未知。 在思考未来可能的情景时，优先考虑有前途的路径，同时考虑其他人最有可能如何对你的行动作出反应，并继续探索未知。 遇到不熟悉的状况，评估它的利害程度，把它同之前的各种让你走到今天这一步的场景作比较。 穷尽你对未来的想象，用你试过最多的招数来应对。 在你考虑了未来的可能性之后，采取你已经探索过的行动。 游戏结束时，回头看看在哪里犯过错，然后洗心革面、更新认知。 在游戏结束时，回过头来评估你在哪里错误地判断了未来的位置，并相应地更新你的理解。 这听起来是不是很像你学玩游戏的方式?  当做错一个动作时，要么是因为你误判了这个动作会带来的结果，要么是你误判了对手可能会采取的行动。这两点正是AlphaZero学会如何玩游戏的法门。 首先，我们需要学习和理解AlphaGo Zero的原理。我之前写过一篇AlphaGo Zero的知识点速查手册可供参考： https://medium.com/applied-data-science/alphago-zero-explained-in-one-diagram-365f5abf67e0 Tim Wheeler 的博客中一篇文章也讲的很详细： http://tim.hibal.org/blog/alpha-zero-how-and-why-it-works/ 基于下面这个代码库进行讲解： https://github.com/AppliedDataSciencePartners/DeepReinforcementLearning 从运行Jupyter notebook中run.ipynb的前两个panel开始。一旦它完成了游戏的足够回合，那么神经网络将开始训练。通过随后的自我对弈和训练，它将逐渐在预测胜率和下一步行动上做得越来越好，从而做出更好的决策。 现在，我们需要更详细地看看面前的代码，并且展示下AI是怎样随着时间的增加变得越来越厉害的。 我们的算法将要学习如何玩这个游戏。虽然不如围棋那样复杂，但也有4531985219092种游戏走位。 四子连珠 游戏规则很简单。玩家轮流在任何一栏的顶部布置自己的颜色。最先在垂直、水平或对角线上放置一排同一种颜色棋子的玩家获胜，如果这种情况没有出现，那游戏就是平局。 下面是组成代码库的关键文件： game.py—— 这个文件包含四子连珠的游戏规则 每个正方形都被分配了一个从0到41的数字，如下图所示： game.py文件给出了从一种游戏状态到另一种状态的逻辑，并且给出了一个选择的动作。 比如，考虑到empty board和38号动作，takeAction方法返回到一个新的游戏状态，也就是底部一行的中心位置。 你可以将game.py文件用任何符合相同API和算法的游戏文件替换掉，根据你给它的规则，通过自我对弈的方法学习。 run.ipynb—— 这个文件包含开启学习过程的代码 它通过算法中的主要环节加载游戏规则，并且由三个阶段组成： 1、自我对弈 2、重新训练神经网络 3、评估神经网络 有两个智能体也参与到这个环节中，他们分别为best_player和current_player。 best_player包含执行最佳的神经网络，并且可以用于生成自我对弈的记忆。然后，current_player在这些记忆上重新训练它的神经网络，然后再与best_player对弈。如果它赢了，best_player内部的神经网络被转换为current_player内部的神经网络，然后循环再次启动。 agent.Py—— 这个文件包含游戏中的一个玩家Agent class 在游戏中，每个玩家都是用自己的神经网络和蒙特卡罗搜索树进行初始化的。 我们需要用模拟的办法运行蒙特卡罗树搜索过程。具体地说，智能体移动到树的叶节点，用它的神经网络对节点进行评估，然后通过树将节点的值返回。 之后，我们还需要用act method多次重复模拟，让智能体理解从当前位置出发的最有利的移动。然后它将最终选择的动作返回到游戏中，以执行动作。 最后，replay method利用以前游戏的记忆，重新训练神经网络。 model.py—— 用Keras搭建残差卷积网络示例 它采用的是AlphaGoZero论文中浓缩版的神经网络结构——即一个卷积层，接着是许多剩余层，然后分成一个数值和指挥中枢。 可以在config文件中指定卷积筛选器的深度和数量。 Keras库是用来与后台的tensorflow建立网络。 查看个人的卷积滤波器和浓密连接层的神经网络，在run.ipynb笔记本运行以下代码： 神经网络中的卷积核 MCTS.py—— 这个文件包含节点（Node），边（Edge）和MCTS类，构成了蒙特卡洛树搜索 MCTS类包含了前文提到的 moveToLeaf 和backFill 方法，以及Edge类的实例存储有关每个潜在移动的统计信息。 config.py—— 这是你设置影响算法的关键参数的地方 调整这些变量会影响运行时间，神经网络的准确性和整体算法的成功。以上参数产生一个高品质的四子连珠选手，但要花很长时间才能做到。为了加快算法的速度，请尝试以下参数。 funcs.py—— 包含可以在两个智能体之间进行比赛的playMatches和playMatchesBetweenVersions函数 如果你想挑战之前创建的智能算法，可以运行下面的代码（在run.ipynb笔记本） initialise.py—— 当你运行该算法，所有的模型和存储文件保存在 runfolder的根目录下 稍后要从此检查点重新运行算法，请将运行文件夹传输到run_archive文件夹，并将运行编号附加到文件夹名称。然后，将运行编号，型号版本号和内存版本号输入到initialise.py文件中，对应于run_archive文件夹中相关文件的位置。像往常一样运行算法，然后从这个检查点开始。 memory.py Memory类的一个实例存储以前游戏的记忆，该算法用于重新训练current_player的神经网络。 loss.py 该文件包含一个自定义损失函数，在传递到交叉熵损失函数之前，屏蔽了来自非法移动的预测。 settings.py run和run_archive文件夹的位置。 loggers.py 日志文件保存到运行文件夹内的日志文件夹中。 要打开日志记录，请在此文件中将logger_disabled变量的值设置为False。 查看日志文件将帮助你了解该算法的工作原理，并在其“头脑”中查看。 例如，下面是logger.mcts文件中的示例。 logger.mcts文件的输出 同样从logger.tourney文件，你可以在评估阶段看到每个移动的概率： logger.tourney文件的输出 通过几天的训练，得到以下小批量迭代次数与损失的关系图： 小批量迭代次数与损失的关系图 最上面的线是策略头中的误差（MCTS移动概率的交叉熵，相对于神经网络的输出）。底部的线是价值头（实际游戏数值和神经网络预测值之间的均方误差）。中间的线是两者的平均值。 显然，神经网络在预测每个游戏状态的值以及可能的下一步移动方面正在变得更好。为了说明这个结果如何变得越来越强大，我让17个参与者组成联赛，从神经网络的第1次迭代到第49次。每一组比赛两次，两个玩家都有机会先玩。 这是最后的排名： 显然，神经网络的最新版本比早期版本更胜一筹，赢得了大部分的游戏。  这也似乎表明学习过程没有达到极限 - 随着训练时间的进一步延长，玩家将会继续变得更强大，学习越来越复杂的策略。 作为一个例子，随着时间的推移，一个神经网络挑选的策略较早的占据了中间列。观察算法的第一个版本与第三十个版本之间的区别： 第一个神经网络版本 第三十个神经网络样本 这是一个很好的策略，因为很多线路都需要中间列 – 尽早占领这一列可以确保你的对手无法利用这一优势。 在游戏文件中有一个称为“Metasquares” 的game.py文件 。其中的X和O用于形成不同大小的正方形。较大的方格意味着要落更多的棋子，当棋盘布满时，落子多的一方获胜。 如果你将Connect4 （四子连珠） 的game.py文件替换成Metasquares的game.py文件，同样算法将会用于学习玩Metasquares游戏。 赶紧自己来动手试试吧！ 原文地址： https://medium.com/applied-data-science/how-to-build-your-own-alphazero-ai-using-python-and-keras-7f664945c181 【今日机器学习概念】 Have a Great Definition 
133,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657291&idx=2&sn=abcf8b98a90162536b6ac5f76c50c14d&chksm=bd4c33d88a3bbace8504c0c33455db4fd79d29e8e46fc36fc38d64c3ad904e4bf713452b9b0c&scene=27,学界 | MIT深度学习课程全部视频及课件开放,继开放自动驾驶课程之后（ ），一向低调的MIT近期又开放了一门更偏概述的深度学习课程——6.S191: Introduction to Deep Learning（深度学习入门），官方介绍该课程为一门对深度学习算法和应用的入门课程（An introductory course on deep learning algorithms and their applications）。 目前，在官网上，所有的课程信息、录像和课件都已公开。感兴趣的同学可以注册学习了。 先附上官网注册链接：http://introtodeeplearning.com/ Coursera和其他高校开放的深度学习入门课程已不少，与已有课程相比，本课程的一大亮点可能是业内一票应用大咖公司的案例介绍，包括谷歌、英伟达、IBM以及中国公司腾讯，都对本课程提供了案例分享，并在每个部分都提供了实验室支持。 课程介绍部分视频 马上观看▼ 以下是来自官方的一些信息： 这是一门介绍深度学习原理及其应用于机器翻译，图像识别，游戏，图像生成等领域的入门课程。 随着课程的深入，本次课程加入了TensorFlow、同伴头脑风暴和实验室的合作课程。 来自从业人员和行业赞助商小组反馈的项目建议作为课程的最后一节。 项目建议部分的持续时间为1分钟，大家可以从深度学习算法，应用程序，开源贡献，创建有趣的数据集或其他相关方面选择一个主题。赞助商将评选出最佳项目作为获奖者。项目建议也可以选择提交一篇有趣的深度学习综述论文。 如果是麻省理工学院的学生（本科或研究生），可以直接在网站提交表单。 普通听众可以通过邮件注册，参加课程。 MIT本次推出的这门公开课，邀请了四家明星企业：Google、NVIDIA、IBM和Tencent作为嘉宾，一起分享深度学习的相关内容，也是默默无闻的搞大事情啊。 Part 1 深度学习简介 Part 2 深度序列建模 Lab TensorFlow 简介，用 RNNs 网络生成音频 Part 1 深度计算机视觉 Part 2 深度生成模型 Lab 人类 X 射线扫描检测疾病 Part 1 深化强化学习 Part 2 局限和新前沿 Lab 综述 / 项目建议 Part 1 嘉宾讲座： Google Part 2 嘉宾讲座： NVIDIA Lab 赞助商展位 + 综述 / 项目建议 Part 1 嘉宾讲座： IBM Part 2 嘉宾讲座： Tencent Lab 项目建议介绍、评审和奖励 当然，想要系统学习深度学习的同学，我们也推荐一些更加专项的课程给大家： 总体来看，大数据文摘刚刚也提到过，这门课程整体来说属于深度学习的基础课程，内容更适合初学者，如果之前已经学习过coursera上相关课程的同学或者比较专业的选手，就不需要再重新学一遍这门课程了。 吴恩达深度学习系列课程，五个部分已经完整放出。 Coursera相关链接： https://www.coursera.org/learn/nlp-sequence-models 目前网易云课堂的汉化版已经完整放出。 相关链接： http://study.163.com/provider/2001053000/index.htm 多伦多大学三巨头，被誉为“深度学习之父“的Geoffrey Hinton教授在Coursera上的Neural Networks For Machine Learning课程。他的UT实验室在2012年的某医药大赛中如一匹黑马般赢得桂冠（即使整个团队没有一个人懂生物），真正地把深度学习带入了主流媒体的视线。链接：https://www.coursera.org/learn/neural-networks 斯坦福大学CS231n卷积神经网络视觉识别课程（李飞飞授课），大数据文摘授权汉化教程链接：http://study.163.com/course/introduction/1003223001.htm 斯坦福大学CS224d自然语言处理深度学习课程，链接：http://cs224d.stanford.edu/ 牛津大学与DeepMind合作的自然语言处理深度学习课程，大数据文摘授权汉化教程链接：http://study.163.com/course/introduction/1004336028.htm MIT 6.S094深度学习与无人车课程。大数据文摘授权汉化教程链接：http://study.163.com/course/introduction.htm?courseId=1004938039 专门致力于为深度学习工程师提供教育资源的fast.ai。 链接：http://www.fast.ai/ Tensorflow提供的机器学习教程。 初学者篇： https://www.tensorflow.org/get_started/mnist/beginners 进阶篇： https://www.tensorflow.org/get_started/mnist/pros AI圣经级教科书（花书）－蒙特利尔大学教授Yoshua Bengio和他的前学生Ian Goodfellow合著的《Deep Learning》；英文版免费阅读：http://www.deeplearningbook.org/ 中文版也已上市！ 以上是一些免费课程，如果想要保证听课质量，保证有答疑和练习，我们也推荐网易云课堂一些收费课程： 人工智能的数学基础。链接：http://mooc.study.163.com/smartSpec/detail/1001358003.htm 机器学习工程师实战课程。链接：http://mooc.study.163.com/smartSpec/detail/1001358002.htm 【今日机器学习概念】 Have a Great Definition 课程推荐 
134,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657263&idx=2&sn=006e5e17bb3839a3c9b6a6d79e30ddad&chksm=bd4c33bc8a3bbaaa62942b9a36a86445061b8ce846e75581e60ad87b53a895721b71ae06f92a&scene=27,“开源”创造者为你论述这一术语的前世今生,"“开源”一词被广泛应用于软件领域，这一术语对时代的进步做出了贡献。值此术语诞生20周年之际，其创造者Christine Peterson对其的前世今生做出了描述。 2月是“开源软件”一词问世的20周年。随着开源软件越来越受欢迎，并且为时代的进步提供了助力。我们也回顾一下“开源”的由来。 我在Foresight Insitute任执行董事期间提出“开源软件”一词。在这期间Linux程序员Todd Anderson对这一术语的广泛流传做出了不小的贡献。 以下将描述我是如何想到它、如何提出以及后续大家对这一词的反应。关于这一词的由来，有很多版本。比如有来自Eric Raymond和Richard Stallman的描述，但是在2006年1月2日我曾亲自对此做出解释。但是直到今天，我才公布这些言论。 “开源软件”这一词的引入是经过深思熟虑的，目的是努力使得“外行”更容易理解这一领域，我们认为这是为了扩宽受众用户群体所必须要做的。之前“自由软件”一词不能适用并不是因为它具有政治含义，而是因为对于新用户来讲，这个名称会误导人关注价格。所以需要一个新的术语，一个关注源代码并且不会立即让新用户混淆概念的术语。此时，第一个在正确的时间出现并满足所有要求的术语就被迅速接受了，那就是“开源”。 这一术语长期以来被用于“情报”（比如间谍）活动中，但据我所知，确实在1998年以前，软件领域从未使用过该术语。以下的文字，将描述这一术语的“前世今生”。 1997年底，Foresight  Institute开始举办周会讨论计算机安全问题。Foresight是一个关注纳米科技和人工智能的非盈利智库。纳米科技和人工智能的可靠性和安全性取决于软件安全。提高软件安全性和可靠性比较靠谱的方法是自由软件，而且现在仍然在寻找更好的方法。对自由软件的兴趣开始在编程社区之外焕发活力，而且世界的逐渐改变使得这一现象越来越显著。虽然，应如何去做尚不明朗，但一直在摸索策略。 在这些会议上，因为考虑到“容易混淆”这个因素，我们讨论了是否需要提出一个新术语。主要争论如下：新手认为“自由软件”这一词指的是价格，因此老前辈们必须出来解释，通常会给出如下解释“free”指的是“freedom”中的“free”(自由)，而不是“free beer”（免费啤酒）中的“free（免费）”。在这一点上，关于软件的讨论就变成了对于酒精饮料价格的讨论。其实问题不在于解释这个词的含义，而是因为一个表达重要含义的术语不应使得“新手”感到迷惑不解。所以我们需要一个更加清楚明白的术语。自由软件一词并没有任何政治问题，问题在于这个词对于新人来讲并不能清晰表明它的概念。 1998 Eric把Foresight作为行动基地，在访问网景期间，他接到了来自网景法律部门或营销部门工作人员的电话。在他聊完后，我要求和他们通电话，这样我可以告诉他们创造一个新术语的必要性。原则上他们立即同意了， 在那一周的开会期间，我始终专注于寻找一个更好的名字并提出了“开源软件”一词。虽然仍然不太理想，但是我觉得已经足够了。我找到其他四个人征求意见，Eric Drexler，Mark Miller和Todd Anderson都挺喜欢这个名字的，但是做市场营销和公共关系的一位朋友认为“open”这个词已经被用烂了，他觉得我们能找到一个更好的词。理论上这位朋友是对的，但是我当时也没有更好的想法，所以我认为我应该先试着去推广它。现在回想起，我当时就应该直接告诉Eric Raymond我的想法，但是那时候我也不太了解他，所以我采取了一个间接的方法。 Todd对这个新术语表达出强烈的赞同并乐意提供支持。这对我帮助很大，因为作为一个非程序员，我在自由软件社区的影响力很弱。 在Foresight，我做纳米科技教育工作做的还不错，但这不足以让我在自由软件问题上可以引起重视。Todd作为一个Linux程序员，他的话更容易有人听。 在那一周的晚些时候，就是1998年2月5日，一群人聚集在VA研究小组进行头脑风暴。参会的除了Eric Raymond, Todd和我之外还有Larry Augustin, Sam Ockman，Jon Hall（绰号maggdog）通过电话参加会议。 主要话题是讨论如何推广，也就是去接洽哪些公司。我说的很少，但是也一直在寻找机会介绍新术语。我觉得如果我直接说“你们这些技术人员都应该开始使用我的新术语”是没什么用的。因为参会的大部分人不认识我，而且就我所知，他们甚至都不同意现在迫切需要一个新术语这个事情。 幸运的是，Todd一直在留心着。与其直接提出编程社区应该使用这个新术语，面对社区这些固执的人，他采用了更委婉和聪明的方法。他仅仅在另一个主题的一句话中用了这个术语，目的就是想在这个对话中提到它看看会发生什么。我很紧张，期待有所回应，但是刚开始没有人说什么。讨论继续在原来的主题上，貌似只有我俩注意到了这个用法。 几分钟后，另一个人用到了这个词，他显然没有注意到，还在继续讨论主题内容而不是术语。Todd和我小心的对视一眼：没错，我们都注意到了发生了什么。我很兴奋——这也许可行了！但是我继续保持沉默。我在这个组中仍处于低位。也许有些人想知道Eric为什么会邀请我。 在会议结束的时候，关于术语的问题被Todd或者Eric明确的提出来了。Maddog提到“可自由分配(freely distributable)”作为早期术语，“合作开发(cooperatively developed)”作为新的术语。Eric列出“自由软件(free software)”、“开源(open source)”和“sourceware”作为主要选项。Todd提议使用“开源(open source)”，Eric表示赞同。我没有说太多，就让Todd和Eric轻轻松松的、非正式的去推广。显然对于参会的大多数人来讲，改名字不是他们在这讨论的主题，这只是一个相对较小的问题。从我的会议记录上来看，只有10%的内容是关于术语问题的。 但是我已经很高兴了。社区里一些主要领导者喜欢这个新名字，或者说至少不反对。这是一个好的开端。也许我能做的不多了，Eric Raymond比我更适合去推广，他也是这么做的。Bruce Perens立即表示支持，并帮忙建立Opensource.org并在推广新术语中发挥了重要作用。 为了让这个术语获得认同，Tim O’Reilly同意并积极的在他多个代表社区的项目中使用这个名字，他的这一举动是很有必要的，至少说是非常值得的。而且在官方即将发布的Netscape Navigator代码中也会使用这个术语。直到2月底，O'Reilly & Associates和Netscape都开始使用这个术语了。 在这之后的一段时间里，这个名字由Eric Raymond向媒体推广，由Tim O'Reilly向商业推广，由此向编程社区推广。它传播的非常快。 1998年4月7日，Tim O'Reilly举行了一次该领域重要领头人的峰会。这作为第一个“自由软件峰会”，在4月14日之后它又被称为第一个“开源峰会”。 这几个月对于开源来讲是非常令人兴奋的。似乎每星期都有新的公司宣布加入。即使对于像我这样仅仅在外围参与的人，阅读Slashdot也已经成为必要。我坚信这个新术语会迅速传播到商业领域，从而获得公众认同。 在Google快速搜索中搜索“开源”的次数比“自由软件”更多，但是自由软件这仍然在被大量使用，这个术语仍然拥有一部分粉丝，因此我们应该采取包容的策略。 当由Eric Raymond写的关于术语更改的说明被发布在Open Source Initiative网站上时，我被列在了VA头脑风暴会议上，而不是作为术语的创始人。这是我的失误，我忘记告诉Eric细节了。我的想法是让它过去，我继续待在幕后就好了，但是Todd不这么认为。他告诉我说有一天我会很高兴被称为“开源软件”这一词的创始人的。他向Eric解释了这个情况，Eric立即更新了网站。 提出一个词只是一个很小的贡献，但我很感激那些记得把它归功给我的人。每一次我听到这个词的时候（现在经常能听到了），它总能给我一点快乐的感觉。 说服社区的巨大功劳要给Eric Raymond和Tim O'Reilly，是他们让这一切成为可能。感谢他们的信任，感谢Todd Anderson所做的一切。以上并不能完全描述开源一词的历史，在此我向那些没有被提到的贡献者表示抱歉。如果想要更加完整的描述可以参考此篇文章中的链接和网络上的其他资源。 原文链接： https://opensource.com/article/18/2/coining-term-open-source-software 【今日机器学习概念】 Have a Great Definition 课程推荐 "
135,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657252&idx=2&sn=c92496a91b566e6d9dff6ca368dc526b&chksm=bd4c33b78a3bbaa1041446041c9c2bd69359dd0ba03713984341faf7f152ba45862a7fca03c6&scene=27,美国现代艺术博物馆的软数据：111件服装展品的前世今生,大数据文摘作品 翻译：王梦泽、元元、小鱼 
136,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657252&idx=1&sn=44933277d20323d5513fc4e4f800c292&chksm=bd4c33b78a3bbaa1ec5093b253adc2b4fc37af93ce0bb90313039bd6c02a1a503d196afc2c4d&scene=27,拯救假期！我用Python写了一个自动回复拜年信息的小程序,大数据文摘授权转载 自云栖社区 作者： 
137,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657263&idx=1&sn=1d161e81af626563548a1416f9bd955f&chksm=bd4c33bc8a3bbaaa22e297dc88d6c3c81bc09cce2e17872b46b18880cccf4500e920157c3c0d&scene=27,小白学数据：教你用Python实现简单监督学习算法,大数据文摘作品 编译：文明、笪洁琼、天培 今天，文摘菌想谈谈监督学习。 监督学习作为运用最广泛的机器学习方法，一直以来都是从数据挖掘信息的重要手段。 这篇监督学习教程适用于刚入门机器学习的小白。 当然了，如果你已经熟练掌握监督学习，也不妨快速浏览这篇教程，检验一下自己的理解程度~ 在监督学习中，我们首先导入包含有训练属性和目标属性的数据集。监督学习算法会从数据集中学习得出训练样本和其目标变量之间的关系，然后将学习到的关系对新样本（未被标记的样本）进行分类。 为了阐明监督学习的工作原理，我们用根据学生学习时间预测其考试成绩的例子来说明。 用数学表示，即 Y = f(X)+ C， 其中 f表示学生学习时间和考试成绩之间的关系 X表示输入（学习小时数） Y表示输出（考试分数） C表示随机误差 监督学习算法的终极目标是给出新的输入X，使得预测结果Y的准确率最大。有很多方法可以实现有监督学习，我们将探讨几种最常用的方法。 根据给定的数据集，机器学习可以分为两大类： 。如果给定的数据集的输出值是类别，那么待解决是分类问题。如果给定的数据集的输出值是连续的，那么该问题是回归问题。 举两个例子 分类：判断是猫还是狗。 回归：房子的售价是多少？  考虑这样一个例子，医学研究员想要分析乳腺癌数据，用于预测患者使用三种治疗方案中的哪一种。该数据分析问题就属于分类问题，通过建立分类模型来预测类别标签，例如 “ 治疗方案A ” 、 “ 治疗方案B ” 或者 “ 治疗方案C ” 。 分类是一个预测类别标签的预测问题，这些类别标签都是离散和无序的。分类包含两个步骤：学习步骤和分类步骤。 分类 方法和选择最优方法 一些常见的分类算法： K近邻 决策树 朴素贝叶斯 支持向量机 在学习步骤中，分类模型通过分析训练集数据建立一个分类器。在分类步骤中，分类器对给定的数据进行分类。用于分析的数据集（包含数据和其对应的标签）被划分为训练集和测试集。训练集从分析用的数据集中随机抽取。 测试集用于评价分类器的预测精度。分类器的精度用测试集中预测正确的百分比表示。为了获得更高的精度，最好的方法是测试多个不同的算法，同时，对每个算法尝试不同的参数。可以通过交互检验选择最好的算法和参数。 对于给定问题，在选取算法时，算法的精度、训练时间、线性、参数数目以及特殊情况都要考虑在内。 在IRIS数据集上实现sklearn中的KNN，并对给定的输入进行花卉类型分类。 首先，要应用机器学习算法，我们需要了解给定数据集的组成。在这个例子中，我们使用内置在sklearn包中的IRIS数据集。现在让我们使用代码查看IRIS数据集。 请确保你的电脑上成功安装了Python。然后，通过PIP安装下面这些python库： 在下面这段代码中，我们使用pandas中的一些方法查看IRIS数据集的一些属性。 输出： 如果一个算法仅存储训练集数据，并等待测试集数据的给出，那么这个算法便可认为是一个“懒惰学习法”。直到给定测试集数据，它才会根据它与存储的训练集样本的相似性来对新样本进行分类。 K近邻分类器就是一个懒惰学习法。 K近邻基于类比学习，比较一个测试样本和与之相似训练集数据。训练集有n个属性表征。每个样本由n维空间中的一个点表示。这样，训练集中的所有样本都储存在n维模式空间中。 “接近度”用距离来度量，例如欧几里得距离。较好的K值可以通过实验确定。 在下面这段代码中，我们导入KNN分类器，将之应用到我们的输入数据中，然后对花卉进行分类。 输出： 其中，0，1，2分别代表不同的花。在该例子中，对于给定的输入，KNN分类器将它们都预测成为1这个类别的花。 K NN对IRIS数据集分类的直观可视化 回归通常被定义为确定两个或多个变量之间的相关关系。例如，你要通过给定的数据X预测一个人的收入。这里， 预测收入是一个经典的回归问题。你的输入应当包含所有与收入相关的个人信息（比如特征），这些信息可以预测收入，例 如工作时长、教育经历、职称以及他的曾住地等。 回归模型 一些常见的回归模型有 线性回归 逻辑回归 多项式回归 线性回归通过拟合一条直线（回归线）来建立因变量（Y）与一个或多个自变量（X）之间关系。 用数学公示表示，即 h(xi) = βo + β1 * xi + e， 其中 βo是截距 β1是斜率 e是误差项 用图表示，即 逻辑回归是一种预测类别的算法，用于找出特征和特定输出概率之间关系。 当然了，我们也可以把逻辑回归归类为分类算法，但就像我们刚才所说，逻辑回归的输出其实是目标对象属于某一类别的概率。既然概率是连续的，我们依旧把逻辑回归算作回归算法。 用数学公式表示： p(X) = βo + β1 * X， 其中 p(x) = p(y = 1 | x) 图形表示为 多项式回归 是一种将自变量x与因变量y的关系拟合为x的n阶多项式的回归算法。 解决线性回归问题 我们有数据集X，以及对应的目标值Y，我们使用普通最小二乘法通过最小化预测误差来拟合线性模型 给定的数据集同样划分为训练集和测试集。训练集由已知标签的样本组成，因此算法能够通过这些已知标签的样本来学习。测试集样本不包含标签，你并不知道你试图预测样本的标签值。 我们将选择一个需要训练的特征，应用线性回归方法拟合训练数据，然后预测测试集的输出。 用Sklearn实现线性回归 输入 输入值： 预测的输出值： 提一下常用的监督学习的python库 Scikit-Learn Tensorflow Pytorch 最后布置一个作业：请根据文章内容，用监督学习推测一下今天的文摘菌是哪位帅哥小编~ 原文链接：https://towardsdatascience.com/supervised-learning-with-python-cf2c1ae543c1 【今日机器学习概念】 Have a Great Definition 课程推荐 
138,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657214&idx=1&sn=206923dcb7d470b5de0739b52d2331a2&chksm=bd4c346d8a3bbd7b96de4a000147a8b882f4f9b7fc9fba34b80ac09e6b4b408de234fe3a681d&scene=27,手把手：用Python搭建机器学习模型预测黄金价格,"自古以来，黄金一直作为货币而存在，就是在今天，黄金也具有非常高的储藏价值，那么有没有可能预测出黄金价格的变化趋势呢？ 答案是肯定的，让我们使用机器学习中的回归算法来预测世界上贵重金属之一,黄金的价格吧。 我们将建立一个机器学习线性回归模型，它将从黄金ETF (GLD)的历史价格中获取信息，并返回黄金ETF价格在第二天的预测值。 GLD 是最大的以黄金进行直接投资的ETF交易基金。 （ 详见： http://www.etf.com/GLD ） 在python的开发环境下用机器学习预测黄金价格的步骤： 导入Python库并读取黄金ETF 的数据 定义解释变量 将数据切分为模型训练数据集和测试数据集 建立线性回归模型 预测黄金ETF的价格 首先:导入实现此策略所需的所有必要的库（ ) 然后我们读取过去10年间每天黄金ETF的价格数据，并将数据储存在Df中。我们移除那些不相关的变量并使用dropna函数删除NaN值。然后我们绘制出黄金ETF的收盘价格。 输出 解释变量是被用来决定第二天黄金ETF价格数值的变量。简单地说，就是我们用来预测黄金ETF价格的特征值。本例中的解释变量是过去3天和9天的价格移动平均值。我们使用dropna()函数删除NaN值，并将特征变量存于X中。 然而，你还可以在X中放入更多你认为对于预测黄金ETF价格有用的变量。这些变量可以是技术指标，也可以是另一种ETF的价格（如黄金矿工ETF (简称GDX)或石油ETF(简称USO)）或美国经济数据。 输出 同样， 简单地说，在这里就是我们试图预测的黄金ETF价格。我们将黄金ETF的价格赋值为y。 输出 在此步骤中， 训练数据用于建立线性回归模型，将输入与预期输出配对。测试数据用于评估模型的训练效果。 前80%的数据用于训练模型，其余的数据用来测试模型。 X_train 和y_train是训练数据集。 X_test & y_test是测试数据集。 接下来我们将建立一个线性回归模型。什么是线性回归呢? 如果我们试图捕捉可以最优解释Y观测值的X变量和Y变量之间的数学关系，我们将在X的观测值形成的散点图中去拟合一条线，那么这条线，也就是 再进一步地说，回归解释了因变量在自变量上的变化。因变量y是你想要预测的变量。自变量x是用来预测因变量的解释变量。下面的回归方程描述了这种关系: 然后我们利用拟合方法来拟合自变量和因变量(x和y)，从而生成系数和回归常数。 输出 黄金ETF价格=1.2×3天的移动平均价－0.2×9天的移动平均价+0.39 现在，是时候检查模型是否在测试数据集中有效了。我们使用由训练数据集建立的线性模型来预测黄金ETF的价格。预测模型可以得到给定解释变量X后相应的黄金ETF价格(y)。 输出 图表显示了黄金ETF价格的预测值和实际值（蓝线是预测值，绿线是实际值）。 现在，让我们使用score()函数来计算模型的拟合优度。 可以看出，模型的R²是95.81%。R²总是在0到100%之间。接近100%的分数表明该模型能很好地解释黄金ETF的价格。 祝贺你，你刚刚学会了一种基本而又强大的机器学习技巧。 原文链接： https://www.quantinsti.com/blog/gold-price-prediction-using-machine-learning-python/ 【今日机器学习概念】 "
139,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657196&idx=2&sn=8913117197841a2ddb1075182e779092&chksm=bd4c347f8a3bbd69073e7a00cb705df519556fb406eff4fc435d01a98a5e0355b47b15be5d51&scene=27,我们结婚吧，在区块链上！,"大数据文摘作品 编译： Aileen “只有死亡才能让我们分开，因为区块链是永存的。”  David Mondrus 这样描述自己与在菲律宾相识的妻子Joyce的婚姻。 Joyce和David在2014年结为夫妇，地点是......在区块链上。 如果你还不知道区块链是什么 区块链跟踪交易，但也可以将元数据包含在交易记录中。 省去冗长的步骤，很酷的结婚 参加Joyce和David的婚礼的人收到QR码，可以通过它连接到记录着他们这次婚姻相关的数据的交易上。 这位夫妇是因为受够了处理跨国婚礼的繁琐麻烦后，萌生了这样结婚的念头。 “想想这是多么的疯狂的事儿啊，”David告诉Bitcoin.com。 不仅如此，婚姻只在你所提交的国家里合法。所以当我们在美国结婚的时候，菲律宾政府对此毫不知情。直到我们前往大使馆后，填写更多的文件，再等待婚姻被正式承认。让我告诉你，这个过程真的超痛苦的。 David了解比特币作为货币的能力。不过，在他眼中却并非仅仅如此。  他说。 “只要比特币存在，我们的承诺就会存在。” 尽管Joyce和David只是在区块链交易中包含了额外的数据，但还有不少方式可以让人们使用区块链来声明自己的爱。 比如Bitnation提供名为“Smart Love”的服务，用户可以根据需要灵活地定义和设计婚姻。 David对智能合约和婚姻做了更多的解释：“你可以选择使用最适合您的法律代码，按照您希望的方式设计婚前合约，婚后合约，托儿合同，甚至是多方婚姻。” 居住在伦敦的两名西班牙裔居民Edurne Lolnaz和Mayel de Borniol的婚姻也是在区块链上注册的。 “我们不需要任何州政府或教会来验证我们的婚姻，”他们在博客中陈述了他们的区块链婚姻。 “因此，我们在证人面前签署了这项协议，在Bitnation（世界上第一个虚拟国家）和 e-Estonia（全球第一个颁发电子身份证的虚拟居住区）的赞助下在Blockchain（世界上第一个分布式公共账本）上获得认证”。 如果对自己的爱情足够自信，承诺不需要寄托在那张纸上，这样酷酷的结婚也很不错。不是吗？ 永远存在的爱情宣言 此外，有些网站，如Eternitywall.it，允许任何人在区块链中嵌入消息并将其发布到在线网站。在该网站上，区块链上不乏爱情宣言。 友情提醒：虽然这样的爱情宣言很特别，但直男们千万不要把这个当情人节礼物…… 一年前，有人发现一封情书出现在比特币交易中。  “Dayah Dover，你的个性无人可及。 你的智慧那么闪耀。 你可以做到只有很少人能做的事情。 而且你总是那么的美丽。 你真的是我的整个世界，给了我生活的意义和乐趣。 Dayah，我爱你。” 发件人花费了0.00314159比特币（写作时大约3美元）。 在情书交易之前，这位Dayah Dover女士的名字已经在流行的 r/bitcoin论坛中出现，但没有具体的帖子提及将她与数字货币联系在一起。 Dover女士在她的Instagram上经常发布自己衣着暴露的自拍，并在她的Instagram上直接与粉丝发私信交流。 她有近25,000名粉丝。“马克思主义者。 无神论者。以人为本。 国际模特”，她是这样描述自己的。 这个小故事只是表明，无论你的爱情是浪漫的，激情的还是有点猥琐的，区块链可能都有用武之地。 原文地址： https://news.bitcoin.com/cross-border-love-on-the-blockchain/ 【今日机器学习概念】 Have a Great Definition "
140,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657196&idx=1&sn=352d4d48f706789a547634e3bca74a17&chksm=bd4c347f8a3bbd692037919ba0c6af8c09bb72bc48612e4dfc40bd7bbe0324dd5679b1ce284c&scene=27,算法和重大人生抉择：如何最科学地选择人生伴侣？,人生中，你总是时刻面临重大抉择： 想在有限的时间里找到最心仪的公寓，却不知道什么时候做最后的决定； 你知道股市有风险投资需谨慎，可没人告诉过你什么时候可以赌一把； 而在这个特殊的日子你可能更想知道，如何锁定那个最有可能跟你终成眷属的另一半? 这些似乎都是无法重复的选择，没有人知道你的决定是不是最佳答案。 但如果你去问一个数学家，他八成会带着神秘的笑容告诉你，理论上来讲，有一种算法都可以为你作答——最佳停时。  或者说，更广为人知的，传说中的【37法则】。 那么37法则是如何得出来的，在生活中，这一算法是如何起作用的？它会对你的人生产生怎么样的影响，又有何缺陷？ 点击以下音频，或者 ，在大数据文摘最新音频栏目 中，来自杜克大学美女主播段天霖将跟大家聊聊这个神奇的算法——最佳停时。 其实不仅今天聊到的最佳停时，在这个崭新的栏目中，我们将陆续探讨这些你在生活中将要用到的算法。尽管相比人生的复杂，这些算法大多是too simple too naive的， 这些算法和观点将主要来自一本算法书籍 （生活中的算法），这本书被称为“the computer science of human decisions（人生抉择中的计算机科学）”。主播段天霖告诉我们，在杜克大学和斯坦福大学等学府的统计学和计算机系，这本书几乎人手一本，是一本难得引人深思的好书。 在这个新的栏目里，我们将从这本书出发，探讨算法和人生的关系。 当然，其中所涉及的并不只是计算机科学，它与数学、工程学、认知科学、心理学、经济学都通通相关。 本书的两位作者除了本专业，也都在这些方面各有建树：Brian Christian是位布朗大学计算机与哲学双学位毕业的作家和诗人，Tom Griffith则是斯坦福统计与心理学毕业的加州伯 克利教授，专攻computational cognitive science，计算认知科学。 不仅如此，这两位大神还专门找到当初设计这些计算机算法的科学家们，了解这些算法背后的故事。接下来的一段时间，我们将在这个新栏目中，跟随他们的脚步，探讨一些人类和计算机所共同面临的难题： 如何分配有限的空间、时间、注意力；如何应对不完整的信息和无限的未知...... 最后，希望这本书的旅程能让你我都能有所收获，并带着一种新的视角来审视取舍与抉择，这个人生中永恒的主题。  当然，我们也欢迎对这本书和我们的栏目感兴趣的读者，加入这个reading club，和我们一同阅读本书，发表你的评论，探讨相关话题。 回到今天的主题，科学松鼠会曾经举过这样一个颇符合今天气氛的有趣例子说明， 一位公主到了适婚年龄，要选驸马。 候选男子100名，都是公主没有见过的。百人以随机顺序，从公主面前逐一经过。对于每一位经过的男子，公主如果选他，其余那些还没有登场的男子就都遣散回家，选驸马的活动结束。如果不选，当下这名男子就离开，公主不可以反悔再从选。如果前99人公主都看不中的话，她必须选择第100名男子为驸马，不管他有多么丑陋。 当然，没有任何选择方法能够保证公主一定选择到最帅的帅哥。对于任何选择方法，总存在某些出场的顺序，让公主与帅哥错过。 因为并不是要讨论数学，这里就直接给出答案答案：最佳选法是 pass 掉最开始的 100/e 名男子（e = 2.718… 是自然对数，即 100/e 约等于 37）。但是记录下这 37 名男子中最英俊者。之后鱼贯而来的男子中，出现的第一位英俊程度超越所有前37人者，即为驸马。如果人都走光了，也没出现这么一位Mr. Right，那么就只好选择第100位男子。 这个最佳选法背后有很有意思的数学推导。感兴趣的话，可自行查阅。 我们究竟能不能用算法的力量锁定生命中的那个TA，到底人们在生活里会不会有意或者无意地运用这些最优策略来做出最好的选择呢? 点击 ，收听并订阅大数据文摘的喜马拉雅专栏，我们会在音频中告诉你答案。 如果你想要加入我们的读书会，和我们一起阅读探讨这本书，我们希望你： 1、有还不错的英文水平： 这本书目前在国内还没有正式的中文译本，所以我们的阅读以英文原著为主； 2、对阅读和表达有热情： 我们会规定一个固定的时间段（通常是一周时间）与大家分享一个章节，并要求你在固定的时间之前，在群里表达相关心得（可以是读书笔记、思维导图、甚至一段语音）； 3、对自己有一定的要求： 每个群限额50人，无法按期完成阅读量或不及时反馈的读者将被清除。 如果读到这里，你依然对这本书以及我们的节目充满期待，那么欢迎扫描二维码，添加 ai_learner 好友，备注“ ”，加入我们。大数据文摘和我们的主播一起陪大家度过一个有温度的春节假期。 Have a great data! 回复 “ ”加入我们 
141,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657196&idx=3&sn=8eb06d3d03eeb81418184be438a6c51d&chksm=bd4c347f8a3bbd6938a64b6035805ba1ba06707e8d79f7c1c0e5faa4f084198dc578e68c14b3&scene=27,AI大事件丨Paige.ai斥资将机器学习带入癌症病理学，TensorFlow 1.6.0（RC0）发布,"大数据文摘作品 作者： 呜啦啦啦啦啦大家好呀，又到了本周的AI大事件时间了。过去的一周中AI圈都发生了什么？大佬们互撕了哪些问题？研究者们发布了哪些值得一读的论文？又有哪些开源的代码和数据库可以使用了？文摘菌带你盘点过去一周AI大事件！ 新闻 人工智能和深度学习的局限性 来源： WWW.WIRED.COM 链接： https://www.wired.com/story/greedy-brittle-opaque-and-shallow-the-downsides-to-deep-learning 深度学习的进步是模式识别的产物：神经网络记住事物的类别，并在下次遇到它们时，或多或少地能够可靠地识别它们。但是大多数有趣的问题根本不是分类问题。 Lightmatter目标通过光子计算和1100万美元的资金重新发明人工智能芯片 来源： TECHCRUNCH.COM 链接： https://techcrunch.com/2018/02/05/lightmatter-aims-to-reinvent-ai-specific-chips-with-photonic-computing-and-11m-in-funding/ Lightmatter是一家创建光子芯片的公司，它主要以光速进行计算。它直接与GPU制造商和定制的深度学习芯片竞争。 Paige.ai斥资2500万美元将机器学习带入癌症病理学 来源： TECHCRUNCH.COM 链接： https://techcrunch.com/2018/02/05/paige-ai-nabs-25m-inks-ip-deal-with-sloan-kettering-to-bring-machine-learning-to-cancer-pathology/ Paige.ai病理学AI引导，已经在A轮融资中获得了2500万美元，用于构建一个帮助理解癌症病理的系统。它拥有2500万份病理幻灯片以及与计算病理相关的知识产权。 文章&教程 熵，交叉熵和KL-散度简介 来源： YOUTU.BE 链接： https://youtu.be/ErfnhcEV1O8 熵，交叉熵和KL-散度经常用于机器学习，特别是用于训练分类器。在这个简短的视频中，您将了解他们来自哪里以及我们为什么在ML中使用它们。 IMPALA：DMLab-30中的可扩展分布式深度RL 来源： 链接： https://deepmind.com/blog/impala-scalable-distributed-deeprl-dmlab-30/ Deep Reinforcement Learning在一系列任务中取得了显著成功，从机器人技术的连续控制问题到围棋和Atari等游戏。迄今为止，在这些领域所取得的进展仅限于个别任务，其中为每项任务调整和培训了独立的代理。在这项工作中，研究人员探索在培训同一代理完成多个任务上挑战。 发现实体消歧的类型（OpenAI） 来源： BLOG.OPENAI.COM 链接： https://blog.openai.com/discovering-types-for-entity-disambiguation/ 通过让神经网络决定该单词是否属于大约100个自动出现的“类型”的一个的系统，用于自动计算出单词指的是哪个对象。 学习与强化学习交流入门 来源： WWW.WILDML.COM 链接： http://www.wildml.com/2018/02/introduction-to-learning-to-trade-with-reinforcement-learning/ 深度学习学术研究界在很大程度上离金融市场比较远。在这篇文章中，我认为培训强化学习代理在金融和加密货币市场进行交易可能是一个非常有趣的研究问题。 代码，项目&数据 Line：解释任何机器学习分类器的预测 来源： GITHUB.COM 链接： https://github.com/marcotcr/lime 这个项目是关于解释机器学习模型在做什么。它目前支持解释对表格或图像起作用的文本分类器和分类器的单独预测。 视频链接： https://www.youtube.com/watch?v=hUnRCxnydCc DMLab-30环境 来源： GITHUB.COM 链接：https://github.com/deepmind/lab/tree/mater/game_scripts/levels/contributed/dmlab30 DMLab-30是为DeepMind Lab设计的一组环境。这些环境使研究人员能够单独或在多任务设置中为大量有趣的任务开发代理。目前已发布28个级别。 在Google表格中构建深度神经网络 来源： TOWARDSDATASCIENCE.COM 链接： https://towardsdatascience.com/building-a-deep-neural-net-in-google-sheets-49cdaf466da0 在Google表格中实现卷积神经网络。网络将手写数字分类,直观了解CNN过滤器如何工作的好方法。 TensorFlow 1.6.0（RC0）发布 来源： GITHUB.COM 链接： https://github.com/tens orflow/tensorflow/releases/tag/v1.6.0-rc0 新功能包括从Estimators中导出已删除的SavedModels，并将新增的FFT支持添加到XLA CPU / GPU中。 Have a Great Definition "
142,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657145&idx=2&sn=86f485b7b6e4532e2f0780e7bea4ee40&chksm=bd4c342a8a3bbd3c6d16181032e7cded8b4bb53bd5b6ac1e9d4bb35138c4cc64a2bbc0edb488&scene=0,李飞飞计算机视觉成名作：斯坦福CS231n作业详解第三弹！,大数据文摘作品 学习斯坦福CS231n公开课的同学看过来，Assignment 1 - 3 的详解全部出炉啦！ 昨天，大数据文摘发起了 ，然后大家参加 活动的热情异常的高！文摘菌在拉小伙伴入群的过程中已忙疯~有图为证： 我们的读者朋友也是很可爱啊 此次#春节打卡#的主打课程之一就是《斯坦福李飞飞-深度学习计算机视觉》，其中包括了三个 Assignment 而且难度系数较高，大数据文摘邀请了一批志愿员整理了课程作业的完整笔记，帮助大家更好的理解课程内容，再次感谢我们可爱负责的志愿者！ 临近年关，为了让大家渡过一个充实的年假，我们志愿者和编辑团队加班加点终于完成了Assignment 3 的Q1 - Q5的详解，主要内容如下： Q1：介绍了训练一个递归神经网络（Recurrent neural networks）来生成一个图片的文字注释 (captions)。 Q2：介绍了用以长短时记忆单元（Long-short term memory，LSTM）为基础的递归神经网络来完成 Q1中的任务。 Q3：介绍了探索图像梯度对于生成新图片的用法 Q4：介绍了实现图片风格迁移的技巧 Q5：介绍了如何构建模型来生成新的像训练集中的图片 Assignment 3 中部分精彩内容如下： 最后，让我们感谢参与本次作业编写的志愿者，是你们无私的付出，让更多读者可以享受这一成果。 当然，如果还没参加#春节打卡#的小伙伴 欢迎加入！ 参与方式： 扫码添加 ai_learner 好友 备注“吴恩达打卡”参与《Deep Learning Specilization》课程打卡； 备注”李飞飞打卡”参与《CS231n：Convolutional Neural Networks for Visual Recognition》课程打卡； 加入小组群，领取文摘君为大家精心准备的学习资料！ 如果希望能组织、督促并激励所在群的小伙伴一起学习，并拿到本组的运营志愿者薪酬（320元），也请在申请时一并说明哦！ 三期作业笔记获取链接： 大数据文摘网易云课堂专栏： https://study.163.com/provider/10146755/index.htm 大数据文摘CSDN专栏： http://blog.csdn.net/BigDataDigest 大数据文摘GitHub专栏： https://github.com/theBigDataDigest/Stanford-CS231n-assignments-in-Chinese Assignment 3 参与成员： 编写： 张礼俊 、SlyneD 校对： Molly 总校对与审核： 寒小阳 【今日机器学习概念】 Have a Great Definition 
143,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657179&idx=2&sn=aee5dc8150d8847594409853cb8250f7&chksm=bd4c34488a3bbd5e3fe39efec0f78cdedf858bea7205a81dca5b9ee75f6b0a14d3a97ea1d710&scene=0,买一送三 | 双节限时钜惠，《数据科学实训营第5期》再次升级！,直播课程5 ：matplotlib与seaborn技能大全(上) 实战辅导5：Titanic/航班数据的可视化练习， 对pandas分析得到的链家网数据，做可视化 直播课程6：matplotlib与seaborn技能大全(下) 实战辅导6：Bokeh与Bokeh server地图可视化 直播课程7 ：机器学习起步：概念、流程、算法一览与sklearn 实战辅导7：完成经典Titanic分类问题，完成自行车租赁回归问题机器学习建模 直播课程8 ：机器学习算法应用进阶 实战辅导8：完成Kaggle比赛数据分析与建模参数选择、效果评估 直播课程9 ：模型优化与模型融合 实战辅导9：用模型融合完成Titanic分类问题的建模优化，完成天池AI电力预测大赛机器学习建模优化 直播课程11：Hadoop与Map-Reduce 实战辅导11：MIT/麻省理工map-reduce作业，互联网公司面试的Map-reduce题目，电商大数据map-reduce统计 直播课程12：Spark大数据处理与Spark SQL 实战辅导12：Spark维基百科数据分析，Spark进行stackoverflow数据分析 直播课程13：Spark大数据机器学习 实战辅导13：一起来打怪之Spark机器学习案例 完成实训营5期的学习全流程，你将掌握数据科学的核心技能，具体为以下几点： 邮箱存满了学员作业与助教批改回复的邮件 4180元 【今日机器学习概念】 Have a Great Definition 
144,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657179&idx=1&sn=5a627b1bc21e8f887fbec0921609472a&chksm=bd4c34488a3bbd5e21382acbdbe99b5d1ca071f18658833e9891d9a8620ef7b8d0903e60a525&scene=0,谷歌开放TPU！与Tensorflow软硬联合，或将占独家地势,作者：钱天培、小鱼 就在刚才，Google宣布TPU测试版对外开放！ 9个月前，Google在I/O大会上揭开TPU的神秘面纱。 （点击查看大数据文摘相关报道） 当时，仅有极少部分开发者有幸能够一探其究竟。而从今天起，所有开发者都可以在Google Cloud Platform试用云端TPU！ 据Google称，每个云端TPU都由四个定制的ASIC构成，每个板卡可以提供高达180 teraflops的浮点性能和64 GB的高带宽内存。作为对比，目前市面上广泛试用的英伟达Tesla P100 GPU性能则为每秒21 teraflops，即便是最新发布的V100也只是刚刚突破100 teraflops的大关。 TPU全称为Tensor Processing Unit。一如其名字所示，这款芯片是专门为加速Google的机器学习开源软件Tensorflow所设计。 不出意料，今天发布的这款TPU实现了与Tensorflow的无缝融合。 几乎无需改动，Tensorflow的代码就可以被TPU加速运行。此外，Google也开源发布了几款图像分类、物体识别和机器翻译的高效模型，包括ResNet-50、Transformer和RetinaNet。只需提供数据，这些模型可以使用TPU在Tensorflow上即刻运行。 Google TPU的对外开放进一步表明，包括Google、Microsoft和Amazon在内的互联网巨头早已摇身一变，成为了硬件大佬。如今Amazon有AWS，Microsoft手握Azure，谷歌此番让TPU和Tensorflow软硬联合，或将突破重围，占据独家地势。 Google Photo已经可以通过机器学习把照片根据人物，地点，时间进行分类。一个很方便的新增功能是你可以让谷歌自动把你想要分享的照片发送给你指定的人。比如你可以设置把每一张你所拍摄的你家宝宝的照片自动发送到你老婆的Google Photo照片库里。 今天起，谷歌TPUs beta版在谷歌云平台开源，以帮助机器学习专家更好地训练和运行机器学习模型。 云端TPU是Google设计的硬件加速器系列，为加速、扩展特定的TensorFlow机器学习工作负载而优化。 每个云端TPU都由四个定制的ASIC构成，每个板卡可以提供高达180万次的浮点性能和64GB的高带宽内存。  这些主板可以单独使用，也可以通过超快专用网络连接在一起，形成所谓的“TPU pod”的机器学习超级计算机。今年晚些时候，谷歌将在GCP上供应这种大型超级计算机。 谷歌设计云端TPU的目标，是为TensorFlow工作负载提供更高质优惠的差异性能，并使机器学习工程师和研究人员能够更快地迭代学习。  例如： 无需使用共享计算机群集完成任务，使用者可以通过控制并支持自定义的Google Compute Engine虚拟机，访问连接网络的云端TPU。 ﻿与其等上几天或几周来训练业务关键的ML模型，使用者可以在晚上通过Cloud TPU上训练同一模型的一系列变体，并在第二天部署生成的、最精确的训练模型。 使用单个云端TPU并按照本教程，使用者可以在不到一天的时间内将ResNet-50训练到ImageNet水平的预期准确度，而且费用不到200美元！ Google Photo已经可以通过机器学习把照片根据人物，地点，时间进行分类。一个很方便的新增功能是你可以让谷歌自动把你想要分享的照片发送给你指定的人。比如你可以设置把每一张你所拍摄的你家宝宝的照片自动发送到你老婆的Google Photo照片库里。 过去，为定制ASIC和超级计算机编写程序需要深入的专业知识。 相比之下，使用高级版TensorFlow API可以编程云端TPU，并且，谷歌也开源了一套参考高性能云端TPU模型实现，可以立刻上手： 运行ResNet-50和其他流行的图像分类模型 实现机器翻译和语言建模的变换 利用RetinaNet进行对象检测 为了提高性能，谷歌不断测试这些模型实现的性能和收敛性，以达到标准数据集的预期精度。 随着时间的推移，我们将开放源代码模型实现。 Adventurous ML专家可以使用谷歌提供的文档和工具，自行优化其他云端TPU中的TensorFlow模型。 如果现在开始使用云端TPU，当谷歌在今年晚些时候推出TPU pods时，使用者可以从时间以及精确度的改善中受益。 正如在NIPS 2017上宣布的那样，如果ResNet-50和Transformer训练的好的话，可能要花费一天时间，而现在使用TPU pods训练时间到不到30分钟，而且无需更改代码。 领先的投资管理公司Two Sigma对Cloud TPU的性能和易用性印象深刻。 “我们决定将我们的深度学习研究集中在云端的原因有很多，但主要是为了获得最新的机器学习基础设施，Google 云端TPU技术不仅新颖而且发展迅速，而且支持运行深度学习算法，我们发现将TensorFlow工作负载移至TPU，可大大降低编程新模型的复杂性以及训练它们所需的时间，从而提高了我们的工作效率。使用云端TPU让我们能够专注于构建模型，而不会被管理集群通信模式的复杂性分散注意力 。”——Two Sigma首席技术官Alfred Spector Google Photo已经 可以通过机器学习把照片根据人物，地点，时间进行分类。一个很方便的新增功能是你可以让谷歌自动把你想要分享的照片发送给你指定的人。比如你可以设置把每一张你所拍摄的你家宝宝的照片自动发送到你老婆的Google Photo照片库里。 云端TPU还对规划和管理ML计算资源进行了简化： 使用者可以为自己的团队提供最先进的ML加速，并根据需求动态调整容量。 无需担心设计所需要投入的资本、时间和技术，也无须担心安装和维护在线ML计算集群的专门电源、散热性能、网络链接、存储要求和所需的资金，使用者可以从谷歌多年来大量优化的、大规模紧和密集成的ML基础设施中受益。 再无需让司机费力更新大量的工作站和服务器集群。 云端TPU已经进行了预先配置 - 也无需安装驱动程序！ 使用者受到和Google Cloud服务的同样复杂的安全保护机制。 “自从使用Google 云端TPU以来，我们对它们的速度和印象都非常深刻——通常需要几天的时间才能做完的事情，现在可能需要只需要几个小时。 深度学习正迅速成为自动驾驶车辆软件运行的中坚力量。 随着训练数据的不断增加，软件运行结果会变得更好，并且每周都有重大的突破。现在，云端TPU通过整合来自我们车队的最新导航相关数据和研究界最新的算法，帮助自动驾驶行业的迅速发展。”—— Lyft L5 自动驾驶软件主管Anantha Kancherla 在Google Cloud上，我们希望为客户提供每个ML工作负载最适合的云端TPU，并提供各种高性能CPU（包括英特尔Skylake）和GPU（包括NVIDIA Tesla V100）。 Google Photo已经 可以通过机器学习把照片根据人物，地点，时间进行分类。一个很方便的新增功能是你可 现在因为云端TPU的数量有限，谷歌以秒计费，费用为6.50美元/TPU /小时。 原文链接： https://cloudplatform.googleblog.com/2018/02/Cloud-TPU-machine-learning-accelerators-now-available-in-beta.html 【今日机器学习概念】 Have a Great Definition 
145,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657145&idx=1&sn=017e4c2727ec1abc627752c625d0de13&chksm=bd4c342a8a3bbd3c939337cbd09ff5d8100c3b973ffc560e90cd1182568d35a7f3f667c4e690&scene=0,坐拥独家数据，亚马逊的广告之道,大数据文摘作品 编译：HAPPEN、 大饼、刘涵 亚马逊广告业务推出已有十年之久，并没有带来多少收入，也没有得到很多关注。而广告巨头 与谷歌、Facebook相比，亚马逊掌握的数据具有自己别具一格的不同之处。 而坐拥这一独特性，其在广告上也有着和这些搜索、社交巨头完全不同的玩儿法。   亚马逊并未单独披露过广告业务的业绩，但是根据 J.P. Morgan的最新报告，2017年亚马逊的广告收入预计将达到28亿美元，   广告公司 WPP 的创始人兼首席执行官 Martin Sorrell 估计该公司2017年在亚马逊上投放的广告支出将达到2亿美元 亚马逊拥有竞争对手无法触及的数据   亚马逊广告业务的成功直接得益于其零售业务。Cadent咨询数据显示，目前大众消费者品公司在数字广告上的花费已经全面超过非数字广告。 Google搜索广告业务存在的前提是 ——消费者在搜索其计划购买的商品时会点击相关的广告并进行购买。这使得Google有海量的用户搜索和历史浏览的记录数据。 可以让广告主将用户的社交图谱与其他数据结合起来，记录下来我们曾经去过的地方以及我们曾经购买过的商品。   亚马逊对全球零售商的威胁显而易见， 但其不断增长的广告业务对谷歌和脸书这两家巨头的威胁，才刚刚被股票分析师和广告公司们意识到。   智能手机屏幕上展示的亚马逊的广告    亚马逊拥有大量Facebook和Google无法访问的数据——即它本身的数据。 根据各种调查显示，现在超过半数的在线产品搜索是直接从亚马逊开始的，其中有很大一部分也在亚马逊结束（搜到了自己想要的结果）。调查还追踪到了这个数字每年都在增长的趋势。   试想一下，如果有一天亚马逊不仅是美国最大的线上零售商，而且也是最大的线下零售商，销售比沃尔玛更多的产品，拥有比Google和Facebook还要多的数据，到时候会发生什么？   这种搜索是如何运作的   数以千计大大小小通过亚马逊卖家平台进行销售的品牌，正在促进亚马逊广告收入的快速增长。 成立于2013年的Jijamas品牌的联合创始人兼首席执行官Gustavo Sanchez说：没有亚马逊，就不会有Jijamas。   Jijamas只卖一件东西：超级柔软的高档女士睡衣。   Sanchez表示，亚马逊的算法会倾向于推荐便宜、量大的商品，而他们的产品最低也要卖70美元，所以几乎没可能出现在亚马逊上“睡衣”搜索结果的前面，就算是有大量客户好评也没用。   Sanchez说：公司的收入增长依赖于在亚马逊上做广告。   Jijamas 是一个高端睡衣品牌，其收入增长几乎全部取决于亚马逊。图为该品牌的联合创始人兼首席执行官Gustavo Sanchez   Quartile是一家去年八月份开始运营的只做亚马逊业务的小型广告代理公司，其首席执行官Daniel Knijnik表示，亚马逊的广告跟Google AdWords平台上的广告差不多，大部分广告显示在关键字搜索结果的顶部。   广告在亚马逊平台中扮演重要角色。亚马逊平台也为第三方卖家提供仓储物流服务并收取额外费用。Knijnik表示，因为广告可以让品牌和消费者更好的连接在一起，之前那些批发给亚马逊的制造商们现在也在网站上开设自己的“店铺”了。   对于Sanchez这样的卖家来说，在亚马逊上打广告有好处也有坏处。   在亚马逊平台上销售，Sanchez要支付商品价格的15%作为上架费，5%到6%作为亚马逊的仓储物流服务费，还有12%是亚马逊的广告费。从今年4月开始，亚马逊将对服装类目额外收取2%的上架费（亚马逊并未透露原因）。也就是说，Jijamas通过“赞助”列表卖出的每套睡衣，都要缴纳售价的35%给亚马逊。   如果亚马逊改变搜索排名算法或者提高广告费，“我也没办法”，Sanchez 表示。他又补充到，亚马逊占其销售总额的65%，其余35%来自他自己的网站。     亚马逊正不断的建立以及购买有关我们喜好和消费行为的数据，包括收购Whole Foods、扩建无人便利店Amazon Go、推出低成本的声控音箱、以及快速扩充其流媒体视频库。   在总额5万亿美元的美国零售市场上，每当亚马逊占比增加一个百分点， Google和Facebook就丧失这500亿美元对应的数据。而且，亚马逊对消费者的了解程度是Google和Facebook无法做到的。   WPP旗下广告公司Mindshare的专注电商业务的子公司Shop+的董事Diana Gordon说：“亚马逊不仅知道你想买什么，他们也知道你怎么买。”她补充道：“他们知道你浏览了什么，以及你复购某类消费品的频次。”   亚马逊的征程不止于此 亚马逊不仅在建立自己的广告业务，也在打造销售团队，以便用于网罗各大品牌。   所有这些都可能使亚马逊获得与Google和Facebook的比较优势，但是为了扩展其业务规模，它必须将眼光放高一些，而不能仅限于针对那些已经在亚马逊上购物的消费者投放广告。   亚马逊跟Google和Facebook一样，都拥有一个覆盖整个互联网的广告网络，这就是为什么一个你差点儿买了的吸尘器广告会在几周内不断出现在你随机浏览的其他网站上的原因。 就跟Google DoubleClick一样。   亚马逊不仅在建立自己的广告业务，也在打造销售团队用于网罗各大品牌。图为亚马逊的创始人Jeff Bezos   亚马逊仍需要扩张其可以发布广告的场所，   该公司一直都在其投放广告的场所上富有创意。不知道各位是否注意到亚马逊快递包装盒上印有一些电影的广告？说不定到了未来，亚马逊还会通过Alexa的播客服务提供音频广告业务。又或者哪一天，送货无人机可能对感到恐慌的民众播放最新的打折信息。   原文链接： https://www.wsj.com/articles/how-amazons-ad-business-could-threaten-google-and-facebook-1517157327 【今日机器学习概念】 Have a Great Definition 
146,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657132&idx=2&sn=1311d92cd8ea897dbcb07daf938b1d03&chksm=bd4c343f8a3bbd29ec434c399a9fe303ed3bc4bd96203c8420b2f41a16af6fcb107380a39599&scene=0,吴恩达李飞飞课程打卡召集令：2018我们一起变成更厉害的人！,年假前最后一周，除了期待一顿丰盛的年夜饭，还要做好被热（xia）心（cao）肠（xin）的亲戚关心的准备：有没有对象啊？存了多少钱啊？什么时候买房啊？ 躲在房间里避开熊孩子的时候，大数据文摘帮你组织了一个拯救自己的大好机会。 在2月份，机器学习课程圈发生了两件大事： ，全部课程完结，喜大普奔；而在大数据文摘志愿者们的努力下，斯坦福李飞飞教授的计算机视觉课程CS231n也全部汉化完成（包括课程和 ）。 很多同学在大数据文摘后台留言表达了积极的学习热情，同时也表示，自己学课程很难坚持下去，希望寻找志同道合的小伙伴或者大咖，互相搀扶一起学习。 在这里统一回复：大家的呼吁文摘菌都收到啦！我们也在努力探索，希望组织大家一起打怪升级。 在春节7天年假期间，无比热爱工作的大数据文摘，成立了吴恩达 和 两个学习社区，希望跟大家一起，在春节期间开启一场机器学习的课程。 当然，春节加班的文摘菌也希望大家的学习可以真的有效率，所以社区内会有严格的打卡制度，奖惩机制。 看到这里，如果你还是想要逼自己一把，可以接着往下拉了解如何参与。 CS231n和DeepLearning都是声名赫赫的明星课程。如果不曾刷过，简直不足以谈Machine Learning呢。 两门课程内容都非常丰富，学习过程中难免会产生携带情绪和各种问题。 SO！文摘菌想到了既能缓解压力，又能督促学习的办法——分批打卡学习课程。 此次#春节打卡#活动持续时间为：春节7天年假，即2018年2月15日—2018年2月21日。 每天至少完成规定视频内容的学习，并记录【学习笔记】，笔记形式、内容不限 每天建议学习时间：1个小时-1.5个小时 每个微信群限额20人，每名参与者缴纳66元人民币 16元用于交付运营志愿者的组织与记录 50元加入奖金池 坚持完成7天打卡的学员，均分微信群内所有奖金（20人一个群，每群奖金池1000元） 深度学习概论 约 60 分钟 神经网络基础 约 180 分钟 浅层神经网络 约 120 分钟 深层神经网络 约 80 分钟 图1 吴恩达《深度学习工程师》学习计划 计算机视觉历史回顾与介绍（上） 27:29 计算机视觉历史回顾与介绍（中） 21:28 计算机视觉历史回顾与介绍（下） 25:46 数据驱动的图像分类方式： K 最近邻与线性分类器（上） 29:35 数据驱动的图像分类方式： K 最近邻与线性分类器（下） 28:57 线性分类器损失函数与最优化（上） 36:30 线性分类器损失函数与最优化（下） 35:50 反向传播与神经网络初步（上） 40:59 反向传播与神经网络初步（下） 40:42 图2《斯坦福李飞飞-深度学习计算机视觉》学习计划  没有基础但对机器学习感兴趣的小白 我们推荐吴恩达《深度学习工程师》课程 欢迎提出学习中的问题，可以和社区学习成员讨论 有一定基础还想提升自己的有志青年 我们推荐《斯坦福李飞飞-深度学习计算机视觉》课程 欢迎提出学习中的问题，可以和社区学习成员讨论 参与方式： 扫描二维码，添加ai_learner好友 备注“吴恩达打卡”参与《Deep Learning Specilization》课程打卡； 备注”李飞飞打卡”参与《CS231n：Convolutional Neural Networks for Visual Recognition》课程打卡。 加入小组群，领取文摘君为大家精心准备的学习资料！ 如果希望能组织、督促并激励所在群的小伙伴一起学习，并拿到本组的运营志愿者薪酬（320元），也请在申请时一并说明哦！ 嗯！快情人节了，如果您有交友诉求，可以一并回复您是什么样的小哥哥or小姐姐，希望和怎样的小伙伴一起打卡。文摘菌努力一把做红娘！(: 古人曰，士别三日，当刮目相看。如果过年不学习，年后上班可能会被吐槽：过个年你变化挺大，看上去像肿了一样。 别打我，群里见！ 课程学习链接： 吴恩达《深度学习工程师》 https://study.163.com/course/introduction/1004570029.htm 《斯坦福李飞飞-深度学习计算机视觉》 https://study.163.com/course/introduction/1003223001.htm 【今日机器学习概念】 Have a Great Definition 
147,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657132&idx=1&sn=f19da5e121aedf4dbf94ad4abf7eb3ee&chksm=bd4c343f8a3bbd29549c687327f940e00443d0b2aa480d28d9fd59f6b0588e282bd4f029098f&scene=0,我为什么说中国的区块链市场被严重低估了,"大数据文摘作品 编译： 修竹、朝夕、叶一、笪洁琼、Yawei Xia 对于虚拟货币市场，2018年的开场颇为动荡，对于中国尤为如此。 本文作者是美国一位区块链资深投资人和知名科技专栏作家，他认为，中国很多优质的区块链项目被低估了。 尽管存在政策禁锢，但长期来讲，技术优势加集中的社会资源，都为中国在区块链行业成为发力提供了优质条件。 回归价值投资的核心方法论，我们该如何看待这波乱潮？这些值得我们关注的中国区块链项目到底想解决现实世界中的什么问题？ 现在区块链市场就像开荒前的美国西部，似乎每天都能发现几十个新的项目。 coinmarketcap.com上有1426种币或代币的项目（我开始写这篇文章的时候又增加了36个），到底要选择哪一种？ 大部分人都选择了以下三种途径。 一 比如比特币(Bitcoin)、莱特币(Litecoin)、达世币(Dash)和以太坊(Ethereum)。这是像指数基金一样的加密投资。他们的资产可能会随着市场的增长而增长，同时有望回报颇丰。如果你想接触一下加密货币但又不想太耗费时间，你可以选择这个做法。 但是多数人想要的更多，市场发展如此迅速，以至于几乎每周都有另一个项目价值骤涨。FOMO(Fearing of missing out，害怕错过)是站在场边看着代币大涨的人们内心的真实感受。 因此，许多人都选择第二种途径：在Reddit和Twitter上闲逛，关注大家的评论并且试图抓住下一个会声名远扬和发家致富的“财富瓶”。 也就是想在下一种币价值彻底爆发前买入。这么做也没什么错，而且有时候也有用。 但是这种途径有用的原因是因为市场实在不按常理出牌。市场会被舆论影响。这些在Reddit上评论的人，他们其实不一定比你多知道什么趋势内幕。之所以有时候能从“假象”中获益，是因为有大群的人在跟你做一样的事情。如果有足够多人的突然想买一种代币，那这个代币就会突然爆发。 这就是为什么约翰·迈克菲(John McAfee)可以影响市场，为什么杰米·戴蒙(Jamie Dimon)的评论可能让比特币暂时崩溃。 但是第三种选择才是真正的“好的投资”，这种选择做的就是跑腿活，一直读、重复读和反复读，直到找到被低估的项目，然后在所有人开始讨论它之前投资。 听起来很简单，但是肯定非常不容易，所以很多人并不会这么做。 我发现了一个我认为被低估了的市场—— 在这篇文章中，我将阐述并论证这一论点，并且介绍一些我认为有潜力的项目。 同时我也想介绍一下中国区块链市场，我们对一些西方的大玩家很熟悉：Y-Combinator，美国运通(American Express)等等。像这些大玩家宣告入场时，他们肯定会持有一定份额。虽然西方大多数人并不熟悉，但是中国同样也能持有这么多份额。因此，想要在这个领域有效评估项目，我们首先需要充分了解这个领域。 我在这篇文章中强调了为什么我认为下一个市场大爆发将发生在中国。接下来我所陈述的也将呼应这一观点。 从政治角度上来讲，中国正在以一个超级大国的姿态挑战美国的地位。中国国内生产总值（GDP）增长速度位居全球第14位（6.7%，与美国1.6%相比），GDP仅次于美国。这里想强调一点，我明白GDP不一定是衡量经济实力或潜力的最佳指标，但在这个话题中它足以说明中国在世界上的经济地位。不管从跨太平洋伙伴关系协定（TPP协议）中退出是否符合美国最佳利益，但中国已然从中获益。庞大的劳动力和宽松的规章制度使得中国能有快速有效的利用新的经济机遇。他们在可再生能源上的成就证明了这一点，虽没有以环境意识著称，但是中国现在是世界上最大的可再生能源投资国。 另外，中国的政治结构意味着发展可以快速发生，带领世界可再生能源的进程。不像美国，总需要平衡势力、向各党派谈判协商以至于延误发展的时机。 我还认为区块链将是中国的下一个大机遇。正如我在讲NEO的文章中所说：中国知道区块链将会造成很大的影响，中国发布的 也说明了这一点。 中国显然已然意识到区块链的潜力。如果他们不了解区块链的重要性，他们也没有必要去禁止。正是因为中国明白，所以他们现在禁止是为了未来可以掌控，他们也一定会去掌控。他们需要时间展示自己的力量、增强实力并制定一个计划来决定何时推进、如何推进。 新加坡已经接受了区块链，同时也证明了确实对经济有潜在影响。新加坡意识到区块链和加密货币会破坏现有产业并取代目前就业岗位，但是新加坡认为这种破坏并不是造成失业，而是就业机会的重新集中。一些行业将会受影响，但是新兴企业最终会从中获益，砍掉中间商，刺激经济增长。 当中国明确了计划，他们很可能成为区块链技术的世界领先国家。我们可以拭目以待。 在中国，我们已经发现了一些新兴的区块链公司和项目。 我认为主要有两个原因导致这个行业被低估。 第一，我认为人们不仅低估了中国进入这个行业后会拥有的能力，也怀疑中国是否会进入这个行业。 这么想也没什么问题，但是我坚信我以上的分析，中国会成为大玩家。因此，我认为现在有机会从大家的犹豫不决中获利。 其次，许多项目有出色的团队和强大的技术，在全球区块链市场上都有很重要的应用。 部分原因是由于他们不从能美国筹集资金，所以在开始只能专注于亚洲市场。因此，大多数西方国家对这些公司一无所知。没有公开的资料，如果不是跟这些团队直接联系的话，很难有效理解这些项目。然而，这些项目的主创人员也意识到了他们的困境并努力提高西方营销方案。想想品牌重塑前的NEO，那时他们叫小蚁(AntShares)。 回顾以上两个因素，对西方营销的缺乏以及对中国不确定性的担忧使得人们不能准确评估市场。结合中国很快开放区块链的事实——我认为这些公司肯定会改进营销策略（他们已经这么做了）。我认为同时我们也有了一个机会，一个在开始就抓住被低估市场的机会。 中国和西方区块链项目的发展截然不同。在西方，早期营销是必不可少。只有在筹资、营销、发展之后，项目才能向投资者和企业开放。因此自然而然会把重点放在营销上。这就是为什么弗洛伊德·梅威瑟（Floyd MayWeather）的支持有这么大影响力。 但是在中国则相反，筹资机制非常不同。中国区块链团队与强大的CEO们以及传统风险投资公司联系来筹集资金。而且由于筹资方式的不同，营销的重要程度大大降低，技术和产品设计的重要程度提高。风投对市场营销不怎么关注，但是很看中底层基础技术。从本质上来讲，这些项目得到机构的支持，然后开发出有竞争力的产品，再去关注于市场营销。这是一个自上而下的方法，而不是自下而上。 由于这些不同，中国项目的投资人和赞助商就能充分反映这些项目的潜力。 所以，了解一下中国的“大人物”是很重要的。这里包括主要投资公司、孵化器、企业和平台。 GBIC (Global Blockchain Innovative Capital) GBIC是全球区块链项目的孵化器，他们用人力资源、市场营销、公共援助、关系网和发展资源来支持他们的投资项目。他们的关系网包括许多国际投资者和交易所。GBIC投资的项目包括Nebulas，深脑（DeepBrain），万物链（IoT Chain），Aelf，Eximchain，智品链（Zeepin）和WePower。 Fenbushi Fenbushi是一家投资区块链项目的中国风险投资公司，Vitalik Buterin（V神，以太坊创始人）是Fenbushi的普通合伙人。他们最好的投资是 TenX, Factom, SiaCoin和 ZCash。 Link VC 另外一个实力雄厚的新加坡风投公司。他们投资了TenX， Quoine, Raiden Network和万物链（IoT Chai，见下文）。 FBG Capital (Fintech Blockchain Group，金融科技区块链集团) FBG资本是新加坡一家基于区块链和数字资产投资的公司。FBG资产在亚洲区块链行业拥有举足轻重的地位。得到这家公司的支持是非常重要的一票，他们投资的项目包括ADEX, Zilliqa, IoT Chain, Aelf, LoopRing和Nebulas。他们为项目提供战略价值，正如CBIC的Richard Lee所说：“他们的关系网包括全球加密领域的顶级基金、交易所和主要投资者/影响者”。 BAT：百度-阿里巴巴-腾讯 这是中国最强大的三家公司，拥有众多的支持和资源。 复星集团（Fosun Group） 中国最大的私人投资集团之一。他们投资过分布科技（OnChain）。 巨杉数据库SequoiaDB 巨杉数据库是中国接触的大数据管理者，他们可以用在企业的大数据集成、存储和管理上。 比特大陆（BitMain） 中国最大的矿机开发者之一。他们有巨大的投资能力，主要投资投资亦来云（Elastos）。 NEO委员会 真正有意思的是中国区块链行业内合作者以及相互合作的数量。 NEO的委员会建议在NEO上开发分布式应用程序（dApps ）； 开发者从一个项目跳到另一个项目；分布科技（OnChain）和NEO合作紧密。我对此的看法是，它与NEO实现智能经济的愿景是一致的。NEO的委员会知道NEO只能是这个组成中的一部分。多种应用程序、协议和平台必须共存-相互连接和相互操作；这将使包括数字资本和身份在内的智能经济的所有方面成为可能。NEO了解为实现智能经济所需要的技术，因为，他积极支持愿意促成这一愿景的项目。NEO委员会的投资表明，项目是更大智能经济生态系统的一部分；这在我看来是非常宝贵的。分布科技（OnChain）和NEO致力于开发支撑更大生态系统的产品。他们拥有非常强大的资源并为他们的项目大力支持。 分布科技 简而言之，NEO的创始人达鸿飞和Erik Zhang创建了一家叫做分布科技（OnChain）的公司。 NEO和分布科技（OnChain）并不是同一家公司，但是他们的关注点一致并且有合作关系。分布科技的系统被称之为DNA（分布式的网络架构）旨在同中国企业和政府合作。而NEO是DNA协议的先驱。 最终DNA会为商业活动提供公有链、私有链和联盟链等业务。这些区块链业务会接入到NEO并参与到分布式的经济形态中。商业活动可以享有私有链和公有链的所有好处。可以想象Neo作为基础的公有链，分布科技作为它的企业级区块链副本（比如让大的商业活动在区块链上运行的方法）。这样结合起来享受两种模式的优点。 QTUM（量子链） 作为NEO的竞争对手，QTUM（量子链）也是在中国发展起来的区块链平台。QTUM在结合以太坊和比特币的技术的基础上插入自己的技术，采用了比特币的安全机制同时使用虚拟机和定制化区块链来实现类似以太坊的智能合约和分布式应用。和上面介绍的NEO类似，一旦得到QTUM的支持，意味着项目将支持更大的生态系统。 罗格•林 罗格•林是非中国籍最有影响力的顾问和投资者之一。 我认为NEO和QTUM都将从未来中国区块链的发展中获利。特别是NEO在这个领域里同其他平台相比被严重低估。这方面我已经写过很多文章，这里就不炒冷饭了，如果对NEO的评论感兴趣的话可以参阅这里。 正如布拉德劳丽所说，评估一个项目最有效的办法是，首先看它的技术和协议，然后看团队和合作伙伴，再看应用以及和真实企业和商业的关联程度。 APEX 代币代码：CPX 简介 ：APEX是Chinapex的项目，一家利用人工智能平台帮助企业收集和管理数据的公司。从根本上说就是帮助企业管理客户数据，目前Chinapex有超过200家企业客户。 为什么我觉得APEX是个值得关注的项目？APEX把数据的控制权还给了用户和顾客。与其控制和出售客户的数据，APEX想让用户自己管理并从共享数据中获益。在目前超过250多个客户中，32%的客户将会参与APEX上线的试运行。 假设你是一名用户，你可以同他们的应用交互，可以为想要共享的信息定价。这些信息将会进入智能合约，商业机构可以从这里购买这些信息。然后这些信息进入到APEX的商业平台上向公司提供先进的数据分析。 支持者： APEX和业内众多的知名企业建立合作关系，比如微软的Azure，亚马逊网页服务，阿里云，甲骨文云服务，百度，腾讯，分布科技以及NEO委员会。 西方的竞争者： Basic Attention Token（BAT）试图掌控大家的上网数据，但是这并不对APEX产生什么威胁。Datum绝对算是一个竞争对手，但是APEX是已经具备强大数据管理能力并且有几百个企业用户的公司产品，这绝对是个非常大的优势。 分析： 这些合作表明强大的企业支持。APEX和分布科技以及NEO的联系已经证明它将会成为未来智能经济的基础组成。 担忧： 所有这些平台想要取得成功的市场地位取决于他们有多少的用户。正如eBay不能没有买家和卖家一样。这是APEX所需要面对的。 路印协议 已经登录币安交易所——代币代码：LRC 简介： 路印协议是一个分布式的自动交易撮合协议，可以通过独特的“环”匹配系统实现智能交易。关键是这个环架构可以同时链接多个交易订单并同时处理。例如比尔想用REQ购买RLC，艾比想用POWR购买REQ，而丹尼想用RLC购买POWR。代替以往分步处理订单并且产生额外交易成本的模式，路印协议可以同时联系这三位买家同时处理他们的订单。 为什么我觉得路印协议是个好项目？它为区块链带来流动性和信任，为区块链和交易所之间提供信任撮合。因为交易是同时执行的，所以无需信任任何一方。如果我想买RLC，我可以同时买入RLC并卖出ETH。更长远的蓝图计划是，撮合交易在平台上能起到重要作用，比如NEO平台，为资产的安全和高效交换提供生态系统。 支持者： FBG资本、QTUM（量子链）基金会、NEO委员会、巨杉数据库 竞争者： 行业内路印协议有强大的竞争对手比如Kyber Network、ox和Bancor等交易协议。 分析： FBG资本为路印协议提供合法性和强有力的支持。QTUM和NEO都看到了路印协议对他们各自平台带来的信任和流动性，路印协议的技术很独特。 担忧： 自从在Coinmarketcap更新了流通市值，我认为该项目目前估值过高。734,089,390（流通量）×$1.43（代币单价）=10.49亿美元。我不认为现在是好的买入时机。 深脑链 已经登录酷币和火币交易所,代币代码：DBC 简介： 当今AI（人工智能）的发展需要大量的计算资源，会花费大量的金钱。深脑链使用分布式的计算能力来降低这个行业的成本和门槛。同时，深脑链还支持数据共享市场。隐私保护是这个平台最重要的考量，DBC（深脑链）预测将降低AI开发70%的成本。 为什么深脑链这个项目值得关注？深脑链为中国带来区块链网络的应用。很多项目都是奔着搭建生态系统而去，像这种专注具体应用场景的不多。 支持者： 最大的支持者是NEO委员会和达鸿飞的投资。业内的其他主要风投公司如戈壁合伙人、金沙江创投和科银资本等参投。 西方的竞争者： Singularity（奇点网络）是深脑的最大竞争对手。 分析： NEO的支持非常振奋人心；对我来说表明NEO对自己的生态系统和基础架构非常自信并且开始开发分布式应用，于是深脑链得到很强的机构支持。同奇点网络相比，深脑链扎根于中国市场对它的发展很有保证，因为中国使用他自己的产品和项目。我认为深脑和奇点网络其实并不是竞争对手。 担忧： 一方面是他们无法支持必要的发展和快速增长的可行环境。因为深脑链的市场重度依赖于规模效应（客户带给平台的价值）。团队需要在市场推广方面迈开大步以促进规模效应的发展。 亦来云 还未上交易所,代币代码:ELA 简介： 亦来云是国内最有野心的项目之一。它旨在使用区块链技术创建一个分布式的网络。通过这个平台开发者可以创造分布式的应用连接到亦来云区块链上但又不直接运行在该区块链上，这是一个大规模的解决方案。同时，用户可以轻松的获得数字内容的身份认证。还怕有人偷走你的相册吗？给它们数字身份，用亦来云保障他们的安全。 所有这些特点在任何操作系统都能够实现，你可以在iPhone上使用这些分布式的应用。这些应用内嵌叫做亦来云实时任务的保护机制防止应用直接连接互联网，进而杜绝恶意软件。亦来云的主链通过 POW（proof of work工作量证明）安全机制并且使用比特币的计算资源，也就是说当一个矿工从比特币区块链上挖到一个区块，他同时在亦来云的区块链上也挖到一个区块。 为什么亦来云这个项目值得关注？亦来云给区块链带来实用性和可扩展性。它聚焦于创造一个像现在互联网一样方便的强大的生态系统。在它的平台上，亦来云可以运行所有的区块链应用。亦来云是NEO获得全球视野的关键。 支持者： 亦来云是比特大陆支持和投资的产品。同时也和蚂蚁矿池有合作关系。比特大陆和蚂蚁矿池是中国最大的挖矿公司，他们同NEO委员会有深入合作。 竞争： 亦来云提供一整套的解决方案。以太坊可能需要众多的分布式应用来实现亦来云的功能。但是有很多用于开发分布式应用的平台和新型的互联网如EOS、AION、Cardano等。亦来云在亚洲的地位把这些西方的竞争者挡在门外。亦来云已经有了正在运行的主链，还需要多年的研发，比较花费时间。 分析： 亦来云是一个大胆的项目。一般来说这种量级的项目，属于规模比较大的，他们会发展的越来越好，而且它已经有了正在运行的主链。和中国挖矿巨头的合作让平台获得巨大的算力，同时和NEO的交互操作也为各自平台带来巨大的价值。 担忧： 到底区块链世界能够支持多少平台？亦来云明显面对激烈的竞争。但我仍然坚信亦来云正在提供很多其他平台无法做到的解决方案。 星云 已经登录火币交易所 代币代码NAS 简介： 尽管是中国的项目，星云更关注西方，因此和其他区域性的项目相比很少受到宣传的障碍。星云提供有效发掘区链项目和合约价值的排名算法并让用户能够搜索到它们。星云有自己的虚拟机并支持分布式应用的开发，是一个允许快速扩展的高效的升级系统，同以太坊智能合约完全兼容，背后的团队实力非常强。 为什么星云是一个值得关注的项目？星云有着自己的区块链搜索引擎被认为是区块链世界的谷歌一点不过分。但是星云的天才之处是如何用好它们的排名算法。在搜索引擎中排名之前需要建立一个价值体系，需要评估区块链项目、分布式应用和协议。星云已经为区块链设计了一个价值体系，允许星云高效的为用户和账号赋予价值并且给予相应的奖励。把这个价值系统和分布式应用、智能合约以及其他先进功能整合起来，星云是第三代区块链项目中有实力的竞争者。 支持者： FBG资本、GBIC和500 Startups（强大的风险投资和孵化公司） 竞争： 星云面对如EOS、Cardano和AION等第三代区块链平台的有力竞争。但是星云所要做的事情跟他们并不在同一个领域。 分析： 在FBG and 500 Startups的支持下，星云在第三代区块链市场里是个沉着有力的竞争者。如果什么时候它和以太坊或者其他平台合作引入星云的排名系统我一点都不惊讶。 担忧： 这个行业中的平台竞争是需要关注的。但是我相信星云的技术真的很特别。 物联网 交易所交易——代币：ITC——在Huobi上可交易 简要概述： 物联网链旨在成为物联网的中国平台——想想西方的物联网。物联网链使用DAG技术来支持物联网带来的巨大交易负担。然而，与物联网不同的是，ITC利用国家委托证据（简称PBFT）达到共识。为了扩大规模，DAG的小部分被这个dPOS分割并单独管理。 为什么物联网很重要：中国很可能将是物联网革命的领头羊。它与企业的紧密结合，促进企业的采用，可以和IOTA的成功类似。 支持者： 物联网连锁公司由Link Capital 和FBG Capital投资。与中国8家能源和技术公司合作，并得到GBIC的支持。 竞争： 物联网在中国市场上还没有任何竞争者，来自西方的物联网正在和IOTA和其他DAG协议如Raiblocks (XRB)竞争。 分析： 物联网拥有雄厚的技术力量、大的企业后盾和重要的投资机构。他们已经有了一个工作原型。目前，它只能在规模较小的交易所上市，因此其市场有限。我认为它有很大的发展空间，也有机会在中国主导物联网市场。 担忧： 我对物联网链的关注和对IOTA的关注是一样的，具体而言，一个中央协调者必须监督网络。一个拥有大量微事务的DAG系统可以在没有中央协调器的情况下运行；在此之前，中央协调器最能监督网络。此外，物联网链在西方国家的营销中面临挑战。不过他们很快就会推出白皮书修订版，并与GBIC合作，非常值得期待。 本体论 还未上交易所——代币符号：ONT 简要概述： 本体是区块链与业务之间的纽带。他们的母公司OnChain已经和中国的企业和政府建立了良好的联系。本体创建了一系列高级应用程序，使企业能够创建私有链，保持对信息的控制，与其他私有链和更大的本体网络互联，并连接到公共链（如NEO）。诸如具有可选功能的可定制的私人连锁、数字标识（ONT ID）和高级信任颁发系统（实体可以向其他实体发出信任，以及所有可追溯到出事发行者的内容）等服务，使本体成为一个非常具有前景的项目。 为什么本体这个项目值得关注：本体是NEO和其他公共区块链的信任网络。NEO是建立在支持智能经济、与企业连接、建立一个互联世界的前提下的，所有这些都是基于区块链的安全。本体利用NEO VM为这一愿景提供了另一关键组件：可编程信任。没有本体，NEO只是另一个公共区块链。 支持者：  Ontology是OnChain的一个项目。OnChain是第一个加入Hyperledger的中国区块链公司，是微软中国多个项目的战略合作伙伴，与日本经济产业省合作，被评为毕马威中国金融科技50强之一，与阿里巴巴合作提供阿里云电子邮件认证服务，接受复星集团投资，并与中国地区政府合作。此外，本体论由NEO委员会支持。 竞争： 我没有看到达到跟NEO和本体相同规模的项目。 分析： 正如我所说的，在NEO的支持和合作下，本体是NEO成功的关键。他们完美地互相补充。NEO提供了将网络的所有组件连接在一起的基础。本体为企业和政府提供了一个入门平台，可以连接到更大的区块链网络。 担忧： 就区块链项目而言，这是我认为最安全的一种。关键是要看他们是否真的可以持续获得新的企业级客户。 矩阵链 代币标志：MAN 简要概述：  MatrixChain集成AI与区块链。MatrixChain以一些独特的方式使用AI，最终简化用户体验。人工智能可以审查智能合同和代码，以确保漏洞和错误不存在。用户只需以简单的脚本语言输入智能合约的规格，AI然后将规格转换成智能合约。但这不是一个简单的过程。 人工智能需要从规范中推断出智能合约的目的是什么，然后启用它。AI还将根据环境和使用输入优化区块链协议。从本质上说，区块链将不断优化，以考虑到实际使用情况，在不硬分叉的情况下。 MatrixChain使用混合PoW和委托PoS协议。区块链分为不同的部分，挖掘和共识分开发生，以提高可扩展性（思考分区）。但是与其他PoW模型不同，计算节点不仅仅是解决无意义的算法。矿工执行马尔可夫链蒙特卡罗（MCMC）计算 -  如果你阅读起来很困难，坚持下去。MCMC计算对于解决某些算法非常重要。即使是一个简单的解释也超出了本文的范围，但是认识到MCMC对于真实世界的大数据应用是至关重要的。因此，矩阵挖掘对于解决现实世界的问题实际上是有用的。 为什么MatrixChain是个值得关注的项目：人工智能和区块链是近年来最具革命性的两项发展。我个人一直在寻找两者的完美组合。我认为MatrixChain提供了这个将两者结合的解决方案。 支持者：  MatrixChain得到了中国人工智能协会的支持，与HyperLedger合作，并获得了区块链风险投资和孵化器Torque Capital Partners的投资。 竞争： 虽然像DeepBrain Chain和Singularity这样的项目正在利用区块链作为连接AI开发人员和计算资源的分散市场，但我并不知道有任何项目会直接与MatrixChain的AI集成竞争。然而，考虑到MatrixChain是智能合约和dApp开发的平台，它与EOS，Ethereum和Cardano等其他平台竞争。 分析： 尽管区块链平台之间的竞争非常激烈，但是使用像Nebulas排名算法这样的新技术实现平台是非常重要的。MatrixChain对AI的使用属于这个保护伞下。我相信AI对区块链来说是非常有利的。MatrixChain正在带头推进这一进步。 担忧： 没有强大的技术背景，我很难评论AI和区块链整合的障碍。但是，我相信有很多挑战，而且考虑到编码的人工失误，任何一个小错都会造成昂贵的损失。 还有很多我想写的项目，在这里没法一一列出。中国在区块链领域有非常瞩目的发展，上面的概述只是一小部分。我打算在以后的文章中深入探讨这些提到的项目。以上只是对每个项目的简要分析，投资前请做深入的研究。 在我感兴趣的其他项目中，我将在以后的文章中进一步讨论如下： Zilliqa   - 一种高级区块链平台，具有缩放解决方案，如Sharding。有FBG资本的支持 NEX  -   NEO 的分散交换和交易协议。后来被NEO委员会认可。 TheKey  -  将数字身份验证带入NEO和OnChain。来自OnChain，NEO，Roger Lim，中国联通（一家领先的电信公司）的联合投资。 WanChain   - 一个 能够提供一整套高级财务方案的平台。该部分 Blockchain互操作性联盟与ICON和AION。 EximChain   - 中国的供应链平台。GBIC支持 Aelf   - 一个分散的云计算解决方案。以FBG Capital和GBIC为后盾。 Zeepin   - 为发布商保护其数字内容创建一个创意内容平台。由NEO委员会和GBIC支持。 Trinity   - 雷电为NEO。实际上是一个脱链拓展解决方案。 WaltonChain   -  Walton在中国是一个连接良好的供应链标志。他们使用RFID技术促进产品在供应链流程中的转换。他们与中国企业有强大的合作关系。 高性能区块链（HPB） - 高度可扩展的区块链，支持技术，可与企业和企业集成。由NEO委员会支持。 VeChain   - 为企业和企业提供BaaS（区块链即服务）。已经与现实世界的业务相结合。 中国区块链公司正在开发一个生态系统。 在美国，他们正在开发dApps。以太坊提供了一个无方向的框架。这并不是为了削弱以太坊的成功。以太坊支持大约85%的dApp开发项目。不过，以太坊并没有把dApp的发展重点放在任何特定的方向上。它确实是分散的。任何人都可以开发任何NEO，都主要集中于创建一个全面和协同的愿景-- 企业，政府和公众可以共享资产，连接和利用区块链的愿景 - 安全高效。要实现这一愿景，他们必须将dApp的发展重点放在这个愿景上。 在美国，市场认为每个行业都会受到干扰和去中心化。我不同意这种看法。我同意今天存在着一套管理我们世界的不太理想的规则。但我认为人们有这种乌托邦的观点，认为这些规则是由我们集中的，以行业为中心的世界创造的。然而，我认为规则超越了生态系统。规则创造了生态系统，而不是相反。这意味着破坏这些“规则”的想法是天真的。他们不能被打乱。要使区块链成功，它必须在这些规则中运作。现在这并不意味着区块链不能做好。它可以在改善世界，改善现有产业，提供更好的社会流动性，削减中间人的框架内进行变革。但是权力决定方向的这一根本规则将永远存在。 我的观点是，中国的区块链项目承认这一事实，而美国的则没有。在中国，区块链公司意识到信任，一定程度的集权（NEO委员会）和互操作性是长期成功的关键。正如布拉德所说：“没有这种信任体系，特别是在中国，企业永远不会触及区块链。”他们正在创建与现有机构合作。是的，中国的项目比较集中，但这不是真正的分权与集权的问题。这是妥协将已建立的业务转移到分散的框架。以上提到的所有项目都是非常现实的落地项目。他们务实，致力于在中心化的世界里工作。 2018年将是一个决定性的时刻，不仅是整个区块链行业，也是中国在生态系统中的角色。中国会在阴影下保持观望吗？或者他们会在改变我们的世界方面发挥积极作用？中国有潜力把区块链的世界置于后面，并大踏步前进。 而当中国确定实行之后，这些项目将大力发展； 获得广泛的机构支持，以革命性的设计和技术为先的方法快速发展。因此，快把中文学起来吧，打开电脑大量阅读。 ---------------------- 免责声明： 本文在海外科技媒体medium上发布后获得了极高的关注量和赞同，我们将其中的精华编译呈现。 这里提到的所有项目及分析，包括NEO，IoT链，DeepBrain，星云和Zeepin，都是作者观点，未收取任何广告费用。本文也并非投资建议，请为自己的一切投资行为负责。 原文链接：https://medium.com/theblock1/an-undervalued-blockchain-market-in-china-is-good-news-for-you-d0c010170622 【今日机器学习概念】 Have a Great Definition "
148,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657109&idx=2&sn=3804ca3492e35764dfff0bcc9ebc2302&chksm=bd4c34068a3bbd1092f46879f7fbadf77c5ea546245af05f91e3cc713abcf702aaf6a158ef5f&scene=27,业界丨黑科技加持，2018平昌冬奥会有什么新玩儿法,大数据文摘作品 编译：魏子敏 尽管距离韩国平昌冬奥会有几千英里的距离，你还是可以从各角度全方位感知这场运动盛典。 不止是因为CCTV 5和朋友圈铺天盖地的消息， 今天正式开幕的平昌奥运会， 平昌冬奥会的奥运村（图片来自IOC Media） 冬奥会应用程序 这次冬奥会的科技元素从赞助商名单就可见一番：英特尔，三星，松下，丰田。被如此多强大的IT公司共同支持，这次的冬奥会有望实现一个伟大的成就：通过云和IT系统来管理所有事情。 这不是一件简单的事情。想象一下冬奥会的规模和范围：十几个国家、十几个不同的场馆、一百多场比赛。其中最大的是平昌奥林匹克体育场，可以容纳三万五千人。而所有这一切都将在世界各地以及无数的平台和形式上进行广播。 三星公司为奥运会推出特别版的“Galaxy Note 8”， 它还支持用户自定义的应用，你可以只跟踪你关心的运动和事件。 花式无人机列队 在周五的开幕典礼上，英特尔出动了无人机列队来表演（这些重达1磅的智能飞行器，会在空中进行一系列花式表演，并重现奥运五环，类似于英特尔在2017年super bowl中的表演），此外， 英特尔的猎鹰8无人机（图片来自英特尔） 不过今年早些时候，针对无人机的使用是否会影响运动员的发挥，也曾引起过争议，国际奥委会高层保证，在冬季奥运期间使用无人驾驶飞机时，安全仍然是“首要任务”，只有当运动员能够适应的情况下，才使用无人机。 VR 这也将是第一个将使用虚拟现实向球迷直播的奥运会。 通过部署VR系统，观众可以通过三星 Gear VR和谷歌Daydream等VR头机，在VR中直播或点播观看30场比赛，包括男子滑雪、女子冰球等。 5G 在所有这些技术中，5G网络受到的关注度一直高居不下。 以韩国的KT移动网络为支撑，由英特尔等公司整合的平昌冬奥会5G网络，可能是全球大部分地区首次看到如此之大的5G网络规模。 5G网络为何备受关注？ 让我们看一下它和4g网络的对比：好的条件下，我们的智能手机目前所享用的4G网络的运行速度可达每秒1千兆位；而 5G（第五代）的运行速度可达到每秒10吉比特， 这也大大减少了延迟。 5G不仅有望改变移动领域，还将辅助我们进一步链接各种智能设备。 而本次冬奥会上，5G集成并不会面临太多问题， Moor Insights and Strategy的分析师Patrick Moorhead解释说，冬季奥运会5G技术主要作用是在场地周围传播高带宽数据。 如果目前的光纤无法提供足够的带宽，它将派上用场。 所以，直到数据在虚拟管道的另一端（在某个屏幕上）显示，人们才能看到这种壮观的景象。 在真实世界中，点对点5G的技术将取代目前家庭和企业的使用光纤网络。 它将连接智能城市灯柱之间的数据，Moorhead在一封电子邮件中写道。 国际奥委会主席托马斯·巴赫（Thomas Bach）几个月前说， 通过优质技术更好地将人们与奥林匹克精神联系起来的或许是目前最好的方式。我们拭目以待一场科技加持的奥林匹克。 原文链接： https://medium.com/@LanceUlanoff/2018-winter-olympic-games-may-medal-in-technology-e9eda6e2a87a?source=topic_page---8------0------------------1 【今日机器学习概念】 Have a Great Definition 
149,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657072&idx=2&sn=7908a6e7a3585ea99d4be3090f503ac4&chksm=bd4c34e38a3bbdf5b4fd4f28e0c7a9af8efa18c7efa974d3b555c1660c28ee2f7b886d6c1c59&scene=0,业界 | 马斯克很忙！称将在3个月内开特斯拉自动驾驶横穿美国,大数据文摘作品 编译：魏子敏 特斯拉去年立过一个flag： 2017年已经过去了，显然特斯拉没有完成这个目标。 刚刚发射猎鹰成功的特斯拉CEO伊隆·马斯克并没有闲下来，近日，在一次媒体会面中，他表示会在三到六个月内开启这段旅程。 驾驶特斯拉横穿美国不是一件容易的事情，考验的除了特斯拉的续航能力，还需要考虑沿途路况、天气等多种变数，甚至驾驶员的个人能力。 事实上，这种自动驾驶的长途旅程Drive.ai之前也做过，他们将其命名为“无人车马拉松项目”（The Drive-a-thon），并详细记录下了这场惊险刺激的“24小时行车日记”。 点击查看大数据文摘报道 近日，在回应一个有关自动驾驶的问题时， 马斯克 表示会在3-6个月的时间内做一场横穿美国大陆的自动驾驶。当被问及这个“横穿驾驶功能”普通特斯拉客户能否使用的时候，他说“以后是可以的”，但没有评价具体什么时候才可以。 马斯克承认，对于去年立下的这一目标，他“错过了”，但是他认定特斯拉“有能力在去年完成跨大陆的越野计划”。为了达成这一目标，公司需要敲非常多自定义代码。 特斯拉的目标之一就是建立一个更稳健，能够更普遍使用的系统。为此，马斯克表示，他对公司自主驾驶在神经网络上取得进展感到高兴。 Musk说他对神经网络取得的进展感到满意，“ 我们从'似乎没什么进展'，一下子进展到了'哇'。” 这位CEO还将自家特斯拉的进展和Google的DeepMind获得AlphaGo的进展做比较， 开始时，我们和大家一样，也没有什么特殊的技能。 原文链接： https://techcrunch.com/2018/02/07/elon-musk-expects-to-do-coast-to-coast-autonomous-tesla-drive-in-3-to-6-months/ 【今日机器学习概念】 Have a Great Definition 
150,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657072&idx=3&sn=e13c04db852661a5428d4920ddce8e53&chksm=bd4c34e38a3bbdf52bd855ef7cde3c5c29f4166fa7af96a4f393e425ebece0333db8b317936c&scene=0,快讯 | Reddit关闭Deepfakes论坛，遏制“非自愿换脸情色”,大数据文摘作品 编译：蒋宝尚 近日，Reddit终于采取行动，关闭了Deepfakes论坛，并更新了全网规则，称将会严格审查涉及非自愿情色和未成年性暗示的网站。至此， 包括twitter等社交平台，pornhub等色情网站等 Reddit官方禁令声明👆 事情还要从一个机器学习的程序说起： Reddit论坛的网友deepfake 用一种AI技术将“小电影”女主角的脸替换成明星盖尔·加朵(神奇女侠的主演)。 很快，这种“换脸”的行为开始迅速在论坛上蔓延起来。 如果仅仅是自娱自乐还不至于此，这位技术咖为这个小程序添加了一些工具，发布了 应用“FakeApp”， 把“换脸“这件事变得非常自动化且可操作： 你只要先收集一个人的照片集或者视频，然后选择一个小电影进行操作，接下来，耐心等待40分钟，电脑将完成剩下的全部工作。 在Reddit上，deepfakes组建了一个同名社区，短短一个月，这个板块已经聚集了近两万名订阅者。而被“抓来”被迫色情的女星也越来越多，从艾玛·沃森到 Sophie Turner…… 不仅仅在reddit，这一 “换脸色情片” 迅速蔓延到了各大社交网站、论坛，并受到了很多关注。 GIF平台Gfycat首先开始移除相关内容，交流平台Discord 也出手封锁讨论制作“换脸色情影片”的服务器。Twitter 同时表示会阻止这类移花接木内容在平台传播。 这些公司发布禁令的最主要原因是“ ”。 全球最大色情影片平台 Pornhub 表示：“本站不容忍任何非自愿的内容，非自愿内容直接违反我们的使用条款，该条款禁止复仇色情报复（revenge porn）、deepfakes，以及任何未经同意或允许上传的内容。” 这个事件的重点是： 其实， 据说，仅仅是这部分的费用，就花掉了几千万美金。 在接受媒体采访时， deepfakes表示， “人人可参与的机器学习研究不是一件坏事。” 的确，不可否认这一自动化换脸技术的强大。如果有热爱学习的同学想要研究一下这个深度学习的技术，文摘菌搜集了一些资料，基本需要以下这些步骤： 1. 尽可能多的搜集要替换的AB两个人的头像。 2. 训练样本。 3. 找到需要替换的视频，用ffmpeg提取成一帧一帧的图片。 4. 用训练出来的样本对每一帧的图片进行替换。 5. 用ffmpeg合成视频。 知乎用户【李瑞】表示，整个过程中最难的是第二步：训练样本。 这个步骤对显卡的要求十分高，据说已经有了可以在云端训练模型的方法。 最近这个话题又火了起来，也只是因为这个关注点很有噱头罢了。 【今日机器学习概念】 Have a Great Definition 
151,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657109&idx=1&sn=cf2b8787ba572d33c79dbed090c10ccc&chksm=bd4c34068a3bbd10811029ef910c87ad528c35a0599ba7cc746dda24867fb9deb8905e32752f&scene=27,我30岁了。现在开始编程，会不会太晚？,"大数据文摘作品 编译：丁慧、吴双、龙牧雪 永远不晚——本文作者在Twitter上征集了300个30岁、40岁甚至50岁才获得第一份开发工作的故事，分享给大家 每天，我会收到来自世界各地的开发者的邮件，他们都会问一个相似的问题： “我XX岁，会因为年纪太大而不能被聘为开发人员吗？” 程序员是吃青春饭的——这是整个软件开发领域最常见的问题之一。 为了让大家知道有多少开发者都在担心他们的年龄，我在Quora上查找了这个话题的变种。 果不其然，我发现所有年龄段的人都在担心自己由于年纪太大，而无法学习编程并被聘为开发人员： • 	 60岁开始编程太晚了吗？ • 	 50岁开始太晚了吗？ • 	 40岁太晚了吗？ • 	 30岁？20岁？……太晚了吗？ Quora上充斥着大量此类问题。还有人问道，“如果我想去谷歌工作，14岁开始学编程是不是太晚了？” 链接地址： https://www.quora.com/Is-it-too-late-to-start-programming-at-14-if-I-want-to-work-at-Google 上周末，我列出了一份300名开发人员的名单，他们在30岁，40岁以及之后才获得了第一份技术开发工作。 我们使用了#DevAfter30标签来分享故事。 所以如果你30岁之后开始从事软件开发工作，欢迎加入我们并分享你的故事。 那么，应该告诉一个恐慌年龄太大的人什么呢？大多数人会说类似Walt Disney的名言： 当然，我同意这种观点。 我当了20年的教师，直到30岁才开始学习编程。 在这之前，我不会写基本的JavaScript语句，不会写Sql查询语句，也不会安装Linux。甚至需要妻子的帮助才会设置Wifi路由器。 我在31岁获得了第一份软件开发工作。 因此我当然相信年龄只是一个数字。 但是我怎么才能说服所有这些每天都在问这个问题的人呢？因为说“要坚信”是不起作用的。 我知道好几个人在比我大得多的年纪才开始从事开发工作。 举个例子，我的一个朋友是50多岁的高中法语老师。在参加了一些免费的在线大学课程后，她被苹果公司聘用为软件工程师。 所以我知道这是可能的。 但是仅仅用我知道的有限个例子，并不足以说服大家不用去担心自己的年龄。大家看的好莱坞电影，讲述的大都是，30岁以下的人都是电脑天才，30岁以上的人对技术一无所知。 来自电影《社交网络》中的一幕，强化了开发者糟糕的刻板形象。 因此，我重新考虑了我的方法。 我想，也许我可以找到一份在30多岁、40多岁或者更大年龄才获得第一份开发工作的人员名单，用它来说服大家不再担心自己的年龄。 网络上确实是有年纪较大的开发人员名单，其中大多数人有几十年的编程经验。但是我找不到任何在30岁之后得到第一份开发工作的人的名单。 所以我发了一条Twitter。 太多的人在不断问我：“我现在[30,40,50]岁了，要想当个技术开发是不是太晚了？” 我得到我的第一份软件工作是在31岁。 你认识在30岁之后才开始自己开发职业生涯的人吗？我在建一个列表，如果知道就请回复我！ 事实证明，很多开发人员在30，40，50岁时获得了他们的第一份科技工作。 我51岁开始编程，不到一年后成为了软件工程师。永远都不会太晚！ 去年的这个时候我获得了第一份开发工作。我今年43了，之前当了10多年的会计，后来爱上了编程并想以此为职业。我通过@freeCodeCamp和其他途径半工半读了近4年了。 我今年46，在作为自动化工程师20年后，去年开始了我的第一份开发工作！ 我今年40，上个月刚刚开始了我的第一份开发工作！ 我39岁开始的转行。我是要养家糊口的，却被从之前的动画相关工作上辞退，当时只有五个月我的孩子就要出生了。参加3个月的编程培训营似乎是我最有赢面的赌局，果然孩子出生前两周我找到了工作！现在已经两年多了。 我37岁找到的自己的第一份编程工作。从在Home Depot挣25000美金一年到获得60000美金年薪的工作！现在我差不多40岁了，挣得比当时多得多！ 我今年52岁，一年前获得了计算机科学的学位，在自己的第一份软件工程师岗位上工作差不多三个月了。 10余年的酒保和服务生经历后，我回到学校学习了图形设计，成功成为了一个网站前端设计/开发。36岁，我挣到了自己的第一份开发工作的薪水！ 我是去年在36岁时开始的，在做了10年全职妈妈后，我成了一个全职开发人员！ 我42岁去上的理工学校，44岁开始了全栈开发工作。我之前的人生一直如在黑洞中不停地爬，我以为自己会一直被困在洞底，这次是一个巨大的进步！  18个月前35岁的我开始了自己的第一份开发工作。从来没有觉得工作如此快乐！   这个月我就33了，虽然高中就学过编程，但重新捡起来的时候已经31了。去年的时候我开始做网站开发工作。重新选择职业永远不会太晚。 我之前是个自由职业钢琴家。30岁回到了学校，因为没有数学背景，我真的是从零开始，最后我拿到了计算机科学的博士学位，38岁的时候找到了我的第一份工作（雅虎），而现在我是微软的首席科学家。 33岁我写下了自己的第一行代码，那年年末我找到了自己的第一份iOS开发工作。 我33岁开始了自己网站前端开发的职业生涯，在照顾我两岁孩子的同时学了所需技能。这并不容易，但不是不可能！ 我33岁放弃了时尚摄影转而开始学编程，几个月后我找到了交互设计开发工作，到今天已经14个月了。 在做律师10年后，我决定转行。去年的时候，42岁的我开始了自己第一份软件开发工作。 我，我，我！30岁拿到计算机科学的学士学位，40岁晋升为Etsy的主管工程师！ 我41岁完成的编程集中培训并找到了自己的第一份开发工作。在此之前我是一所大学的英语教授以及副院长。 我最初是在广告行业，之后拿到了一个理工学位，后来学习了针灸并有自己的小诊所，之后我决定将副业转为主业，去参加了编程培训班。今年我得到了第一份开发工作，作为我38岁的生日礼物。 大家好！我今年37岁,4个月前仅仅靠在freecodecamp中的学习，我获得了自己的第一份开发工作！作为一个初级岗，工资给的相当不错！ 在医学研究领域工作了相当长时间后，我在40岁找到了自己的第一份开发工作。想要开始就永远也不会太晚！ 最后，我用#DevAfter30#标签建立起了一个30岁之后开始从事开发工作的300位开发者名单。 要知道这是相当普遍的，而且你也会被不错的公司聘用。 永远不晚，加油！如果你也有类似的经历，欢迎留言分享~周末愉快~ 原文链接： https://medium.freecodecamp.org/stories-from-300-developers-who-got-their-first-tech-job-in-their-30s-40s-and-50s-64306eb6bb27?source=userActivityShare-913be27d2547-1516039444 【今日机器学习概念】 Have a Great Definition "
152,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657024&idx=2&sn=bfdb35d7f942a66b270f9402e536f7f8&chksm=bd4c34d38a3bbdc5c90ba2ad7f9d4f80774a97b887a8b62e37200b88e11e6641de81e7b9b957&scene=0,BlockChange丨谁在监管加密货币？各国数字货币政策情况概览,编译：白丁、  笪洁琼 、小鱼 当前各国对加密数字货币的监管差异很大，在接下来的几个月中还会有许多变数；与此同时，了解各国政府对数字加密货币监管所持的态度也 具有十分重要的意义。 美国（美国证券交易委员会（SEC）、美国商品期货交易委员会（CFTC）和美国国税局（IRS））、中国、韩国、日本和欧盟作为全球加密数字货币大潮的中坚力量，任意一方或几方在监管方面的改变对整个市场而言具有牵一发而动全身的巨大影响。本文总结了以上国家和地区的有关监管政策和当局表态，为未来趋势的解读和分析提供了较为全面的信息参考。 美国证券交易委员会（SEC）表示，“美国证券交易委员会的责任是保护投资者，维护公平、有序、高效的市场环境，为资本形成提供便利。”1934年，美国国会创立了证交会，成为了第一个证券市场的联邦监管机构。在1929年股市崩盘后，就暴露出许多公司都向投资者提供了有关其业绩和未来前景的虚假或误导性信息。从那以后，SEC的主要职能一直是核实企业发布的声明，并确保证券机构(如经纪商、交易商和交易所)公平、诚实地对待投资者。 截至目前，SEC尚未批准任何持有数字虚拟货币的交易产品（如ETF基金等），或用于上市或交易的与数字虚拟货币有关的任何其他资产；也没有注册任何用于交易的数字货币。 更多SEC关于数字虚拟货币的意见，请见2017年12月11日的声明。 美国商品期货交易委员会（CFTC）表示， 通过避免系统性风险，期货交易委员会希望为市场使用者及其资金、消费者和公众提供保护，避免涉及衍生品和其他产品的欺诈、操纵和恣意妄为对其造成损害。” CFTC认定比特币属于大宗商品 ，并在声明中表示其监管对象包括洲际贸易中涉及比特币的欺诈、操纵等行为，以及与比特币直接挂钩的大宗商品期货交易。 2018年1月19日，CFTC发布声明，对两起加密数字货币欺诈案例提起公诉。面对数不胜数的旁氏骗局，此类监管的出现恰逢其时。 更多CFTC关于加密数字货币立场的报道，请参见2017年10月17日的消息。 美国国税局（IRS）： 尽管部分交易所可以正常出具1099报税表格，个人仍需针对比特币及其他加密数字货币的盈利部分缴纳相应税款。加密数字货币交易带来的长期和短期资本盈利或损失都需按要求进行申报。 中国出台了一系列限制加密数字货币交易的措施。首先，自2017年9月4日起禁止首次代币发行众筹（ICO），也就是新款虚拟货币的首次公开发售；此外，中国还向各家地区交易所下发通知，叫停加密数字货币交易，并出台相应措施打击比特币挖矿行为。上述措施很可能改变比特币挖矿的行业形态，推高有关成本。比特币价格便宜、地处芯片制造厂、低廉的劳动力成本等因素在最初阶段吸引了大批矿工涌入中国，但现在他们可能不得不另谋出路了。 中国人民银行、中国网信办和中国工信部共同开展了针对加密数字货币的限制行动。比特币和替代数字货币依然可以在海外交易市场进行交易；中国镜内有关交易活动进行地点已经调整至中国香港。 然而，中国并不反对加密货币这种技术。 中国人民银行已经开始测试自家的数字加密货币，在成为首个发行数字货币的大型央行路上又前进了一大步。为避免比特币和虚拟货币泛滥，中国希望能够对数字交易实行全面监管。 金融机构和第三方支付机构不可接受、使用或出售虚拟货币。尽管虚拟货币的用途是合法的，中国人民银行仍要求各交易所在相应监管机构进行登记，同时建议其密切跟踪市场情况。有消息称中国人民银行已经向涉及虚拟货币业务的银行提出了警告。 据报道，韩国司法部于2017年1月11日确认了一项叫停所有加密数字货币交易的计划。然而，韩国总统办公室很快发布了一份声明，表示该政策尚未通过最终批准。模糊不清的态度遭到了韩国民众和政界人士的强烈反弹。政府在监管问题上的表态导致加密数字货币价格出现显著变化，而政府官员在相关交易中大赚特赚的消息一经曝出，对事态的影响不亚于火上浇油。 韩国政府可能将于2018年1月25日就加密数字货币监管一事发表最终声明。韩国金融监督委员会负责人表示： 然而韩国银行（韩中央银行）行长Lee Ju-yeol在一次新闻发布会上表示，“加密数字货币不是合法货币，目前的使用情况也与货币有所不同。” 2017年4月1日，日本金融厅颁布了一项新法律，允许在支付中使用数字货币。《虚拟货币法》对虚拟货币进行了定义和描述，并对比特币有关情况加以澄清：比特币是一种资产，也可以用于支付。然而，该项法律并未将比特币认定为合法货币。经过数个月的激烈讨论，最终该项法律认为比特币交易违反了《反洗钱法》和“了解你的客户”（KYC）等相关规定，而比特币也因此被归入预付款工具类目下。2017年9月29日，日本金融厅向11家公司发放了首批数字货币交易许可证。 在本文涉及的国家和地区中，日本在加密数字货币监管上走到了最前沿，政府开始与交易所共同开展监管工作而非彻底关停。 2017年4月起，比特币支付已经成为合法的支付方式，目前日本有超过4500家商户接受比特币支付。 欧洲银行管理局此前向公众就虚拟货币相关风险发布警告，并于近期表示将采用反洗钱和反恐融资相关规定对虚拟货币进行监管。 整体来说，尽管多国政府已经在其声明中表示正在评估数字加密货币的未来潜力，除避免洗钱和为恐怖组织提供资金的意愿外，几乎没有任何实质性的定论。 近期，有关各方一致认为2018年加密数字货币将面临更加严格、更大力度的监管态势，政策落地的国家或地区以及落地方式将会推动虚拟货币价格上涨。 但同时这也意味无法在中国和韩国境内进行交易，而有关虚拟货币的价格，在未来一段时间可能有所下降。 原文链接：https://hackernoon.com/state-of-global-cryptocurrency-regulation-january-2018-6e03dea0f036 【今日机器学习概念】 Have a Great Definition 
153,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657024&idx=3&sn=78f98a4724c25d3e4f08fd2f18cbdab3&chksm=bd4c34d38a3bbdc541ff2664251e810bc44e89f98374ae06354e7e112fe5cf35a793e845641a&scene=0,这个霸道总裁玩跑车、造火箭，却把全中国的科技大佬都燃哭了,本文摘自 超级技术 你的朋友圈被硅谷钢铁侠马斯克的火箭刷屏了吗？ 美国东部时间2月6日15:45分(北京时间2月7日4:45分)， 太空探索公司SpaceX，在美国宇航局的肯尼迪发射中心，成功发射了“猎鹰重型”超级运载火箭，不仅把埃隆•马斯克(Elon Musk)的红色特斯拉跑车送上了太空，而且成功地回收了两枚助推火箭。 年年都有火箭发射升空，为何这次事情不一般，被受关注呢？小编这就为你梳理一下。 此次发射的“重型猎鹰”火箭是自阿波罗时代土星五号火箭以来，人类发射的运载力最强的火箭，绝对的巨无霸级别。 它的近地轨道运载能力（LEO）：63.8 吨——相当于可以把 比目前纪录保持者德尔塔 IV 重型火箭的 28.8 吨足足提高了一倍还多。（数据来自DeepTech） 如果这个数据还不直观，我们可以和1年多前中国刚最近发射的“长征五号”运载力做个对比：2016年11月首飞成功的“长征5号”只能把25吨重的货物运送到“近地球轨道”，极限仅够运送一个5吨左右的火星探测器到火星。 我们可能要在2030年，才能做出重型猎鹰这种运载量级的火箭。 此次发射的三枚一级箭体完成了回收。 三枚一级火箭将按计划执行回收程序返回地球（虽然中间的箭体似乎在直播时出了小bug）。但是现场的视频清晰展示了两侧助推火箭返回佛罗里达海岸后，在SpaceX的两块着陆区同步垂直着陆的震撼画面。 据说两枚助推火箭还是此前用过的“二手货”，由此也可见 SpaceX 的回收技术已经十分成熟。 《经济学人》主编在《超级技术：改变未来社会和商业的技术趋势》分析马斯克SpaceX的商业火箭发射有两个重要意义： 三级火箭的第一级占总成本的70%，但是通常发射完成后掉到大海里。回收和重复使用火箭的第一级可以颠覆性降低火箭发射成本，从而大幅度降低人类通往太空的成本，未来，低成本太空旅行成为大概率事件。 SpaceX公司的火箭目前主要用于将火箭发射到轨道上，并将货物运送到国际空间站，但是马斯克的野心昭然若揭：在火星上建立殖民地，如果地球被灾难摧毁了，那里将成为人类的绿色方舟。 另外，全世界实现载人航天飞行的只有三个国家，且全部是国家主导，马斯克和他的SpaceX完全是一朵“奇葩”，一个异类。未来，埃隆•马斯克可能成为第一个不是被国家力量送上太空的宇航员。 这次的重型猎鹰发射所搭载的正是他本人的一辆桃红色特斯拉Roadster跑车。 不仅如此，一个身着宇航服的“驾驶员”假人“Starman”会坐在驾驶位。 车上还带有一套微缩版本的阿西莫夫《基地》三部曲。 这辆车会被送入地球—火星转移轨道，同时，车子会不间断的播放 David Bowie 的成名作《太空怪咖》（Space Oddity）。 如果不出意外，按照马斯克本人的原话，“这辆车会在宇宙中飞行超过 10 亿年。” 我们不得不承认，马斯克真的是有极致浪漫情怀的企业家。经过十余年的探索，他把外人当做白日梦的幻想，成为了现实。 玩儿跑车、造火箭，这位霸道总裁的人生有点令人不敢直视。 12岁的他在做“炸弹”。1984年，南非一本名为《个人计算机和办公技术》的刊物发布了马斯克设计的一款游戏源代码。这款游戏名为“炸弹”（Blastar），灵感来源于科幻小说的太空场景。马斯克设计的这款游戏在计算机界并非出类拔萃，但显然超过了绝大多数12岁的孩子。 1995年，24岁的埃隆•马斯克进入斯坦福大学攻读材料科学和应用物理硕士课程，但在入学后的第2天，埃隆•马斯克决定离开学校开始创业。 在接受采访时，他认为互联网、可再生能源和太空探索这三个领域正在发生巨变（事实上他的确做到了，他的三家公司特斯拉、太阳能城市、space x），并且自己可以在这些领域有所作为。 长期以来，他一直想让世界知道，他和硅谷那些作坊式的创业者是不一样的。他并不是在顺应潮流，也不是为了发财，他是在追求一个整体的计划。 “我的确在大学期间就开始思考这些事情，”他说，“这不是事后编造出来的故事。我不想被看作一个新手，我不喜欢跟风和投机。我不是投资者。我喜欢把那些对于未来真正重要和有价值的技术，以某些方式变成现实。 马斯克所具备的世界观，同时也是硅谷很多创业者所缺乏的。 他是拥有远大抱负的天才。与其说他是追求财富的CEO，不如说他是指挥军队取得胜利的将军。当扎克伯格希望帮助你分享宝宝照片的时候，马斯克则是希望将人类从自我毁灭和意外灾难中拯救出来。 不怪乎，埃隆•马斯克被人称作是硅谷钢铁侠，脱去锁链的普罗米修斯。他在自传中写道： “我希望死在火星上，我想去那里参观一下，然后回来一阵子，等到我大概70 岁的时候再去，这样我就能一直住在那儿了。如果顺利的话，一切就会这样发展下去。” 好了，现在马斯克不仅可以完成梦想自己死在火星上，现在还可以带着我们一起死在火星了…… 《超级技术：改变未来社会和商业的技术趋势》 （诺贝尔物理学奖得主等科技大咖，预测未来30年的全球突破性技术：脑机接口、基因测序、机器学习、量子计算、智能制造…… 2050年，技术将如何改变我们的世界？） 【今日机器学习概念】 Have a Great Defination 
154,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657072&idx=1&sn=959d28892da396ae08a4188c0a421af1&chksm=bd4c34e38a3bbdf5afe879466840866e7a8872eda658c7fc45086b3713423a2ebe7e88547c91&scene=0,临近春节你为什么打不到车？概率论来帮忙！,"大数据文摘字幕组作品 马斯克已经让他的Tesla跑车飞上了天，然而地面上想打车的你，可能会发现随着春节的临近，越来越难呼唤到一辆车了。 加班需谨慎 要说打车，Uber是世界上最流行的打车软件之一。Uber必须不停地匹配搭车者和司机，并使他们能尽可能快地抵达目的地。 然而，现实世界充满了不确定性。雨雪啦，事故啦，很多事件的发生都可能影响车辆的供需。 许多目前的机器学习模型还是基于确定性的，但是现实世界的数据基本都是不完整的，或者某种意义上不完善的。 这样一来，在做预测（比如预测车辆供需）的时候，概率论就很有用武之地了。 贝叶斯推断能让我们在预测之前对现实世界有一个先验假设，并且能基于观测不断更新模型。 不久前，为了更好地适应现实世界的不确定性，Uber的团队开源了一种编程语言Pyro。Pyro是一种概率语言，使用Python和PyTorch构建。我们可以通过它，建立一个既可以扩展也十分高效的贝叶斯深度学习模型。 编程语言那么多，为什么偏偏还要开发一种？ 因为这种语言能适应不确定性建模——对于模型中两次同样的输入值，可能会有两个不同的结果。 Pyro程序的基本单位是随机函数，它帮助我们明确地计算给定输入的输出概率。 Pyro的问世，能否缓解打车难的问题呢？ 今天，就让我们一起来看看YouTube网红小哥Siraj Raval的视频：Uber Pyro概率编程入门。 视频附有代码，可以跟随一起练手哦。 时长8分钟 附有中文字幕 点击观看 ▼ Pyro是由Uber的人工智能实验室开源的。这个实验室来头也不一般，它最开始是Uber收购的一家创业公司Geometric Intelligence，这家公司的创始人是纽约大学教授Gary Marcus，不过他加入几个月后就退出了。对，就是那个挑起了对深度学习前景的质疑、引发Yann LeCun等各界AI人士论战的那个Gary Marcus。 (⊙ˍ⊙) 还不知道大佬们的互怼经过？可以点击下面的文章查看： Marcus十大理由质疑深度学习？LeCun说大部分错了 Gary Marcus再发万字长文，列14个Q&A回应机器学习批判言论 除了预测几小时后的打车需求和车辆供给，Pyro也被Uber用来做财务预算，它可以预测接下来几周的财务数据。 同时，Uber的其他业务条线也在利用Pyro，比如Uber Eats用它来预测食物的准备和运输时间；它也为无人车部门的工作做出了贡献。 Σ（ﾟдﾟlll）原来Uber搞出了这么厉害的东西！ 你猜Uber和Tesla的车谁能先飞起来？（被火箭带上外太空的不算） 我们的征途是星辰大海 这张图还是好燃啊！ So long, and thanks for all the fish! 原视频作者：Siraj Raval，大数据文摘经授权译制 原视频链接： https://www.youtube.com/watch?v=ATaMq62fXno 翻译： 狗小白、Barbara、唱歌的蔬菜 校对： 蒋畅 时间轴： 蒋宝尚 后期： 安琪 统筹： 龙牧雪 【今日机器学习概念】 Have a Great Definition "
155,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657024&idx=1&sn=6568bb91dc824d7326e5a956a0c9d167&chksm=bd4c34d38a3bbdc5e236080b748514b1ecf46cea0ad9b56961e5e96421bd58019567999e0a7d&scene=0,牛津大学人类未来研究所：万字长文谈AI新职场方向-政策研究,"大数据文摘作品 编译：Happen、Chloe、田奥、糖竹子、及子龙、林海、Aileen 最近两年，虽然AI这个词语充斥在人类的媒体和生活中，但实际上AI技术的发展才刚刚起步，目前AI能做的事情还非常初级。黑暗森林法则里的“技术大爆炸”不知道何时会突然到来，各种法律、伦理和人性都会受到前所未有的挑战。本文的团队认为未雨绸缪，在那个时代到来之前做好准备，现在开始制定最完善＂AI政策 ” 也许是对世界最有贡献的事情之一。 这是一篇来自牛津大学人类未来研究所的万字长文，由专注于研究AI政策的 Miles Brundage撰写，并获得八万小时（80,000 Hours，大学研究机构）团队和其他人员的帮助，希望给愿意从事""AI政策""行业的人们一些指导和方向。 现在能够改善世界的最具影响力事情，可能就是积极推动人工智能的发展了。在过去短短几年中，从事AI技术研究的人数急剧增长，他们致力于解决如何安全地规划人工智能，因此我们为正考虑从事这项工作的人提供这本指南。 还有一个很重要却很有可能被忽视的话题：AI政策和战略的改进。这包括了许多问题，比如： • 我们怎样才能避免为了发展强大的AI系统而开展危险的军备竞赛？ • 先进的AI系统带来的好处如何才能广泛分配？ • AI研究开放程度可以多大？ 我们估计，目前从事AI行业的人中，仅有不到10%特别关注未来开发出的高性能AI系统所产生的种种问题。越来越多的工作集中在更短期的问题上，如无人驾驶汽车政策和无人驾驶飞机政策。 我们迫切需要解决AI政策与战略相关问题，这是因为： 1.实施解决方案耗时长； 2.在AI还不够先进且这个话题涉及到较少的意见、利益的当下，有些问题会得到更好地解决； 3.我们不知道何时能开发出AI一些特定技能，无法排除突然技术大爆炸的可能性。 因此，对于合适的人来说，努力去解决这些问题，是为当今世界作出贡献的并且最有前途的职业之一。 “AI政策”是关于AI的社会决策制定的分析和实践（注意，广义上，我们说“社会”而不是政府，因为许多决策制定者都参与制定“政策”）。“AI策略”这个术语有时指的是研究“AI政策”的大局问题，例如：我们希望AI技术应该小范围传播还是广泛传播、那些研究问题应该优先考虑。接下来，我们将介绍“长期AI政策”底下的几个战略问题。文章结尾处的参考文献很好地介绍了AI政策及AI战略协议下的一些问题。 AI政策分为短期政策和长期政策。 短期AI政策侧重于当前社会需要解决的问题。这些问题包括无人驾驶汽车的责任问题、相对小规模的工人下岗问题、算法偏差以及越来越多的自动监控。 长期AI政策侧重于在未来的AI比今天更为先进的情况下，出现影响整体甚至更大程度的问题，尤其当AI快速发展的时候。这将产生非常持久的后果，例如与人类智力相当或超智能AI带来的AI安全风险或与不稳定性。 短期和长期政策之间的这种区别并不是一成不变的：比如，如果我们把高级AI出现的时间估计得过长，那么，最终本文提及的长期问题，就很有可能出现得比许多人的预期要早。事实上，AI专家们对高级AI出现时间的估计确实存在着较大的差异。也许，与安全问题相比，AI中最严重的经济问题可能需要更长的时间才能出现。 但是，短期或长期问题的划分是很有用的粗浅分类，它反映了普遍存在的观点，即认为与人力智力相当或者超智能AI不可能在短期内出现，然而，一旦它出现了，它将产生变革性、持久的社会影响。 大多数与短期“狭义AI”系统有关的政策，都不大可能对它们本身产生极其持久的影响，但是研究这些问题可能有助于获得经验，以便在长期的更强大AI系统的政策问题上开展工作，一些相同的政策框架和工具也适用于两者。另一方面，从长远来看，上文所提到的长期政策与战略比起短息的策略更加重要得多，尤其是当AI系统开发进展迅速时，就更可能如此。 在研究AI政策时，为了让你对于各种问题有所了解，请考虑以下问题。 如果未来的AI系统将拥有哪些能力，会造成哪些社会后果？例如，如果AI系统能够…将发生什么？比如： • 分析物理论文并提出新的实验？ • 在其他领域做同样的事情，包括AI开发？ • 分析社会科学论文、互联网内容和/或监测数据，对于不同情况下的人类行为作出预测？ • 为了说服特定人群相信某些特定观点而生成语言及图片？ • 分析各种领域和来源的文献，以生成新材料、技术或软件？ • 有计划划的进行以上这些事情？ • 拥有比人类更多的技能，能够低成本、高效并可靠地找到电脑系统的漏洞，这种AI系统可能性有多大？哪种指标能够在这方面提供最新消息？ • 国家或非国家行动者应采取哪些措施来防止这种情况发生，并/或减轻潜在的负面影响？ • AI系统是否能够在提高抵御黑客攻击能力方面提供帮助？与此同时，AI能否协助开展黑客攻击？在某种程度上，黑客与拥有敏感数据的机构之间存在“计算军备竞赛”，是否应该给后者提供补贴或监管，以增加他们现有的计算资源？ • 在近期、中期以及长期中应该发展哪种自动武器？哪种指标能够在这方面提供最新消息？ • 不同种类的自动武器可以有哪些应用？例如，哪种自动武器可能应用到空中支援、巷战、侦察、监视被占领土、暗杀或其他秘密行动上？ • 考虑到自动武器的种类和应用，它对世界和平与安全有哪些影响？ • 拥有能力更强的自动武器将有哪些潜在优势（更高的精确度、更少的人员死亡、减少对人类士兵的需求）与潜在劣势（更容易发生战争、潜在的地缘不稳定性，例如军备竞争、意外风险、滥用）？ • 相对廉价的自动武器开发，是否有可能导致私人更容易获得武器，并更具有破坏性？为了防止这种可能性，应该采取哪些监管措施，何时实施比较合适？AI发展的哪些指标表明了这种行动的正当性？ • 从其他新武器技术（例如核武器、化学武器、地雷）的发展以及国际监管的回应中，我们能够吸取哪些相关经验教训？ • 在限制或停止自动武器的开发与部署方面，存在哪些可行的途径？限制开发的做法是否一直可取？推动其地下开发或者转移给不那么负社会责任的政党，是否风险太大？ 一个在广泛领域中具有创造性的长期推理能力的AI系统的行为是很难被预测的。一旦这种强大的AI在行动时有目标偏差，结果可能将会造成全球灾难性风险。 即使AI系统与用户追求一致，运行一个有明确目标的AI系统仍旧可能导致非法行为，这对于没有仔细检查系统的人来说是难以预料的——甚至那些做过检查了的人。例如，一个目标为“赚钱”的AI系统可能会为了这个目标而触犯法律，尽管在系统开发与测试阶段，发生这种情况的迹象可能不明显。 介于上述考虑，开发和部署这种具有潜在危险性的系统，就合作和冲突产生了一些重要的问题，例如： • 在开发和部署安全AI时，如何激发相关角色之间的合作精神？ • 基于博弈论的国际竞争与合作如何形成与分析？ •相关的多方机构之间就构成部署AI系统潜在风险的因素达成预先协议是否有帮助，在哪种条件下这种部署是合法的？ • 多方机构之间的哪种协议具有强制性？ 问自己一个关键问题： 粗略概括为四种主要角色：直接研究、在政府和企业内工作、宣传及协助招聘。 你可能对研究AI政策有兴趣：分析AI短期和长期的战略考虑，评估提出的解决方案，并给出新的方案建议。或者你有兴趣在政府工作——从各个利益相关方收集信息，与政府其他部门同事商议哪些方案可行，再直接实行方案。你可能想在企业做这些事情，而不在政府。再或者，你想做政策宣传——扩大宣传好方案的声音，提高公众对特定问题重要性的认识。或者你想做招聘——帮助人们做这些选择，为求职者和雇主牵线搭桥，使人们确信AI政策以及其中的某些问题非常重要。 由于目前值得倡导的提案非常有限，与宣传相比，战略分析、制定并实施可行方案在当下可能有更多的长期价值。然而假以时日，宣传最终会很重要，多个利益相关方都要参与确立首选方案。不同技能适用于这些不同的解决方法，而有些是通用技能，如AI知识、写作能力、互联网熟练度。现阶段，强烈建议有研究经验的人考虑上述各种研究问题，有其他技能的人也可以在许多潜在领域有所作为。 下文举例说明在AI政策领域可以做些什么，并特别关注研究和实践两大方面。 笼统地说，这一职业发展道路包括成为专家、并推动AI政策思考及干预过程不断向前发展。在举例列出具体研究领域和可能感兴趣的雇主之前，先说明你可以在政府、企业、学术界或是非盈利组织做这一工作。通常，政府不在新的政策思路发展的前沿，至少对长期AI政策而言是这样，但随着AI安全性和经济相关性日益受重视，这点可能会改变。注意你可以跨过研究和实践的界限——贡献构思的同时也实施解决方案。 如果你有兴趣做短期政策研究，比如在这一领域建立直接影响力或专业可信的形象，你可以在各种机构工作。我们认为着重于短期的工作不太可能有很大影响力，因为到现在已经受到足够多的关注，但对很多人来说，为获得技能和信誉从而能研究更紧迫的问题，这是必要而有用的一步。 至于哪个机构或部门能使你取得最大的影响力，没有一个清晰明确的第一名，比如你的兴趣、你知识储备的领域、职位细节、你的国籍（如果想在政府工作）及其他因素也起作用。因此，致力在AI政策领域工作的人应该适应AI领域的变化。对此，我们提出了一些建议。例如，两年前OpenAI还没产生但现在已经是AI领域的重要角色，中国AI行业整体也在迅速发展。 正进行或即将进行这些研究的相关机构，以及有发展机会的地方，举例如下： • 牛津大学，正对未来的工作进行大量的分析； • 各种智库，比如布鲁金斯学会、新美国安全中心、数据与社会、国际特赦组织和阿兰图灵学院； • 咨询公司，比如麦肯锡； • 谷歌、DeepMind、微软、OpenAI、百度、腾讯、亚马逊等公司，以及非营利组织； • 美国联邦航空局，无人机方面； • AI合作组织（The Partnership on Artificial Intelligence to Benefit People and Society） 当然，在任何大学都能做学术研究，但是，在一个人才充足的相关问题研究团队中工作能带给你很多帮助。拥有这种研究团队的大学包括牛津大学、剑桥大学、加州大学伯克利分校、麻省理工学院、华盛顿大学和斯坦福大学。如你认为自己能得到一个以上这样的工作，建议你找开放式工作，这样你既能与技术专家保持密切联系以便调整自己的研究，同时能灵活决定自己的研究目标，影响相关组织的研究方向（而不是钻进牛角尖）。 对于长期政策及战略研究，并没有多少严肃的研究工作正在进行，短期内也看不到会出现太多严肃研究的苗头。以下名单几乎囊括全部： • Superintelligence的作者Nick Bostrom教授创办的牛津大学人类未来研究所（下文简称FHI）。 FHI /耶鲁大学AI全球政治研究小组有意聘请研究员、研究助理和实习生，研究方向是AI战略及政策，特别是长期战略问题。查看现需职位并订阅新职位开放通知。可随时向FHIjobs@philosophy.ox.ac.uk发送简历和研究兴趣简述。 • 剑桥大学生存风险研究中心和位于剑桥大学的利弗休姆智能未来中心，研究有关AI安全性的技术和战略问题。查看现需职位并订阅新职位开放通知。 • Alphabet旗下的DeepMind可能是规模最大、最先进的强机器智能研究团队。团队有一些专门研究安全和道德问题的工作人员。查看现需职位并订阅新职位开放通知。Google Brain是Google的另一个深入学习研究项目。 • OpenAI，2015年成立，旨在“建立安全的AGI（强人工智能），确保AGI的利好被尽量广泛均匀地分配”。OpenAI已从科技界获得10亿美元资金承诺。 • 全球灾难性风险研究所（CGRI）是一个无党派智库，旨在降低大到严重危害甚至毁灭人类文明的事件发生的风险。 如在政府从事这项工作，无法指出哪里最好，但可以是国防界和情报界（如美国情报高级研究计划局、美国国防高级研究计划局、美国国防部净评估办公室）和美国白宫科技政策办公室（OSTP），后者发布了《时刻准备着：为了人工智能的未来》报告。这三者在AI领域都有影响力，已经资助并开展相关研究。在美国国家科学基金会、美国国土安全高级研究计划局、美国海军研究局以及美国数字服务小组也对决定哪些研究项目拨款施加影响。 AI合作组织很可能在促进关于这些问题的讨论和共识建立上起到一定作用。至于它会否进行大量内部研究，尚不清楚。 虽然通常在上述组织中，至少有一个会发布空缺职位，但你也应尽量广撒网，了解哪些职位将会公布、哪些职位没有大范围公布。上述考虑同样适用于衡量工作机会的优劣—— 例如，与技术专家的接触程度，甚至对长期问题而言，与技术专家保持密切联系都非常重要，以确保你的工作符合合理的AI应用前景。然而，如前文所述，专家意见各不相同，所以你也应尽力观察AI趋势、独立而批判性地思考，多去理解合理的AI应用场景的范围，少作具体预测。 除了制定和评估政策外，还需要有人落实政策。 最终，你想得到可能的最有影响力且最相关的职位。在其它条件相同时，你在政府或主流AI公司的职位级别越高，AI成熟后你能决定政策的可能性就越大。 以下具体步骤以供考虑： 短期政策实践选择 参见上文讨论的政府机构，比如无人机和自动武器系统政策落实到的机构。也应考虑地方和州政府，国际机构（比如联合国裁军研究所、联合国裁军审议委员会），非营利组织如阻止杀手机器人运动、劳工部、美国国内政策委员会（及其他地方的同等机构），以及主要国家的国家立法机构。 如果你的目标是发挥最大作用，那么地方和州政府的工作、小企业的工作，只是获取经验的途径，而非目的。也有特例，包括特别杰出的司法管辖区（如美国加利福尼亚州），它能给其他各州或联邦政府提供示范，也包括发展前景特别好的初创公司。 此外，私企和非营利组织目前扮演重要角色，至少近期内很可能仍是AI行业发展的领跑者。因此如果你有兴趣将政策落到实处，那么应该首选Google、DeepMind、微软、Facebook和OpenAI这一类作为理想工作处。 长期政策实践选择 如果你的目标是在将来实施人工智能政策，那么，现在还不好说在哪里工作最好，因为这将取决于在这些年间制定和提出的各种政策。但是，杰出国家的立法和行政部门（例如内阁，美国国家安全委员会，科学技术政策局，美国国会），联合国（目前正在成立一个犯罪和司法研究所下属的AI中心）和欧洲委员会，以及一些关键性的企业应该被纳入考虑范围之中。 在申请或考虑接受工作时，请务必寻求有关行业和政策趋势的意见，以确保进入比较贴近实用的组织机构工作。对于那些还没能在长远AI问题上获得相关行业资质的人来说，在未来几年内想办法获得知识和经验是更有意义的事情，而不仅仅是为了尽快地到一个最有潜力的组织机构工作。要让长期的AI政策实践而不是政策研究变得尤为重要可能还要很长一段时间，而且将来有更多信息来让你辨别哪些组织更接地气。 AI政策不是一个非常成熟的领域，它涉及了许多其他学科。理想情况下，你会熟悉许多学科，并且至少在一个领域内具有深厚的专业知识。例如： 毫不奇怪的说，要做AI政策工作，最好要知道AI的科学技术概况。这将有助于你将炒作与实际情况分开，对其现状形成良好感觉，并且可以更加明智地思考这个领域在将来会如何演变。 这些学科可以帮助你了解不同机构在处理人工智能方面问题的作用及其制约（例如国内政治学和比较政治学相关子学科）和国际问题/动态（国际关系是一个相关的子学科）。科学和技术政策的子领域与AI政策极其相关，并提供了大量可供学习的案例以及一些基础性的概念框架。在诸如核武器竞赛和国际网络冲突等政治学领域，有许多类似的问题，这些问题与长期的AI政策相关，而且这两门学科的本科/研究生课程都倾向于强调统计分析和博弈理论等工具，可能对AI做出政策分析有用。 这是许多在AI政策上工作的人所具有的背景。例如，有一个我们机器人年会系列，主要由法律学者组织，研究AI（主要是短期的）法律/政策问题，如责任，问责制，军事等问题。面对组织需要处理的AI相关细粒度问题，法律对于促进深入思考是有用的，而政治学和公共政策倾向于在更高的抽象层次上运作。理解法律还允许人们识别各种工具和杠杆来影响AI开发和部署。最后，国际法作为对国际关系的补充，提供了有关国际规范的一些有洞察力的观点，这些准则可能会形成并约束任何大型政府的先进AI的决策程序。 当仔细思考工作的未来时，经济学是至关重要的。但是，在广泛的经济学文献中也有可能对其他AI政策问题有所了解，如工业组织和博弈理论。尤其是游戏理论在具备了非常先进的人工智能后可以用来映射思考一些关于协作的问题。 以上只是相关学科的一些例子，但其他有关学科包括科学和技术研究，这是一个实证/概念领域，旨在促进对科学技术在社会中的作用的科学思考和科学家和工程师的决策过程；社会学和人类学，在考虑人工智能的社会和经济影响时尤为重要；心理学有助于研究小规模的人工智能所产生的影响，并了解人类与AI和机器人的如何交互作用，从而反过来可能会形成适应的政策和这个主题框架；媒体和传播学，与研究公众对AI的态度有关，以及更强大的有说服力的AI系统的潜在影响。 哲学家有能力以严谨的方式构建人工智能政策问题，伦理与分析何种未来更为美好直接相关。诸如尼克·博斯特罗姆和托比·奥德这样的AI政策工作中的很多研究人员在其他领域都有哲学背景。 现在以及将来的一个特别关键的研究领域涉及到人工智能的安全隐患问题。未来AI可能会在这些领域更大程度上地使用，而且更为重视安全决策。目前，在AI政策领域，安全和情报研究专家和国家安全执法领域还没有得到充分的重视。 如果你不能直接进入顶级政策职位，以下是你可以在该领域建立职业资本的一般步骤。 我们对这一领域任何人士的主要建议都是深入浅出的：尽可能多地学习，与其他对AI政策感兴趣的人进行交流，培养自己的技能、想法和相关工作经验，并尝试阐明和解决问题。 除此之外： AI政策是新颖的和迅速变化的，如果你正在寻找这方面的工作，你应该能够找到合适的人，以找到工作机会或被推荐。因此，如果经济上允许的话，就去参加AI大会并参加有关政策性问题的会议；与AI研究人员交谈；参加Facebook相关主题讨论群组，如人工智能安全；与圈内人员联系，谈谈你们的工作；即使没有空余的职位，如果你认为可以为将来增加价值，也可以表示出对工作的兴趣。 与人事政策研究与实践“前线”人员的交流是非常宝贵的，因为对这个话题的大部分分析还没有公布，所以考虑去人类未来学院这样的地方实习（或至少考虑注册他们的空缺职位资讯，上面会列出他们组织和其他地方的工作机会，包括实习和志愿者工作）。参加你的“本专业”学科或行业的会议和研讨会，以找到对AI感兴趣的其他人也是有价值的，帮助在其他领域工作的人员了解最新的发展情况，并找到可能的合作者。 如前所述，你将需要在一定程度上集中精力，了解最先进的技术状态，合理的趋势判断对于选择关注正确的问题来说至关重要。跟随AI发展的简单做法是订阅杰克·克拉克的Import AI资讯 （编者注，或者关注“大数据文摘”微信公众号），并遵循一些引导，如果你还不知道什么是“热点”，还要查看arXiv Sanity Preserver，它会过滤最新的上传到预打印的网站arXiv上的文章。 对于那些对术语背景知之甚少的人，参加Peter Norvig和Sebastian Thrun或Andrew Ng的在线课程可能是一个好主意。 一个粗略的经验法则是每周阅读三篇左右AI论文，以了解领域中发生的事情，人们使用的术语，以便能够区分真实和虚假的AI新闻。关于AI术语，你的目标应该是至少达到可互动级别的专业 - 基本上是能够在会议中进行非正式对话以通过AI研究员图灵测试，即使你无法自己撰写新奇的研究论文。 请参阅下面的阅读材料清单。不幸的是，没有一本关于人工智能政策的规范教科书，你可以阅读以了解基础知识，也许那些关键的观点并没有包含在上面提到的学科中。所以广泛地阅读你不熟悉的领域，同时也利用你现有的专业知识。如果你刚开始（例如本科生），你可以考虑在主修计算机科学专业同时辅修政治科学，公共政策或经济学等专业，同时在这些领域之外广泛阅读。但是，要采取哪些课程以及主修哪些课程取决于你的特殊优势和可选项（例如你所在学校的课程）。 为了了解如何制定政策，除了在政府或公司任职别无他法。许多有关例如“拉动哪个杠杆”，哪个是关键人物，什么问题在政治桌面上/下面的等等方面的知识，都不存在于书籍和文章，而是存在于处理这些问题的人身上的隐性知识。如果你可以在白宫，国会，联邦机构，地方/州政府，与政府进行互动的宣传团体，公司的政策/法律部门等地方实习，那么请努力争取。 在美国，AAAS科学和技术奖学金是博士们获得政策相关经验的一个成熟媒介。公共关系也是与政策密切相关的一个领域，在此领域中获得经验是很有价值的- 实际上，面向不同领域的团队往往会在公司和政府中共同合作。 在英国，政党政治（例如议会助理）和/或公务员制度（例如在商业，能源和工业战略部工作）方面的经验可能是有帮助的。 同样，将利益相关者聚集在一起讨论问题的经验也是有价值的，这种经验可以来自私营部门或智囊团。另一个经验来源是开展政治活动，这可能是沟通，政策研究，言语写作，联盟建设，事件管理，团队建设等方面所需技能的重要来源。 最后，在一家类似谷歌的主流技术公司担任战略职务，即使最初的工作并不与AI直接相关，也将对转向AI政策行业提供很大帮助。你需要权衡取舍是将时间花在解决研究问题上还是在积攒相关经验上，但如果对AI政策感兴趣，有条件的人应该努力在实际政策问题上积攒一些工作经验。 这一部分总的来说将介绍两种典型的进入AI政策领域工作的方法——从一名AI研究员转变为一名AI政策研究员/从业者，或者从其他领域的政策研究员/从业者转向关注AI政策问题。 有AI技术背景的人在政策工作中是重要且稀缺资源。然而，这份工作需要一定的政策专业知识。一种方式是寻找有政策专业知识的同伴或组织，加入他们并从中学习。总体来说，建议对政治和政策都有所涉猎。先了解政策问题的整体形势，再根据自己对不同领域的适应性和重要性判断主攻哪个方向是非常有效的方法。文末推荐的阅读资料对这种方法会有一定帮助。 我们认为这会是一个充满激情的职业生涯，它为少数有强硬AI技术背景的人提供了在政策领域工作的机会和创造“元”价值的机会。相比研究一个个的技术项目，有些人通过帮助AI组织发展，倡导国家AI研究还有在国际层面沟通解决问题，能在AI领域能创造更大的影响力。 对于拥有其他政策研究背景的人，想转向AI政策研究应当迅速了解AI政策问题的大致轮廓（详情可参考资料列表）并且找到自己想要深入研究的方向。AI是一个令人兴奋的领域，它的政策环境也将随着新的技术成就而迅速转变。因此，打下坚实的技术基础并且密切关注事态发展是非常有意义的。 除去上述建议，为了有政策研究背景的人能够快速熟悉AI领域，还有一些非常有效的方法：学习AI在线课程，参加相关课程培训（有些大学开设了相关课程，并且大型公司有时也会提供培训机会）或者读一个AI的硕士课程。另外，参加We Robot 和Governance of Emerging Technologies 这类会议对他们也十分有帮助，能让他们对AI政策与原研究领域的相似和不同之处有更好的认识。 以下资料列表可以根据个人背景情况和理解能力选择阅读。如果你致力于AI政策事业，我们选择的这些行业内有代表意义的材料，应该会让你感到有趣。如果你对这些内容感到无聊枯燥，那可能是一个糟糕的信号。另一方面，如果阅读这些材料后你感到讨论的内容十分重要，或者在这些文献中发现能用自己的专业能力补充相关内容，将是很赞的开始。 一个需要注意的地方是列表中有些相当专业的内容与专业研究AI政策更加相关——例如，一些AI课程教材会比较难懂，而《为人工智能的未来做好准备》这类报告对入门者来说更加容易理解。在以下各板块中，我们大致对提供的材料按照初级到高级进行了排序。 我们的建议是先查看一些资料，找到自己的兴趣点，再决定进入哪一领域并阅读大量相关信息。 在介绍并列出相关课程、书籍和论文后，我们也给出了科技政策课程的教学大纲案例，这些大纲提供了更加广泛的文献指引。 视频 • Beneficial AI 2017会议视频（多场演讲） https://futureoflife.org/bai-2017/ • Nick Bostrom的《AI中的道德伦理》，纽约大学Virginia Dagnum, and Yann LeCun的公开讨论会 https://www.youtube.com/watch?v=RXCqKwMHpb0 • Miles Brundage《AI政策的远期规划》，多人演讲 https://www.youtube.com/watch?v=RXCqKwMHpb0 书籍 • Bostrom, N.《超智:规划、危险与策略》（2014） 此为对长期AI政策有兴趣的必读书籍 • Erik Brynjolfsson and Andrew Mcafee《第二次机器时代》（2014） • Lin, P., Abney, K., and Bekey, G. (eds).《机器人伦理：社会和政策对机器人学的影响》 (这是一篇很好的关于AI和机器人学的道德伦理与政策问题的介绍。包括对自动武器和社会服务型机器人的讨论。 • Russell, S. and Norvig, P. 《人工智能入门》第三版（2010）；Goodfellow, I., Courville, A., and Bengio, Y.《深度学习》，（2016） 这两本书是最好的了解人工智能背后应用科技的书籍。Russell and Norvig’s的教材被各类AI课程采用而且介绍了许多重要概念和术语。然而它对深度学习少有介绍，因为编写时期AI这一子领域还未像现在这样热门。Goodfellow et al的课本是关于深度学习最好的材料，网上也可找到免费资源。技术背景相对较弱的同学可以先观看AI网络视频，例如Norvig and Thrun’s 网络课程和Andrew Ng’s网络课程。 • Neal, H., Smith, T. and McCormick, J《除了卫星：二十一世纪美国科技政策》 Howlett, M. et al. 《公共政策研究：政策周期与政策子系统》第三版 第一本书概括性描述了美国科学政策的历史、机构和相关问题。而第二本书介绍了更多公共政策原理，包含什么是公共政策、怎样实施公共政策以及政策是怎样变化的。 文章和报告 • 2016年白宫发表《为人工智能的未来做好准备》 这篇报道反映了全美四家研究会为白宫总结的当下顶尖的AI短期政策思路。英国和欧洲政府也有发表相关文件，但白宫的报告是公认最优秀的一篇。报告对一些值得认真评估的短期和长期政策关系发表了相关声明（例如，我们应当不计时长的致力于同一件事）。 • 其他政策报告： o 当代AI报告（2016）：近期人工智能科技对社会和经济造成的影响 o 英国下议院科学技术委员会2016年报告：机器人技术与人工智能 o 经济学人（2016）：人工智能特别报告 • Bostrom, N《AI发展开放的战略意义》 尽管AI学者们在关于促进分布式控制、人工智能带来的福利和降低AI安全风险等不同目标上意见分歧，但开放是AI政策永恒的主要问题之一。这篇文章是相关战略问题最好的入门读物。 • Bostrom, N., Dafoe, A., and Flynn, C.《发展超智机器的政策需求》 这篇文章对长期AI政策评估提供了总体框架，并且强调了在未来几年会影响AI发展形态的几项主要研究内容。 • Brundage, M. and Bryson, J. 《人工智能的智策》2016 这篇文章描述了当今美国短期“实际意义”的AI政策的概况（一些政策可能没有以AI的名义出台，但对其实际产生了影响）并就加强政府相关专业技能提供了一些建议。文章也提到了其他相关文章，例如无人驾驶汽车政策。 • We Robot会议论文，主要讨论了短期AI政策：  这里是2016年会议内容和2017年会议内容。 大会是法学界关于人工智能和机器人学举办的重要会议。2018届会议将在斯坦福召开。 AI法律、政策和伦理 • Burton, Emanuelle, Judy Goldsmith, Sven Koenig, Benjamin Kuipers, Nicholas Mattei, and Toby Walsh. 2017《人工智能课程的道德思考》arXiv:1701.07769 [Cs]. • 纳什维尔范得比特大学法学院法律与创新项目组教学资料与讨论案例。 其他阅读清单 • 全球AI政策参考书目  http://www.allandafoe.com/aireadings • 80,000小时AI安全技术大纲  https://80000hours.org/ai-safety-syllabus/ 汇总了大量关于AI政策和策略的工作 • 科学技术政策大纲 o Andrew Maynard的《高等科学技术政策 》 https://sfis.asu.edu/sites/default/files/hsd_502_s16.pdf o David Hart的《科学、技术和公共政策》 https://schar.gmu.edu/sites/default/files/current-students/Courses/Spring_2017/PUBP/Hart-PUBP-710-002-Spring-2017.pdf • 机器学习的公平性、责任心和透明性（FATML）-教学大纲和资料 o 哥伦比亚大学奖学金项目《关于机器学习的公平性、责任心和透明性》 http://www.fatml.org/resources.html o FATML相关项目奖学金列表  http://www.fatml.org/resources/relevant-scholarship 你认为一个聪明的人可以独自推动这些议题还是不得不加入某个团队？ 我认为会是独自推动的形式，因为这个领域还没有得到充分发展。因而，相关议题的解决需要很强的自我导向。那些对这个问题很有兴趣并且特别具有自我导向的聪明的人，我相信投入50-500个小时进来去测试一下取得进展的能力，是一个合理的行为。 什么类型的独立研究项目最让你为看到人们在这些问题上努力而感到兴奋？ 有人写关于以上话题的论文并且给这些问题一些有帮助的广泛的概述（很好的解释他们，全面的讨论不同的方法，在一个高的水平上讨论各方法的优缺点）或者攻克一小块他们可以详细解释或者有独到看法的内容。 在你看来，目前AI政策领域最大的突破是什么？ 我认为一系列具有交叉性的思考非常重要。我认为单个最重要的战略思考是：快速的开始可能使某些人或者某些事获得决定性战略优势（其中某些事可以是为了某个目标AI系统的最优化）。另一个也同样是最重要的事是，存在一个排列的问题，这个很难，但是我们在实现超级智能系统之前我们需要解决它。 哪三个人选你认为最有潜力在AI政策方面可以做博士生导师？ 我不认识很多能在这些领域带学生的人，尤其是那些对于变革性AI感兴趣的人。我猜Allan Dafoe可能是最好的人选。也可以考虑在剑桥大学获取博士学位，即使没有该领域背景的指导老师的情况，也可以同时寻求机会与FHI合作。 Helen Toner曾经提出的一些建议： 上面提到的UCLA的PULSE团体，斯坦福的CISAC，伯克利的长期网络安全中心，宾夕法尼亚大学的Perry World House也是一定的自我导向研究能力，并令人信服（也许不是去读博士，而是做博士后）。 对于正在开始AI政策职业的人，你有什么大多数其他人不会给的建议？ 试着独立研究一个相关的问题几个月。如果资金是一个瓶颈的话可以通过EA Grant申请资金或者试着为此筹集资金。 但是独立工作不意味着拒绝寻求建议，最好去和尽量多的在这些问题上有深刻思考的人去交流。 如果你想从事AI政策工作，擅长政治有多重要？ 对于所谓的从业者会相当重要，但是对于研究员重要度会小一些。 不同“开放”程度下，从事AI工作的相关组织成本和收益是什么？ 一个组织是不是应该发表论文，公布他的源代码，和大学等其他组织合作，这些取决于它工作有多么高级，多么接近上面所说的AI的重要类型。 开放会推动科学快速发展（通过共享好的东西），减少威权主义和AI诱发的单极性风险。但是也会增加AI被恶意分子滥用和技术竞赛的风险。 对于什么样的开放是受欢迎的拥有一个完善的原则，怎样是令人满意的，在什么时候，什么条件下开放，将能够便利人们更容易践行开放的受益形式，而不会产生未来开放形式的问题。我们有兴趣分析一个组织开放的各种方法以及潜在的代价和益处。 其他的风险： 上面的部分指出了种种高级AI系统潜在的风险，下面我们列出了三个其他的广泛的风险： 对于十分强大的AI系统失去控制： AI系统将在大范围的环境下变得更加强大，可以使他们以创新的方式达到特定的目标。但是，设计出可以被人类有意识的控制的AI系统，并能够可靠地避免负面影响，将会很有挑战性，尤其是当AI系统的能力和可能影响的方面超越了人类的预见能力。设计鲁莽的系统会将限制他们的人类设定为需要克服的阻碍，追求不合理目标的强大AI系统对于人类也将非常难以控制。相较于现在的电脑蠕虫或者网络犯罪，被用于错误目的的AI系统理应被认为会制造出困难（很有可能更大的困难）。如果被错误使用的AI系统变得足够强大，他们对于目标的追求有可能严重的危害人类长久的未来。对于我们有可能会严重到人类的毁灭。 逐渐地丢失对于社会方向重要的把控： 逐渐失去对社会方向的有意义的控制：随着越来越多的控制逐渐被分解为复杂而难以理解的AI系统，这些系统追求的是实现我们的目标（比如利润最大化），人类可能丢失对于我们社会发展方向做出有意义的集体决定的能力。最新出现的关于基于种族或者性别产生歧视的AI系统就是这个趋势一个早期的例子。基于个人爱好口味预测进行特定消息推送过滤器事件也是一个例子。如果我们设计的系统忠实而透明地反映我们价值观的技术能力远远落后于我们的决策自动化的能力，那么这可能会给文明的轨迹带来长期的问题。 AI系统的道德相关性： 目前，关于什么类型的非人类可以算作“道德相关“基本没有达成一致（黑猩猩？猪？蚂蚁？）。尽管对此没有很好的定义，但是我们发现一些AI系统在某些方面变得具有道德相关性貌似是合理的。如果发生，对AI系统应该如何设计和使用将会产生重大的影响，对于特定的AI代理需要一些保护。例如，它可能廉价的复制AI “工人”；如果这样，他将降低这些“工人”可以从事的劳动的价值，潜在的创造一个情景，在其中AI “工人”只能有维持生活的基本收入（比如，足够支持硬件和电的成本）。这种情况值得避免的程度直接和AI系统值得被定以一定的”人权”的程度紧紧相连。 致谢 Miles Brundage是本篇指南的作者，感谢Jan Leike, Jelena Luketina, Jack Clark, Matthijs Maas, Ben Todd, Sebastian Farquhar, Nick Beckstead, Helen Toner, Richard Batty, David Krueger, Jonathan Yan, Brittany Smith, Robert Wiblin, Carrick Flynn, Allan Dafoe, Niel Bowerman, 还有Michael Page对本文早期版本提供的宝贵建议。他们对最终版本的内容仍保留各自的意见。 原文链接： https://80000hours.org/articles/ai-policy-guide/ 【今日机器学习概念】 Have a Great Definition "
156,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657005&idx=1&sn=03fca88281c95daed5523603bcf6102d&chksm=bd4c34be8a3bbda8d13975e6aeee8ffbdff843cb7ca06507e4dba03429cf28e2e19db6df49db&scene=0,手把手：我的深度学习模型训练好了，然后要做啥？,大数据文摘作品 编译：姜范波、云舟 本文讲的是如何快速而不求完美地部署一个训练好的机器学习模型并应用到实际中。如果你已经成功地使用诸如Tensorflow或Caffe这样的框架训练好了一个机器学习模型， 现在你正在试图让这个模型能够快速的演示，那么读这篇文章就对了。 阅读时长： 10-15分钟 使用前检查清单 检查tensorflow的安装 从 stdin 运行在线分类 在本地运行分类 把分类器放到硬编码（hardcoded）的代理 把分类器放到有服务发现（service discovery）的代理 用一个伪DNS调用分类器 机器学习的实际应用 当我们第一次进入Hive的机器学习空间时，针对我们的实际应用场景，我们已经拥有了数百万张准确标记的图像， （即随机权重）。然而，在更典型的应用场景中，图像的数量级通常只有数百幅，这种情况下，我建议微调现有的模型。比如，https://www.tensorflow.org/tutorials/image_retraining有一个关于如何微调Imagenet模型（在1.2M图像上训练1000个类别）以对花进行分类的样本数据集（3647个图像， 5个类别）。 上面的Tensorflow教程简要而言，是在安装bazel和tensorflow之后，需要运行以下代码，用大约30分钟的来建模，5分钟来训练： 或者，如果你安装了Docker，则可以使用以下预构建的Docker镜像： 这将进入容器内部的交互式shell中并运行上述命令; 如果你愿意的话，也可以按照容器内的其余部分进行操作。 现在，tensorflow已经将模型信息保存到/tmp/output_graph.pb和/tmp/output_labels.txt中，这些作为命令行参数传递给label_image.py脚本。Google的image_recognition教程也链接到另一个脚本，但是这里我们仍将使用label_image.py。 将本地运行转换为在线运行（Tensorflow）   如果我们只想接受来自标准输入的文件名，每行一个，我们就可以很容易地进行“在线”运行： 然而，从性能的角度来看这样糟糕透了——  当然可以改进。先修改label_image.py 脚本。对我而言，这个脚本的位置在： in bazel-bin/tensorflow/examples/image_retraining/label_image.runfiles/org_tensorflow/tensorflow/examples/image_retraining/label_image.py.   修改如下： 141 :   for  line in sys. stdin : 修改后马上快了很多，但这还不是最好。 原因在于用with tf.Session（）构建对话。Tensorflow本质上是在每次调用run_graph时将所有的计算加载到内存中。一旦开始尝试在GPU上进行运算，这一点就会变得很明显—— 据我所知，这种结构并不存在于Caffe或Pytorch框架中。 解决方法是把with命令去掉，传递一个sess变量到run_graph： 如果你运行完这一段，你会发现每张图只需要大约0.1秒，对于在线应用来说已经够快了。 将本地运行转换为在线运行（其他ML框架） Caffe使用net.forward代码，很容易被放入一个可调用的框架中：see http://nbviewer.jupyter.org/github/BVLC/caffe/blob/master/examples/00-classification.ipynb Mxnet也是非常独特的：它实际上已经准备好了面向大众的服务器代码。 部署 我们的计划是，将这些代码包装到一个Flask应用程序中。如果你没有听说Flask，简单解释一下， 作为一个快速参考，这里是一个Flask应用程序，它接收包含多部分表单数据的POST请求： 这里是如何将相应的FLASK应用程序连接到上面的run_graph： 模型部署至此看起来还是相当不错的。除了一点——需要FlASK和Tensorflow完全同步——Flask按照接收的顺序一次处理一个请求，并且Tensorflow在进行图像分类时完全占用线程。 速度瓶颈可能还是在实际的计算工作中，所以升级Flask包装代码没有太多的意义。现在，也许这个代码足以处理你的负载。 有两种显而易见的方法可以扩大请求的通量：通过增加工人数量来横向放大，这在下一节将会介绍，或者通过使用GPU和批处理逻辑来纵向扩展。实现后者需要一个能够一次处理多个待处理请求的web服务器，并决定是否继续等待更大的批处理或将其发送到Tensorflow图形线程进行分类，对于这个Flask应用程序是非常不适合的。有两种可能性：使用Twisted + Klein来保留Python代码，或者如果你更喜欢一流的事件循环支持，并且能够连接到非Python ML框架（如Torch），则可以使用Node.js + ZeroMQ。 扩展：负载平衡和服务发现   那么，假设现在你只有一台服务器来部署模型，由于它太慢了，或者我们的负载变得太高了，此时你想要启动更多服务器——如何在每个服务器上分配请求？ 常规的方法是添加一个代理层，也许是haproxy或nginx， 为了在本节稍后使用，以下是运行基本Node.js负载均衡器http代理的一些示例代码： 为了自动检测后端服务器的数量和位置， 设置和学习使用它们不在本文的讨论范围之内，所以我使用了一个非常基本的，通过node.js服务发现包seport实现的代理。 Proxy代码： Worker代码： 然而，当应用于机器学习时，这个设置遇到了带宽问题。 每秒几十到几百张图像，这个系统就会成为网络带宽的瓶颈。在目前的设置中，所有的数据都必须通过我们的单个seaport 主节点，这也是呈现给客户端的端点。 为了解决这个问题，我们需要我们的客户端不要访问http://127.0.0.1:12480这个端点，而是要在后端服务器之间通过自动轮换来访问。如果你懂网络，一定会想：这不就是DNS干的活嘛！   但是，设置自定义的DNS服务器已经超出了本文的范围。相反，通过更改客户端以遵循两步“手动DNS”协议，我们可以重新使用我们的基础版的seaport 代理来实现客户端直接连接到其服务器的“点对点”协议： Proxy代码： （Worker 代码同上） Client代码：   结论和进一步阅读 至此你的系统应该可以进入实际应用了，但它总是要发展的。本指南中未涉及几个重要的主题： o   值得注意的工具包括Openstack / VMware（如果您使用的是自己的硬件），Chef / Puppet（用于安装Docker并处理网络路由）以及Docker（用于安装Tensorflow，Python等）。 o   如果你在云端，Kubernetes或Marathon / Mesos也很棒 o   一开始手动管理不难。 o   Tensorflow Serving是一个很好的工具，可以非常彻底地处理这个问题，以及批处理和整体部署。 缺点是设置和编写客户端代码有点难，另外不支持Caffe / PyTorch。 o   在生产阶段不要用Matlab o   使用nvidia-docker，试试其它的在线Dockfiles。 后处理层。 o    一旦你在生产中得到了一些不同的ML模型，你可能会开始想要混合和匹配不同的用例——只有在模型B不确定的情况下才运行模型A，在Caffe中运行模型C并将结果传递给模型D在Tensorflow 等等。   原文链接： https://thehive.ai/blog/simple-ml-serving?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 【今日机器学习概念】 Have a Great Definition 
157,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657005&idx=3&sn=741832181147c544b8991d8024bda3da&chksm=bd4c34be8a3bbda8768e6f0e783782435b843839b7c0bf4198909ebdd8f0dbd79618450d26ed&scene=0,BlockChange | 比特币已死？还好区块链并不知情,"大数据文摘作品 编译：魏子敏 当各位被“币圈”最近动荡不安的行情搞得心神不宁时，我们该记住，区块链技术的价值并不会因此改变。 2018年刚刚开始两个月，已经有至少二十位分析师、记者和其他“专家”预言，比特币“药丸（要完）”。其实不止这几天，自2011年以来，比特币已经在这些人的口中，死了“249次”了。 幸好区块链并不知道比特币“去世”的消息。它在分布式账本中继续平稳而持续地收集、编纂和验证每一笔交易，每隔十分钟左右就创建一个新的区块，从未间断。确切地说，自2009年1月3日出现，其正常运行时间高达99.992044937％。 当你在阅读这篇文章的时候，区块链依然在发布新的比特币来奖励那些挖到新版块的“矿工”，和2009年如出一辙。 在比特币价格跌至6,145美元（截至本文撰写时）十分钟之后，它还为这个区块链增加了一个新的区块，并将一直持续下去。交易一直在进行，比特币被发出、收到。 区块链不关心比特币又跌了多少。它不会焦虑或狂喜。但是每隔十分钟，它就会前进一步。 每隔十分钟，它的区块链的价值和实力就会增加，任何人都不能阻止这一点。每隔十分钟，它会前一点进。每隔十分钟，分类帐就会被验证和更新。 随着比特币和区块链的推进，其背后的产业也逐渐推进。当你阅读这篇文章的时候，成千上万的开发者，企业家，投资者和用户正在为其贡献力量。 世界上最好的工程师正在开发Lightning、Segwit、Schnorr、TumbleBit、MimbleWimble等项目，以确保这些网络在全球商业中的可扩展性。 区块链并不关心比特币的价格，也不关心媒体对它的评价 - 它专注自己的工作，每隔十分钟就要运行一次。 它一直在向前移动，一次一块。 原文链接：https://decentralize.today/bitcoin-is-dead-the-blockchain-didnt-get-the-memo-c5b03d8dc8d7 【今日机器学习概念】 Have a Great Definition "
158,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657005&idx=2&sn=cb2c8f881338238fdd779d6f4a3e7134&chksm=bd4c34be8a3bbda8269fba66c452fa19fd49379f272ba1fb3b3d7a70d6625e3d729188ca6d51&scene=0,李飞飞计算机视觉成名作：斯坦福CS231n作业详解第二弹！,大数据文摘作品 学习斯坦福CS231n公开课的同学看过来，Assignment 2 的Q1-Q5详解来啦！本期作业详解帮你搞定基于神经网络的图片识别、卷积神经网络和深度学习框架Tensorflow，快来和文摘菌一起写作业吧！ 在不久前，文摘菌发布了李飞飞计算机视觉成名作斯坦福CS231n作业详解第一弹， 点击查看相关第一弹内容 ，受到了很多读者的打call，文摘菌在此表示感谢，会继续做好服务大家的工作的 经过各位同学和编辑团队的不断努（cui）力（gao），本门课程的进展飞速，课程第二部分和第三部分的笔记也都已经完成，我们会在年前陆续放出，供大家在假期学习。 先简单带大家回顾下 的主要内容： Q1 ：介绍了kNN分类+ 完整代码 Q2 ：介绍了SVM分类器+ 完整代码 Q3 ：介绍了Softmax分类器 + 完整代码 Q4 ：介绍了如何搭建一个完全连接的神经网络分类器 + 完整代码 Q5 ：介绍了如何抽取图像特征 + 完整代码 再次感谢笔记作者和校对人员！ 只看视频不动手的你可能学了门假课程，李飞飞计算机视觉成名作斯坦福CS231n作业详解重磅来袭！ 眼看大家期待的年假就要来了，文摘菌也为大家准备了“年货”！那就是李飞飞计算机视觉成名作斯坦福CS231n作业第二弹！ 先来看下assignment 2 中部分精彩内容： 也给大家透露下 的主要内容： Q1 -  Q3 ： 利用简单的cifar10数据集，并以图片分类识别为目的教大家一步一步构建神经网络。 详细的解释了神经网络中前向传播和反向传播的原理 很细节的Python代码解析 + 神经网络中矩阵运算的图像化解释 + 模块化Python代码的流程图解析。 Q4 ： 实现卷积神经网络卷积层的前向计算与反向传导  实现卷积神经网络池化层的前向计算与反向传导  介绍了卷积层与池化层的加速 Q5 ： 介绍了两个流行的深度学习框架之一：Tensorflow 笔记中不仅有知识点的详细解释，还有完整的代码哦！在夜深人静的时候，敲上几行代码，跑跑神经网络算法，是否有一种众人皆醉我独醒的骄傲呢。 另外，李飞飞计算机视觉成名作斯坦福CS231n作业第三弹正在紧张筹备中，笔记作者和校对人员在加工赶制assignment3的作业笔记，争取在年前让大家带上满满的“年货”回家！请各位持续关注哦。 以下是第二期作业笔记获取链接： 大数据文摘网易云课堂专栏： https://study.163.com/provider/10146755/index.htm 大数据文摘CSDN专栏： http://blog.csdn.net/BigDataDigest 大数据文摘GitHub专栏： https://github.com/theBigDataDigest/Stanford-CS231n-assignments-in-Chinese/tree/master/assignment2 全体作者 ：碧海听滔  观自在降魔  Fanli  SlyneD  土豆  MoreZheng  张礼俊 Assignment 2 参与成员： 编写 ：土豆  MoreZheng  SlyneD 校对 ：碧海听滔  Molly 总校对与审核 ：寒小阳 【今日机器学习概念】 Have a Great Definition 
159,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656976&idx=1&sn=12401bd7e1e526d9fd9d597bde0c090b&chksm=bd4c34838a3bbd9599524ff9122ff53164c7adce7b721a62431b039ecd07c8abfb8caa936242&scene=0,不学好数学也想当数据科学家？不存在的,大数据文摘作品 编译：文明 修竹 高宁 天培 数据科学家需不需要有扎实的数学基础呢？ 随着越来越多优秀开源项目的涌现，各类数据科学工具都实现了“半自动化”，数据分析的背后数学原理似乎不再是数据科学家的必备技能。 而在近期，诸如谷歌Cloud AutoML之类的人工智能自动化平台也不断趋于成熟，甚至让人可以不用编程就能建立机器学习模型（点击阅读 《谷歌重磅：不用写代码也能建模调参，Cloud AutoML要实现全民玩AI》 ）。 这么看来，数据科学家确实不再需要扎实的数学基础了？ 著名数据科学论坛KDnuggets的网红博主 Tirthajyoti Sarkar表示，当然不是啦，强烈反对！ 为什么数据科学依旧离不开数学？我们又需要会哪些数学知识？让我们听这位大咖一一道来。 首先，我不是一名IT工程师，我在半导体领域工作，更确切的说是高功率半导体领域。作为一名技术开发工程师，我的日常工作内容主要涉及半导体物理，硅制造过程的有限元模拟，以及电子电路理论。当然，这其中会涉及一些数学，但令人难过的是，我并没有用到过数据科学家们所需要的那些数学。 我有不少朋友在IT行业工作，我也目睹了不少传统IT工程师充满激情的学习或者参与到令人激动的数据科学和机器学习/人工智能领域。我现在涉足这个领域是为了学习一些这行所需要的技术，希望把这些技术应用在半导体装置或工艺设计领域。但当我开始通过自学深入了解这些令人激动的内容时，我很快发现我在大学里学的那些基础的数学知识，我已经记不清了。 虽然我拥有美国一所著名大学的电气工程博士学位，但在没有复习一些必须的数学知识的前提下，想要牢固的掌握机器学习或者数据科学技术还是有一些困难。我必须要说的是IT工程师工作内容和长期的培训使得他们远离了应用数据领域。他们虽然每天处理大量的数据和信息，却并没有对这些数据建立严谨的模型。通常，由于巨大的时间压力，他们工作的重点是“立即处理完当前需求然后处理下一个”而不是科学性的深度挖掘这些数据。遗憾的是，数据科学永远是一门科学，而仅仅有数据是远远不够的。 这些工具和技术包括了，模拟物理或信息过程从而探寻潜在动力学过程，严格地评价数据来源的质量，训练人们从信息流中识别隐藏模式的识别能力，或者理解模型的局限性。这些内容都是科学过程中的标志。 应用科学或者应用工程学课程中通常包含这些内容，一些相似领域中的高水平研究工作中也包含了这些内容。遗憾的是，即便是工作超过十年的传统IT工程师（开发运营，数据库或者QA/测试）都缺乏对这些知识的学习。原因很简单，用不到。 现在不一样了！ 在大多数情况下，拥有完美的SQL查询知识，清晰的商业需求，以及一定的RDBMS知识就足够完成提取-转换-装载（ETL）循环的工作，这就是一名IT工程师在公司中所产生的价值。但如果有人突然开始问你一些奇怪的问题，例如，你怎么知道人工生成的测试数据是否足够随机？你怎么知道下一个数据点是否分布在3-sigma的范围内？遇到这些问题，你该怎么办？或者，仅是隔壁计算机科学的研究生偶尔的打趣--计算机进行任何有意义的数学运算的数据表（即：矩阵）的运算负荷会随矩阵大小（行或者列）的增加呈非线性增长，也会让IT工程师感到困惑和恼火。 数据成为了风口上的话题，这些问题出现的频率越来越高，也越来越紧急。 主管、技术经理以及决策者们已经不再满足传统ETL工具给出的干巴巴的表格描述了。他们想要看到表格下面隐藏的模式以及列与列之间的相关关系。他们希望得到完整的描述和推论统计，这些描述和统计可能有助于预测建模，并扩展出远远超出数据集所包含数据范围的投射能力。 今天的数据必须讲述一个故事、或者唱一首美妙的歌。但是，要听懂它优美的旋律，你必须精通音乐的基本音符，而这些音符就是数学。 不再啰嗦，让我们来找出问题的症结所在。一名普通的IT工程师要跨入商业分析、数据科学或者数据挖掘领域，他必须学习或复习哪些基本的数学知识。接下来，我将给出我的观点。 让我们从最基础的内容开始。现代数学的大厦是建立在一些基本内容如集合论、泛函分析以及数论等内容上的。从应用数学学习的角度看，我们可以通过一些简明的模块来简化这些基本内容的学习(没有特别的顺序)： a) 集合论基础，b) 实数和复数及其基本属性，c) 多项式函数、指数、对数、三角恒等式，d) 线性和二次方程，e) 不平等、无穷级数、二项式定理，f) 排列组合，g) 绘图、笛卡儿坐标系和极坐标系、圆锥曲线论，h) 基础几何定理、三角形的性质。 当年牛顿想要解释天体运行的规律，但他却没有一个足够好的数学工具来描述他提出的物理概念。在英格兰的城市爆发瘟疫的期间，他搬到了他在乡下的农场，在这里，他提出了现代数学的一个分支--微积分。从那以后，微积分被认为是任何分析研究学科如理论科学、应用科学、工程学、社会科学和经济学等通往高等教育的大门。 毫不意外的，微积分的概念和应用出现在数据科学和机器学习中。涉及的重要概念包括： a) 单变量函数的极限、连续性以及可微性，b) 中值定理、不定型以及L’Hospita规则，c) 最大值和最小值，d) 乘积和链式法则，e) 泰勒级数，f) 积分计算的基本和平均价值定理，g) 定积分和广义积分的计算，h) Beta和Gamma函数， i) 双变量函数的极限、连续性和偏微分，j) 常微分和偏微分方程基础。  一个长期没有联系的猎头突然在领英上加你好友？淘宝突然向你推荐一种超好吃的饼干？网易云音乐为你推荐了最符合你口味的小众歌曲？ 学习了线性代数基础后，你就有了学习科技行业的核心内容所需的数学知识储备，这种感觉是不是很愉快？ 所需学习的必要内容如下（排序不分先后且可能有遗漏）： a) 矩阵和向量的基本性质--标量乘法、线性变换、转置、共轭、秩以及行列式，b) 内积和外积，c) 矩阵乘法规则以及各种算法，d) 矩阵的逆，e) 特殊矩阵--方阵，单位矩阵，三角矩阵，稀疏矩阵和稠密矩阵的概念，单位向量，对称矩阵，Hermitian矩阵，反Hermitian矩阵和酉矩阵，f) 矩阵分解的概念/矩阵LU分解，Gaussian/Gauss-Jordan消元法求解Ax = b的线性方程组，g) 向量空间，基，极化，正交性，标准正交，线性最小二乘，h) 奇异值分解，i) 特征值，特征向量，对角化。 还有一篇很好的文章推荐--《线性代数可以让你实现什么？》 (链接：https://medium.com/@jeremyjkun/here-s-just-a-fraction-of-what-you-can-do-with-linear-algebra-633383d4153f) 统计和概率 “只有死亡和税收是永远不变的，其他一切都遵从正态分布。” 在关于数据科学的讨论中，无论怎么强调要扎实掌握统计学和概率学基本概念的重要性都不为过。实际上，许多该行业的从业都者认为机器学习就是统计学习。我从著名的《统计学习基础（An Introduction to Statistical Learning）》开始了我第一个机器学习MOOC课程，几乎瞬间我就意识到我在这门学科上存在不少概念空白。为了弥补这些空白，我开始学习其他有关基本统计学和概率学的MOOC课程，并研读相关主题的文章或观看视频。这门学科范围很广，因此针对性的学习计划是掌握大部分基本概念的关键。我尽量把它们一一列取出来，但是我也有些担心，毕竟这不是我擅长的领域。 1. 数据摘要和描述性统计，集中趋势，方差，协方差，相关性；2. 概率：基本概念，期望，概率微积分，贝叶斯定理，条件概率；3. 概率分布函数——均匀分布，正态分布，二项分布，卡方分布，t分布，中心极限定理；4. 采样，度量，误差，随机数； 5. 假设检验，A/B测试，置信区间，p值；6. 方差分析；7. 线性回归；8. 幂，效应量，检测手段；8. 研究性学习和试验计划。 这些话题跟应用数学领域的传统话语没什么不同，它们大多是相关的并广泛应用到多个专业领域研究——理论计算机科学，控制理论或运筹学。然而在机器学习实践中，对这些强大技术有基本掌握是非常有用的，值得在这里一提。 比如，几乎所有的机器学习算法/技术目的都是在特定约束条件下，使得某种估计误差最小化。这是一个最优化问题，通常用线性规划或类似的技术解决。另一方面，这些技术在帮助理解计算机算法的时间复杂度上效果显著，因为当算法应用到大型数据集时，时间复杂度就非常重要了。在这个大数据时代，通常人们期望一名数据科学家可以提取、转换和分析数十亿条记录，他或她必须非常谨慎的选择合适的算法，因为不同算法会导致最终性能的天壤之别。一般的理论和算法性质可以在计算机科学课上学习，但是要理解时间复杂度是如何分析和计算的（比如针对给定大小的数据集，该算法需要运行多长时间？），就必须要熟悉基本的数学概念比如动态规划或者递归方程。熟悉数学归纳法的证明技术也非常有用。 看到有这么多数学知识要学，是不是有点望而却步了？觉得自己要重新上一遍大学了？不用担心，你可以根据需要边做边学，但最重要的是保持思想的开放。不慌不慌，这些主题你也许大多已经在大学学过，也可能是第一次接触，不过当你学完后，你一定可以慢慢听到数据中隐藏的“旋律”。到那时，你就已经朝着成为数据科学家的方向迈出了一大步。 原文链接： https://www.kdnuggets.com/2017/12/mathematics-needed-learn-data-science-machine-learning.html 【今日机器学习概念】 Have a Great Definition 
160,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656947&idx=2&sn=3bd50b20c2fabb42a23b602c5df023a4&chksm=bd4c35608a3bbc76e78ca6f3541814a93ecd9a93a19aac2bbd19813c44efcabff2d842a395f6&scene=27,谷歌的AI相册“事故”：它把我的三张照片拟合成了一张恐怖片,大数据文摘作品 编译：蒋宝尚 Android制造商开发的应用程序能够帮助你整理手机上的数千照片。它还可以根据地点的不同，帮助你生成地域相册；可以通过面部识别把你家人、朋友、宠物的照片分类成不同的相册。如果你拍摄了一系列类似的照片，它可以把照片制作成一个小动画。 或者......它可能会把你的朋友变成一个潜伏在森林里的巨人头。 Alex Harker在班夫拍了几张风景照以及和朋友一起滑雪的照片。 一旦图片存入手机，Google相册助手就会认为这三张照片属于同一个框架。但实际上并不是。 Harker在Reddit发文： 我拍了三张照片， 但是由于一些古怪的原因，谷歌的相册助手把这三张照片拟合成了一张非常奇怪的照片。 照片显示Harker的朋友Matt藏在树后，他其他的朋友没有在合成的照片中出现。 他在Reddit上分享了这件有趣的事情，并且很快就登上了头条，获得了超过188000个点赞。 专家指出，尽管合成照片展现出的画面毫无意义，  虽然有一个巨大的头部潜伏在松树之外，但照片前景处理的很好。 瘾科技（Engadget）的专家Steve Dent写到： 如果仔细研究照片，就会发现算法对细节的处理就不能令人满意。它把左边的树隐藏起来，并把人物“插在”树木之后，这一点做得相当不错。它也巧妙地剪掉了人物的上半身，顺着斜坡的轮廓，看起来人物的上半身好像藏在山沟里，似乎在告诉朋克滑雪者放慢脚步。 Google Photos和其他人工智能驱动的图像软件出现的严重的bug是技术试图“愚弄”我们的一个例子。 原文链接：https://qz.com/1188170/google-photos-tried-to-fix-this-ski-photo/ 【今日机器学习概念】 Have a Great Defination 
161,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656976&idx=3&sn=2ffb22430df8521cd51fd4b07917346c&chksm=bd4c34838a3bbd952388dddd3508c082048ef7795e3fc60750e061447e1cad6926d8c292e580&scene=0,AI大事件丨OpenAI启动Research2.0，AI破译怪异古老手稿,呜啦啦啦啦啦大家好呀，又到了本周的AI大事件时间了。过去的一周中AI圈都发生了什么？大佬们互撕了哪些问题？研究者们发布了哪些值得一读的论文？又有哪些开源的代码和数据库可以使用了？文摘菌带你盘点过去一周AI大事件！ 来源：TECHCRUNCH.COM 链接： https://techcrunch.com/2018/01/30/andrew-ng-officially-launches-his-175m-ai-fund/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这个新基金的投资者包括NEA，Sequoia，Greylock Partners和软银集团。Andrew Ng则将作为普通合伙人领导该基金，Eva Wang担任合伙人兼首席运营官，另外，Steven Syverud也将加入合伙人行列。这个基金的第一笔投资正是Andrew Ng之前发布的另一个创业项目landing.ai，但目前尚不清楚这个创业基金具体以何种类型为目标。 来源：BLOG.OPENAI.COM  链接：https://blog.openai.com/requests-for-research-2/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI OpenAI发布了新的一批（七个）未解决的问题，需要提出新的解决方案。这些需要解决的具体问题正是开展深度学习和强化学习研究的绝佳机会。 来源：GIZMODO.COM  链接：https://gizmodo.com/artificial-intelligence-may-have-cracked-freaky-600-yea-1822519232?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 伏尼契手稿（Voynich manuscript）发现于一百多年前，这本长达240页的手稿充斥着看似编码的语言和不可思议的插图，在过去一直被语言学家和密码学家当作世界性难题。而在近日，加拿大的研究人员利用人工智能在揭开文件隐藏意义方面迈出了巨大的一步。 来源：WWW.THEATLANTIC.COM  链接：https://www.theatlantic.com/technology/archive/2018/01/the-shallowness-of-google-translate/551570/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 谷歌翻译使用最先进的人工智能技术，但简单的测试表明，人工智能距离真正理解人类的自然语言还有很长的路要走。虽然这一结果对AI领域的研究人员来说丝毫不意外，但是将当前模型的局限性系统地传达给公众也是很重要的。 来源：MEDIUM.COM 在强化学习中，偏差和方差不再仅仅评价在监督学习中模型与训练数据的适配性，还会表明强化信号如何对真实环境的奖励结构做出反应。 来源：PARRT.CS.USFCA.EDU 链接：http://parrt.cs.usfca.edu/doc/matrix-calculus/index.html?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这篇文章解释了深度神经网络的训练需要的所有矩阵微积分知识，相信这没有超出你在微积分1中学到的知识。 来源：DEEPMIND.COM 链接：https://deepmind.com/blog/learning-explanatory-rules-noisy-data/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 深度学习专注于直观的感性思维，而象征性的程序综合则侧重于概念性的，基于规则的思维。这篇文章表明，系统可以将直观的感性思维和理性的推理结合起来。 来源：GITHUB.COM  链接：https://github.com/tensorflow/minigo?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 基于神经网络Go AI的纯Python实现，使用TensorFlow。虽然这个项目受到了DeepMind AlphaGo算法的启发，但该项目不是DeepMind的项目，也不隶属于官方的AlphaGo项目。 来源：DENSEPOSE.ORG 链接：http://densepose.org/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 密集人体姿态映射旨在将RGB图像上的所有像素映射到人体的3D表面。你可以点击链接观看视频，并阅读文献。数据将很快在网站上公布。 来源：GITHUB.COM  链接：https://github.com/hannw/nlstm?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI Nested LSTM Cell的TensorFlow实现，与Tensorflow RNN API完全兼容。 来源：ARXIV.ORG 链接：https://arxiv.org/abs/1801.10198?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 作者表示，可以通过对于多个源文档的摘要生成维基百科文章。他们通过抽取摘要并粗略地识别显著信息和一个神经抽象模型来生成维基百科文章。 电子健康记录的可拓展性和准确深度学习（新版本） 来源：ARXIV.ORG 链接：https://arxiv.org/abs/1801.07860?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 作者提出了患者基于快速医疗保健互操作性资源（Fast Healthcare Interoperability Resources :FHIR）格式数据的全部EHR原始记录的表示。他们表明，使用这种表示的深度学习方法能够准确预测来自多个中心的多个医疗事件，而无需特定的数据协调工作。 来源：ARXIV.ORG 链接：https://arxiv.org/abs/1801.10308?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 作者提出Nested LSTM（NLSTM），是一种具有多级记忆的新型RNN架构。Nested LSTM通过嵌套增加LSTM的深度，而不是堆叠。NLSTM中存储器单元的值由具有其自己内部存储器单元的LSTM单元计算。 【今日机器学习概念】 Have a Great Definition 
162,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656932&idx=2&sn=d5577f00682fc67b45ff743fcadd77f8&chksm=bd4c35778a3bbc614a3056e79830e314b8f8fc82e790005490777298570b7cbfde80edfc1bf4&scene=0,重磅译制 | 更新：牛津大学xDeepMind自然语言处理 第6讲（下）NLP硬件和软件-英伟达GPU,大数据文摘重磅课程汉化《牛津大学xDeepMind自然语言处理》 本周更新至：Lecture 6 英伟达：NLP硬件和软件（2） 马上观看▼ 牛津大学Deep NLP是一门关于自然语言处理（NLP）的高阶课程。课程由 牛津大学 和 谷歌DeepMind （AlphaGo的开发机构）联合开设，是牛津大学计算机系2017年春季学期最新课程。由Phil Blunsom主讲，同时邀请到多位来自DeepMind和NVIDIA的业界讲师来做客座讲座。 大数据文摘已联系课程主讲人 取得翻译授权 ，并联合 北京邮电大学模式识别实验室 组织了视频汉化， 发布。 课程现已上线 ，请大家多给我们好评，为辛勤工作的字幕组打CALL！ 学习地址：   http://study.163.com/course/introduction/1004336028.htm 本课时PPT精华▼ 关注大数据文摘并进入微信公众号 课程英文资料地址: https://github.com/oxford-cs-deepnlp-2017/lectures 《牛津大学xDeepMind自然语言处理》汉化视频 更新中 ，点击文末 可直接加入（或复制打开以下链接）： http://study.163.com/course/introduction/1004336028.htm 大数据文摘另一门经授权汉化的《斯坦福CS231n深度学习计算机视觉》课程已更新完毕，已有8万+人学习，复制打开以下链接免费加入课程： http://study.163.com/course/courseMain.htm?courseId=1003223001 大数据文摘 另一门经授权汉化的《MIT6.S094深度学习与无人车》课程 ， 复制打开以下链接免费加入课程： http://study.163.com/course/introduction/1004938039.htm 本期工作人员 翻译 北京邮电 大学模式识别 实验室 李楠  闵峰  乔一宁  张世平   刀哥  momo  无敌乔卡特 终校 蔡斐召  蒋宝尚 项目管理 龙牧雪  李楠 顾问 张闯  寒小阳  汪德诚 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 
163,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656976&idx=2&sn=cd3e380b9f31094d0a4608d958f31192&chksm=bd4c34838a3bbd95c4987311065cfef4cedf2c2ac27ec46777ec1cc02f3d1d024d20a737e85d&scene=0,公开课 | 年前“封麦”直播：配对标注还原数据真实排序+慢特征分析用于个性化推荐系统+精准营销中的Host2vec用户识别,本周四晚，年前“封麦”公开课，3场连续语音直播！错过这场，咱们就年后再见啦。公开课可以永久回听，暂时没空的小伙伴可以扫码进入直播间收藏课程，假期学起来。 大量有标注数据的产生，是机器学习研究取得进展的重要因素。如果我给你一张“赫敏”的照片，问你“ ”，你可能会打满分。但是，你的女票/男票对同一张照片会打几分？很难说。 Emma Watson，图片来自网络 如果我同时给你两张照片，比如同时让你看“赫敏”和“罗恩”的照片，让你给出两张照片“美不美”的相对得分，这样是不是更好呢？如果有了很多人给出的照片相对得分，我们可以更科学地恢复出数据中隐藏的“真相”——到底谁美。 本次公开课主要介绍在众包平台中，众多工作者用连续变量对数据进行标注的问题。此类问题经常出现在对视频中人物的图像进行标注、工作面试评估、年龄估计等应用中。为了获得较准确的标注，一般需要专业人员对这些数据进行评估。由于需要标注的数据量较大、专业人员人数少且雇佣成本高，所以通常需要求助于群众的智慧，雇佣众多没有经过专业训练的人对数据进行标注。 在标注的过程中，工作者一次看到一对比较对象，给出他们的偏好，基于这些偏好，我们能够较好的恢复出原始数据的排序。 本次公开课将对比配对Ranking问题中的 ，尝试小世界网络图构造。 曾令辉 ，华院数据技术（上海）有限公司算法研究员，致力于基于人格分析的用户智能画像，通过对小数据的精准分析获得用户的人格特质，立体化深度洞察人与人的内驱差异。复旦大学计算数学专业理学博士，博士期间主要研究力学和工程中的数值代数和科学计算问题。曾任职华为，历任无线网络研究部MBB研究部和云核心网 NFV 研究部研发工程师，主要从事于云计算和区块链等技术在电信网络中的应用。 2月8日（周四）19:00 扫码听课👇 慢特征分析（SFA）是Wiskott提出的一种在快速变化的时序信号中抽取慢特征的批量学习算法。 我们常见的视频、脑电波和时间序列等都属于时序信号。什么是慢特征？慢特征就是变化比较缓慢的特征。 比如，人的感观器官中，视网膜比较原始（能处理的信号维度少），对光线强弱的变化明显，即随时间变化快。 本次公开课将介绍如何采取定量刻画的方式提取慢特征，从数学的角度进行分析，包括数学模型和输入输出信号的分析。 最后，我们将结合个性化推荐系统的一个案例，具体给出行为数据中的慢特征分析方法。 为帮助大家理解此次公开课内容，大数据文摘特意采访了公开课嘉宾徐清博士—— 大数据文摘： 对于从未接触过慢特征的小白来说，怎么理解慢特征比较合适？ 徐博士： 慢特征就是变化比较缓慢的特征。比如说， 。像素点和色块的变化是很快的，但是物体的变化（以及视频中是否有猴子）相对来说比较缓慢。这种变化比较缓慢的特征抗干扰性强，比如说，稍微对像素点加点扰动，或者把彩色的变成黑白的，猴子还是猴子，但是色块已经不是原来的色块了。 视频中是否有猴子，是一种慢特征 大数据文摘： 是否可以将猴子的变化理解成一种慢特征？ 徐博士： 是的， 。 大数据文摘： 如何判定大脑处理的高层次信息随时间变化缓慢？ 徐博士： 大脑处理的信息可以用脑电实验做出来，脑电信号的变化一般来说比像素点的变化缓慢得多。 大数据文摘： 请问定量刻画慢特征是如何实现的？ 徐博士： 这也是本次公开课的重点，这方面结果国内研究和相关资料比较少，也是也比较新研究课题。在这里先给大家透露一下，利用 可以定量计算慢特征。 徐清 ，华院数据技术（上海）有限公司分维（Fra+）团队算法研究员，致力于研究个性化推荐技术，整合不同来源小数据打造新一代智能画像引擎。本科与博士均毕业于复旦大学数学科学学院，研究方向是随机控制、随机分析与优化理论。博士期间建立了无穷时域的二次倒向随机微分方程理论，在金融风险度量、Feymann-Kac表示等领域中有诸多应用，所写论文Some Results on the Controllability of Stochastic Schrodinger Equations荣获第三届随机系统与控制论坛优秀博士生论文奖。在校期间荣获多次全国数学与建模竞赛一等奖，三次荣获国家奖学金，2011届复旦大学本科生毕业之星。 2月8日（周四）19:40 扫码听课👇 随着人口结构的波峰迁徙、城镇化水平的持续提高、数字化全面渗透至生产生活的各个领域，我们迎来了新消费升级时代。在时代的大趋势下，如何通过机器学习进行用户识别与行为特征分析，进而基于客户需求及动机的深层次消费者洞察，将大数据带来的信息更好的应用在消费场景当中，是数字化精准营销领域一直在研究探索的课题。 本次公开课将主要介绍 。 Lookalike Machine Based on Host2vec Model Host2vec是Word2vec方法在用户群拓展推荐领域的迁移应用。 用户上网行为特征序列等价于Word2vec中的word序列，同一个用户一段时间周期内的上网特征集可视为positive，将one-hot编码后的海量高维稀疏的用户online浏览行为，通过浅层神经网络训练后，映射到低维稠密的向量空间中，最终得到每个上网特征的embedding表示，即用有限维度的低维向量来表示该host（域名/IP/URL标签/Patterns…），进而可以通过计算每个低维向量之间的相似度来衡量host之间乃至用户之间的相似性。 相比较于传统的用户群拓展算法将种子用户标记为正样本、备选用户标记为负样本、并训练分类模型筛选备选用户群， 。 以股票app用户举例，与同花顺股票最为近似的标签集中于金融相关的外汇、财经、基金、证券等，截图内，中国游戏中心也与同花顺股票非常近似，实际为其旗下的德州扑克游戏人群与同花顺股票人群重合度较高，需要另外拆分标签。 林昱洲 ，华院分析DMP数据产品总监，高级数据分析师。中国人民大学统计学学士，意大利佛罗伦萨大学统计精算与金融学硕士。在数据挖掘、统计建模、大数据处理技术、互联网精准营销、DMP产品设计等领域有丰富的项目经验，擅长使用R语言、Python、SAS等统计程序实现评分卡、协同过滤、文本挖掘、BP神经网络、逻辑回归、RFM、Embedding等算法模型。曾负责实施运营商、金融、电商等多个领域的数据分析和挖掘项目，在数据运营、精准营销、风险评估、客户画像等领域有多年的市场经验。 2月8日（周四）20:20 扫码听课👇 公开课福利！ 进入直播间后，点击“邀请朋友一起来听课”，生成专属邀请海报，开课前邀请人数排名前5的小伙伴，将获赠大数据文摘与清华大学数据科学研究院联合发布的2017年 《顶级数据团队建设全景报告》 完整版PDF一份。如有疑问，请添加课程小助手微信（微信ID：ai_learner） 【今日机器学习概念】 Have a Great Definition 
164,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656947&idx=1&sn=987aad20cf13528af7935bb463cdcf6c&chksm=bd4c35608a3bbc76a501d0a01577a7460dff743718338167a6a1921b295a639db5f00287220c&scene=27,全球最聪明的大脑怎么看AI？他们预测了这13大发展趋势,大数据文摘作品 作者：ROSIEBROWN 编译： 彭湘伟、 蒋宝尚、小鱼 被华尔街时报，福布斯和财富杂志称为 ，人工智能成果颇丰 AI在新领域的表现优于职业玩家和扑克玩家。通过 各种线上项目，一步扩大了深度学习的教育范围。最近微软公布说，语音识别的准确率多次打破了之前的记录。 2017年AI领域取得了诸多成果。 点击查看大数据文摘总结报道 《2017年你错过了哪些AI圈大事？最全盘点，值得收藏！》 2018年AI又将何去何从？ 以下是来自世界顶级研究人员和行业领军人物对2018年AI领域发展作出的13个预测。让我们听听这些最聪明的大脑怎么说。 “2018年，AI设备将会在医药行业上线。我们将把算法植入产品中，并且进行整合和验证，让那些来自概念的解决方案生根发芽，这样医生们就可以用AI设备辅助工作。 到2018年末，AI技术会以多种形式嵌入医疗系统的诊断体系中，在大部分诊断医学领域会采用这种系统，同时， 在2018年，在全球范围内，我们会通过AI技术，真正地改变医疗服务提供者的工作方式，以及病人们体验医疗服务的方式。” ——Mark Michalski，马萨诸塞州总医院和临床数据科学中心的执行主管。 “2018年，深度学习将会颠覆工程仿真和设计。未来三到五年里，深度学习会加速产品的研发周期，并将其从过去以月计数缩短到以天计数，在产品特性、性能和成本的研发流水线上给出一种快速创新的模式” ——Marc Edgar，通用电气研究部的高级信息科学家。 “在2018和未来几年里，我们的诊断系统会深度嵌入AI技术，但我们不会称之为AI设备，而只是一套常规的系统。人们会问：‘在没有这些系统之前，我们是怎么生活的？’” ——Luciano Prevedello，医学博士，公共卫生学硕士，来自俄亥俄州立大学韦克斯勒放射学和放射医学中心。 “看到AI的发展速度如此之快，我希望它能够根据个人的口味创造个性化媒体，比如音乐。想象一下，未来的音乐服务不仅播放你可能喜欢的老歌，而且能持续创作合你心意的新歌。” ——Jan Kautz，NVIDIA视觉计算与机器学习研究的高级主管。 “AI将影响并推动25%的技术行业的发展。关键在于机构组织和从业人员如何面对AI技术带来的改变。” ——Nicola Morini Bianzino，埃森哲人工智能与发展和技术决策指导部门主管。 “有了AI技术，面部信息会成为人们信用卡，身份证和条形码。随着生物特征识别技术的成熟，人脸识别作为个人信息认证已经变得很安全。传统零售业结合AI技术会给我们带来更好的体验，像亚马逊和全食超市。 ” ——Georges Nahon，Orange Silicon Valley的首席执行官；Orange Institute（一所全球研究联合实验室）的主席。 “深度学习将会显著提高放射学报告中定量分析的可靠性。人们对深度学习是个”黑盒子”的担心会越来越少，因为新的技术会帮助我们去理解深度学习所”看”到的。” ——Bradley J. Erickson，医学博士，放射科顾问；卫生科学研究部生物医学统计和信息学顾问；梅奥诊所放射科研究副主席。 “智能手机上大量的App将运行深度神经网络算法支持AI技术的实现。家用机器人会更智能，其成本也会更低。 它们将视觉、语言和语音等交互方式巧妙融合，用户很难察觉不同交流方式之间的差异。” ——Robinson Piramuthu，易趣网计算机视觉的首席科学家。 “机器人将在人类认为的复杂任务中表现的更好，比如在房间里走来走去和跨过物体。它们处理繁琐的事情也变得游刃有余。我也期待自然语言处理的进展，因为这方面的技术还有很大的提升空间。 未来， ” ——Chris Nicholson，Skymind.io的首席执行官和联合创始人。 “越来越多来自不同背景的人都在搭建、开发和产品化AI项目。随着开发工具和基础设施的不断改进，人们把数据和算法转化为实用产品的过程更加容易。产品和应用程序将允许底层模型在内部运作时进行交互式查询，从而提高人们对这些系统的信任，特别是在任务关键型应用程序中。在医学领域，我们会将多个跨学科的信息源进行整合后加以利用，而不是关注单应用程序的案例，尽管目前这种应用正在席卷医药行业。” ——George Shih，MD.ai创始人；康奈尔大学威尔医学院信息放射科的副主席兼副教授副教授。 “AI技术可以探测到天体物理学中未知物体发射出的引力波，这为当代天体物理学开启了一个新的研究领域。” ——Eliu Huerta，伊利诺伊大学厄巴纳—香槟分校超级计算应用国家中心重力组组长，天体物理学家。 “AI在成像上达到了”技术成熟度曲线”的峰值，AI设备从研究实验室搬进了放射科医生的工作站，最终成为病人床边的某种设备。医用AI设备的评估和实现对开发人员、投资公司、医疗组织和其他机构吸引力远不如其他案例，例如工作流工具、质量/安全分析、病人分类等。 医疗和AI成像行业面临的最大挑战之一是监管机构能否跟上技术创新的步伐。美国食品药物管理局（FDA）需要找到有效合理的方法，简化可用于筛选、检测和诊断疾病的算法的审批流程。”­­ ——Safwan Halabi，Lucile Packard儿童医院，斯坦福大学儿童健康中心放射信息科主任。 “AI私人助理会变得越来越聪明。当私人助理学习了很多我们日常生活的规律后， 想象有那么一天，我不再为准备晚餐复杂的步骤而担心了。我的AI私人助理会知道我喜欢吃什么，我的厨房里有什么，每周哪几天我喜欢在家做饭，当我工作回来时，做饭所需的食材就在我的家门口的台阶上，它都帮我准备好了。” ——Alejandro Troccoli，NVIDIA高级研究科学家 原文链接：  https://blogs.nvidia.com/blog/2017/12/03/ai-headed-2018/?ncid=so-twi-dplglncn-29699 【今日机器学习概念】 Have a Great Definition 
165,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656932&idx=1&sn=98c750c0cfa837c9448761fc1e4fb359&chksm=bd4c35778a3bbc613d9d520d4286ebf017a8896bbde4c30ef8c0fc897fe0e0716fabfd5fe1c2&scene=0,我们分析了1亿条阅读量超高的标题，这就是为什么你会被标题党吸引,"大数据文摘作品 编译：潇夜、Happen、吴双、龙牧雪 震惊！这24张图只有当过妈妈的人才能看懂，这就是为什么女人比男人寿命更长…… 你一定见过这样的“标题党”文章。本文作者分析了Facebook和Twitter上转发量较大的1亿条文章标题，找出了撰写标题的套路，看完你会吓坏了！ 或者不会:) 文章标题的重要性无需夸大。一个好的标题可以吸引观众来点击、阅读以及分享你的内容。很多情况下，引发人们分享的其实是标题而非文章内容本身。 我们分析了Facebook和Twitter上转发量较大的1亿篇文章的标题 ，找出了哪些关键词让文章被浏览最多次、用哪些词做标题开头和结尾最有效、哪些词不能使用、标题应该多长…… 虽然并不存在能够制造病毒式传播或者流行标题的万能公式，但我们还是可以学到一些增加文章点击量的经验。 最吸引人的标题关键词 对 的分析结果显示，获得Facebook最多参与（喜欢、分享、评论）的三连词或三字词组如下所示： 为什么这些数据会让你再次思考 在我们的样本中，标题中最有影响力的三个词组是 … 短语“会让你”获得的用户参与度是第二受欢迎的词组的两倍以上。这让人非常惊讶。在我们最开始寻找参与度高的词组时，这句话甚至都不在我们的名单上。 那么为什么这样一个词组会表现的如此出色呢？比较有意思的一点是 。它不能用来作为标题的开头或者结尾，而是清晰地明确了内容与对读者潜在影响之间的关系。 这样一种标题的格式阐明了读者为什么应该关心其内容，同时也从文字上承诺了读者这篇文章内容会对“你”有直接影响，通常是情绪反应。这样的标题意义明确，简洁有效。 典型的这类标题： 这24张图会让你感受到世界的美好 这家航空公司为乘客提供的服务会让你流泪——如此感人 6个残酷的真理会让你变得更好 “谁穿得更好看？”这些照片会让你开怀大笑 13个旅游提示会让你在旅行中更聪明 情感类标题可以提升Facebook的互动率 在分析中，我们通过衡量互动次数发现Facebook上情绪短语的使用有持续性效果。例如： 喜极而泣 让你哭泣 让人起鸡皮疙瘩 太可爱了 震惊地看到 融化你的心 笑到停不下来 许多包含情绪短语的影响大的帖子都有图片或者视频，尽管也有一部分是故事。下面是一个视频帖的标题： 患罕见病的小女孩与纽约城市芭蕾舞团共舞， 她会融化你的心！ 尽管这些情感相关的帖子表现出色，但内容作者在使用情感相关或非常煽情的短语时还是必须小心谨慎。 ，因为这些标题常常是为了“让事情看起来比原本事实真相更严重”。 好奇心和窥视欲也能获得Facebook的高参与度 能引起人们的好奇心或者窥视欲的标题同样也在Facebook上获得了较高的参与度。比如： 接下来发生了什么 正在谈论它 Twitter上的反响 吓坏了 前X名的歌曲 读者往往对人们 的内容感到好奇，比如热搜榜上最受欢迎的话题或者Twitter上人们对于某个话题或事件的反应等等。这种类型的内容往往借助读者的好奇心和窥视欲来吸引其注意力。去年里这种帖子中最常见的标题就是 “ ” 。 我们想提醒作者尽量避免“接下来会发生什么”这种风格的标题。虽然它们之前表现不错，但是现在Facebook会将这类隐瞒信息的钓鱼式标题分类并做降权处理。我个人认为这是一件好事， 。 其他吸引人的标题 解释类： 这就是为什么 原因是 这些短语同样与好奇心相关。比如： 这就是为什么女人比男人寿命更长…… 这就是为什么你应该朝左睡 我们都希望能通过阅读完一篇文章来变得更聪明一些。 而这类解释原因类的文章恰恰承诺读者可以提供一个看待事件的另外视角。在某些方面，这些标题与包含“会让你”词组的标题类似，因为它们都在保证读者会 从文章内容中得到些什么。 测试类： 我们能否猜测 只有X在 这些短语在测试类标题中非常流行，比如： 我们能否猜到你的真实年龄？ 50人中只有1个人可以识别这16个语法错误，你可以吗？ 这种标题类型中最常用的是一种测试的变体，它会挑战你让你回答问题，并且根据你的答案看看是否可以预测你的年龄、教育水平、工作状态等等。这些测试迎合了我们想要更了解自己的想法，或者想证明自己很聪明、自己确实成长在80年代、自己生活在合适的城市或者其他一些事情。 这些标题很难让人忽视。 X件只有 这些流行标题迎合了人们对于圈子的归属感，比如： 25件只有老师才能理解的事 17件只有双胞胎妈妈才了解的事 9件只有和哥哥长大的女孩才明白的事 10件只有夜班护士才懂的事 我们看到了有关圈子的标题在显著增长，特别是政治上的党派标题。就好像分享支持他们观点的文章是这些圈子的义务一样。我们在美国大选中看到了这一点，相似的事情也发生在最近的英国选举中。 绝对不能用：那些表现最糟糕的词 这个图里是Facebook上参与度最低的标题中的常用短语： 注意：我们只查看了那些被用于至少100个不同领域中的短语或词组。还有一些短语会比上面的短语表现更糟糕，但是上面列出的短语是最常用的短语中表现最糟糕的。 有趣的是，在Facebook上类似于“节省费用”的短语表现得非常糟。虽然也有一些单独的文章表现不错，但是其平均参与度非常低。相比之下，“节省费用”这个短语在Pinterest的DIY话题上却表现不错。如下图所示： 这一结果突出了网络平台的重要性。也许，Facebook并不是一个人们想要去寻找节省开支小贴士的地方，而Pinterest的DIY板块就是个更好的选择。分析结果印证了这些举措的重要性：研究什么才是真正适合你的受众、让你的话题和特定社交网络环境匹配。 为不同领域写作也是一样的，例如“需要知道”这样的短语可能在健康领域表现良好，但是在其他环境中表现不尽如人意。关键是要研究如何才能和你的特定受众产生共鸣，然后再来测试你的文章标题。 常用于标题开头和结尾的词 最流行的短语“Will make you（会让你）”是一个很明显位于标题中心的短语，因为它连接了两个不同的元素。也就是说它通过将某事物与情绪反应联系起来形成语句结构。 这比较令人惊讶，因为之前的研究表明标题最重要的部分是前三个词和最后三个词。这可能是因为使用“会使你”这个连接词组实际上强调了句子开始和结束部分的重要性。 我们认为，研究标题中开头的前三个词的词组和末尾的短语是有用的。 以Facebook的互动数衡量（x表示数字），以下是用于标题开头的最流行的短语： 以Facebook的互动数衡量（x表示数字），以下是标题结尾最常用的短语： 最后，以Facebook的平均互动数来衡量，以下是最常见的标题开头第一个词： 双词短语 我们也找到了最常用的双连词或者两个单词的组合。它们通常是我们前面所列出的三词短语或者三连词的一部分，比如： make you（让你）-will make you（会让你） is why（为何）-this is why（是为何） 然而，有一些例外的双词短语获得了较高的平均参与度，包括： goes viral（走红） ：9746 次平均参与 most beautiful（最美） ：3921 次平均参与 这些都与我们在研究三词短语时发现的吸引人的标题类型一致。第一种能激起好奇心，例如“ ”。 第二种是情感内容，通常表示对于某种特殊内容的明确承诺。比如“ 布拉格的Clementinum是世界上最美的图书馆 ”。Bored Panda选取了一个相似的标题“ 世界上最美的图书馆在捷克，布拉格 ”。两个帖子都在Facebook上获得了超过250000次的参与。 列表类文章、数字10 许多吸引人的标题短语都包含数字，也有许多使用了列表类文章的格式，即标题以数字为开头。众所周知，列表类文章能获得高于平均水平的社交分享次数。我们对于不同数字在表现上的差异非常感兴趣，比如以10开头或者4开头的列表文章。下图展示了在我们的样本中，以不同数字开头的列表文章在Facebook上的平均参与度 。 我们可以看到数字10是标题中表现最好的数字，这也证实了之前在这方面的研究。我们研究发现，接下来三个表现最好的数字是5、15、7。 许多营销人员主张为那些综合性文章使用独特的数字或者更长的数字。例如，Buzzfeed在使用数字23上取得了许多次成功，但是平均来说使用数字10、5、15、7的文章表现最好。 你的标题应该多长？比你想象的长 接下来我们来看看标题的长度。Jacob Neilson这类专家一直认为新闻网站最好的标题都是十分简短的。Jacob认为标题应该是短短的五个词语或少于40个字符。Buffer的Kevan Lee曾写了一个综述，提出博客标题最好是六个词或少于50个字符。相比之下，Outbrain在研究了100000篇帖子后，认为16到18个词或者80到110个字符是吸引参与度的最佳选择。此外，MailChimp的研究表明标题电子邮件的主题长度其实无关紧要。 我们决定去测试一下这些假设。我们绘制了帖子标题的字数和在Facebook中的平均参与度的关系。结果见下图。                                                                                                                                                                                      我们可以看到， 。当标题更长或更短时，Facebook参与度平均值开始下降。 12+的词可能听起来很多，但如果你想要明确主题、格式和使用高效的三连词，你就会用到这么多词。下面是一些例子： This Infographic Shows How Only 10 Companies Own All The World’s Food Brands（这张图显示全世界所有食品品牌仅由这10家公司拥有） E-Cigarettes Found to Have 10 times More Cancer Causing Ingredients than Regular Cigarettes（电子香烟被发现含有高于普通香烟10倍的致癌成分） 我们还研究了标题字符数和Facebook参与度平均值之间的关系。结果如下： 字符数与Facebook参与度平均值呈现了和单词数相似的关系，这并不让人奇怪。 因此，我们的研究结果倾向于支持Outbrain先前的研究工作，即在参与度上， 。 Twitter上的标题关键词 标题在Facebook上的表现是否与Twitter相同呢？这不一定。我们发现Twitter获得最高参与度的标题短语与在Facebook上的截然不同。唯一的例外是“会让你”（will make you），这个在Facebook上参与度最高的短语，在Twitter上分享度也排在第四。 格外有意思的是，Twitter上分享度较高的标题中极少有情感短语。这与我们在Facebook上的发现不太一样。 高分享度的Twitter短语都注重 ，例如 “第一次”（for first time） 和 。 Twitter上分享度较高的三连词更注重 和 ，比如： 真相是 的崛起 需要知道的事 这就是...  我们所知道的... 你可以在你自己的推文中尝试不同的关键词来测试不同标题在Twitter中的影响力。 建议你花费与写文章同样长的时间来写标题。 读者需要更有力的点击理由。每当读者看到一条标题，无论是在收件箱、社交媒体还是搜索结果页，他们会做瞬间的成本-效益计算，其心理都是相同的：这东西值得我花费几秒钟吗？ 当你拟定标题时，可以问问自己这些问题： 为什么读者要关心你的内容？ 你能对文章给读者带来的影响作出一定的承诺或断言吗？ 具体明确（例如 “这就是什么”,“这就是如何使”，“原因是” ） 你能在标题里包括一个情感因素吗？（尤其是当你想在Facebook上获得一定的吸引力） 如果标题不包含情感，就使其有用（例如 “适用于你”,“N个简单小贴士”，“你应该用” ） 你是否在探讨一个热门话题？如果是这样的话，你是否能在标题里将其突显出来？ 你能否将文章变成一次测试题或者挑战？ 你是否能将文章定位成一篇解释帖或者回答帖？ 尝试讲故事。是的，你可以在15个词的标题中讲一个故事。海明威用3个词就做到了： “出售：婴儿鞋，从未穿过。” 谁是你的目标圈——哪些标题能引起圈中人的共鸣？党派性或有争议的标题是否会更加吸引你的目标圈群体？ 标题长度是否在12-18个词之间？ 原文链接： http://buzzsumo.com/blog/most-shared-headlines-study/ 文摘菌有话说： 以后我就这样写标题了🌚你们想看吗？ 10件只有数据科学家才知道的事 这10个AI服务，让人起鸡皮疙瘩 人人都在谈论的大数据政策，会让你流泪 【今日机器学习概念】 Have a Great Definition "
166,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656892&idx=2&sn=74f2ea75d609c531292c19863516178e&chksm=bd4c352f8a3bbc39712309a7f5979746cad35b4e2b12dcba065ce0858bf3840994301fd9132d&scene=0,公开课 | 独家首发：微软Hackathon冠军队带你玩转新零售，堪比外挂的秘笈分享,大家好，文摘菌又来搞事情啦~ 本次公开课，大数据文摘邀请到了【微软大中华区 零售解决方案新创业黑客松】大赛上海站冠军团队成员之一、观远数据合伙人周远（字节）。他将从赛题背景、数据探索、特征工程、模型调优等方面，为大家带来观远团队在刚结束的黑客松大赛上的第一手经验： 销量数据预测有哪些难点？ 零售数据有哪些特征、需要怎样做预处理？ 时间序列、树模型、深度学习模型之间应该怎样选择？ 如何进一步优化模型？ 大家扫码即可加入直播间 👇 时间：2月5日（周一）18:00 形式：语音+PPT直播 ↑可永久回听↑ 文摘菌在这里也针对公开课内容为大家做个简要介绍： 黑客松比赛介绍 黑客松（Hackathon） 是黑客+马拉松（Hack+Marathon）的组合词，又叫编程马拉松，最初是流行于黑客（Hacker）群体的一种叫法，指多名黑客聚集在一起，以马拉松（不间断）的形式进行黑客活动。后来黑客松逐渐演化成一种活动模式，指一群人，在某一段特定的时间内，相聚在一起，以他们共同商定的方式，紧密合作、持续工作，实现一个共同的目标。 本次黑客松大赛由微软联合百威英博、可口可乐等零售行业大佬一起举办，微软提供云计 算平台资源和技术支持，零售业大佬提供世界级快消品牌运营中的真实数据问题，参赛队伍做出库存需求、销量预测等创新解决方案。 大赛涉及 顶级level+真实场景，与当下火热的新零售概念不谋而合。参赛队伍均为已获得融资的初创企业，成绩通过创新性、商业前景、技术可行性、客户业务结合度、成果展示等指标加权得出。 更重要的是，通过线下的密切合作方式，可以与数据技术同行、潜在客户以及投资方进行近距离的交流。 夺冠历程 比赛由百威命题，我们（观远算法团队）选择的题目是销售数量预测（POS forecasting）。 这题的数据是 销量。 门店总数有430+，产品总数有820+，总的数据量有400多万条每日销量记录。 比赛现场百威啤酒随意畅饮~ 比赛的数据只有门店、商品ID，所以很多诸如门店位置、天气情况、当地收入水平、各种体育赛事信息、 搜索引擎的关键词趋势等等 特征都无法加入，给比赛增加了一定的难度。 为此，我们首先查看并分析了数据的统计特征： 缺失值 数值分布 可视化 商品比较 初步分析后，我们对数据进行了预处理： 正则化：基于统计规则、基于模型预测、移动平均、对预测值做log处理 日期对齐 异常数据清理 接下来，就是特征选择了。在筛选了一些基础特征后，我们利用 XG Boost叶子结点信息来生成新特征。但是 用GBDT生成的特征进行数值回归效果一般。 在此基础上，我们发现了一种更加高效地实现从高维稀疏特征来自动构建特征向量空间的embedding方法，其原理类似于著名的Word2vec在自然语言处理领域的应用。针对构建好的特征，用t-SNE进行降维处理，得到了各个月份，各个门店，各个商品的相关度。 t-SNE降维 门店vs商品的节假日、周期性规律 接下来就是模型的选择和调试了。我们的基线是历史平均（平均绝对百分误差MAPE: 0.744），对比了时间序列模型、树模型、深度学习相关模型之后我们发现，在没有GPU的条件下，基于 Keras + TensorFlow的 神经网络表现一般（MAPE: 0.654），不如XGBoost（MAPE: 0.251）、LightGBM（MAPE: 0.256）。 Embedding 虽然深度学习相关方法看起来很吸引人，感觉不用做复杂的特征工程了，但实际上各种网络的参数还是相当多的：embedding层的shape，全连接层的数量和大小，dropout设多少，要不要做batch norm，激活函数用什么，预测值要不要做成分类问题，还是做归一化转成sigmoid处理？ 最终，我们选择了融合模型 ，MAPE值为0.236。 模型部署 嘉宾介绍 ，花名字节。毕业于浙江大学电气工程学院，曾任职于微策略，阿里云从事软件性能优化，技术研发等工作。现作为观远数据技术合伙人，主要负责数据分析平台后端开发。 ↑扫码进入直播间↑ 黑客松冠军和你分享踩过的坑 【今日机器学习概念】 Have a Great Definition 
167,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656892&idx=1&sn=3772288554e70326f34e52116cb4c777&chksm=bd4c352f8a3bbc394d10d7467d07e1a28bb5bb8fc020fbf1c620ebe098ad98fdc6d757d27828&scene=0,低调现身北京的吴恩达，刚刚给人工智能公司下了个定义,大数据文摘作品 记者：魏子敏 2月的第一天，吴恩达在北京完成了一次颇为低调的露面。 国家会议中心工业互联网峰会的主论坛上，吴恩达以Landing.AI创始人&CEO的身份，几乎全程中文，进行了一场题为《人工智能在生产制造业中的实践》的演讲。 图：吴恩达做了以《人工智能在生产制造业中的实践》为题的演讲 上个月，吴恩达宣布了自己的这家新公司Landing.AI的成立，并表示这一新公司将专注用人工智能辅助制造业领域的转型（ ），本次的演讲也基于他在工业领域AI应用的实践上展开。 和前两日高调启动的AI Fund基金，以及刷屏AI媒体的deeplearning.ai深度学习系列课程第五部分更新相比，吴恩达这次的北京之行似乎并没有得到太多的关注和曝光：他的演讲被排在“工业互联网产业生态与行业实践”的主论坛的第三位，十余页PPT，半小时的演讲时间，会后也没有安排任何媒体访谈或者行业会面，匆匆离开。 点击 感受 一下吴恩达的中文（随手录，请原谅渣画质） 尽管如此，整个主论坛依然座无虚席，在主讲台周围，很多听众甚至像”大学课堂“一般席地而坐。 图：整个主论坛依然座无虚席 两次强调自己斯坦福教育背景，吴恩达的此次演讲也颇为“学院风”，为现场工业领域从业者细心的讲述了机器学习和神经网络到底是什么。同时，他还罗列了监督式学习在生产制造中的事例。最后，吴恩达重新定义了他所理解的人工智能公司，也总结了对于人工智能时代的看法，可谓一次短小而精悍的精彩演说。 大数据文摘带来了吴恩达本次演讲的精华整理，根据现场演讲内容编辑，在不改变原意的前提下内容有删改： “如果本次演讲你只要记住一张ppt，那我希望你记住的是这一张。” 吴恩达在演讲中着重强调的这张PPT，对比了互联网时代和人工智能时代的几大特点： “ 很多公司对于互联网公司有一个误区，他们认为给一个商场配上一个线上网站，就等于互联网公司。 我之前曾经跟一个公司的CIO聊天，他说，亚马逊有一个网站卖东西，我们也有一个网站卖东西，那我们是一样的啊。当然不是一样的，因为亚马逊（Amazon）是一个典型的互联网公司。” 1、互联网公司需要大量的A/B测试 2、迭代速度很快 3、工程师及产品经理共同进行决策 互联网的产品和用户都非常复杂，所以不能只依靠首席信息官（CIO）一个人决策，还需要很多职位，需要产品经理、工程师一起来做，因为他们更加了解技术和用户之间的细节，这需要工程师和产品经理一起来做决策。 一个传统的技术公司加上神经网络或者机器学习，这还不是AI公司。能够安排你的公司做非常好的人工智能工作，这才是真正的人工智能公司。 坦白来说，现在谷歌和百度已经把自己尝试把自己变成一个AI公司，还没有做完，但是他们的想法是非常领先的。 二十年前，我们不会想到，a／b测试会变得这么重要，在互联网时代，我们花了一段时间才懂得a／b测试的重要性。 而到了今天，人工智能公司到底是什么，我们也没有完全想清楚，但我觉得有可能会包括这些要点： 1、数据搜集的战略： 如何搜集数据？通过什么工作，在什么国家搜集数据，都需要明确。这是个很复杂的问题。 2、集中的数据库： 今天回去大家就可以开始做这件事，如果你的公司有50个数据库（databases），如果一个工程师做某个项目的时候需要去到50个数据库找数据，那是非常困难的，所以现在的趋势是要尽量把数据集中起来，这件事各位今天就可以开始做了。 3、普遍的自动化： 同时我也看到很多AI公司正在做这件事，有很多自动化的机会。 4、新的人才需求： 机器学习工程师，计算机视觉算法工程师。 而今天在许多人工智能公司，产品经理和工程师的工作也发生了变化。 在互联网时代，如果你要做一个app，工作流程一般是产品经理来画一张图，工程师会看产品经理的这张图再去写代码。而在人工智能时代，比如你要做一个自动驾驶的产品，产品经理没办法直接做一张图，他需要把一些数据给到工程师，让工程师从数据库拿数据，然后要求达到某个数值的准确率。 今天在AI公司，我们的产品经理和工程师的工作已经产生了不小的变化了。 那么我到底要不要使用人工智能呢？ 在很多公司，大家会认为要先有信息革命（IT revolution），因为很多传统行业中，信息还是写在纸上，我们需要把信息先存在电脑里，产生数据，之后才能进行人工智能革命（AI revolution)。 举个例子，我觉得金融（行业）是一个人工智能（进展比较好的行业），因为金融有很多在线的数据，所以这个行业的人工智能革命已经快要起来了。 医疗行业我也很看好，在美国有“奥巴马医疗改革（Obamacare）“，中国也一样。十年前你的x光片可能就是一张片子，但现在医疗数据都是在电脑上的，所以其人工智能革命也在进展中。 而工业和教育（行业）正处于发展中。 有很多人问我AI的战略问题，我需要三年时间先把IT搞好，那么是不是三年后我再来做人工智能革命。我的建议是，不要这样做。 如果你的公司已经有了一些物联网（IOT）的部署，有了一些数据，那么我会鼓励大家先用AI来试一试，找AI团队，先用这些数据给IT团队一些反馈：到底是每十分钟采集一次数据还是每秒钟采集一次数据？这也是很大的价值。 其实，今天即使最好的人工智能公司，他们的IT革命也是不断完善，他们的数据也不是完美的。 如果左边这个圈代表人工智能的优势，右边这个圈代表产业知识，那么我们想做的是选择中间的一些机会，用人工智能可以做，并且对你们的公司有益处。今天的人工智能和产业都很复杂，所以人工智能专家应该和产业专家结成跨行业的团队，才能产生最大的价值。我个人背景是人工智能，所以也很兴奋有机会和很多制造公司合作，才可以获得两个圆中间最有价值的机会，希望未来有更多机会和各位合作。 吴恩达也在本次讲座中指出了一些人工智能在工业中的应用案例，我们在此简单列举给各位： 100年前，电能对社会带来了巨大变革，人工智能也将对各行业带来同样的影响👇 人工智能在工业互联网时代有着各种应用👇 吴恩达也提出了一些人工智能在生产制造中的实践和应用案例，比如自动视觉检测👇 比如机器参数调整，产品优化，维护预测👇 监督式学习在生产制造中的示例👇 其他人工智能模型👇 【今日机器学习概念】 Have a Great Definition 
168,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651657275&idx=1&sn=fbb57f4a10fa10b268face2284c945e9&chksm=bd4c33a88a3bbabe5af4690d949348a391fa29c516b67013b4716ddd4cc15d3a57dcff48a7b5&scene=27,亲历互联网泡沫，我从中为区块链发展汲取了这些经验,"大数据文摘作品 编译：Niki、小饭盆、Shan LIU  、小鱼 我常将当今区块链的发展和互联网早期的发展对比。 从2013年到2015年，区块链的发展现状与互联网在1994年所处的阶段相似： 大众对去年ICO的集体狂热，与1995年美国网景公司（Netscape）的股票首次公开发行(IPO)时简直如出一辙；   而现在，市场对区块链的态度很接近1996年的情形。 当时投资者也是热捧互联网企业，而且确实研发出了很多出色的科技成果，只是大家的注意力更多放在了他们为之疯狂的互联网股票上。   当然，这种对比不完全可取，它们之间也不一定都是简单的线性关系。   对于是否能用互联网的历史发展映射区块链的发展进程，我们持怀疑态度。 真的有价值的是解决方案，而不是遇到的问题   我们总是需要一段时间来接受和认可这种新兴的复杂技术，而真正有价值的其实是具有优雅与创新特点的解决方案。   1994年人们开始对互联网着迷时，我说过：   “互联网是一种绕过审查机构传递数据的方式。这一方式是通过获取数据，然后将其分散成多个数据包，然后从一个节点发送到下一节点，直到这些数据被传送到最终目的地，最后再进行组合，从而避开审查机构。棒极了！！！！” 2013年大众的视线转移到比特币上，我说过：   “比特币是一种人与人之间进行资产转移的方式，绕过了审查机构和第三方的监管。那么这是如何实现的呢？首先你会拥有一个私人密钥，通过这个密钥可以将交易信息传输到一个对等网络上。在这个网络上，成千上万的“矿工”争先恐后的将这笔交易信息加密后写入一个全网络用户都信任的交易区块中。”   互联网和区块链在发展过程中面临不少难题，但对于大多数国家的人，这些问题无关紧要。   那么互联网和区块链对于这一问题的解决方案是什么呢？ 在互联网时代，没有人在意今天发生了什么。而对于区块链，没有人在意明天会发生什么。   这两个故事的关键在于它们都是从好的方面出发，相比它们带来的问题，大家更关注他们作为解决方案所带来的便利。 开创性的解决方案发展成为一个新行业 尽管互联网在1994年时是社会热点，实际上却没有真正意义上的互联网行业或商业。直到1995年八月，在网景上市后，这个行业才开始蓬勃发展。 搜索引擎Altavista 美国数字设备公司（DEC）Palo Alto实验室的研究员Louis Monier在1995年十二月发布了Altavista搜索引擎。Altavista成为了网站一夜成名最早的故事之一，也成为在那个时代最重要的搜索引擎。   之前富有创造力现在却有些古板的DEC公司的主管们意识到：原来我们是像网景一样酷炫、高价值的互联网公司啊。   当时的DEC已经有了一系列成功的网络产品，他们把这些产品出售给企业、政府和大学。产品涉及互联网的方方面面：从路由器、网卡到防火墙、email服务器（支持X．400电子邮件系统）。   一夜之间，这些产品被迅速转移至匆忙创建的互联网业务部门内，并全部更名为AltaVista。   截至1996年一月，我还住在牙买加首都金斯敦，运营着CaribWeb和一系列算是比较成功的旅游网站。   随着“网络管理员”这一新岗位的出现 ，市场上任何一个稍微懂点HTML，CGI和PERL的人都被大公司挖走了。   我最终还是接受了来自AltaVista关于“企业网络管理员”一职的邀请，成为了团队的创始成员之一。短短几周内，我们又挖来了Lotus市场部高管团队的大部分人，那时微软在办公软件的竞争中打败了Lotus。   我们的口号就是：互联网，互联网，互联网。那时候在互联网市场没有人比我们更有经验或是有更强大的产品组合。我们主要的目标市场是那些迫切想要转型为互联网公司的企业。   当然，互联网作为解决方案，它要解决的问题还不是很清晰。就像其他一些新发展的行业，我们把互联网解决方案卖给需要构建互联网解决方 案的 人。 当时的互联网是一个泡沫，但我们都从中受益 那时很多明智的人把互联网行业称为一个巨大的庞氏骗局，其实是可以理解的。  最初，从1995年到2000年，互联网行业的商业模型就是上市和通过发布与其他互联网创业公司合作的新闻来提升股价。   但我并不否定这个发展过程。我们现在都从互联网所衍生的看似无意义的革新中受益。我们现在使用的大部分核心技术和知识，也是得益于当时的融资促进了互联网行业的迅速发展。   当这一切发 生时，也有一些公司在跟随互联网飞速发展的同时 ，依然坚持他们自己的观点和远景。亚马逊就是其 中最有名的一个例子。   在2000年，互联网公司不再采用单一提升股票的经营方式，而是专注于解决实际问题，最后他们也成功了。现在多数大规模的互联网公司都是那个时期开始兴起的。   在2000年的巨大冲击后，得益于技术的发展，没有人再有钱去支付Sun和甲骨文(Oracle)的许可费了。Apache、Linux、 mysql、Java 和 PHP 等技术开始兴起。   讲到这里，希望大家能看到，互联网的发展和我在AltaVista的经历与比特币和现在的区块链行业之间的相似性。   当时我们努力想把这些互联网行业的疯狂想法应用于其他各行各业。我们掌握着解决方案，也明白这将是一场技术革新，它会改变生活中的一切，却常因为行业内很少有人采用我们先进的技术而沮丧。 在正确的时间着手解决最简单的问题   在1995年初，一个对互联网行业充满好奇的销售员将一个学术会议网站卖给了Reed Elsevier（全球最大的科学与医药信息出版商）。他雇我来管理网站，那时我刚刚从威尔士大学毕业，在制作自己的第一个付费网站gig。不记得他是怎么找到我的，大概是通过一个新闻媒体。 这个学术会议网站很成功，因为他们的出版物，我们满怀信心地选择了这个网站。但是董事会上出现了问题，后来被告知董事们的困惑是“为什么人们愿意选择互联网上的出版物。”   我觉得这个故事发生在网景的SSL协议发表的那段时间之前或左右。那时候还没有支付网关。人们需要打印出那些期刊书籍，因为没有人喜欢在640x480 VGA CRT 的电脑屏幕上读书。而且在那个时期大部分高管从未接触过电脑，所以用电脑读书这个想法对他们来说是异想天开。 总的来说我们就是在那个时期的市场上太过超前了。   在互联网可以解决行业存在的实际问题之前，很多看似毫无关联的科技、市场和行业都应该及时出现，以支持互联网行业的发展。 互联网解决的超级简单问题 一开始我确实在旅游网站工作，第二年我搬到了英属维尔京群岛（BVI），同时期互联网公司开启了拨号连网服务。 我把个人网站的BVI部分租给了当地的出版商。我刚刚查过，23年后的今天网站依然存在。   在一个月内，大约15％的人口已经注册了互联网，主要是因为打给美国的电话或传真每分钟的费用是3美元，所以电子邮件解决了一个切实的需求。 在我去牙买加之前的几个月里，我将网站出售给大约10-20家酒店和餐馆。之所以这么容易将网站卖出，因为这些企业的确有向美国的富裕游客推销自己的真实需求。 当然，这只是一个例子，但是互联网已经解决了这些超级简单的问题：   •与家人和世界各地的客户进行交流   •将小企业推广到国际市场 比特币 比特币的出现是为了解决2个不同但相关的问题：   提供了分布式的电子储值方式   没有第三方或监管机构情况下，提供了快速又便宜的P2P支付方式   到2011年，无意中又加入了一个重要的用例：   投机性增长资产   到2013年初，我放弃了所有其他项目，专注于比特币便宜的P2P支付方式。我推出了针对发展中国家的Kipochi定向付款。   我们推出的这种付款方式过于先进。相比于BTC肯尼亚人更喜欢先令。现行的主流支付技术正在竭尽全力阻止我们从法定货币和BTC之间的转换。   换句话说，有些事情需要在最新的支付方式落实之前解决。   在过去的几年中，用比特币进行支付让我和来自不同国界的同事感受到了巨大的便利。但是这种支付方式并没有普及开来。   讽刺的是，比特币作为一种储值和投机性增长资产表现却非常出色，截至2017年底，比特币的价格一路飙升，以至于 Satoshi针对快速便宜的P2P支付的解决方案都无法使用了。希望Lightning Networks能够揽回大局。 以太坊 以太坊承诺在技术上将做出更大的突破。也许技术层面还达不到早期喊出的口号—“The world’s computer”。   最初，我对以太坊很感兴趣，但是看到上面的口号就把我拒之门外了（由于个人经济条件有限）。 直到2015年底，当以太坊的基础设施基本完善后，我才开始重新关注。   在过去的两年中，我一直尝试建立一个名为uPort的以太坊分布式身份校验平台。所以现在我非常看好以太坊。   将区块链技术应用到各行各业需要做很多的尝试，就像早期的互联网。   也就是说在区块链应用普及之前，我们得先拥有大量的开发者和相应的开发工具。   2017年绝对是科技准备发力的一年，与此同时我们也将专注于规模化的解决方案。   尽管目前区块链技术相关的平台还没有获得合法的执照。但我相信替代DAO的公司可能会在一两年之后出现。如今，以太坊上运行着真实的应用程序，并且解决着现实存在的问题。   我对这一波ICO热潮持怀疑态度。但是谁也不能否认在以太坊上部署ERC20 tokens协议的简单性，这个过程已经取得了巨大的成功。即使像CryptoKitties这样一个很简单的养猫游戏，却成了一个赚钱利器，同时它也是一个真正意义上的区块链应用程序。   就像90年代人们为之疯狂的互联网，目前绝大多数的ICO是建立迅速致富这样愚蠢的想法之上。   但与此同时（就像在90年代），正是由于这笔资金，区块链各种重要的基础设施和开发工具才能不断完善 等你去参加下一届Devcon会议，你就知道我在说什么了。   另外还有不少由天资聪颖的人创建的ICO（和私有资金资助的）项目。他们在等待时机成熟的同时，也从经济模型、政策机制和工具等方面做全盘考量。   区块链将是新一代的亚马逊、Google和PayPals。 区块链的可扩展性 每个人都担心和抱怨区块链的可扩展性。这也是一个值得关心的问题，就像当初人们在接受互联网时所持的态度。   1996年的时候我还在AltaVista，当时写了perl代码，在每个http请求上启动一个新的unix进程。接着服务器启动一个新的unix进程连接到数据库，然后生成HTML。HTML从我们在帕洛阿尔托的数据中心发送到世界各地，整个过程效率超低。   很快，fast-cgi，nsapi，isapi和servlets改进了上述缺点，我们也可以一直连接DB数据库。CDN开始将静态数据向用户迁移，编程语言发展的也很快。   多年来，我们从单进程，多进程再到异步线程不断发展。开发人员越来越聪明，极大程度地利用了缓存这一功能，所以现在支持大规模Web应用程序轻而易举。   以太坊也遵从着同样的发展规律。以太坊的第一个版本就像互联网早期的CGI版本。在这种趋势下，POS，Sharding，WebAsm，Plasma, Raiden, Truebit等项目的性能也将大大提高。   作为开发者，我们也应首先关注链上逻辑。   最重要的是，这些关键的技术发展是相互独立的。不过即使它们其中一个或两个出现问题，我们仍然可以从剩余的部分获益。 展望   在我们这个领域的人始终坚信，我们会解决世界上各行各业的很多问题。   实现这个过程可能并不像人们想象的那样容易。   也不要担心出售区块链业务或相关产业时需要大费口舌去说服对方。   有很多商业方面的实际问题通过区块链都可以轻易解决，并且市场对区块链业务也有一定的需求。但是，在推荐你出色的解决方案之前，多花些时间听听客户的实际需求。   除了像Jeff Bezos，Marc Andreesen和Peter Thiel这样的少数企业家外，   尝试去发现像这样的人吧！那种为区块链构建基础设施、制定标准和开发工具而忘我工作的人！   原文链接： https://medium.com/@pelleb/personal-look-at-the-early-days-of-internet-vs-blockchain-today-590a98cb009f 【今日机器学习概念】 Have a Great Definition "
169,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656844&idx=2&sn=b5e02244f82d29f51d8f0f1fe535fc42&chksm=bd4c351f8a3bbc09ae89da99d05c8b9b2e647f60deef343ff44aa4dc14aa58a8a213217dd1d8&scene=0,在这个信息爆炸的时代，如何治愈你的焦虑,每个人都有焦虑，一处BUG、一份工作、一次约会，都会导致人产生焦虑的情绪。 而在这个不安、求快、新旧交替的时代，对于大多数人来说，并不是最好的时代，金字塔顶端的位置永远是有限的。 以前，一个人想要进入一个领域，最有效的方式就是买许多这个领域的书，耐心地、由浅入深地读。但自从有了互联网，世界开始变得不太一样了。当我们遇到解决不了的问题，总是喜欢去百度一下，很多详细且免费的信息就这样轻而易举的被大家获得了。 随之而来的，就是这些海量的驳杂的信息所带来的焦虑感了。其最本质的原因就是信息太多，我们完全处理不过来。另外，还有很大一部分人心里面的想法是： 于是，人们开始随波逐流，看到别人在学什么就跟着一起去学。 但，获取知识的最高境界，并不是什么都懂一点，而是有着自己独立的思考，去选择想要学习的知识，并真正掌握这些知识。 下面这些文章和公众号，推荐给大家，希望各位能够从中收获不一样的知识。 ☝ 在日内瓦举办的联合国特定常规武器公约会议上，一段可怕的视频公诸于众…… ☝ 点击文章标题查看内容 走进业界大神的世界，教你读懂数据、学会管理、了解投资！文中附送AI/区块链/大数据强悍资源。 ☝ 点击文章标题查看内容 在金融市场上有一句广为流传的说法：当出租车司机都告诉你要买股票时，你就该知道是时候抛售了。当韩国大妈都在激烈讨论区块链技术的时候，你就该知道这玩意儿变味了。 ☝ 点击文章标题查看内容 厂商们为了提高手机屏占比，红外线、耳机孔、指纹物理按键都慢慢被干掉，那下一个被砍掉的是什么？未来手机形态又是怎样？ ☝ 点击文章标题查看内容 为什么你在超市买了一瓶酒，今日头条就给你推荐开瓶器，你在各大app面前还有隐私吗？ ☝ 点击文章标题查看内容 微软官方通过发起投票来收集更多用户的反馈信息，在线调查用户想要如何在 Excel 中使用 Python 。 ☝ 点击文章标题查看内容 大数据，高并发的互联网业务，微服务架构势在必行，为何服务化了，系统的耦合却更加严重了呢？又该如何解耦呢？尽在此文。 ☝ 点击文章标题查看内容 架构师很苦很难，但他们却是一群改变世界的人！ 【今日机器学习概念】 Have a Great Definition 
170,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656798&idx=1&sn=fc7699a893f3a619dc6d912f37d60253&chksm=bd4c35cd8a3bbcdb2682656a6263df60bfdb2f73ec8c5a5b8eb0ea2fcdfc96100d2cc2089c63&scene=0,吴恩达更新了！深度学习系列课程第5课放出，全剧终,大数据文摘作品 作者：龙牧雪，魏子敏 在各位同学们推特、朋友圈、Coursera不懈的催更之下，跳水了几个月的吴恩达爸爸终于推出了深度学习系列课程的第五部分。至此，吴恩达的深度学习系列课程完整发布，各位同学可以放心开始上课了。 Coursera课程链接： https://www.coursera.org/learn/nlp-sequence-models 图：deeplearning.ai官网的第五课状态终于从coming soon变成了可点击 图：Coursera官网显示，深度学习第5部分课程1月31日开始 昨天凌晨，吴恩达通过海外科技媒体medium公布了自己继deeplearning.ai和Landing.ai之外，第三个落地的人工智能创业项目——创投基金AI Fund。（点击查看大数据文摘相关报道 《吴恩达创业项目第3弹揭晓：创投基金AI Fund，已募资1.75亿美金》 ）。 而在如此激动人心的消息之下，网友们却无心捧场，留言完全是另外一片画风：集体催更课程！ 图：大佬别忙着搞大事情了，先把课程发完啊～～ 文摘菌的文章下的留言区也未能幸免： 图：从暑假等到寒假了，心疼这位同学一秒钟 我们等课程到绝望的小伙伴，昨天也发朋友圈说，大佬再不发更我就要去喊大家“写联名信催更”了！ 图：各种表情包出炉 确实，去年8月份，吴恩达的初创公司deeplearning.ai通过Coursera提供深度学习的最新在线课程，并列出了5个部分课程的上线日期。 但是，第五部分的课程一拖再拖。作为一个按月收费的课程，大家催更的心情也非常可以理解了。 图：说好的2017年12月更新，硬是拖到月底，再拖到2018年1月…… 依旧是7天免费试听，之后49美元/月，按月收费（这也是万众催更的一部分原因吧哈哈哈，每拖延一个月，可是要多花49刀啊）。 如果你只想看视频，可以选择用Audit模式旁听课程，免费，但是不能做作业（编程练习），也不能完成小测验。 课程需要三周时间完成，共包括约4小时的视频，10小时的练习和小测验。从这个配比来看，练习和测验依旧是课程重头戏。 第一周：循环神经网络RNN RNN Gated Recurrent Unit(GRU) LSTM 第二周：自然语言处理和词嵌入 Word2Vec GloVe 第三周：序列模型和注意力机制 Beam Search 语音识别 图：Coursera课程内容 图：网易云课堂上的汉化课程目录  练习依旧使用在线云平台完成，可以直观看到模型的产出。 图：Coursera的练习平台 有了第五课“Sequence Models”里面关于NLP的内容，吴恩达终于把深度学习系列的内容拼全了。从深度学习入门，到计算机视觉，再到自然语言处理，吴恩达的课程无疑为想入行人工智能的小伙伴们提供了极佳的入口。 学习之前，大数据文摘也总结了一些大牛们写出的前四课的课程笔记给大家，可以点击查看： 总体来看，大数据文摘之前也提到过，吴恩达的这门课程整体来说属于深度学习的基础课程，因为课程定位为AI普及课，内容事实上更适合初学者，如果之前已经学习过coursera上相关课程的同学或者比较专业的选手，就不需要再重新学一遍这门课程了。 当然，想要系统学习深度学习的同学，我们也推荐一些更加专项的课程给大家： 多伦多大学三巨头，被誉为“深度学习之父“的Geoffrey Hinton教授在Coursera上的Neural Networks For Machine Learning课程。他的UT实验室在2012年的某医药大赛中如一匹黑马般赢得桂冠（即使整个团队没有一个人懂生物），真正地把深度学习带入了主流媒体的视线。链接 https://www.coursera.org/learn/neural-networks 斯坦福大学CS231n卷积神经网络视觉识别课程（李飞飞授课），大数据文摘授权汉化教程链接： http://study.163.com/course/introduction/1003223001.htm 斯坦福大学CS224d自然语言处理深度学习课程，链接： http://cs224d.stanford.edu/ 牛津大学与DeepMind合作的自然语言处理深度学习课程，大数据文摘授权汉化教程链接： http://study.163.com/course/introduction/1004336028.htm MIT 6.S094深度学习与无人车课程。大数据文摘授权汉化教程链接： http://study.163.com/course/introduction.htm?courseId=1004938039 专门致力于为深度学习工程师提供教育资源的fast.ai。链接： http://www.fast.ai/ Tensorflow提供的机器学习教程，分为两篇 初学者篇： https://www.tensorflow.org/get_started/mnist/beginners 进阶篇： https://www.tensorflow.org/get_started/mnist/pros AI圣经级教科书（花书）－蒙特利尔大学教授Yoshua Bengio和他的前学生Ian Goodfellow合著的《Deep Learning》；英文版免费阅读： http://www.deeplearningbook.org/ 中文版也已上市！ 以上是一些免费课程，如果想要保证听课质量，保证有答疑和练习，我们也推荐网易云课堂一些收费课程： 人工智能的数学基础。链接： http://mooc.study.163.com/smartSpec/detail/1001358003.htm 机器学习工程师实战课程。链接： http://mooc.study.163.com/smartSpec/detail/1001358002.htm 本文图片来源 https://www.coursera.org/learn/nlp-sequence-models/home/welcome http://mooc.study.163.com/course/2001280005#/info 【今日机器学习概念】 Have a Great Definition 
171,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656844&idx=1&sn=8610ff1e50e9ef0e7a6096522f0ef28c&chksm=bd4c351f8a3bbc096672c70c06474e535c3649909304b5f65698c996f6ec320092602432b541&scene=0,2017年你错过了哪些AI圈大事？最全盘点，值得收藏！,大数据文摘作品 编译：彭湘伟、吕征达、小明同学、林海、Yawei Xia 假设你在2017年昏睡了一年，忽然惊醒的时候，想要了解这个世界在今年有哪些最值得骄傲的成就，这篇文章 值得你花几十分钟读一读 。 这一年，谷歌发布了Google Translate的新模型，并详细描述了网络结构——循环神经网络。Facebook的聊天机器人，因为失控创造了自己的语言被关闭。DeepMind 的研究员在他们的文章中展示了如何生成语音。一个已经成功超越人类的深度学习成就叫做唇语识别。 本文将带你浏览2017年几乎所有最有意义的AI研究，从文本、语音、计算机视觉到强化学习和最重要的新闻。 其中的大部分事件，文摘菌都在其发生之时做过相关报道，回忆起来，感慨万分，我们也在相应部分附上了报道链接，方便查看细节。 大约一年前，谷歌发布了Google Translate的新模型，并详细描述了网络结构——循环神经网络。 链接： https://blog.statsbot.co/machine-learning-translation-96f0ed8f19e4 关键成果： 与人类翻译的准确率之差缩小了55%-85% （研究者使用6分制打分标准评估得到）。如果不依赖谷歌庞大的数据库进行训练，这一结果很难复现。 你可能听过这个谣言：Facebook的聊天机器人，因失控创造自己的语言而被关闭。 点击查看大数据文摘相关报道 该聊天机器人原本被设计用来谈判，其目的是与其他机器人（代理）进行文本谈判并达成协议： 每一个机器人（代理）有对方不掌握的交易信息。同时，谈判的设定是不达成交易就不终止。 他们收集了一个人类谈判的数据库，并训练出了一个监督式的循环网络。随后，他们让强化训练后的机器人，通过自我对话的方式继续训练，直到与人类语言近似到一定程度为止。 该机器人已经学会了一种真正的谈判技巧——对交易中的某些因素假装表现出兴趣，随后仅仅通过牺牲它们来达成真正目的。 新闻里声称机器人发明了一种新语言，这种说法有点过于夸张。当用同一个机器人来训练的时候，它没有被限制必须用与人类语言，所以算法进行了一些变异，这很正常。 文章链接： https://blog.statsbot.co/machine-learning-translation-96f0ed8f19e4 在过去的一年里，循环网络得到了很大的改进，并被应用于诸多领域。RNN的结构也越来越复杂，但是在某些领域，简约前向网络（DSSM）都取得了相似的结果。例如，在邮件智能回复方面，谷歌取得了与LSTM之前一样的效果。另外，Yandex基于这套网络，发布了新的搜索引擎。 DeepMind 的研究员在他们的文章中展示了如何生成语音。简单的说，他们基于之前生成图像的方法，PixelRNN 和PixelCNN，创造了一个自回归全卷积的WaveNet模型。 该网络被以点到点的方式训练： 最终研究人员取得了极好的结果。在语音生成方面，机器人与人类的差距缩小了50%。 该网络的主要缺陷在于效率低下。因为使用了自回归技术，音频是按顺序生成，并且每1-2分钟，才能生成一秒语音。 如果去掉对文字输入的依赖，仅仅基于前期产生的语音，该网络会产生出类似人类的语言。但这样并没有实际意义。 这一模型不仅仅可以用于语音生成，也可以用于音乐创作。 设想，在不依赖输入数据的情况下，仅仅被钢琴游戏的数据库训练，该模型便可生成音频。 唇语识别是另外一个已经成功超越人类的深度学习成就。 点击查看大数据文摘相关报道 《Lip ReadingSentences in the Wild》。Google Deepmind 在这篇于牛津大学合作发表的论文中，公布了他们给予电视数据训练的模型。该模型性能超越了BBC频道专业的唇语阅读员。 该数据集包括10万条配有音频和视频的语句。LSTM训练音频，CNN+LSTM训练视频。最后将两者的状态向量作为最终LSTM模型的输入，以产生文字输出。 训练中，使用不同的数据类型，包括音频，视频以及音频+视频。换句话说，这是个多渠道模型。 华盛顿大学进行了一项研究，以合成美国前总统奥巴马的嘴唇动作。选择他为对象的原因在于，在网络上有大量他的视频（17小时的高清视频）。 他们不能过多地直接使用网络模型输出的合成画面。因此，论文的作者使用了一些技巧来改善纹理的时间方面的问题。 效果如此令人震惊。 谷歌大脑团队在他们公布的文章中，介绍了他们如何将新一代OCR（光学字符识别）引擎引入谷歌地图中，以实现街道标志和店铺标志的自动识别。 点击查看大数据文摘相关报道 在开发过程中，谷歌解码了新的FSNS（法语街道名标示），有很多复杂的场景。 为了识别出每一个标志，网络模型最多使用了标志的四张图片。特征通过CNN提取后，经过空间变化（考虑像素坐标）再输入到LSTM模型中。 相似的方法被用于识别布告牌中店铺名称的的项目。但是该项目的图像数据有很多无关信息，网络模型必须对焦正确的信息进行读取。这一算法已经被应用于800亿张图片上。 另一种称做视觉推理的任务，是要让神经网络利用图片中信息来回答问题。例如：图片中有于黄色金属圆柱体一般大的橡胶物品么？这种问题对算法来讲很难，到目前为止，准确率只有68.5%。 点击查看大数据文摘相关报道： DeepMind在这一领域取得了突破，在CLEVR数据集中，他们取得了95.5% 的超高准确率。 这一网络模型的结构很有意思： 1. 通过预训练好的LSTM模型，从文字问题中抽象出问题。 2. 使用4层的CNN模型，从图片中得到特征图（下图中的黄色，蓝色，和红色部分），再加入坐标，将其与文字对应起来。 3. 之后，再用另一个网络模型处理并集成这三类特征。 4. 最终，通过一个前反馈网络中的柔性最大激活函数（softmax），将答案呈现出来。 Uizard（一家哥本哈根创业公司）开发了一款趣味十足的基于神经网络的应用程序：它能够根据界面设计师的截屏图片生成GUI（图形用户界面）的布局代码。 这是一款十分实用的神经网络应用程序，它能够让软件开发变得更加容易。开发者（作者）声称该应用可以达到77%的准确率。不过，这款应用程序仍处在研究阶段，尚未投入实际使用。 现在暂无项目的开源代码和数据集，但是该公司承诺未来会在网上发布。 也许你已经见识过了谷歌的“Quick，Draw！”，一款让用户在20秒内画出不同物体草图的小程序。谷歌公司收集该程序的数据集来教会神经网络如何作画，正如他们在博客和文章中介绍的那样。 公司收集到的数据集中包含70000张草图，这个数据集现已公开。草图不是以图片的形式表示的，而是以图中线条的详细的向量形式表示。 研究人员使用RNN训练出序列到序列的变分自动编码器来作为编码/解码机制。 最后，为了适应自动编码器，模型接收描述原始图片特征的特征向量（隐向量）作为输入。 而解码器可以从输入的向量中提取出一个图，并且可以通过改变输入向量获得新的草图。 甚至可以通过向量运算创造出“catpig”（猫猪）的形象。 生成对抗网络（GANS）是深度学习中最受关注的主题之一。多数情况下，这个网络是用来处理图像的。 点击大数据文摘相关报道 文章链接： https://blog.statsbot.co/generative-adversarial-networks-gans-engine-and-applications-f96291965b47 GANS的思想是两个网络——生成器和鉴别器——的竞争。第一个网络生成一张图片，第二个网络则是试图分辨出该图片是真正的图片还是生成的图片。 GANS的示意图如下所示： 在训练过程中，生成器首先通过一个随机向量（噪音）生成图像，然后把它输入能够判别图像真假的鉴别器中。来自真实世界的图像同样会被输入到鉴别器中。 这样的结构难以训练，因为很难找到两个网络之间的平衡点。多数情况鉴别器获胜然后训练过程陷入停滞。不过，该系统的优点是可以解决鉴别器的损失函数（比如，提高照片的质量）难以设置的问题。 经典的GAN训练结果样例是卧室图片以及人脸图片： 先前我们讨论了自动编码（Sketch-RNN），即将原始数据编码成一个潜在的表示形式。生成器的工作原理也是一样的。 使用向量生成图像的想法在这个项目中的人脸生成样例中有很好的体现。你可以通过改变向量来观察人脸是如何改变的。 同样的算法也适用于潜空间： “戴眼镜的男人”-“男人”+“女人”= “戴眼镜的女人” 如果在训练过程中，你赋予潜向量一个被控参数，那么当你生成该向量时，你就可以通过改变它来管理图片中必需的图像了。这种方法称为条件GAN（conditional GAN）。 “Face Aging With Conditional Generative Adversarial Networks.” 的作者们就是这样做的。通过IMDB数据集中年龄已知的演员的照片来训练模型，研究人员们就有机会来改变他们的脸部年龄。 谷歌又找到了一个GAN的趣味应用——筛选并改善照片。GAN由专业图片数据集训练而来：生成器要改善不尽人意的照片），而鉴别器要做到区分“改善后的”照片和真实的专业照片。 训练好的算法通过谷歌街景全景寻找最佳的构图，同时获得一些专业的、半专业质量的图片。（根据摄像师的等级） 一个令人印象深刻的GANs的例子是通过文本生成图像。 这项研究的作者提出不仅要将文本嵌入生成器（条件GAN）的输入中，还要嵌入到鉴别器中，以便验证文本和图片的相关性。为了确保鉴别器能够学习并执行预期的功能，除了正常的训练过程，他们还添加了错误描述真实图片的文本及相应图片，并一起投入训练。 2016年度引人注目的文章之一是BAIR的“Image-to-Image Translation with Conditional AdversarialNetworks” 。研究人员解决了由图像生成图像的问题，比如当需要由卫星图像生成地图或者通过草图绘制物体的真实纹理。 点击查看大数据文摘相关报道 这是条件GAN的又一个出色表现的例子。在这个例子中，条件由整个图片决定。图像分割中的热门技术UNet被用来作为生成器的结构，新提出的PatchGAN分类器被用来作为鉴别器以防图像难以区分。（图片被分割为N小块，每一块的真假分别预测） Christopher Hesse做了一个猫的演示，这个演示引起了用户对Pix2pix的极大兴趣。 为了应用Pix2pix，你需要来自不同领域的对应成对的图片数据集。比如，在这种情况下，通过纸牌来生成这样的数据集并不是件难事儿。然而，如果你想做些更复杂的，像“改变”图片中的物体或图片风格，从原则上来讲这样的数据集无法获取。 点击查看大数据文摘相关报道 因此，Pix2pix的作者们继续深入思考并提出了CycleGAN来实现不同领域图片之间的转换而不需要明确的匹配——“Unpaired Image-to-Image Translation.” CycleGAN的思路是训练两对生成器-鉴别器来把图像从一个领域转变到另一个领域再转变回来，这样的话需要保证周期一致性——在一系列的转变之后，要得到与原始L1损失相近的图像。周期损失则是保证生成器转变后的图片不会与原始图片完全不相关。 这个方法能让你把马变成斑马： 这样的转变并不稳定，经常会出现失败案例： 机器学习同样在医药领域大展身手。除了超声波图像、核磁共振图像和诊断识别外，机器学习还可以用于寻找新的抗癌药物。 我们曾经报道过该研究的详细内容。简单来说就是在对抗自编码器（AEE）的帮助下，可以得到分子的潜在表示并用以寻找新的分子。基于此，已有69种新分子被发现，约有35种已经投入到对抗癌症的使用中，其余的分子也拥有巨大潜力。 很多学者都对对抗性攻击这个主题展开了积极探索。什么是对抗性攻击？举个例子，在ImageNet上训练得到的标准网络在受到特殊噪声影响的图片上进行分类会变得十分不稳定。在下面的例子中可以看到，人眼观察到经过噪声影响的图像与原始图像相比基本没有变化，但是模型却出现预测错误的问题。 点击查看大数据文摘相关报道： 《用100元的支票骗到100万：看看对抗性攻击是怎么为非作歹的》 模型的稳定通过FGSM算法已经实现：通过调节模型的参数，可以朝着期望类别的方向改变一个或多个梯度步长，并且改变原始图片。 Kaggle上的一个项目就与此相关：参赛者需要创造万能的攻击/防御图片，最终决出谁是最好的。 为什么还应该研究攻击呢？第一，如果我们想要保护自己的产品，可以在验证码上添加噪声来阻止垃圾信息传播者自动识别它们。第二，算法逐渐融入到我们的生活中——人脸识别和自动驾驶。这时候，攻击者就可以利用算法的弱点了。 下面是一个特殊眼镜欺骗人脸识别系统并“冒充他人”的例子。因此，在训练模型的时候我们应该把可能遭受的攻击纳入考虑范围内。 这样处理后的指示牌也是无法正确识别的。 强化学习是机器学习中最有意思且最有活力的发展路径之一。 这种路径的核心在于学习agent的成功行为，而这基于一个通过经验给予奖励的环境，就和人类通过他们的生活学习一样。 强化学习被积极应用于游戏、机器人和系统控制中（比如交通系统） 当然很多人都已经听说“阿法狗”在比赛中战胜了顶级的职业选手。研究人员使用“加强学习”训练机器人，机器人通过自己的演练，来提升自己的策略。 在过去的几年里，DeepMind已经学会了使用深度强化学习来玩游戏，甚至比人类玩得更好。目前，算法已经学会玩更复杂的游戏，比如Doom。 大部分的注意力集中于加速学习，因为在与环境的交互作用下，agent的经验需要在modern GPUs上进行大量训练。 在他的博客中，Deepmind报告说，引入额外的损耗(辅助任务)，比如预测帧的变化(像素控制)，使agent更好地理解行为的结果，从而显著加快学习速度。 学习结果： 在OpenAI中，他们通过虚拟环境中的人已经积极研究出了agent的培养方式，与现实生活相比较而言，这对于实验来说更安全。 在其中一项研究中，研究小组展示了one-shot learning的可能性:一个人在虚拟现实中展示如何执行一项特定的任务，而一个演示足以让算法学会它，然后在实际情况下进行复制。 OpenAI和DeepMind都在这个问题上进行了研究探索。项目的底线是每一个agent有一个任务，该算法为人提供两种可能的解决方案，并指出哪一个更好。这个过程迭代重复，并且从人学习如何解决这个问题的过程中得到900位反馈(二进制标记)。 点击查看大数据文摘相关报道 在训练过程中，有一个问题需要认真思考 - 我们正在教给机器什么。例如，计算机决定该算法真的想要获取这个对象，但实际上，他只是模拟了这个动作。 还有另一项来自DeepMind的研究。教机器人复杂的行为(行走、跳跃等)，甚至做得和人类很相似。你必须大量地参与到损耗功能的选择中，这将鼓励期望的行为。然而，如果算法自己能通过简单的奖励来学习复杂行为，就更好了。 研究人员成功地做到了这一点:他们通过构建一个带有障碍物的复杂环境以及用简单的奖励来教agent(身体模拟器)完成复杂的动作，促进运动的进展。 通过视频你可以看到机器人已经做得很好了。 在2017年7月，谷歌宣称他们利用Deep Mind在机器学习开发中的优势成果，来减少其数据中心的能源损耗。 点击查看大数据文摘相关报道 基于来自数据中心的上千个传感器所传递的信息，谷歌的开发人员编写了一个模型来预测PUE（能源使用效率）以及更高效的数据中心管理模式。该项目意义深远。 训练模型在任务与任务间的转换很差，每一个任务都需要特定的模型加以对应，在一篇题为“万能模型”的文章中提到，谷歌大脑的模型在适用的普遍性上已小有成就。 论文链接：https://arxiv.org/abs/1706.05137 研究人员已经编写了一个可以在不同领域(文本、语音和图像)执行8个任务的模型。例如，翻译不同的语言，文本解析，图像和声音识别。 为了实现这一点他们搭建了一个复杂的网络架构，并利用不同的模块处理输入的数据和生成的结果。编码与解码的模块主要有三种类型：卷积、attention、混合专家系统。 主要成果: 获得了近乎完美的模型(作者没有对超参数进行微调)。 不同领域间的知识转换，也就是说，在拥有充分数据的项目预测中，模型表现很稳定。 不同任务所需要的模块之间不仅不会相互干扰而且还会彼此增益，比如MoE用于 Imagenet 任务。 顺便说一下，这个模型存出现于T2T之中…… 在他们的帖子里，Facebook的工作人员告诉我们，他们的工程师们仅用一个小时内就能在Imagenet上教授resnet - 50模型。这需要256个gpu(特斯拉P100)的集群。 他们使用Gloo和caffe2来进行分布式学习。为了使过程有效，必须要大量的整学习策略 (8192个元素):梯度平均、预热阶段、特殊学习速率等。 因此，当从8扩展到256 GPU时，可以达到90%的效率。现在，来自Facebook的研究人员可以更快进行实验。 自动驾驶汽车领域正在快速发展，也进入了积极的测试阶段。最近行业内的大事件主要有Intel MobilEye的收购，Uber和谷歌前雇员盗取技术的丑闻，使用自动驾驶仪造成的第一起死亡事故。 点击查看大数据文摘相关报道 谷歌Waymo正在推出一个beta程序。谷歌是该领域的先驱，技术广受认可，他们的汽车已经累计行驶了超过300万英里。 最近美国各州已经允许自动驾驶汽车运行上路了。 机械学习正在被引入医学。例如，谷歌与医疗中心合作帮助病患诊断。 点击查看大数据文摘相关链接： Deepmind甚至建立了一个独立的业务单元。 今年，在“Data Science Bowl”的项目下，举办了一项奖金为100万美元竞赛，竞赛内容是以高清图像为基础，对肺癌一年内的发病率进行预测。 就像之前大量资本进入大数据产业一样，机器学习也在投资界受到热捧。 中国在人工智能领域投资1500亿美元，成为该领域的先驱。 我们看一组对比数据。百度研究院雇佣了1300人，在同领域脸书只雇了80个。 学习“机器学习”永远不会算太晚。无论如何，随着时间的推移，所有开发人员都将使用机器学习，这将成为一项通用技能，就像今天大家都会使用数据库一样。 原文链接：https://blog.statsbot.co/deep-learning-achievements-4c563e034257 【今日机器学习概念】 Have a Great Defination 回复 “ ”加入我们 
172,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656798&idx=2&sn=b91c11d9702f644201871a5cb8b22bee&chksm=bd4c35cd8a3bbcdba51408b158f30810243cca2346e4a69a21727c791e7bd99d97f25f307357&scene=0,学界丨Hinton胶囊网络代码低调开源，GitHub链接你找得到吗？,大数据文摘作品 作者：魏子敏，龙牧雪 “卷积神经网络（CNN）的时代已经过去了！” ——Geoffrey Hinton 酝酿许久，深度学习之父Geoffrey Hinton在10月份发表了备受瞩目的Capsule Networks(CapsNet)。 Hinton本次挟CapsNet而来，大有要用它取代CNN的气势。 今天，有科技媒体发布Capsule Networks(CapsNet)开源的消息，文摘菌激动的去找了找Github链接，发现本次开源非常低调且隐蔽，隐藏在谷歌tensorflow的专题之下，没有相关报道，谷歌也搜不到，不熟悉Github的同学很难查找。 先放上链接： https://github.com/Sarasra/models/tree/master/research/capsules 因为发布低调，所以，Star数只有23，Folk数也只有12个。当然，这也并不影响这个开源项目的优秀和影响力。 欲取代CNN的Capsule Network究竟是什么来头？它能为AI界带来革命性转折么？大数据文摘之前也曾就此做过一篇详细解读，点击查看： 《欲取代CNN的Capsule Network究竟是什么来头？它能为AI界带来革命性转折么？》 这位被誉为深度学习之父Geoffrey Hinto究竟是何许人也呢？在上世界50年代，深度神经网络的概念就已出现，从理论上来讲可以解决众多问题，但是一直以来却没有人知道该如何训练它，渐渐的也就被放弃。直至1986年，Hinton想到了通过反向传播来训练深度网络，标志了深度学习发展的一大转机。然而，受限于当时的计算机运算能力，直到2012年，Hinton的发明才得以一显神通。这一突破也为近年来人工智能的发展奠定了基础。 2017年10月26日，Hinton又发表了一项开创性的论文——Capsule Networks（胶囊网络），或将再次改写深度学习的发展历程。（论文链接： https://arxiv.org/pdf/1710.09829v1.pdf ） 关注大数据文摘，后台回复 Hinton 即可下载此篇论文。 本次的开源项目代码发布者是Hinton论文Dynamic Routing Between Capsules的第一作者Sara Sabour。 寻找路径如下哦： 14K个Fork来自所有TensorFlow模型的被Fork数总和↑ 【今日机器学习概念】 Have a Great Definition 
173,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656798&idx=3&sn=2ef616efcc06ff19ad13aaeb4138d016&chksm=bd4c35cd8a3bbcdbc8456dda15db3e0a630c2e2acae33c5a34efdf1b5fa7d7142f49095cd114&scene=0,BlockChange | 平衡之道：区块链是一场非常大型的社会实验（圆桌实录）,大数据文摘作品 编辑：亭八 只要你仍然在接收外界信息，你一定听过“区块链”。作为比特币底层设计思想的衍生，它现在已经成为最火的技术之一，在世界范围内引起了巨大的关注。 在中国，很多企业都在这一块进行探索，寄希望于在商业模式上成熟起来。 2018年1月30日，由MIT科技评论和DeepTech主办的全球新兴科技峰会在北京召开，其中，区块链专场异常火爆。 宜信公司首席战略官陈欢、Hyperledger执行董事，万维网奠基人之一Brian Behlendorf、MIT Media Lab研究主管，数字货币计划研究主任Neha Narula、能源区块链实验室首席战略官曹寅对区块链的理解、发展、影响以及比特币等问题展开讨论，并提出了不少有趣的观点。 大数据文摘在不改变愿意的前提下，对这一头脑风暴其进行了记录： 曹寅： 我觉得区块链是现在最受欢迎的话题了，世界上有很多包括像俄罗斯、日本、美国、中国在内的国家政府都关注这个话题。 陈欢： 在中国有很多企业都在反复地讨论区块链。 除此之外，中国最大的挑战和问题，应该就是法律法规方面的不足。法律法规还没有决定是支持还是反对区块链的发展。另外，我们的商业模式也不成熟，有很多企业尚未提出自己的商业模式，我们还没有准备好怎么去利用它。 区块链它是有益处的，但是安全也是一个威胁。 这点也是值得很多企业反复思考的。 曹寅： 谢谢您的分享，Brian Behlendorf你的观点呢？ Brian Behlendorf： 现在使用区块链技术的企业并不少，传统企业也在用。我们已经有了一些法律法规了，先用就会先有优势，区块链能够帮助你更好地去做自己的一些企业。但问题是你要遵守法律法规。 我相信大部分的工具，都会不断地优化，持续地为客户带来很好地体验。 另外，教育宣传工具也应该及时的到位，网上的教育视频也应该准备好帮大家更好的去理解区块链技术。 Neha  Narula： 我觉得教育和宣传非常地关键， 这也是我们现在遇到的一个很大的问题。现在我们还没有足够的学生来满足市场的需求，我们在MIT反复地设计不同的课程来帮助学生更好地理解区块链。 我们的区块链技术涉及到不同的领域。网络上的代币是需要专家来设计一些监管的流程的，需要一些经济学家的加入。我们现在有不同的学科专家都进来这个领域，但这也是个问题，因为不同的专业背景的人要一块提出政策就会有点麻烦。 曹寅： 短期来看我们的专家或人才们能够帮助我们更好地理解、运用区块链技术。 中期来看，我们的法律法规政策要起作用。长期来看，整个商业模型要起来。所以我觉得我们的理念应该转换，我们的整个区块链的趋势、我们的生态系统也必须要起来。 区块链包括像代币，他们是否会改变人类社会？ 他们的改变度是不是会比所谓的革命性还要强一些？在有的一些小国家，比如说爱沙尼亚，这类国家，已经有一些国家级的项目了，比如说电子公民。这是一种新的社会契约，这也是一种新的政治组织，三位怎么看区块链是否能够成为新的工具去结成社会契约，还是说区块链它会为更多地企业、利益相关方去组织他们自己的国家，甚至是说一个社会呢？ Brian Behlendorf： 我之前有一些案例， 现在去中心化的技术有很多，我觉得已经很少有一个单独的供应商坐在中间，去为所有的利益相关方提供所有的产品服务了。区块链只是一种平衡的技术，它让更多的利益放在竞争的过程中，这样大家会越来越平等。 我们也说到供应链的变革，像银行是不是已经改变了传统的垄断模式，我觉得区块链会帮助很多国家解决一些大问题，但也有一些政治方面的考虑，特别是一些社会契约的考虑，这可能会促使一些新的非国家体的出现。现在全球有很多不同的理念，怎么样进行人与人之间的管制很重要。还有究竟区块链的使命是什么，是不是让政策及时地出台，是不是能够帮助政府去统治，每个人的观点都不一样，但是我觉得区块链是可以提高管理效率。 Neha  Narula： 我觉得这些网络系统听上去非常吸引人，而且会产生更多的自治体系。怎么组织社会、怎么组织架构，会是一个新的问题。 陈欢： 我完全同意区块链会改变很多我们的治理问题。我认为在未来会有很多的社群，都会接受我们这样的区块链治理的想法。 曹寅： 我也同意各位所说的， 。可能在未来的十年，我们的区块链+物联网+人工智能+云+大数据，它们肯定能大幅改变人类社会。 巴菲特说他并没有在比特币上或者是加密货币投钱，但是李嘉诚（亚洲首富）已经在2014年对比特币进行了大投资。我们可以看到我们两个首富之间的想法是有一些不同的。所以，各位觉得比特币潜在的价值在哪呢？ Neha  Narula： 很多人都会问为什么要选择比特币？实际上比特币非常地有价值。其实很多东西都是大家都认可了之后，它才有价值的。 你可以先想想为什么人们会觉得金钱有价值？金钱的价值是怎么衡量的？想想债券、股票这些东西他们为什么有价值？ 这些传统的东西都是在他们周围的人认可后，才有价值的。这样你就能想清楚为什么很多人认为比特币有价值。 我认为巴菲特最大的特点是他不会去投资他不了解的东西 。他不了解比特币，所以他就离比特币远远的。比特币价值的大幅波动就是因为很多人有时候会认可它，有时候又不认可它。 Brian Behlendorf： 我们现在有1300多种其他的代币，有很多的虚拟资产和现实资产。我相信在未来会有越来越多的人，把自己的资产放在比特币或者是区块链系统之上，然后在上面进行交易。 陈欢： 电子货币可能是一个社区的货币，而我们的社区也会很好地利用这些不同的代币，这样他们的价值就可以显现出来。所以我们需要考虑的是使用代币的社群到底有多大，这样就可以在各个方面考虑我们的代币价值有多大。 曹寅： 各位是否相信比特币或者其他的代币会代替我们真正的货币？ Brian Behlendorf： 我们的法定货币很有可能会在我们分布式账本上被比特币代替。 到那个时候，我们电子钱包里的货币就可以帮助我们进行金钱的一些转账等等，大大提高转账效率。 Neha  Narula： 我觉得会有那么一些国家可以最后使用我们的加密货币来代替自己的国家货币。 但可能过程会不太顺利。未来我们可能看到比特币会主导市场。 现在越来越多地人正在开采，并且加入到比特币社群之中。因为他们知道有些国家货币因为通胀问题而贬值了，这让他们很痛心。 陈欢： 我觉得十年对于比特币或者是加密货币来说是很长的一段时间， 我也相信某些国家会开始使用加密货币，至少会代替一部分的法定货币的功能。 曹寅： 我认为这个答案不是将会，而是肯定会。 比如说委内瑞拉或者是津巴布韦这些比较偏远的国家，他们现在有很多的国民正在使用比特币，而不是使用自己的本国货币，所以我认为现在的整个状况也在改变。 *感谢主办方提供速记和照片 【今日机器学习概念】 Have a Great Definition 
174,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656715&idx=1&sn=87fddf5074b40b9a1db2eebdb28735b2&chksm=bd4c35988a3bbc8e8d093992162984a4917045f8ba4eb69d597279675066e41da19b1530ce7a&scene=27,吴恩达创业项目第3弹揭晓：创投基金AI Fund，已募资1.75亿美金,"大数据文摘作品 作者：魏子敏 龙牧雪 就在刚刚，吴恩达通过海外科技媒体medium公布了自己继deeplearning.ai和Landing.ai之外，第三个落地的人工智能创业项目—— 。至此，吴恩达神秘的三大AI项目全部尘埃落定。 今年6月份，从百度离职的吴恩达宣布成立新公司deeplearning.ai，专注AI领域的教育培训，同时也透露，除了教育领域这一项目，自己还有另外两个人工智能创业项目进行中 （戳这里了解大数据文摘相关报道） 。 上个月，他宣布了另一家新公司Landing.ai的成立，并表示这一新公司将专注用人工智能辅助制造业领域的转型 （戳这里了解大数据文摘相关报道） 。 就在刚刚，吴恩达的第三个项目终于浮出水面： 北京时间1月30日12点，吴恩达就先在自己的推特上预热了这一消息：还记得我去年po出的自己的三大人工智能项目吗？你应该已经听过Deeplearning.ai和Landing.ai了，明天我将宣布我的第三个项目，吊足了科技媒体和从业者的胃口。 在吴恩达这条推特下，文摘菌看到了一片催更“跳水”几个月的【深度学习课程】第五部分的呼声，在这里也替大家喊出这些留言背后的声音：大佬别忙着搞大事情了，先把课程发完啊～～ 吴恩达通过海外科技媒体medium宣布了自己第三个AI项目的启动：AI Fund，表示 。 在启动语中，吴恩达也宣布了AI Fund这一项目和之前的deeplearning.ai以及Landing.ai的相互支持： 2017年8月，在deeplearning.ai刚刚发布的时候，海外科技媒体techcrunch就有报道，从美国证券交易委员会的备案信息来看，吴恩达已募集到了高达1.5亿美元的AI风投基金，在加州注册了名为“AI Fund, L.P.”风险投资基金（点击查看大数据文摘相关报道 《吴恩达刚刚募集了1.5亿AI风投基金，新公司第二套组合拳开打？》 ）。 当时，吴恩达并未对这一基金给出任何回应，半年后，这一项目终于正式公布。 据报道，AI Fund的这一基金主要用于资助AI创业项目。吴恩达的目标不是通过提供资金带入外部创业公司，而是为小团队提供支持，帮助演变发展。这与他在百度的工作有些类似。 2017年各类人工智能类风投资金尤为活跃，包括谷歌的GradientVentures，筹集了1.36亿美金的Basis Set Ventures，筹集1.02亿美金的Element.AI，微软也建立了自己的AI资金，丰田布阵1亿美金给AI投资。吴恩达新的投资基金也无疑是人工智能类风投的又一重磅。 该基金将专注提供种子轮和A轮投资基金，除了资金支持，被孵化的创业公司最大的利益应该是，在未来有机会受益于吴恩达在AI圈的专业知识和人脉网络。 可以看出， 三者之间能否真的良性循环起来，我们尽管仍然不得而知，但是吴恩达在推动AI从学界到工业界的进程上，已经刻下了不可被忽略的一笔。 以下是吴恩达发布的AI Fund启动语，大数据文摘在不改变愿意的情况下进行了编译： 各位朋友， 我很高兴地宣布AI Fund成立。我们筹集了1.75亿美元，将用其来助力人工智能改善人类生活。在发展这些业务的同时，也希望能够帮助各位进入人工智能领域，加速建设人工智能社会。 感谢我们的投资者，包括NEA，红杉，Greylock Partners，软银集团和其他支持我们的投资者。 在人类刚刚发明电力的时候，多数创新都是围绕着照明的小幅度改进。虽然这是重要的基础设施，但真正的变革发生在电力应用到多个行业之后。这样的变革要花更久时间才会出现。 在带领百度AI团队时，我的一部分工作是组建团队、探索新的方向，然后系统地评估他们的潜力，并决定是否继续相应的人工智能业务。这个过程十分有趣，它也让我感受到了自从Google Brain时期就感受到的东西：我们可以开发系统的、可重复的流程来开创和追寻新的AI机会。 我们即将见证人工智能为各行各业带来的改变。AI Fund团队目前正在发展3个AI驱动的新方向，其中一些我们希望稍后公布。随着这些项目逐渐成熟并转化为商业应用，AI Fund将为这些团队提供额外的资金，从而使他们能够迅速开展行动，而不会因为长达数月的筹款而分心。 六个月的时间差距可以决定一个新的AI解决方案能开展起来还是已经落后 ，所以我们设立了AI Fund，让我们的团队尽快取得进展。这也使我们的团队在准备充分的时候才能公布他们的工作。 我上个月宣布了Landing.AI，专注于使用AI来改造制造业。 就像任何社会转型一样，向人工智能的过渡也会让一些人感到震惊。 我想确保每个人都能获得AI时代所需要的技能，每个人都可以从事有意义的工作。 我将担任AI Fund的普通合伙人（General Partner）。 Eva Wang将担任合伙人和首席运营官，Steven Syverud也将担任合伙人。 Eva曾是Fenwick＆West的合伙人，将为AI Fund带来相当可观的运营和法律专业知识，Steven曾担任Sycamore首席执行官，领导Coursera Specializations产品的开发，并将提供重要的产品和业务发展知识。 Eva Wang（左一），吴恩达（左二），Steven Syverud 如果你在AI领域工作，你的未来将不可估量。 就像托马斯·爱迪生（Thomas Edison）曾经推动了电力社会的建立，现在是建立一个人工智能社会的时候了。AI Fund将致力于加速这一重要的全球转型。 吴恩达 Andrew Ng 【今日机器学习概念】 Have a Great Definition "
175,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656715&idx=3&sn=2c9593e40598a9c2346d91a1c2fae0a8&chksm=bd4c35988a3bbc8eec7286994a47815a7fd13f0d7f24b74c0f216f4c28082010345f20a94212&scene=27,业界丨身为数据科学家怎么能不掌握这四大技能！,大数据文摘作品  作者：seattle data guy 编译：王梦泽、吴双、蒋宝尚 想成为一名高级数据科学家除了拥有卓越的专业技能，你还需要其它技能来拉近和业务经理的距离。这看起来简单，但随着每年新技术的不断累积，技术和业务之间的距离会继续增大。因此，我们发现管理者和数据科学家有清晰的合作方向是非常重要的。 业务和IT知识都是十分专业的，然而由于技能的专业化，许多企业都出现了两个专业间的空白。我们的任务是帮助填补它！ 数据科学家必须有技术方面的扎实基本功，这包括编程、查询、数据清洗等。然而随着数据科学家的成长，他们需要更多地关注设计决策以及与管理者的沟通，这会大大增强经验丰富的数据科学家的影响力。他们可以做出更高层次的决策，并帮助陷入困境的年轻数据科学家，而不是被困在日复一日的编码中。更有经验的数据科学家能利用他们的经验来做出简化复杂系统、优化数据流的设计决策，同时协助决定哪些项目最为恰当，这使得数据科学家自身及其公司都能有更大获益。 数据科学家往往希望将他们所知道的每一种技术和算法都应用于每一个问题的解决方案上。相应地，这就会使系统非常复杂难以维护。 数据科学确实需要复杂抽象的模型及大量的复杂技术（从Hadoop到Tensorflow）。在这个充斥着复杂性的领域，人们会倾向于开发复杂的系统和算法，稍不留神就会在开发中涉及四、五种不同的技术并使新的热门算法或框架。然而，像大多数涉及工程的其他领域一样，减少复杂性往往会带来诸多好处。 如果冯•诺依曼，埃尔温•薛定谔和爱因斯坦可以帮助我们理解数学和物理驱动领域的复杂性，那么我们数据科学家不能隐藏在复杂性背后。 工程师的角色就是去简化任务。如果你曾经建造或看到过鲁布•戈德堡机械（Rube Goldberg machine），你会理解什么是用复杂方法去完成简单任务。一些数据科学家的算法和数据系统看起来像是用胶带和口香糖粘起来的老鼠夹，而不是简洁有效的解决方案。更简单的系统意味着随着时间推移系统会更加容易维护，并且未来的数据科学家能够按需添加和删除模块。但若你使用三种不同的语言，两个数据源，十个算法且没有留下任何文档资料，未来的工程师可能会默默诅咒你哦。 简单的算法和系统也应使添加和删减模块是容易的。因此当需要技术进行改变和更新或者需要删除模块时，可怜的未来数据科学家不会陷入和你的代码一起玩叠叠乐积木游戏（Jenga）的困境 。但会纠结于“如果删了这段代码，系统会不会崩溃”。（这一纠结的根源是怕出现技术债务） 强大的数据专家能做的重要工作之一是：将可能没有主键或明显联系的数据集关联在一起。数据可以呈现人之间或业务之间的日常交互。能够在这些数据中找出统计模式，是数据科学家可以帮助决策者作出明智决定的重要能力。然而，你想要关联在一起的数据并不总是位于相同的系统或有着相同粒度。 与数据打交道的人会知道，数据并不总是很好的整合在一个数据库中。比如，财务数据与IT服务管理数据通常是分开存放的，外部的数据源往往可能并不是在同一个维度进行的聚合。这会成为一个问题，因为找出数据中的价值有时确实会需要来自其他部门或系统的数据。 数据啮合是需要在相同的粒度级别上进行的。一种理解的方式是：将一块大拼图与由许多小块数据拼图组成的大拼图组合起来。 例如，假如给你提供了医疗保单、信用卡和社区犯罪率的数据，想由此找出这些社会经济因素如何影响病人，你会怎样处理？一些数据可能是以人为单位，而另一些数据可能是街道或城市级别，而且没有明确的方式来关联这些数据集。最好的处理方式是什么？这成为了一个不能忽视且必须被解决的问题。 	 作为数据科学家，你需要知道如何解释可能不划算的项目的投资回报率（ROI）。这与良好的直接沟通有关（我们的团队永远不会停止讨论如何沟通），也与能够清楚表达价值并且对长短期目标进行优先排序有关（重申一遍，说起来容易做起来难） 团队总是会有超出他们处理能力的过多的项目和项目要求。有经验的团队成员需要起带头作用来帮助决策者决定哪些项目是值得进行的。在有很大机会成功但可能不会有最高投资回报率的短期项目和很有可能会失败但同时也会产生较大投资回报率的长期项目之间需要有一个良好的平衡。 这种情况下，决策矩阵会有助于简化过程。 经典的决策矩阵之一是一个2*2矩阵，行和列分别为重要性和紧迫性。多数的大学商业课程中都会出现这种矩阵，它很简单，这也是它很棒的原因。 我曾在公司和一些很聪明的人共事，但还是工作中的每个项目都被列为优先。如果你没听过这个说法，我会在这里讲出来： 如果每件事都被优先考虑，那么，相当于没有事情被排在优先。 选择正确的项目意味着必须做出取舍。不是所有的事情都是高优的。 许多公司都存在这个问题，这就是为什么对于数据科学家团队中有经验的成员，能够清晰表达出哪些项目需要当下执行还是以后执行是非常重要的。而使用这个简单的矩阵能带来一定帮助。 （简洁十分重要，使用矩阵来明确投资回报率是有帮助的）。 有了简明直接的沟通，项目继续向前推进，信任也随之建立起来了。 做出能在受控环境中操作的算法或模型是一回事。将稳健模型集成到实时且能处理大量数据的系统又是另一回事。根据公司的不同，有时数据科学家只需开发算法本身，之后开发人员或机器学习工程师会负责将其转为上线的产品。 然而还会有其他的情况，小的公司和小的团队可能会需要数据科学家团队来将代码转为上线产品。这意味着算法需要能以合理的速度控制数据流量。如果算法要运行三个小时并且需要被实时访问，这显然不能在产品上使用。因此，良好的系统设计及优化是必要的。 随着数据增多，越来越多的人会与系统交互，模型跟上脚步是十分重要的。 当高级数据专家的技术能力和其他能力相结合时，才能对他们自身和其公司产生最大的影响。数据科学家宝贵的经验是非常有价值的，这些经验能够指导年轻的开发人员做出更好的设计决策，帮助管理者找出哪些项目会带来最好的投资回报率，从而也放大了他们的参与对于团队的影响。 原文链接： https://hackernoon.com/4-must-have-skills-every-data-scientist-should-learn-8ab3f23bc325 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 
176,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656656&idx=3&sn=72956f8014b200744c88753a46a15363&chksm=bd4c36438a3bbf55a7c99767256f4a47faffcdfc620f90536f54091b07d4acb1e6884a077d99&scene=27,AI大事件  |  Google和Facebook在法国布局实验室，TensorFlow 1.5发布,呜啦啦啦啦啦大家好呀，又到了本周的AI大事件时间了。过去的一周中AI圈都发生了什么？大佬们互撕了哪些问题？研究者们发布了哪些值得一读的论文？又有哪些开源的代码和数据库可以使用了？文摘菌带你盘点过去一周AI大事件！ 新闻 Google和Facebook在法国布局实验室 来源： TECHCRUNCH.COM 链接： https://techcrunch.com/2018/01/22/google-is-launching-an-ai-research-center-in-france-and-expanding-its-office/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI Google决定在法国建立一个新的人工智能研究实验室，同时Facebook宣布对他们在法国的AI实验室FAIR-Paris投资1000万欧元。法国能在人工智能领域追上加拿大的步伐吗？ Facebook的Yann LeCun转入研究型职位 来源： WWW.THEVERGE.COM 链接： https://www.theverge.com/2018/1/23/16924460/facebook-ai-chief-yann-lecun-stepping-down-jerome-pesenti?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI Yann LeCun此前一直担任Facebook内部人工智能研究部门的负责人，而在最近的职位转换中，他将成为Facebook的首席人工智能科学家，此后将更加专注于人工智能的研究。来自英国AI创业公司Benevolent的JérômePesenti将接替他的职位，JérômePesenti之前还曾担任过IBM大数据集团的首席技术官。 MIT在“神经形态计算”上更进一步 来源： NEWS.MIT.EDU 链接： http://news.mit.edu/2018/engineers-design-artificial-synapse-brain-on-a-chip-hardware-0122?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 在“神经形态计算”这一新兴领域的研究人员试图设计出像人脑一样工作的计算机芯片，而不是像现在的数字芯片那样进行基于二进制的开/关信号的计算。 TensorFlow 1.5发布 来源： DEVELOPERS.GOOGLEBLOG.COM   链接： https://developers.googleblog.com/2018/01/announcing-tensorflow-15.html?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 最值得注意的是，TensorFlow的“Eager Execution”现在可以预览。这允许您立即执行TensorFlow中的操作，因为它们是从Python调用的。 文章&教程 更快的R-CNN：降低物体检测的门槛 来源： TRYOLABS.COM 链接： https://tryolabs.com/blog/2018/01/18/faster-r-cnn-down-the-rabbit-hole-of-modern-object-detection/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 本篇文章将带你进行更快的R-CNN的深入演练，从高层次的概述开始，并且会细致地探讨每个组件的细节。 如何使用Python和Keras构建自己的AlphaZero AI 来源： MEDIUM.COM   链接： https://medium.com/applied-data-science/how-to-build-your-own-alphazero-ai-using-python-and-keras-7f664945c188?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这个代码库包含一个AlphaZero方法的复本，内置Python和Keras。这个教程能够帮助你深入了解AlphaZero的工作原理，并能够调整代码进行新游戏。 使用ROC曲线的哲学论证 来源： LUKEOAKDENRAYNER.WORDPRESS.COM   链接： https://lukeoakdenrayner.wordpress.com/2018/01/07/the-philosophical-argument-for-using-roc-curves/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这篇文章重点讨论了医学领域的AI，但不仅限于医学领域，它主要回答了什么是性能测试，以及一个好的性能指标的功能是什么。 代码，项目&数据 FAIR的物体检测研究平台 来源： GITHUB.COM 链接： https://github.com/facebookresearch/Detectron?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI Detectron是Facebook AI Research的软件系统，实现了包括Mask R-CNN在内的最先进的物体检测算法。软件系统由Python编写，并且由Caffe2深度学习框架提供支持。 来自DeepMind的Psychlab 来源： DEEPMIND.COM   链接： https://deepmind.com/blog/open-sourcing-psychlab/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI Psychlab允许你应用认知心理学等领域的方法来研究受控环境中代理的行为。 信任域策略优化的PyTorch实现 来源： GITHUB.COM 链接： https://github.com/ikostrikov/pytorch-trpo?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这篇文章介绍了信任域策略优化（TRPO）的PyTorch实现。与PyTorch中另一个TRPO实现相比，此实现使用了精确的Hessian向量乘积方法而不是有限差分近似。 论文 情感分析的深度学习：一个调查 来源： ARXIV.ORG   链接： https://arxiv.org/abs/1801.07883?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 随着深度学习在许多其他应用领域的成功，近年来深度学习在情感分析中也得到了广泛的应用。 本文首先对深度学习进行了概述，然后对其在情感分析中的应用进行了全面的调查。 Psychlab：深度增强学习代理的心理学实验室 来源： ARXIV.ORG   链接： https://arxiv.org/abs/1801.08116?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI Psychlab是DeepMind Lab第一人称3D游戏的心理学模拟实验室。Psychlab支持经典的心理学实验，并且能够使人类和智能代理一起工作。另外，它还有一个简单、灵活的API，使用户可以轻松地创建自己的任务。 通过对手的学习认知进行学习 来源： ARXIV.ORG   链接： https://arxiv.org/abs/1701.08230?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 对手学习认知（LOLA）是预测其他代理人学习的一种方法。 LOLA学习规则使用一个额外的术语说明一个代理的策略对其他代理的预期参数的影响。初步的研究结果表明，两个LOLA代理的博弈出现了针锋相对的情况，因此在迭代囚徒困境（IPD）中进行了合作，而独立学习则没有出现。 【今日机器学习概念】 Have a Great Definition 
177,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656656&idx=2&sn=bb7051497d55605ccecd1f350b760bf2&chksm=bd4c36438a3bbf5587b88b7bcea404931fa947666d3c2653039127c08998f6231f56dfd7689c&scene=27,学界丨先睹为快：神经网络顶会ICLR 2018论文接受结果速览,大数据文摘作品 专栏作者｜不看镜头的ZARD 今天早晨，ICLR 2018的论文接受结果揭晓，我们就带大家来大致了解一下今年ICLR 2018的论文接受概况。 ICLR全称International Conference of Learning Representation，是由Lecun，Hinton和Bengio三位神经网络的元老联手发起的。 论文接受率： 2.3%的口头展示，31.4%的poster接受，9%的workshop，51%拒绝。 ICLR口头论文中一大半的论文会成为ICLR Best paper，同时也代表了2018年的研究方向，下面我们就简单的介绍一下今年的oral论文，由于ICLR会议的论文范围较广，方向比较新，我们也不能够做到面面俱到。 这篇论文提出了在Variation Auto-Encoder中使用Wasserstein距离进行度量，从而第一次让VAE能够产生跟Generative Adversarial Network比肩的效果。 并且WAE在理论上面联系了VAE和GAN。是一篇不可多得理论与实践兼得的好论文。WAE产生的图像如下图： Spherical CNNs (阿姆斯特丹大学Max Welling组) 卷积神经网络只能够在2D planar图像中使用，但是近年来很多问题如机器人运动，自动驾驶需要对spherical image进行分析。传统的方法是将spherical image投影到2D planar图像，但是这个过程会产生distortion，如下图： 于是作者提出了spherical CNN。Spherical CNN通过傅立叶变换来避免过度的计算。通过傅立叶变换来实现spherical CNN的示意图如下： 相信本篇论文提出的spherical CNN能够在自动驾驶，机器人运动的任务中得到广泛的应用。 Boosting Dilated Convolution with Mixed Tensor Decomposition  本篇论文通过tensor decomposition的角度来分析神经网络，并且提出了mix tensor decomposition的方法来提高神经网络的表达能力。作者在实践中使用了mix dilation的办法来进行mix tensor decomposition。结构图如下： 两个对偶的网络weight sharing，仅仅通过dilation的变化就可以得到不同的连接，提高神经网络的expressive efficiency。 本篇论文的理论分析详尽，并且论文讲述简单易懂，美中不足的是实验部分太弱，但是也不影响该论文被接受为oral。 Ask the right questions：active question reformulation with reinforcement learning（Google） 这篇论文提出了一个做question answering的新的思路，通过question reformulation将一个问题转换成类似的问题，然后反复的选择最佳问题。Question reformulation和answer selection通过强化学习进行训练。流程图如下： 由于ICLR的审稿意见是公开的，所以我们可以看到作者和审阅者之间的思想碰撞，下面我们就介绍一些有趣的事情。 这两篇论文提出了类似的方法，通过将数据库的图像的线形组合来做Data Augmentation，并且在CIFAR，IMAGENET上面都取得了好的结果， 这篇论文是神经网络之父的CapsuleNet的后续，也被ICLR接受了，Geoffrey Hinton是该论文的第一作者。 这篇论文是NVIDIA提出的使用GAN生成high resolution image的论文，由于在论文中违反了double blind原则，在review阶段被拒绝（strong reject）， 附上大会及相关链接，感兴趣的读者可以自行查看： ICLR 2018会议链接： https://openreview.net/group?id=ICLR.cc/2018/Conference 论文链接： Ask the right question: https://openreview.net/pdf?id=S1CChZ-CZ Wasserstein Auto-Encoders: https://openreview.net/pdf?id=HkL7n1-0b Spherical CNNs: https://openreview.net/pdf?id=Hkbd5xZRb Have a Great Definition 
178,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656715&idx=2&sn=39b9435ed9cd576b3cad0fdfcc6eaf5d&chksm=bd4c35988a3bbc8ef2ce960b5b536dd2ce9a13c099b42ccfb8fd26029ca800843efa48e4ab6a&scene=27,Blockchange丨老矿工的区块链5000字终极指南,大数据文摘作品 编译：小鱼、蒋宝尚 “老矿工”用5000字讲清区块链工作原理：去中心化、分布式存储、哈希函数加密，这些都是什么？ 除非你居住在世外桃源，要不然你一定听说过比特币和区块链。毕竟它们是当下最热门的话题之一，也被评为了年度流行语。即使那些没有接触过数字货币、也不知道其如何工作的人也在讨论区块链。 在理解这些新技术的时候，我那些没有技术背景的朋友“懵了”，他们一连几个星期缠着让我解释到底什么是区块链。 作为比特币的资深“老矿工”，我用最浅显易懂的语言写了这篇文章，帮助大家理解当下最流行的趋势。 “对于每个复杂的问题，都有一个看似简单明了、实际上却是错误的答案。” —— H. L. Mencken 和其他文章在开头尝试定义区块链不同，我先解释它解决的问题。 想象一下，你最好的朋友Joe正在国外旅游时候，突然给你打电话说：“我的钱完全花光了，借我点钱。” 因为你是热心肠的人，所以你说：“马上打给你。” 然后，你打电话给你的银行客户经理：“从我的账户转1000美元到Joe的账户。” 你的客户经理回复：“好的，先生。” 他登陆了你的账户，查看了一下你是否有足够的账户余额进行1000美元的转账。你很富有，有足够的钱可以转账，于是他在一个表格中做了如下登记： 之后，你打电话告诉Joe，“我已经给你寄了1000美元，你可以去银行取钱了。” 整个过程中，你和Joe都信任银行并让它管理你的钱。上述交易过程并不涉及真金白银，只是需要在一个表格中进行修改。更准确地说，这个表格并不是你和Joe拥有或能够直接控制的。 这就是现行制度所体现的问题：为了建立起我们之间的相互信任，我们需要求助独立的第三方。 多年来，我们通过“中间人”才能信任彼此。你可能会问，“这种中间人制度会带来什么问题？” 问题就在于，“中间人”的数量是有限的。只要一个人或一个组织有意无意地腐败了，那么整个社会就将陷入混乱状态。 ● 如果表格中的交易记录在火灾中烧毁，该怎么办？ ● 如果你的客户经理写了1500美元而不是1000美元呢？ ● 如果他故意这样做呢？ 多年来，我们一直把所有的鸡蛋都放在别人的篮子里。 是否能够有一个系统可以在没有第三方（银行）的参与下进行转账？ 为了回答这个问题，我们可以想一想，转账的含义是什么？ 只是在表格中登记的一个条目。  那么，有没有办法在不依靠第三方的情况下，维护我们之间的交易记录？ 你可能已经猜到了答案——那就是区块链。 区块链如何实现自己登记交易记录？这就需要用到分布式记账的技术。 这种方法要求有足够多的人选择不依赖于第三方。 只有这样，这些人才能依靠自己运营这个去中心化的系统。  “可以存一些比特币，万一以后它涨了呢。如果这么想的人多了，那设想就变成现实了。”  ——中本聪 系统里有多少人就算足够多了？至少三个。 但这里，我们假设有十个人想要放弃银行或任何其他管理交易的第三方。在彼此同意的情况下，他们一直都有对方账户的详细信息但不知道对方的身份。 每个人都从建立自己的空文件夹开始。随着这个过程不断推进，这十个人将不断向他们的空文件夹中添加页面。这个页面集合就是追踪交易的表格。 接下来，网络中的每个人手里都有一支笔，用来填写空白页。 每人都准备好写入系统内发生的任何交易。 现在，假设2号想转账10美元给9号。 为了完成交易，2号发表声明告诉大家，“我想转10美元给9号。收到消息的人就在自己的空白页上进行交易记录。” 每人都检查2号的余额是否足够，是否能将10美元转给9号。如果她余额足够，每个人就会在他们的空白页面上记录这笔交易。 随着时间的推移，会有更多的人利用该网络进行转账交易。每当他们想做一个交易，他们就通知其他人。只要有一个人听到这个通知，TA就会把交易记录写在TA的页面上。 记录将继续进行，直到所有人都用完当前页面上的空间。假设一个页面的空间只能记录十个交易，当第十个交易完成后，每个人的空间也都用完了。 当一个页面被填满时，就可以将其放入文件夹中，并创建出一个新的页面，重复上述步骤2的过程。 在我们将文件放进文件夹之前，我们需要用网络上每个人都同意的唯一数字来加密。通过加密，密码副本将放入每个人的文件夹中，我们就能确保没有人能对加密数字进行修改，且不会随时间而改变。不论是在今天、明天，甚至是一年之后，密码副本一旦进入文件夹，它将始终停留在文件夹中并处于加密状态。而且，如果每个人都信任这一加密方式，那么他们就会相信页面内容。页面的加密方式是网络交易的关键。 保护页面不被修改这项工作叫做“挖矿”。但为了简单起见，我们将继续称它为“加密”。 在区块链出现前，我们相信第三方/中间人，相信他们在表格中登记的每笔交易都不会改变。而在刚刚描述的这种分布式和分散系统中，人们也会信任这一加密方式。 在我们学习如何加密页面之前，我们需要知道加密的原理。我称之为“魔法机器”。 想象一台由厚厚的墙包围的机器。如果从左边给机器发送一个非空的盒子，它会“吐出”一个包含其他内容的盒子。 这台机器被称为“哈希函数”，但是为了方便理解，我们暂且称它为“魔法机器”。 假设你从左边发送数字4，它在右边吐出单词：'dcbea'。 它是如何将数字4转换成'dcbea'这个词？ 没人知道。而且，转换过程不可逆。 即使你知道机器输出了“dcbea”，你也无法知道对应的输入内容。但是每次你把数字4输进机器上，它总是会吐出同一个词“dcbea”。 图：哈希（4）== dcbea 发送数字26会怎么样？ 图：哈希（26）== 94c8e 我们这次得到了'94c8e'。 有趣！ 所以机器输出的结果中也会包含数字。 现在，如果我问你以下问题：  “我从左边给机器输入什么，可以从机器右边获得一个以三个0开头的单词？例如，000ab，00098，000fa或000XX。” 上面已经提到，机器有一个属性，即我们无法从右边的结果逆推出左边所输入的内容。 面对这样的机器，如何解决刚才提出的问题？ 我想到一种方法。 为什么不一一地尝试宇宙中的每一个数字，直到我们得到一个以连续三个0开头的单词？ 经过几千次的尝试，最终会得到一个能够产生正确结果的数字。 要计算给定输出的输入内容是非常困难的。 但与此同时，验证输入输出是否对应确实很容易。请记住，对一个给定的数字，机器每次都会吐出相同的单词。 如果我给你一个数字，比如说72533，并且问你，“把这个数字输进机器，是否输出了一个以三个0开头的单词？”，完成这个过程你觉得有多困难？ 你需要做的就是把数字扔给机器，看看在右边输出了什么而已。 这样的机器最重要的特性就是，给定一个输出，计算输入是非常困难的，但是给定输入和输出，验证输入输出是否对应确实很容易。 我们将使用这个神奇的机器来加密页面。像往常一样，我们将从一个假设开始。 想象一下，我给你两个盒子，第一个盒子里包含了数字20893。然后，我问你，“你能算出这样一个数字吗：如果用它加上第一个盒子里的数字，然后发送给机器，可以得到一个以三个0开头的单词。” 这与我们之前看到的情况类似。我们已经了解到，计算这样一个数字的唯一方法是通过尝试整个宇宙中可用的每一个数字。 经过几千次尝试，我们会偶然发现一个数字，比如说21191，当用它加上20893（即21191 + 20893 = 42084）并发送给机器时，会产生一个满足我们要求的词。 在这种情况下，号码21191成为20893的封印。假设有一个页面的内容是20893。为了加密这个页面（即让人无法改变它的内容），我们在这页上添加一个名为“21191”的封印。 一旦加密数字（即21191）印在页面上，页面就被加密了。 加密数字也可以被称为“工作证明”，意思是这个数字证明了为了计算它所做的努力。 如果有人想验证页面是否被修改，他所要做的就是将页面内容加上封印数字，并送到魔法机器。如果机器给出以三个0开头的单词，则证明页面内容不变。如果结果不符合我们的要求，我们可以扔掉页面，因为它的内容是妥协的，是没有用的。 我们将使用类似的加密机制来加密我们所有的页面，并将它们放在各自的文件夹中。 为了加密包含网络交易的页面，我们需要找到一个数字，当把它附加到交易清单上并送给机器时，我们能在右边得到一个以三个0开头的词。 注意：我一直只使用“以三个0开头的词”这个短语作为例子。因为它演示了哈希函数如何工作。真正的计算原理比这更复杂。 在机器上花费时间和电力后，一旦计算出这个数字，页面就被这个数字封印了。如果有人试图改变页面的内容，任何人都可以利用封印数字验证页面的完整性。 现在我们已经知道如何加密页面了，我们将回到编写第十个交易的页面上。编写这十个交易用尽了我们的空间。 当每个人用来编写进一步交易的页面都用完时，为了获得页面，他们就会不停的计算加密数字，以便可以将其隐藏在文件夹中。 网络中的每个人都会计算加密数字。第一个在网络中找到的人会将其宣布给其他人。 一旦收到加密数字，每个人都会验证它是否产生合法的输出。输出如果合法，每个人都用这个数字标记他们的页面，并将其放在文件夹中。 但是，如果有个人说公布的加密数字产生的输出不合法，怎么办？ 这种情况并不罕见。可能有以下原因： ● 他可能误读了网络中公布的交易 ● 他可能误写了在网络中公布的交易 ● 在写交易时，他可能会试图欺骗或不诚实，或者在网络上偏袒自己或其他人 不管是什么原因，这个人只有一个选择——放弃他的页面，并复制别人的页面放在文件夹中。 如果他没有把他的页面放在文件夹中，他将无法编写更多的交易，也会被禁止成为网络的一部分。 大多数人同意的加密数字就变成了真正的加密数字。 那么，为什么每个人都努力计算加密数字，即使知道别人会计算并向他们宣布？为什么不坐下来等待通知呢？ 这就是激励机制出现的地方。每个人都是区块链的一部分，都有资格获得奖励。计算加密数字的第一个人将因为他的努力（即消耗的CPU功率和电力）而获得奖金。 简单想象一下，如果5号计算了一个页面的加密数字，他会得到一些钱，比如1美元，这些钱是凭空而来的。换句话说，5号的账户余额增加了1美元，而其他人的账户余额却不会减少。 这就是比特币存在的方式。这是第一个在区块链（分布式帐本）上交易的货币。为了保持人们在网络上继续工作的动力，人们将获得作为回报的比特币。 当一定数量的人都拥有比特币时，比特币的价值就会增长，那么其他人也会想购买比特币。这使比特币的价格进一步增长，继而更多的人想购买比特币，比特币的价格又会增长。 奖励使每个人都有了继续在网络上工作的动力。 而且，一旦所有人都将页面收到他们的文件夹中，他们就会带出一个新的空白页面，这个过程在不停重复进行。 一个页面可以被视为一个交易块（区块），而文件夹可以被视为一连串页面（区块链）。 这就是区块链的工作原理。 除此之外，还有一件小事。 想象一下，这个文件夹中已经有五个页面了——全部用加密数字进行了加密。如果我为了自己的利益回到第二页并修改交易，该怎么办？加密数字可以让任何人发现交易中的不一致性，对吗？如果我继续为已修改的交易计算一个新的加密数字，并在页面上添加这一数字，该怎么办呢？ 为了防止某人返回并修改页面（Block）以及加密数字，计算加密数字的方法有一些小小的改动。 请记住我给出两个盒子的目的：一个盒子存放号码20893，另外一个则为你的计算预留空间。实际上，为了计算区块链中的加密数字，两个盒子是不够的，其实有三个盒子：两个盒子作为预填盒子，另外一个盒子用于计算。 当这三个盒子所有的内容被发送到机器时，从右边出来的答案必须满足要求。 我们已经知道，一个盒子用来存放交易清单，另一个盒子用来存放封印数字。 第三个盒子包含魔法机器的前一页输出结果。 有了这个小技巧，我们就能确保每一页都依赖于它的前一页。 因此，如果有人要修改一个历史页面，那么他必须改变所有页面的内容和加密数字，以保持区块链上的一致性。 如果我们开始时想象的十个人中的一个人试图欺骗和修改区块链（包含交易记录的页面的文件夹）的内容，他将不得不调整几个页面并计算新的加密数字来加密这些页面。我们知道计算加密数字有多困难。因此，网络上一个不诚实的人无法击败九个诚实的人。 如果一个不诚实的人试图在一个页面上做出欺骗行为，那会在网络中创造另一个链条，但是欺骗的链条永远无法赶上诚实的链条——因为一个人的努力和速度无法击败九个人累积的努力和速度。因此，这个机制可以保证网络中最长的链是最诚实的链。 如果，不是一个人不诚实，而是有六个人不诚实呢？ 在这种情况下，协议就变得一塌糊涂。它被称为“51％攻击”。如果网络中的大多数人都变得不诚实，并欺骗网络的其余部分，协议目的就失效了。 如果区块链会崩溃，那么这可能就是唯一可能的原因。虽然这种情况不太可能发生，但是我们必须知道区块链系统的弱点：它建立在大多数人群总是诚实的假设之上。 以上就是“老矿工”关于区块链的全部介绍。你看懂了吗？欢迎留言分享你的“矿工”经验。 原文链接： https://thenextweb.com/contributors/2017/11/01/ultimate-3500-word-plain-english-guide-blockchain/ 【今日机器学习概念】 Have a Great Definition 
179,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656656&idx=1&sn=7afe0839ae000d8e13a945d62ad404d2&chksm=bd4c36438a3bbf551ea2d6537c7204a584a144cfcf98da019f2b71e11e8be31b2a5fd2b81704&scene=27,我们对比了GitHub上8800个开源机器学习项目，并选出了其中的Top30,"大数据文摘作品 编译：叶一、Shan LIU、Aileen 2017年是机器学习应用全面开花的一年，惊为天人的想法和项目层出不穷。 这是一份极具竞争性的列表，它精挑细选了发表于2017年1月-12月份的机器学习库、数据集和应用类的优质项目。我们通过流行度、参与度和时近性来对其质量进行评级。有一项数据可以让你对表单质量有一个直观印象：这些项目的GitHub平均stars数是3558。 开源项目对于数据科学家而言是很有意义的。 你可以尽情尝试一下这些可能在去年与你失之交臂的机器学习项目。   No.1 - FastText： GitHub stars数: 11786个  来源：Facebook研究 链接： https://github.com/facebookresearch/fastText 以及[Muse：基于FastText的多语言无监督/监督词嵌入（GitHub stars数：695个）https://github.com/facebookresearch/MUSE] No.2- Deep-photo-styletransfer： 《Deep Photo Style Transfer》的代码与数据 GitHub stars数：9747个 链接： https://github.com/luanfujun/deep-photo-styletransfer No.3 - face recognition： GitHub stars数：8672个 来源：Adam Geitgey 链接:  https://github.com/ageitgey/face_recognition No.4 - Magenta： GitHub stars数：8113 链接： https://github.com/tensorflow/magenta No.5 - Sonnet： GitHub stars数：5731个 来源：DeepMind 成员 Malcolm Reynolds  链接： https://github.com/deepmind/sonnet No.6 - deeplearn.js：  GitHub stars数：5462个  来源：Google Brain 团队 Nikhil Thorat  链接： https://github.com/PAIR-code/deeplearnjs No.7 - Fast Style Transfer： GitHub stars数：4843个 来源：MIT的Logan Engstrom   链接： https://github.com/lengstrom/fast-style-transfer No.8 - Pysc2： GitHub stars数：3683个 来源：DeepMind Timo Ewalds 等人  链接： https://github.com/deepmind/pysc2 No.9 - AirSim： GitHub stars数：3681个  来源：微软的Shital Shah  链接： https://github.com/Microsoft/AirSim No.10 - Facets： GitHub stars数：3371个 来源：Google Brain 链接： https://github.com/PAIR-code/facets No.11 - Style2Paints： GitHub stars数: 3310个 链接： https://github.com/lllyasviel/style2paints No.12 - Tensor2Tensor： GitHub stars数目: 3087个 来源： Google Brain 的Ryan Sepassi 链接： https://github.com/tensorflow/tensor2tensor No.13-  （如horse2zebra, edges2cats，等） GitHub stars数：2847个 来源：UC Berkeley 朱俊彦博士 链接： https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix   No.14 - Faiss： GitHub stars数：2629个 来源：Facebook 链接： https://github.com/facebookresearch/faiss No.15 Fashion-mnist： GitHub stars数：2780个 来源：Zalando Tech 的 Han Xiao 链接： https://github.com/zalandoresearch/fashion-mnist No.16 - ParlAI： GitHub stars数: 2578个  来源：Facebook Research的 Alexander Miller  链接： https://github.com/facebookresearch/ParlAI   No.17 Fairseq： GitHub stars数: 2571个  来源：FAIR 链接： https://github.com/facebookresearch/fairseq No.18 Pyro： GitHub stars数: 2387个  来源：Uber AI Labs 链接:   https://github.com/uber/pyro   No.19 iGAN： GitHub stars数: 2369个  链接： https://github.com/junyanz/iGAN   No.20 Deep-image-prior： GitHub stars数: 2188个  来源：Skoltech 的 Dmitry Ulyanov博士  链接： https://github.com/DmitryUlyanov/deep-image-prior   No.21 Face_classification： GitHub stars数: 1967个  链接： https://github.com/oarriaga/face_classification No.22 Speech to Text WaveNet： GitHub stars数: 1961个  来源： Kakao Brain 的 Namju Kim 链接： https://github.com/buriburisuri/speech-to-text-wavenet   No.23 StarGAN： GitHub stars数: 1954个   来源：韩国大学的Yunjey Choi 链接： https://github.com/yunjey/StarGAN   No.24 MI-agents： GitHub stars数: 1658个  来源：深度学习 Unity3D 的Arthur Juliani  链接： https://github.com/Unity-Technologies/ml-agents No.25 Deep Video Analytics： GitHub stars数: 1494个  来源：康奈尔大学的Akshay Bhat  No.26  OpenNMT： GitHub stars数：1490个  链接： https://github.com/OpenNMT/OpenNMT No.27 Pix2PixHD： GitHub stars数：1283个 来源：英伟达 AI 科学家 Ming-Yu Liu 链接： https://github.com/NVIDIA/pix2pixHD   No.28 Horovod： GitHub stars数：1188 个 来源：Uber 工程团队 链接： https://github.com/uber/horovod No.29 AI-Blocks： GitHub stars数：899 个 链接： https://github.com/MrNothing/AI-Blocks No.30 Voice Conversion with Non-Parallel Data： GitHub stars数：845个 来源：Kakao Brain人工智能研究团队的Dabi Ahn 链接： https://github.com/andabi/deep-voice-conversion 原文链接：  https://medium.mybridge.co/30-amazing-machine-learning-projects-for-the-past-year-v-2018-b853b8621ac7 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 "
180,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656631&idx=2&sn=a6846b8d929e454fdb6fdf36e6ae7986&chksm=bd4c36248a3bbf320f54abe053edb7f0fd1075cff4464bfcfede4a377a4ccd878be0db5de477&scene=27,别错过这张AI商用清单：你的生产难题可能被一个应用解决,"大数据文摘作品 作者：Liam Hänel  编译： 赵逸云、蒋宝尚、钱天培 人工智能席卷各行各业早已是不争的事实。 一边是大把人担心AI抢走自己的饭碗，另一边又是人工智障事故频出、难在业界落地。 AI在业界的应用程度到底如何，恐怕还得从已有的商用AI看起。 今天，文摘菌就来盘点一下已实现产品化的商用AI，看看它们在业界都能搞出些什么名堂。 如果你真怕被AI抢走饭碗，所谓知己知彼，赶紧要来了解AI在业界的具体应用。 如果你是企业负责人，更是别错过这张清单——或许你的生产运转难题就可以被其中的某一个AI应用解决！ Capio —  语言转录和识别   电话、录像和在线内容的转录   探索更多的顾客和职员的对话  强化对话界面的高级AI    把用户的交互转化为有价值的理解   使音频变为可搜索文档   关于客户对话的重要见解   给网页和APP添加信息、声音和视频模块   Arago/HIRO —  IT的优化和自动化以及商业运作   针对IoT（物联网）的行为AI    针对企业的一套智能应用软件   系列改进企业产品的产品    在新闻公布之前发掘事件和信息   帮助您回答关于您业务的问题    更智能的Salesforce    在网页和移动应用程序上添加智能决策    帮您索引、搜索、可视化和分析您的数据    时间模式识别和预测的框架   将原始数据自动转换为有用的信息    帮助您监视服务器的错误    自动处理您的业务中的重复性任务   使复杂的数据科学易于企业使用 Ruths.ai —  帮助您最大限度地使用您的数据    分析市场    捕获、分类和提取您所有数据中的关键信息   基于搜索的快速数据洞察    更快、更好、更低成本地解决大数据问题    在复杂的人类和商业生态系统中找到隐藏价值   助您优化定价   Algorithmia —  许多算法、函数和模型的通用API（Application Programming Interface,应用程序编程接口）   神经网络的工作台 CognitiveScale —  针对企业的特定领域的高级ML（机器学习）   针对企业的高级机器学习    针对企业的高级机器学习   开源的机器学习和深度学习平台  针对企业的高级机器学习   计算系统的深度学习    针对企业的高级机器学习     针对企业的高级机器学习   有关金融、电子商务和数字市场的一系列AI产品   Java虚拟机上针对企业的开源深度学习和ETL（数据仓库技术）   针对企业的高级机器学习    针对企业的日志分析 PipelineAI— 大规模解决ML（机器学习）和AI产品的问题   使用神经科学建立AI Amazon Mechanical Turk —  能使简单流程自动化的人力市场   大规模自动发掘目标   自动准备好随时都能立即使用的合适的数据    帮助构建从社交媒体到博客的数据   自动将网页提取为结构化数据   从几乎任何网站提取数据 Playment —  针对企业的数据训练、图像标注等等    运营团队使业务流程自动化的工具   BigML —  所有预测用例的单个平台 译者注（支持跨云导入数据的管理平台） CrowdFlower —  为机器学习团队训练数据，标注图像   适用于大规模数据初始化、部署和运行的数据科学平台   用来研究、开发和生产的企业级数据科学平台    用来协作、构建和部署的平台    使分析人员可以使用开源算法来访问DS   帮助您学习、工作和玩机器学习模型   使得数据科学团队更加高效   帮助DS团队将机器学习模型投入生产   个构建，测试和部署AI算法的平台   研究能够发掘复杂数据模式的引擎   整合离散数据源    使数据的结构更有助于分析   使数据科学家能够快速部署和更新预测模型   自动编写报告，网站，电子邮件，文章等等   AnOdot —  检测业务事件    开发适应性更强、可信度更高和可编程的AI模型 Deckard.ai —  帮助预测项目时间表    在网页和移动应用程序上添加智能决策    将项目与正确的团队联系起来    用可获得的网页知识来强化编程环境    用于预测和个性化的深度学习平台    使得开发适合您业务的聊天机器人更加容易   帮助聊天机器人自我学习，会使其更加聪明   快速的网页和移动应用测试   增加服务器正常运行时间以及预测停机时间   项目管理以及易于团队使用的聊天软件 Improve.ai —  自动优化APP内容、设计和定价等   开发者的手势识别    训练深度学习算法使能像人脑一样学习   提取出复杂的机器学习库例如TensorFlow，以便更高效地管理AI模型 译者注（Bonsai总部位于加州伯克利(Berkeley)，是一个软件开发平台，允许所有开发者搭建、训练、使用智能模型。不需要复杂的AI算法和技术，Bonsai人工智能引擎能让开发人员更高效地编码，以更好地控制和优化硬件和软件。）    帮助设计者，工程师和领导者做决定    帮助分析算法   Alation —  帮助您协同工作、提高生产力和数据索引    系列不同的企业级AI产品    去除集群管理的弊病，让我们专注于DS(数字服务) （译者注；该产品背后的理念是提供处理数据的单独空间，不受托管环境和  Hadoop 集群管理的影响，整个过程在云中完成。）   帮助预测项目时间表   在线趋势的洞察和其他文本分析工具    商用AI平台   帮助知识工作者处理大量的信息    针对风险管理和运营的SaaS AI    使您的业务软件更加智能    帮助员工完成任务以及使用微型APP访问数据   更好的网站分析 eContext — 使非结构化数据结构化    创建人、设备和数据间的智能交互   深入洞察客户和内部数据   大规模自动化决策   Bonsai —  发展适应性更强、可信度更高和可编程的AI模型Cycorp — 一系列不同的企业级AI产品   帮助您将数字广告定位于您的目标人群    以图像，语音，文本和视频的形式分析数据    目前是Uber人工智能实验室的一部分   能够处理琐事，为员工节省时间   统一数据以获取更优推荐的平台    将机器学习模型的速度提高了100倍 Amazon Machine Learn —  机器学习是其中一项服务   导入预测模型并无限缩放以回答存在的问题   Alluvium —  该平台实时监控工厂的生产状况    了解您商店里购物者的行为    帮助统一应用程序开发和数据科学    结合智能传感器及人工智能对数据进行分析   针对制造工艺优化的机器学习   系列关于燃料和工业的工作流程优化产品    帮助您开发、部署和运营工业应用程序   帮助可再生能源公司更好地利用其数据    制造业分析    使数据科学里的数据工程自动化   给您连接的产品添加一个语音助手    管理您的物联网应用的开发平台     重点工业的一个预测平台   商业建筑的智能建筑管理 Agolo —  从您的文本和信息里实时创建摘要    从您的文本和视觉资料中提取含义    不需要任何训练的文本分析和挖掘工作    高级语言处理   自动从文本中获取知识    建立用户的个人资料并更好地了解他们    可扩展的文本分析软件   捕获、衡量消费者行为并根据消费者反馈采取行动    针对自动分类文本的可扩展API   针对您的数据解释出更多有用的信息    帮助您找出文档里的错误和不精确之处   基于Python的免费开源自然语言处理库    自动化信息的提取、管理和分析    使文本数据可理解    帮助您提高招聘广告的撰写方式    自动编写报告、网站、电子邮件、文章等等   ABBYY —  添加即时文本捕获功能至移动应用程序等    具有视觉和判断能力的自动无人机    分析微妙的面部表情来识别人的情绪    使世界上每一台相机智能化    帮助相机检测分析视频馈送 （译者注；Angus.ai是将您现有的安全摄像机转变为新一代监控和警报工具的最佳软件平台。）   找出风力涡轮机的缺陷    从手写和输入的表格中提取和转换数据   帮助您组织媒体库   医疗和运输行业的可视化分析   针对一系列用途和行业的图像检测    品牌及脸部识别    使得卫星图像有用   第一个智能云视频平台   用于汽车和人体检测的计算机视觉    匹配相似的物品并给出组合建议   面部识别   使用面部识别帮助您选择求职者    医疗数据的分析和解释   识别不同的对象和事物   专注于社交网络的品牌识别    卫星图像分析    基于计算机视觉平台的深度学习    使用卫星图像进行行星监测与分析    卫星图像分析    眼神和情绪追踪平台    理解并描述视频内容   主要用于工业目的的图像分析 CloudSight —  数秒内对图像的高质量理解    外来和有意放置物体的安全监测    系列的智能计算机视觉技术 原文链接： https://medium.com/imlyra/a-list-of-artificial-intelligence-tools-you-can-use-today-for-personal-use-1-3-7f1b60b6c94f 【今日机器学习概念】 Have a Great Definition "
181,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656611&idx=2&sn=a110fa4f2602aa22fb39d5b962734d1c&chksm=bd4c36308a3bbf26fa0190bd81615388a021db0716b77b5f12904eab25d2ee3c90c91156ca0f&scene=27,我们可以从Alexa语音助手的错误中学到什么：用户对话界面的设计性挑战,大数据文摘作品 编译：杨捷、Bill、Aileen 交谈是人与人之间互动的关键，追根溯源它可以是远古穴居人篝火旁的围坐，或者政坛上冗长的辩论，又甚至于你与牙医之间尴尬的小对话。我们常常可以通过交流很快速地判断出对方是否有兴趣、我们是否愿意与之约会或形成雇佣关系。如果我们希望完成某件事，那就交谈吧，这是我们传递信息并且与他人交流的途径。   所以这表明我们也将在交谈中实现与服务和商品的互动，不是吗？   确实如此。 这些长期以来在人与人的交谈中已被解决的问题对于对话界面仍然是个挑战。   对话是我们都熟知的交互界面，因此，站在服务的角度理解，对于交互界面设计师来说，想要用户为了与一项服务互动而必须重新学习对话是不合理的。不论用户选择用何种自然的方式与系统对话，服务方都必须试图去理解。   以下是亚马逊Alexa语音助手的最近大热而引起人们注意的一些有关交互界面的挑战：     “谁正在讲话？”   在一个当地新闻节目中，新闻主播模仿了一个偶然通过与Alexa语音助手对话买到了玩偶的小女孩。捕获到的声音信号被Alexa处理为一则命令，随即许多观众也通过Alexa接口尝试订购了一个玩偶。   认证在交易和交流服务中都是至关重要的：我们期待合理的保障措施，尤其面对需要支付和登陆的时候。当处理资金与个人信息时，我们需要更谨慎。   在人与人的交流中，我们有很多我们甚至不会意识到的形式的认证方式：   面对面： 我们通过长相得知我们在与谁交谈，毕竟我们知道朋友的长相。   声音： 我们通过声音辨认交谈的对象，包括语气、词汇等。有时有人错误地接起了电话，你立刻就能觉察。   位置/直觉： 我们对一个新环境中可能遇到某人的概率做了逻辑性的假设。正在外地度假时你突然发现一个人看起来好熟悉？好吧，应该不可能……   但是对话机器人是如何核实客户身份的？   一个折衷的办法是利用传统的验证方法，比如密码验证，虽然显得有些拙劣但是效果很好。然而理想的办法是收集足够多有关客户声音和外貌（取决于介质）的信息，使得对话界面可以不再依赖这种看起来比较笨拙的输入方式，它就好像你的朋友，必须确认你真的是你，才肯借钱给你。   “你在说什么？”     语境同样与上则买娃娃的新闻故事息息相关，如果Alexa已经辨认出其正处于电视节目的环境中（主持人假装想要娃娃的小女孩时使用的是过去时态），那么Alexa就不会采取行动。   这是我们在人际交往中认为理所应当的事情，比如对方可以记住我们在哪里、正在做什么包括我们刚刚谈到的所有一切。毕竟，你可能不会花太多的时间与一个不记得你最近给他说过什么的朋友交往。   从Alexa的故事中我们明白，对于情境的理解需要深入，从什么时候该保持安静到得知某一问题可能会涉及到曾经发生的事情（就像在正常对话中一样）或者用户所说的同音异义语表达的究竟是什么意思——比如你正在感受饥饿（hungry）或者你正要前往匈牙利（Hungary）。   真正的挑战在于这几乎是一个零和游戏，要么提供丰富的语境信息来定义对话代理的行为，要么干脆几乎什么都不提供，因为但凡一个微小的不准确都会使的机器变得不可靠（错误的理解）或者反应迟钝（根据它的理解做出了错误的回应）。   “我正在和谁讲话？” 在这个视频中一个小孩要求亚马逊Alexa为他播放他最喜爱的歌，然而Alexa误解了他的意思并且做出了完全不同的回应   对话界面更有可能在人与人之间共享，就像Alexa被设计为一种家庭内部的存在（亦或一个家庭数字成员），所以它需要理解并且适应不同的用户。它需要明白用户的喜好，年龄，和如何给予他们反馈。如果用户是一个孩子，它们则应提供一种适合孩子的反应方式。   就像通常人们根据聊天的对象和关系程度来调整对话的内容，会话代理同样需要根据听众来调整他们的语调和语言。这也可以归结于语境，如果用户确实很匆忙，   智力水平 Alexa： “对不起，您可以重复一遍吗？” “算了……”   一个充满抱怨的爸爸正在努力使用亚马逊“Trevor” 啊不，是Alexa   我们每天都在进行着对话，与其他交流方式不同的是，人们在交谈时往往有明确的期待。主要表现为对被理解的期待和以及因为需要不断重复表达或者不断被误解而产生的失望。    对话界面令人兴奋并且感到新奇的原因是它可以完全达到免提和隐形的效果。然而这意味着它必须顺利地工作，因为它未设置连击缓冲键或其它选项供用户选择。   与图形用户界面所达到的即时性和反馈不同，对话界面需要时间接受所有的语音信号并且知道在作出回复之前输入语音已经结束，然后用户须收听整个回应来判断界面回应的准确性。   需要强调的是，触摸屏的输入是实时的，包括用户触摸到了那里和怎样触摸：   触摸屏界面通过获取触摸位置和触摸类型（例如按压力度、长度）来工作，这种类型的输入非常迅速   但是语音界面主要输入的是随着时间变化的声波，如下所示：   这些额外需花的时间应该被作为一个考量因素列入到专门为对话服务的新型交互方式的设计中，仅仅将现有的交互方式适配到新型的平台中是不够的。   接下来，我们应该向哪里努力？   我们需要学习如何创建自然对话方式，替代现有的图形界面。对话本身是没有改变的，我们必须向人类已创造的人际交流直觉机制致敬，毕竟我们无需要求他们重新学习这项技能。   我们该如何做呢？   使其更简单，容易上手：  通过智能地使用数据（包括语境、用户行为和用户属性）将所有的事物都拟人化，给用户提供一种和谐并感到舒适的沟通对象。此外，人们总是在思考的半途中就改变了主意或者不总是能清楚地表达自己的想法，所以   使其更令人信赖：  为了使用户信任地将他们的财产或信誉交给看不见的隐形私人助手，用户需要清楚私人助手采取的行动和背后的原因。同时，当私人助手无法满足用户要求时，应该清楚地向用户传达系统的限制，透明化有助于用户避免碰壁或有其他不好的经历。   最后，很重要的一点是： 会话只是提供了另一种交互的方法，但是不能完全地取代视觉或者其他交流方式。 一个理想的交互世界可能看起来更加变化多端：能无缝对接各种最合适类型的交互界面来达成给定的任务。 原文链接： https://uxdesign.cc/what-we-can-learn-from-alexas-mistakes-a4670a9e6c3e#.rz8y92jbk 【今日机器学习概 念】 Have a Great Definition 回复 “ ”加入我们 
182,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656590&idx=2&sn=721367c890bbe5b5849058375c671a61&chksm=bd4c361d8a3bbf0be281f2f9dfd705ee8c73a8fc06b316f9b1641f81af1b886ade30bdc90fb7&scene=27,业界丨李飞飞达沃斯论坛直击，与美国银行、埃森哲CTO圆桌聊AI应用,"大数据文摘作品 作者：Aileen，魏子敏 “雪城【达沃斯】一整周都覆盖在人工智能的热潮之中。AI诚然是一个非常热的话题了。” 正如李飞飞刚刚在推特中所说，1月23日至26日在瑞士达沃斯召开的第48届世界经济论坛年会上，人工智能风头十足。作为人工智能界代表，李飞飞也全程推特直播了这次大会。 昨天，谷歌云人工智能和机器学习首席科学家李飞飞、埃森哲首席技术创新官Paul Daugherty，以及美国银行（Bank of America）首席运营和技术官Catherine Bessant同桌聊了聊AI的应用问题。 作为全球顶级的经济论坛，在达沃斯的AI探讨也少了技术细节，更多充斥着行业应用的案例和大的趋势探讨。而主持人作为WIRED的资深记者，面对三位难得一见的ai大咖，问的各种问题可以说非常“媒体”了，包括“2018AI趋势“、”人类会不会失业“等老生长谈问题，让人略有失望。 也难怪李飞飞会在推特中提到，这次的达沃斯大会没有太多技术细节的探讨，但我也享受相对geek的对话。 不过三位关于AI应用的对话依然值得一看，以下是圆桌论坛视频，当然来不及看视频的读者也可以接着往下看，我们整理了圆桌精华呈现给各位。 主持人： 三位可以介绍一下在各自的公司如何应用人工智能。 埃森哲首席技术创新官Paul Daugherty： 在埃森哲，与其说""人工智能”，我们把AI更看作是""应用智能“，因为关键在于如何把智能科技应用到业界，转化我们的工作方式。我们把AI分成三类： 1) 企业和组织如何应用AI创新 - 比如我们在生命科学领域，利用深度学习和神经网络加速医疗试验，更快的把最新治疗方法推出市场。 2）用自然语言处理等技术转化人类与机器的交流方式- 例如我们在英国正在进行的项目，为老人提供更方便的语音交互服务。 ３）其他更广范围的应用，比如生产流程，后台操作等一系列领域的改变。 美国银行（Bank of America）首席运营和技术官Catherine Bessan： 在BOA我们利用AI： １)进一步改善客户体验，让客户在进行银行／金融活动时更加流畅，高效和智能 ２）改进我们公司内部运作的效率，减少失误 ３） AI 的作用不是代替人类交流，而是帮助人类和人类间更好的交流。例如在我们银行的客服部门，我们用AI可以猜到客户的问题，更快的提供技术类答案，空出多余的时间对顾客提供更多细节和咨询服务。 李飞飞： 谷歌在AI还没什么人知道的时候就开始做AI了，如今AI应用在谷歌的各种产品中，比如谷歌图片搜索利用图片识别技术，Google Home利用识别，Google Photo利用标签技术。我们还用机器学习技术控制我们数据中心的气温，从而节省能源。 主持人：AI存在多年，2018年对于AI的特别之处在哪里 李飞飞： 在技术方面，虽然人们从60年前就开始研究AI，直到最近AI才有了巨大的进步，源于三大助力：计算能力(GPU，芯片技术），大量数据，深度神经网络下算法的进步。所以看到AI真正的能力其实只是最近今年的事情。在商业方面，也是最近AI才开始在各个领域大放异彩：电商，娱乐，金融，工业，医疗等等。 Paul Daugherty补充： 正因为如此，各个企业也正在慢慢学习如何应用AI进行创新中。 Catherine Bessan： 还有一点，过去的18～24个月里，AI的市场成长很快，很多很多公司开始出售AI产品。人们也突然对数据保护，数据安全有了更多的知识和觉悟。 主持人：对人力市场的影响？人们要害怕失去工作吗？ Paul Daugherty： 这个公式“人类+机器=Super Powers”才是正确的理解。机器帮助人类，同时人类也要学习更适合的技能。机器代替人类完成一些工作，在有些行业会快一些，有些还早。就算是人们经常谈起的最容易被机器取代的卡车司机行业，仅在美国现在还有150，000就业机会等待人们去申请。更宏观的看，在美国现在失业人数大概6百万人，同时也有大概6百万的就业机会正在招聘。所以问题是如何更好的匹配人类和工作。 Catherine Bessan:  不用担心，机器的影响完全在人类的掌控之中。机器会给人类创造更新种类的就业机会，现在来看，在AI技术方面的工作就有很大的需求。 李飞飞： 技术进步对人类的影响的讨论，从人类诞生那一刻就开始了。人类就是不挺创新的生物。人们常常忽略的一点还有如何利用机器学习技术本身去使教育更加有效率，帮助人们终生学习。 主持人 ：AI如何帮助企业增长？ 李飞飞:  AI帮助增长的一个重要的点是，深度学习等算法可以挖掘到数据里一些隐藏的洞见，没有这些算法的话，数据的那些价值就流失了。比如图片，视频里大量的信息都可以被算法挖掘出来，做出新产品，帮助企业增长。 主持人：美国vs其他地区的AI 发展 李飞飞： 作为一个科学家，我不觉得科学技术有国界。无论哪里有技术突破，都是造福全人类的。 主持人： AI中存在的人类偏见 李飞飞： 这绝对是个问题。从数据获取，数据标签到模型设计，整个流程中都有Human bias出现的可能，人们现在也非常注意这个问题。同时，还有模型的可解释性，模型可否被信赖。还要确保设计机器模型的人员的多元化。我们非常需要更多人才；而且很多研究表明，当多元化的人在一起时可以刺激创新。机器代表着设计它的人类的价值观，所以我们需要各种文化的人参与进来。 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 "
183,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656631&idx=1&sn=9b97463ceecee643556aff45f64935e9&chksm=bd4c36248a3bbf32b9430dac35c8757dd947bffd8e6100436587ce3d6ffe0d640b2f2e8c5d29&scene=27,汤晓鸥与MIT、宾大教授共话AI：热潮终将退去，人工智能的中国式文艺复兴,"大数据文摘作品 记者：龙牧雪 “《前任3》票房赚了18亿，那是一个前任6亿啊！” 香港中文大学信息工程系教授、商汤科技联合创始人汤晓鸥昨天在《麻省理工科技评论》与DeepTech深科技主办的新兴科技峰会EmTech China上，保持了“被科研耽误的段子手”的特性，如此调侃道。 你没进错场，汤晓鸥演讲的主题是人工智能，不是娱乐新闻。但是他的演讲自带段子手属性，还两次晒了自家娃，引发全场爆笑，简直让文摘菌回忆起了自己养蛙时候的心情。 下面，文摘菌就带大家回顾一下汤晓鸥的演讲全程，以及之后的圆桌讨论环节。参与28日上午峰会的，还有从事自然语言处理研究的宾夕法尼亚大学计算机与信息科学系教授Dan Roth和从事计算机视觉研究的MIT脑与认知科学系和人工智能实验室教授Tomaso Poggio，大家可以往后翻查看他们的演讲PPT。 汤晓鸥：人工智能的中国式文艺复兴 Ladies and Gentlemen, I will conduct my entire talk in Chinese, in 东北 Chinese.  一上台，汤晓鸥首先表示，自己将用东北口音普通话完成演讲 今天我讲的题目是《人工智能的中国式文艺复兴》，这个题目我在上海讲过一次，我这个人不太喜欢重复自己，于是我又想了一个新的题目，叫《人工智能的中国式十月革命》。 有的人告诉我是区块链（笑）。 如果说人工智能=大跃进，大跃进之后是三年自然灾害， 那么区块链=三年自然灾害 言归正传，我每次演讲，都是从这张照片开始。有两个原因，第一，这是我儿子；第二，他长得漂亮。 言归正传地晒娃 今天又多了一个更名正言顺的原因：在座有很多MIT的教授，我儿子再过四、五年就要申请大学了，我想提前让教授们认识一下我儿子，帮助他将来申请。我想我长这样都可以进MIT， 他这么帅，应该没问题。虽然他学习成绩很一般，而且不是一般的一般。 再一次言归正传，我想大部分中国人都应该知道这部电影——《战狼》。 一下子赚了56亿票房，约8.8亿美金。这在15、20年前是不可能的；那时候中国的一部电影是不会赚这么多钱的。这有很多原因，其中一个非常重要的原因就是今天我们都愿意花钱去电影院看电影了，而15年前、20年前，很多人会去买盗版的VCD，或者去网上下载一个盗版。如果这样，导演和演员也就没有动力再继续坚持下去了。今天中国电影的成果最重要的推动力就是我们对原创和版权的尊重。 我们现在不是只有一部电影这样成功，比如《羞羞的铁拳》赚了22亿，《芳华》是一部文艺片，也能达到14亿的票房，当然，冯导的电影从来没有让人失望过。 《无问西东》是一部非常有情怀的文艺片，也做到了5亿票房。都非常不容易。所以，对原创的尊重使得中国的原创电影不断往前发展。 在三四十年代，全球电影发展起来时，中国电影并不落后，像《马路天使》、《一江春水向东流》一点也不输给好莱坞电影。即使在那个战火连天的年代，中国还能够拍出这些好电影，一个原因可能也是当时没有DVD和互联网来帮助盗版。 再往前，说一下文艺复兴的时候，如果米开朗基罗的这些作品，或者任何一个艺术品很快有人进行复制了拿去卖，那么他可能也赚不到什么钱，也就活不下去了。所以，对于原创的尊重也是文艺复兴能真正兴起的一个原因吧。 我在最后放了一个现代艺术品，我觉得和米开朗琪罗的《大卫》有异曲同工之妙，是用手纸做的一个弹琴的艺术家。这个也是给MIT教授看的，因为这个是我儿子做的。（晒娃乘以二！） 说到原创，下面我们来讲讲人工智能。 我看到大家都在点头，应该大家都同意，第一个想到的一定是商汤。（观众爆笑） 花式晒公司 我觉得大家这个笑就很不礼貌了。OK，是谷歌。 但是我相信人工智能这个热潮一定会过去的，等这个热潮过去了以后，商汤一定会成为人工智能最顶级的公司。（掌声） 因为谷歌真的把资金投入人工智能发展，2015年的研发经费就是120亿美金。2014年有一家公司叫DeepMind，只有12个员工，没有赚钱，只是在用深度学习玩游戏和下棋，但是谷歌就花了6.6亿美金收购了这家公司。 但是如果那样做的话，就是对公司、对原创的不尊重，就不会有后来的AlphaGo了。大家也就不会坐在这儿对人工智能产生这么大的兴趣。 那么AlphaGo之后大家还能做点什么呢？谷歌又做了AlphaGo 2（AlphaGo Zero），有些公司开始学着AlphaGo下围棋，还有的公司选择打扑克牌，这从某种意义上讲，都是跟在别人的后面做事情。 真正有意义的事情是，在AlphaGo之前你做了什么？有没有做什么事情让机器在某项任务上战胜人类。在AlphaGo之前我们做了一件事情，2014年，我们团队从事人脸识别，在全球第一次让机器的人脸识别能力超过了人的眼睛，像AlphaGo一样，在某一个人类定义的单项任务上，机器超越了人类。超越了人类就过了一条红线，而过了这条红线就可以在工业上进行应用了。 2014年，我们用20万人脸来对机器进行训练做到了98.5%的准确率，而人是97.5%；2015年我们用30万人脸进行训练，达到了99.55%的准确率。 2016年，我们用6000万人脸训练，达到了百万分之一的误识率；2017年，我们用20亿人脸训练可以达到一亿分之一的误识率， 所以，我们和高通签署了全球AI战略合作协议。 那么除了人脸识别，我们现在还做什么？我从我们做的十几个行业里选出一个来简单介绍一下——视频分析。 下面这个技术是 。 这是里约奥运会的跳水比赛直播，大家可以看到过了9分钟也没有看到跳水的内容，要花一大堆时间看一些枯燥的内容介绍。所以，我们用计算机视觉分析的方法，可以从很长的一段视频里把重点内容检测出来，你就可以直接跳过没有意义的部分，直接看这些有趣的、真正的跳水的镜头。 下面这个演示是基于内容的视频搜索。 在电影中，我们可以把各种各样的片段搜索出来，比如说你想搜索武打动作片段，或者喜剧片段，我们可以直接把它搜索出来，或者你想搜索科幻的，我们可以把科幻的片段搜索出来。 下面这个演示是用自然语言描述来进行场景搜索。 我们用自然语言来描述一个电影中的场景，然后它就可以自动根据你的描述把这个电影片段搜索出来，比如，我们要搜house of cards中的一个片段，“Claire和Frank坐在蓝色沙发上”，大家看到下面这段场景就出来了。 另外我们不但能把视频分析出来，还能理解这个视频，然后用自然语言描述出来。比如下面这些运动视频， 。 上世纪的一部电影《美国往事》是在威尼斯的Lido酒店拍摄的，下面这个演示里，我们能把电影场景里的所有物体都检测出来。 不仅仅检测演员是哪一个演员，他穿的是什么衣服。这个场景是在餐厅里，所有的桌子、花、椅子全部能够实时的自动检测出来。这样的技术在以前是非常难的，但是现在我们都可以做到了。  再回头来看我们如何用这些技术来分析前面提到的电影《战狼》和《羞羞的铁拳》，我们通过分析这些演员的动作和他们之间的关系，可以分析出来在不同的场景之下，这两个演员是谁，在做什么，这个片段是什么类的情节。 同时，我们可以给每一帧情节分类，可以识别出每一个镜头是打斗场景还是恋爱场景。 我们也可以把一个电影最精彩的镜头提取出来，大家可以挑选比如动作的精彩镜头、感情戏的精彩镜头、悲剧的精彩镜头等等。 那么总结起来，我们在做什么呢？ 我们是在教机器看电影。 （笑） 一开始我们是教机器来识别人脸，Google是在教机器来下围棋，而现在我们来教机器代替人看电影。这个感觉有点怪， 我想未来可能就是这样的啊。（笑） 我觉得大家听了这个一定觉得很可笑。实际上所有的任务，都是我们人安排给机器做的，机器是按照我们的指令在做事情，不存在机器控制人类这样的事情，AI的真正目的是帮助人类，帮助我们提高生产效率。 最后给年轻人留下两句话： 第一句，电影一定要自己亲自去看。 第二句，AI这个词在中国拼音翻译过来就是“爱”，所以谈恋爱也要自己亲自去谈，否则你就不止是“前任3”了，很有可能是“前任4”、“前任5”了。 "
184,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656611&idx=1&sn=00296af4ca74510394744e38a22fb74a&chksm=bd4c36308a3bbf264eb82b05c9afdbfbbbae06a7387e09cfe67c101244637675109030e25f08&scene=27,我分析了2万条饿了么、美团红包记录，这些是红包最多的APP（附数据集）,授权转载自公众号 THU数据派（ID： datapi ） 作者：窦英通 笔者在2015年7月创建了一个以分享滴滴打车红包为主的微信群聊，创建的本意是为了方便大家在分享红包时不打扰别人，在乘车需要红包时能方便地领到红包。随着群人数和分享红包种类的增加，该群已成为一个各类 O2O 服务APP优惠券红包的集散地。 ，笔者最近将这些记录导出，通过数量，时间，语义等维度分析这些数据，下面将笔者自己的解读分享出来以供大家学习交流。   本群主要成员为北京某大学的大学生。两年时间里本群共产生21477条聊天记录，其中有效的红包分享记录约为20000条，群成员在10个月内从几十人增长到500人满群。 聊天记录可导出为 Excel 表格格式，单条聊天记录的格式如图1所示。 图1 每一列的数据分别为微信群群号（没错，微信群也有群号）、消息发送时间，发送者微信昵称，发送者微信号，发送形式（接收或发送），消息类型（文本、网页、动画表情、照片壁纸）和消息内容。因为大部分红包都是以网页的形式分享，而且每种 APP 只使用各自固定的域名，例如滴滴打车使用 xiaojukeji.com ，饿了么使用 ele.me。通过对不同域名数量的统计，笔者分析出了红包数量最多的12个APP 以及他们的数量比例（图2），这12类 APP的红包数量占所有红包总量的95%。 图2 从图中可以看出外卖红包是所有红包种类中数量最多的，因为衣食住行中，“食”的频率最高。 ，这与市场调查机构公布的2016和2017年外卖 APP 市场份额报告的结论（饿了么与美团外卖市场份额不相上下）不一致。这是因为微信群聊参与者身份和地域的局限性导致该统计结果只能反应小范围内外卖APP 的市场份额。 除了图中的 APP 之外，红包数量比较多的 APP 还有：去哪儿、由你单车、嘀嗒拼车、爱鲜蜂、一米鲜、携程、 每日优鲜、乐惠、优酷、开心消消乐、Airbnb、中国移动、触宝、有货。需要补充的是，图2中京东的红包包括了京东商城、京东到家和京东金融，网易的红包包括了网易严选，考拉海购和阴阳师。 以上 APP 基本上涵盖了中国大部分主流提供 O2O 服务的APP，同时也体现了大学生的消费特征。共享出行，外卖，生鲜配送，网购，娱乐休闲是当前大学生主要的消费形式。 从图1中可以看到每个红包在分享时都有一条相应的广告语，笔者分析了这些广告语的高频词汇，并将其做成词云图，如图3所示。 图3 细心的读者可能发现红包的广告语有几种类型，一种是宣传 APP （及其提供的服务）本身，一种是其他品牌的广告，常见的有影视剧和品牌促销活动等，还有一种类型是 APP 自身的明星代言，例如饿了么的王祖蓝和科比。我分析了2015年8月，2016年8月和2017年8月这三个月中这三类红包的比例，如图4所示。 图4 2015年夏天是O2O服务刚开始迅猛发展的时候，那个时候他们的市场份额还不高，所以红包主要还是以宣传自家服务为主，到了2016年夏天， O2O服务竞争到了火热阶段（外卖领域和出行领域），那个时候的红包折扣力度也比较大，分享人数较多，所以我们看到其他品牌广告占比明显上升， 。笔者没有行业经验，但猜测红包冠名广告的曝光率和点击率要高于一些其他的广告形式。2017年夏天，这时外卖和出行市场格局已定，红包的折扣力度减小，分享人数下降，所以大部分广告是针对自己APP的宣传，常见的广告语是“第X个领到红包的金额最大”，以刺激大家点击链接进而产生消费。 图5是红包数量前七名的APP红包数量两年间的变化趋势。 （建议横屏观看） 图5 从红包数量变化趋势中可以得到以下几点结论：首先， 。在2016年8月之前，美团外卖的红包数量要高于饿了么红包数量，之后饿了么红包数量一路反超，远远高于美团红包数量。造成变化的原因不是饿了么增加推广力度，而是因为大部分群成员（北京某高校学生）从一个校区整体迁往了另一个校区，而美团外卖在原校区的规模相对于饿了么要比新校区的规模大。同样，在2017年6月之后，红包数量的整体下跌是因为大部分群成员从大学毕业，对外卖的需求下降。这从另一个角度反映了小规模数据的不稳定性。 第二，同样是外卖红包，我们可以看到在2016年2月和2017年2月，也就是 ，显而易见，大部分群成员都回家过年，对外卖的需求大大减少。有趣的是，滴滴红包数量并没有明显变化，一方面是春运的影响，另一方面说明 。 最后，我们看到滴滴红包的数量稳定增长一直到2016年7月达到最高峰，从2016年8月开始一路下跌。笔者认为造成下跌原因和群成员的关系不大，主要原因是2016年8月1日滴滴宣布收购优步中国，国内的共享出行领域滴滴一家独大，笔者清楚记得 。一方面是优惠力度的下降，另一方面部分摇摆乘客可能会选择别的出行方式，笔者认为这才是导致滴滴红包分享数量的下降的原因。 图6 图6将滴滴和ofo红包数量变化趋势专门列出来，这样可以更直观的看到其变化。之所以没有列出摩拜，是因为摩拜的分享次数较少，在图表上不明显。如果说2015年夏天是汽车共享出行开始迅猛发展的时候，那么从图中可以看出 。事实上滴滴从2012年就开始做出租车叫车业务，ofo早在2014年就开始在大学校园推广共享单车。随着4G网络的和智能手机的普及，微信使用人数越来越多，在多种因素的综合作用下，这些出行O2O服务在2015年后才开始迅速发展。 下面我们将时间维度缩小到一天内，看看一天内出行红包和外卖红包的分享数量和时间的关系（图7）。 图7 一般而言，一次线上的红包分享可以代表分享者同时在线下产生了相应的行为，通过变化红包分享数量变化趋势可以看到，在“食”和“行”方面，统计数据很好地体现了我们一般的认知。 。 相信大部分读者都经历了支付宝跨年红包的洗礼，作为敏感的红包群群主，我发现 ，图8是群聊中从2017年12月10日到2018年1月10日支付宝跨年红包的分享数量变化。 图8 由于笔者在国外，并没有参与到瓜分红包的行动中，但笔者好奇的是：在2017年12月12日到2017年12月22 日，支付宝分享红包的吱口令中，“支付宝”三个字有大量变体字出现，让人一度以为是欺诈消息，我分析这十天所有的支付宝变体，将其做成图9的词云。 图9 支付宝一共产生了十种变体，起初笔者猜测支付宝是为了防止微信的追踪和屏蔽，但我想这样变体也不妨碍微信监测到消息，况且在这之前和之后红包都是正常的，所以我特别期待懂这个问题的朋友能够解答我的疑问。 总而言之，这份两万条记录的数据集规模太小，所以很难得到宏观的结论，目前得到大部分结论也是显而易见的。利用该数据集进行进一步例如行为预测，用户画像，也是不现实的。另外，该数据集的特殊性在于它的独一无二，不同于微博等公开可获取的数据，这样的数据只能通过人为组织收集， 所以，假设我有足够多的群成员，我可以通过收集他们的性别，职业和收入的情况，结合他们线上分享红包的时间、种类、次数，可能会得到一些有趣的经济学结论。进一步，如果我们能获取到每个红包群成员点击的情况，这样又增加了一个数据维度，可以结合时间以及冠名广告和点击率做红包发送的优化，也可以结合群内其他数据维度来进行用户的画像，行为预测等等。当然， 不过以上所说的种种限制，对于微信官方来说都不是问题，微信利用自己的平台优势关联了无数的APP，利用不同的数据源，微信可以通过协同过滤（Collaborative Filtering）以及多视角学习（Multi-viewLearning）进行用户画像从而进行更精准的推荐。从另一个角度想，我们越来越多的行为都被 BAT 三家收集到，大家在互联网上越来越透明，所以对隐私的保护越来越重要，这不仅要靠企业自律，还要靠国家加强立法。 通过这次分析，笔者最主要的发现就是 ，并不是说如果数量到百万千万级就不是小数据了，而是说 。这对数据挖掘从业者有一定的启示。 微信群聊记录可以通过“同步助手”导出到电脑上，可以导出为文本文档、表格或者网页格式，结合 Excel 和相关 Python工具包，可以轻松实现对微信群聊数据的挖掘，各位读者可以自己动手挖掘感兴趣的微信聊天记录。我也把本文用到的数据集匿名化处理后发布在网上以供大家学习使用。 数据集下载地址： 【今日机器学习概念】 Have a Great Definition 
185,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656607&idx=2&sn=6c314aff52a020f9f0b5ed60e1eb1853&chksm=bd4c360c8a3bbf1a1f1a1c84e8f84325f6b93601c0efc4608ab09eb3eb6c825cab8ef05205b2&scene=27,大咖丨张钹院士：人工智能赶超人类的三大法宝,按要求转载自公众号联合时报（ID：lhsbwx） 中国科学院院士张钹对国内外人工智能产业发展现状，提出我国仅靠跟随性的应用深度学习发展人工智能，是无法引领这项技术实现革命性突破的。 语音也在里面学，文字也在里面学，图像也在里面学，会不会互相干扰呢？其实不仅不会互相干扰，在一定程度上还略微有帮助。北美已在引领这些发展，如果中国只低头用深度学习去解决应用问题，不去研究一个目的背后需要解决的问题，要做到“引领”则是不可能的。 为什么机器下围棋能超过人类;为什么在图像识别的某些方面会超过人类，成功的因素是什么?我认为有 这就是深度学习成功的三大法宝。大家对于前两个方面比较注意、有体会，很多人还没有体会到算法的重要性。 在这里主要是谈人工智能和大数据的关系，以及中国在人工智能领域如何赶上和超过世界的先进水平。 深度学习的提出，在人工智能领域中是一个重大突破。以往，人工智能只能用来解决人们对它非常了解，而且能够清楚地将它表达出来的问题。但深度学习拓展了人工智能所能解决问题的边界。 其次，深度学习具有一定的通用性。 比如，人们用深度学习做图像识别，不一定要具备非常丰富、专业的图像知识。即使你不是这个领域的专家，也能把深度学习应用到这个领域。所以，深度学习是一种大众化的工具，它把解决问题的领域大大延展了。对大众而言，这些奇迹引发人们认识到了深度学习的威力。就是在图像识别领域，在某一个图像库里，机器识别准确度略微超过人类，或者机器的误识率低于人类，微软做的工作、百度在语音识别上的工作，识别错误率略低于人类，在两个领域的识别上机器都超过了人类。 第一，大家都希望把深度学习的方法用到其他领域可能会产生新的奇迹，这些奇迹会不会发生，在什么样的情况下会发生； 第二，如何推动深度学习继续向前发展。 这些奇迹来自何处?为什么机器下围棋能超过人类，为什么在图像识别的某些方面会超过人类，成功的因素是什么?我认为有三大法宝：数据、计算资源和算法。这就是深度学习成功的三大法宝。大家对于前两个方面比较注意、有体会，很多人还没有体会到算法的重要性。我用阿尔法棋作为例子，具体谈谈它怎么来使用这三个法宝。 阿尔法棋用了两个多星期的时间，学了七千万局棋局。机器还自己跟自己下，跟李世石下之前也下了千万局的棋局。也就是说比所有的棋手多下了几千万局的棋，最后的结果是4比1战胜李世石。最好的棋手一生中所下的棋局是百万级，而阿尔法棋下过的棋局是几十亿级的，这两项数据非常不对称，人类绝对会输。这里可以看到数据的力量和计算资源的力量，大家没有看到背后算法的力量。但阿尔法棋能够在两三周里学到几千万个棋局，靠的是什么，其实是靠学习算法，它自己跟自己下棋，靠的是什么，靠的是强化学习算法，没有这些，它是做不到的。 是不是所有问题，只要有数据，就能够做到这么好呢?不是!这要受四个条件限制： 首先是需要有大量的数据，第二是完全信息，第三是确定性，第四是单领域和单任务。 只有这四个限定条件达成后才有可能做到刚才说的，达到或者超过人类的水平。有很多问题(同时)符合这些条件，比如说医疗数据，可以做大数据处理，像某些疾病的医疗诊断、医疗图像的识别、医学图像识别等等，只要(问题领域)符合这四个条件，都可以做，而且经过努力，依靠那三大法宝是可以达到或者超过人类的水平。但是，大量的工作并不符合以上四个条件，不符合中间一条两条或者四条都不符合，如果一旦不符合这四个条件中的任何一个，现在的人工智能技术就有困难。 对此，大家以往一直感到困惑，语音也在里面学，文字也在里面学，图像也在里面学，会不会互相干扰呢，过去我们怕装不同东西的时候它会乱了，会互相干扰，其实不仅不会互相干扰，在一定程度上还略微有帮助。北美已在引领这些发展，如果中国只低头用深度学习去解决应用问题，不去研究一个目的背后需要解决的问题，要达到引领是不可能的。 深度学习也不是完美的。很多人以为用深度学习去做产业或者应用不会有问题，但是这里要强调，深度学习有大量的隐患，这些隐患在很多应用场合下是绝对不允许的。首先，它需要大量的样本，有些问题很难获取很多样本，比如特殊疾病，罕见疾病，根本没有那么多样本。最重要的是，不可理解性，现在看到深度学习建立的系统，实际上跟人的思路很不一样。因此，说机器识别能力超过了人，这只是在非常特定的环境下说，其实很多方面它不如人。比如它识别率比人高，只是说它区别马和牛的能力比人高，就是在一定的数据库下它识别能力比人高，但是它根本上不认识马和牛。将来如果做一个人机决策系统，机器做出来的决策，人都不知道它怎么做出来的，那怎么用呢，谁敢用呢? 现在实际要解决的问题就是人和机器能够合作的问题。 大家都在强调，今后的方向肯定是人和机器合作，要各展所长，这里面有一个问题就是机器如何理解人，人如何理解机器。过去的重点是放在机器如何理解人上面，比如说人类的语音命令，用自然语言发的命令它能够听懂，这是所谓自然语言对话。这其实忽视了一个非常重要的另外一个点，就是人如何理解机器，这是由深度学习引起的，因为深度学习出来以后，它做出来的事情人非常不理解，这就给人机共同合作带来了巨大的困难，所以现在很多的重点除了做自然语言理解，理解用户的意图等等这些工作外，还要集中在人如何理解机器这方面。 为什么会发生这种情况，为什么机器的思路跟人不一样，因为机器处理的方式要用专业的语言。机器怎么识别猫呢?它只是从一些局部的特征，局部的纹理来识别它，它根本不是从猫的整体来识别，因为机器要取得整体的特性是非常困难的，它只取得局部的特性，所以它都是在利用局部特性，在一个特征空间里去认识猫，跟人认识猫的角度完全不一样，人认识猫是从所谓语义空间里，是通过它的各种各样的属性来识别它。 目前，这些研究不仅只是大学或者科研机构的事情了，企业也都在纷纷参与。我有个团队也是围绕上面的问题，重点是如何突破将来人工智能要解决的基础和关键问题，而不仅只是低头跟随性地应用深度学习，只有从这点上着手，我们才有可能实现在人工智能领域追赶、超过或引领的目标。 【今日机器学习概念】 Have a Great Definition 
186,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656631&idx=3&sn=a0bd17767d352893195b1402a2e6053d&chksm=bd4c36248a3bbf3262cf1fd3f3733f922fc9e4fc273e1b47e3f7bf05430e9aad618167f369d8&scene=27,还想找个程序员当女婿？如果告诉你程序员就是下一代蓝领呢？,大数据文摘作品 编译：林海 吴双、小鱼 还记得去年某AI峰会上，一位妈妈高调征婚替女儿找“程序员”女婿的新闻刷爆了当天的朋友圈。程序员向来被认为是一个还算体面的职业，高门槛，高收入，有前景，这些都让外行人望而却步。但是，越来越多的技术需求下，程序员的技能正在被“批量生产”。 通常，当我问起人们对程序员的印象时，他们都把程序员想象成马克·扎克伯格那样：一个穿着连帽衫的大学辍学生，热火朝天地写上72小时代码，就能做出一款app，并以迅速发家致富为目标，还试图“改变世界”。   但是，从全美国来看，硅谷程序员的范例并不适用于其他地区。 那其他几百万的程序员呢？他们的情况就和我所遇到的程序员Devon差不多。Devon是位于俄勒冈州波特兰市一家安全软件公司的程序员，他每周工作40个小时，薪酬丰厚，工作内容极具智力挑战。“我的父亲是蓝领工人，”Devon说。实际上在许多方面，Devon也是一位“蓝领”。 政治家们总是老生常谈，为好的蓝领工作逐渐减少而惋惜。并认为那样的工作才是真正的中产阶级公民社会的支柱。现在不必再如此担心了。如果下一代蓝领工作已经出现，而且就是现在常见的编程工作呢？如果编程不再被视为高收入、诱人的职业，而是和克莱斯勒工厂的技术性工作一样呢？ 还有一些事情也会随上述情况而发生变化，比如为适应程序员工作所做的培训，以及参加培训的动机都会有所改变。正如我的朋友，技术思考者和企业家Anil Dash所述： 这样一来，在社区大学就可以学习编程，职业中期者则可以选择参加高强度的、长达数月的集中学习项目来提高自己，比如Dev Bootcamp。年少得志者将不再那么受关注，工人阶层将成为主流。   “蓝领”程序员无需具备像设计新颖的闪电交易和神经网络算法这样的深度知识。为什么呢？因为常规工作中几乎用不到如此高水平的专业知识！但是，任何一个蓝领程序员都应该足以胜任本地银行所需的Java代码编写工作。这完完全全就是中产阶级的工作，而且这种工作的人才需求还在不断增加！全美IT工作者的平均薪资大概是81000美元（是全美所有工作薪资平均水平的两倍），而且从2014年到2024年， ，比其他任何职业领域扩张得都要快。 在美国，人们都在努力抓住这一机会，特别是那些受到去工业化（deindustrialization）影响最大的州。在肯塔基州，资深矿工Rusty Justice决定放弃挖煤，转而学习编程。他与别人共同建立了程序员商店Bit Source，帮助那些想通过再培训转型为程序员的煤矿工人。令人惊喜的是，Justice最初发布的11个职位共迎来了950个申请者。结果表明，矿工非常适应这种高度专注、团队合作并需要复杂工程技术的工作。“煤矿工人只是工作有点灰头土脸的技术工人，”Justice说。   同时，田纳西州的非赢利组织CodeTN也正在努力推动高中学生进入社区大学学习编程的项目。有些学生（和老师）担心他们并不适合走扎克伯格式的套路。“这种担心完全是多余的”，CodeTN共同创建者Caleb Fristoe说。“我们需要让更多的雇主说‘是的，我们只是需要一个人来管理登录页面，’”他说到。“不需要你成为一个超级明星。”   但可以肯定的是，社会还是需要超级明星的！无论是在公司还是在学术机构，创新者都是开拓类似机器学习这样新领域的奠基人。但是， 几十年来，流行文化一定程度上过度地美化了这种“孤独天才”的程序员，我们曾经艳羡《社交网络》（The Social Network）里的亿万富翁程序员，《黑客军团》（Mr. Robot）里身着皮衣的匿名黑客。但是， 素材来源： https://www.wired.com/2017/02/programming-is-the-new-blue-collar-job/?mbid=social_twitter   【今日机器学习概念】 Have a Great Definition 
187,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656607&idx=1&sn=941c2c82b37d32357ad7f6141e889e83&chksm=bd4c360c8a3bbf1a4a12bdfa9cc06da61a610e68c85784a8c15c783e958aead34525e1c6d92d&scene=27,只看视频不动手的你可能学了门假课程，李飞飞计算机视觉成名作斯坦福CS231n作业详解重磅来袭！,大数据文摘作品 看完视频并不是真正的学习了一遍，更重要的是写作业、动手实践、讨论，这才能把学到的知识真正掌握住。看完斯坦福CS231n的公开课，是不是觉得还不够过瘾？快来和文摘菌一起写作业敲代码吧！ 提到深度学习与计算机视觉，不得不提ImageNet和它的创建者，斯坦福大学计算机科学系副教授、Google Cloud 人工智能和机器学习团队的首席科学家李飞飞。而她的成名作，斯坦福大学课程《深度学习与计算机视觉》自从公开视频和作业，也造福了一批对计算机视觉感兴趣的IT从业者。 先来看看某互联网招聘平台普通IT和视觉算法工程师薪资对比: 而深度学习和计算机视觉的课程那么多，文摘菌为何偏偏推荐这一门？ 首先，该课是计算机视觉的一门经典的课程， 其次，课程内容安排合理，由浅入深。主要介绍了深度学习（尤其是卷积神经网络和与其相关的框架）在计算机视觉领域的应用，内容涵盖多种神经网络具体结构与训练应用细节，以及针对大规模图像识别，物体定位，物体检测，图像风格迁移，图像理解描述与视频内容识别等问题的前沿解决思路。从一个简单的cifar10数据集和最简单的KNN算法开始介绍，慢慢引入深度学习相关的知识点。比如dropout、batchnormalization等。最后介绍了一些深度学习经典的范例，比如RNNs， LSTMs ，GAN等。 最后，也是小编要强调的一个原因，视频课程中嵌入了中文字幕！没错，尽管多数IT从业者都有基本的英文水平，但是要理解如此高深的课程，还是要花费大量功夫。而汉化视频不仅需要高神准的英文水平，更需要一定的深度学习专业能力。 大数据文摘联合北京邮电大学模式识别实验室共同完成了这一巨大的工程！ 整整耗时6个月（从2016年9月-2017年2月）！特别感谢字幕汉化组的成员，为你们疯狂的打call。 字幕汉化组工作人员的辛苦也换来了丰厚的回报，自课程推出后，在网易云课堂的播放次数截至今日就达到了77790次，课程评分高达5颗星，5颗哦！大数据文摘也收获该课程的一大批真爱粉，大家还很期待的询问有关CS224的课程呢。 对了，是不是还有同学没有来得及学习这一经典课程？快戳下面的链接学习吧！ https://study.163.com/provider/10146755/index.htm 大家学习的热情也很高，各种精彩的笔记： 看来也有很多大佬在学习该课程，如果你以为听完课程就入门机器视觉了，那你就太单纯了。上完课还是要做作业的，还是要敲代码的。可是做作业遇到困难怎么办？做完的作业没有参考答案怎么办？ 文摘菌听到了大家的心声，也邀请了一批一线从业人员，牺牲休息时间，亲手研读课程作业，并且整理了课程作业的完整笔记。 笔记作者和校对人员对于作业每一道题涉及到的知识点，都进行了相关知识点的讲解。讲解内容不仅涉及到课程上的一些知识，也有一线从业人员的心得体会和知识点的扩充。针对每一道题目大家都可以进行实操，以加深对每一道题的理解。 比如针对assignment1中的Q2，我们的志愿者同学给出了这么详细的答案： 为了帮助大家顺利完成作业，笔记作者和校对人员给出了每道题完整的代码作为参考，并且代码都有详细的注释，有没有超级棒？ 那么这么精彩的笔记怎么拿到呢？以下是第一期作业笔记获取链接 大数据文摘网易云课堂专栏： https://study.163.com/provider/10146755/index.htm 大数据文摘CSDN专栏： http://blog.csdn.net/BigDataDigest 大数据文摘GitHub专栏： https://github.com/theBigDataDigest/Stanford-CS231n-assignments-in-Chinese/tree/master/assignment1 我们会根据进度分批把作业全部发布出来，请各位持续关注大数据文摘哦。 最后，让我们感谢本次作业的工作人员，是你们无私的付出，让更多读者可以享受这一成果。 全体作者： 郭承坤  观自在降魔  Fanli  SlyneD  土豆  MoreZheng   张礼俊 校对： 毛丽   郭承坤 总校对与审核： 寒小阳 文案： 冯晓丽 【今日机器学习概念】 Have a Great Definition 
188,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656590&idx=1&sn=9b76661ae32c25a159fdabb946e4bc2c&chksm=bd4c361d8a3bbf0b1c16cf4a5c9ade6be09fa5923e8c28b381600f3a0429daf328c8627b5e5f&scene=27,自带迷幻剂技能的小贴纸：忽悠神经网络，让它将一切都当作烤面包机!,大数据文摘作品 当下的图像识别技术看似愈发成熟了，但自带蠢萌属性的它实际上依然可以被轻易愚弄。 研究人员最近就成功忽悠了一把以智能著称的算法，让它们一脸懵逼地犯下了一系列错误： 比如把两个滑雪的人辨识为一只狗，把一个棒球看成是一杯意式咖啡，又例如把一只乌龟误认为是一把步枪。 最新的一个欺骗机器的方法操作更为简单，却有更深远的影响， 图注按顺序为：将贴纸放在桌上，输入分类器的图像，分类器输出结果 这款由谷歌的研究人员新近开发的自带迷幻剂属性的小贴纸可是相当厉害了。 据一篇最近提交的和这个神经网络攻击有关的研究论文所述，这块小小的“狗皮膏药”（对抗性补丁）是具有“场景无关性”的，这意味着任何一个“对光照条件、相机角度、被攻击的分类器类型或甚至场景中的其他事物没有事先了解”的人都可以利用这张贴纸，去实行对图像识别算法的攻击。 相关研究论文的arxiv链接：https://arxiv.org/abs/1712.09665 再加上贴纸本身可以在网络上被分享和打印出来，这个攻击方法简直是唾手可得。 一个由谷歌深度学习研究团队Google Brain的成员Tom Brown上传的油管视频，就展示了这块对抗性补丁是怎样作用于一张香蕉的图片上的。 点击查看相关视频👇 起先，一只香蕉放在桌上的图片是能够被VGG16这个神经网络正确识别为“香蕉”的，但把迷幻小贴纸放置于香蕉旁边后，神经网络随即把图片分类成了“烤面包机”。 正如研究人员在论文中所述， “对抗性补丁正是利用了这一特性，通过生成远远比真实物体显眼得多的图像输入（从而欺骗了模型）。”同时，研究人员在论文中写道，“因此，在攻击物体探测或是图像细分模型的时候，我们希望被定为识别目标的烤面包机贴纸一方面能被分辨为‘烤面包机’，另一方面也不会对图像本身的其他部分造成影响。” 即使现在研究人员已经有了许多种让机器学习算法产生视觉错误的方法，这个办法却因其简易操作且难以察觉的特点而显得尤为重要。 研究人员如是说。 目前而言，让机器把一根香蕉看成是一部烤面包机的小恶作剧并不会对社会造成什么实际的危害。 最重要的是随着无人驾驶技术的普及，这些智能汽车非常依赖于图像识别软件来理解它们周边的环境并与之互动。试想成千上万坨大型重磅的金属块在高速公路上飞驰时只看得见烤面包机，这将是一件多么危险的事情。 原文链接：https://gizmodo.com/this-simple-sticker-can-trick-neural-networks-into-thin-1821735479 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 
189,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656590&idx=3&sn=58b9ae713a2273571fc070c28a2a7020&chksm=bd4c361d8a3bbf0bb3aa005260a4611be317e5a6fc38768255d22f6e7164f405f34a2dc662d2&scene=27,快讯 | Facebook开源物体识别工具Detectron，加速计算机视觉研究,"大数据文摘作品 作者：龙牧雪 冯晓丽 1月22日，Facebook的人工智能实验室（FAIR）开源了计算机视觉研究平台Detectron。Detectron系统实现了最先进的物体检测算法，包括Mask R-CNN。 它是用Python编写的，支持Caffe2深度学习框架。 就在2天前，纽约大学教授Yann LeCun刚刚宣布卸任Facebook人工智能实验室（FAIR）主任，并担任AI首席科学家。 👉 在一些“搞事情”媒体各种“Facebook变天、LeCun连降两级”的报道之下，昨天，Yann LeCun又发了一个“澄清帖”，说明Jerome Pesenti所担任的AI副总裁是一个新职位，并不是来取代LeCun的AI实验室主任地位的，这一组织结构的变化在几个月前就已经发生。这一职位变动也从人员架构上说明了Facebook高层对AI的重视程度在提升。 正如Yann LeCun所言，Facebook人工智能实验室发展势头正猛。 近日，Facebook的人工智能实验室（FAIR）开源了计算机视觉研究平台Detectron。Detectron系统实现了最先进的物体检测算法，包括Mask R-CNN。 它是用Python编写的，支持Caffe2深度学习框架。 不久前，FAIR才开源了语音识别的工具wav2letter，戳这里看大数据文摘介绍 。 这一系列工具的开源，将使更多研究人员能使用到Facebook的平台，进一步扩大Facebook人工智能实验室的影响力。 针对Detectron的开源，研究员Ross Girshick发表了一篇博客，具体介绍了该开源平台的性能。大数据文摘特摘录如下： Mask R-CNN 输出的范例 Detectron 项目于2016年7月启动，旨在创建一个基于 Caffe2 的快速、灵活的物体检测系统。经过一年半的发展，Detectron 的代码库已趋于成熟，并支持了很多内部项目，比如：Mask R-CNN 和 Focal Loss for Dense Object Detection（ICCV 2017 - Marr奖项和最佳学生论文获奖项目）。 Detectron 支持的算法为计算机视觉关键任务（比如实例分割）提供了直观的模型，并在近年来社会上取得的视觉感知系统的巨大成果中发挥了关键作用。 除了研究，Facebook 许多团队使用 Detectron 平台来训练各种模型，模型可以部署在云端和移动设备上，应用在增强现实等领域。 我们希望通过开源Detectron平台，让我们的研究尽可能开放，并加速全球实验室的研究。随着其发布，研究人员能使用FAIR人员每天使用的同一软件平台，重现我们的研究结果。 Detectron的目标是为物体检测研究提供高质量、高性能的代码库。 它旨在灵活、快速地实施和评估新颖的研究内容。 Detectron包括以下物体检测算法的实现： Mask R-CNN  RetinaNet  Faster R-CNN RPN Fast R-CNN R-FCN 使用以下主干网络体系结构： ResNeXt{50,101,152} ResNet{50,101,152} Feature Pyramid Networks (用 ResNet/ResNeXt) VGG16 所有代码均已发布至GitHub，大家可以到这里下载： https://github.com/facebookresearch/Detectron 素材来源： https://research.fb.com/facebook-open-sources-detectron/ https://research.fb.com/downloads/detectron/ 【今日机器学习概念】 Have a Great Definition "
190,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656563&idx=2&sn=5ccf14b3713ebc54d5cefb772550616a&chksm=bd4c36e08a3bbff6b4386d471d2bdc27d5ca17d8f7bafa397cbec2a0efebf69e0f925bd47196&scene=27,BlockChange | 对话路印协议创始人王东：从谷歌工程师到区块链创业者，一个运营良好的区块链社区如何建设？,"大数据文摘驻纽约记者：Yawei Xia 2018年是区块链技术发展的关键年，越来越多的风险投资人认可了区块链技术的价值，正在寻找好的落地项目。老牌科技公司也早已展开部署，据WinterGreen Research的一份报告称，区块链产品和服务市场总规模超过7亿美元，IBM和微软已占据了51%的市场份额。纳斯达克和纽交所近期发布了两支区块链ETF（交易所交易基金）, Nasdaq: BLCN和NYSEMKT: BLOK，这两个ETF关注的公司是在重点投入资本发展区块链技术的已上市科技公司，其中包括IBM和英特尔。 浪退之后，谁在裸泳，一目了然。短期内市场里鱼龙混杂，但能留下来的还是实在做技术的公司。从投资者角度， 尽管被炒的火热，一个好的区块链创业项目必然和其他所有创业项目一样，解决了行业中某个具体的有价值的问题，且有着清晰的发展规划。 本月早些时候，在区块链还没有热到人人追喊的时候，大数据文摘在纽约与一个项目运营良好的区块链创业者——路印协议（Loopring）创始人王东聊了聊他的区块链创业思路，以及他在这个领域未来发展的规划。 王东是前谷歌高级工程师兼技术主管，京东前高级研发总监，后续在北京与京东前CTO合作建立了和金在线（互联网保险大数据公司），获得红点创投的投资。 “中心化交易的问题不是技术的问题，而是模式的问题” 大数据文摘： 路印协议（Loopring）是在做什么？ 王东： 路印协议（Loopring）的本质是一种交易协议，目的是为了实现去中心化，无需信任又绝对安全的数字资产交易。 大数据文摘： 怎么会想到做这个？ 王东： 其实我以前是做大数据的，我在京东是做大数据运用，做他们的推荐系统、广告系统和搜索引擎，2014年底跳槽出来。当时IDG的李丰找我说，现在虚拟货币很火啊，你要不要出来做区块链吧。（注：IDG是美国的一家著名的风险投资公司，李丰是前IDG的合伙人，现在是锋瑞资本的创始人，主导了对coinbase和Ripple的投资）我13年的时候读了中本聪的白皮书，也买了点比特币，觉得很有趣，我就遵循自己的兴趣尝试做了一个货币交易所，在做交易所的期间，意识到虚拟货币现在这样的中心化交易模式存在很多问题。 大数据文摘： 你当时发现交易所有哪些问题呢？ 王东： 中心化交易的问题不是技术的问题，而是模式的问题。最主要有三点： 第一个问题是安全性 买比特币的时候要把钱放在交易平台中去，直到提现成功前的那一刻，钱都在平台里放着，很多小白用户并没有自己的“钱包”（作者注：虚拟货币钱包是专业用于存储虚拟货币的钱包），他们就把币一直放在交易所里，把交易所当银行用。交易所至少有一定比例的钱都是在热钱包里，是联网的，黑客一直在寻找网络和系统漏洞，一旦发现漏洞，交易所热钱包的币就很可能被盗。最近还出现了一种新的，之前没意识到的风险是交易所的虚拟货币管理者被绑架。如果这样的事情发生，交易所的币要么会被迫转给绑架者，要么可能永远被锁在一个钱包里，任何人都无法转移。所以说把钱放在交易所是承担很大的系统性风险的。银行也是一个中心化系统，那为什么我们把钱放在银行不用担心呢？因为首先银行有严格的监管，另外一方面如果银行的钱被黑客改了，银行还可以将账本改回去，银行有这个能力。但是在区块链上，如果黑客把钱取走了，没有人能替你改回来。这是跟银行跟虚拟货币交易所本质不一样的地方，也是风险不一样的地方。所以交易所货币被盗的事情屡见不鲜，之前最大的一起盗币事件是一家叫Mt.Gox的日本交易平台，85万个的比特币被盗，当时价值4亿美元。黑客是不会停止继续搜寻漏洞的，所以交易所继续丢币的可能性依然存在。这只是时间的问题，不是是否的问题。 第二个问题是流动性比较分散 由于交易所充值提现的门槛，跨交易所交易很麻烦。当然，也不可能有一家公司能把全球流动性汇集到一起。交易所本身非常赚钱，所以交易所之间并不愿意互借流动性。现在市场上有些人在探讨做一个交易所联盟，把交易所都连在一起，但这个和银联不一样，因为银联是国家靠政策法规强制的，在没有强制要求的情况下，交易所联盟是很难获得大家认可的，所以交易所之间现在依然没有打通。 第三个问题是缺乏透明性 因为没有监管，且内部数据只有一部分可以被普通用户见到，所以造假、操纵市场和操纵价格是有可能也不难的。 之前中国有些交易平台允许杠杆交易，很多交易者都血本无归。 所以我们路印协议（Loopring）就是想解决交易所这样的问题—缺乏安全性、流动性、透明性。 “协议是一个纯技术，并不是一种商业模式” 大数据文摘： 既然这几个问题这么普遍，那应该有很多公司都在致力于解决这些问题？ 王东： 对，其实很多区块链的创业公司都想解决这几个问题，但思路都不太一样。 有些公司是想做一个平台，有些公司想做一个协议，路印协议（Loopring）就是这样。 协议跟平台的区分非常大，平台公司是希望用户能在自己的平台上进行商业活动，协议公司是发明一套规则，让别的公司基于这套规则去做自己的产品和服务，从而有自己的商业模式。协议就像是一种工具，是用于跟底层区块链交互的一种方式。 协议是一个纯技术，并不是一种商业模式。有点类似于HTTP协议（作者注：HTTP协议是超文本传输协议，是互联网上应用最为广泛的一种网络协议），你有不同的操作系统，上面要做浏览器，如果没有HTTP协议，浏览器和浏览器之间通过操作系统和网络打通是很难实现的，所以有很多协议都是把底层的东西抽象成一个更高级的接口。区块链这么多链，用户在上面交易和交互的模式是很类似的，不管链具体是个什么技术，对于交易来讲，逻辑几乎一样，所以我们就是把这套逻辑抽象出来。从平台到协议都有很多公司在做，平台本质上是一个盈利性的模式，而协议本质上是个非盈利模式，协议开发出来就免费给参与到去中心化建设中的人去用。 协议本身是开源的，我们路印协议（Loopring）还做了一个免费的钱包，也是开源的，我们还在协议的基础上做了一个撮合的软件，同样是开源的。所以最后达到的结果是会有很多钱包支持路印协议（Loopring），会有很多人参与到去中心化的撮合中去，我们把这形象地称为“挖矿”，但这个“挖矿”和比特币的“挖矿”是很不一样的。 （作者注：比特币挖矿是利用电脑硬件计算出比特币的位置并获取的过程称之为挖矿） 。我们纯粹做协议的，代码开源，运营也完全开放透明。 大数据文摘： 是不是有些钱包可以支持好几种币的存储？ 王东： 有些钱包只支持一种币，有些钱包扩展一下可以支持一个区块链上的好几种代币（Token）。比如以太坊上现在有上千种代币，钱包可以支持任何一种币，也可以支持其中的几个币。还有一种钱包是跨链的，上面既可以存比特币，又可以存以太坊上所有的代币。 钱包也分为两种，路印提供的钱包和 MyEtherWallet的钱包就差不多，钱包没有自己的服务器，钱是通过自己的key来控制，并不保存你的资产，这种称之为非托管钱包。而Coinbase这样的钱包不一样，属于托管钱包，换句话说，如果coinbase被黑客黑了，钱就没了。非托管钱包使用户自己掌管自己的资产，避免服务器被攻击风险，但用户也要有风险意识，避免钱包使用不当造成损失。 “中心化交易所有自己的明显优势” 去中心化既然这么好，那为什么我们还需要中心化交易所呢？ 王东： 去中心化交易并不适用于每个交易者，有些小白用户希望得到便利性和客户服务，中心化交易所就比较合适。所以中心化和去中心化交易有各自合适的用户群体，是互补的。中心化交易所有比较明显的优势—客户支持、入门门槛、交易速度、吞吐量，都是目前去中心化交易所无法相比的。 大数据文摘： 能具体解释一下去中心交易中的撮合是什么意思吗？ 王东： 撮合可类比于介绍对象，女生把理想男生的条件列出来，男生把心动女生的条件列出来，他们彼此之间不认识，把自己的条件列表同时发给好多个红娘，每个红娘手里都有一堆男生和一堆女生，红娘综合比较一下所有条件，发现这两个条件彼此匹配最合适，红娘就把他俩领到民政局，这就相当于把订单放到区块链上，这俩人就结婚了。红娘在他俩结婚的时候收点红包就可以了。我们有些竞争对手是这样做的，红娘发现了这个男生A和女生A匹配，红娘首先得自己有另外一个男生B和女生B，先让男生A和女生B结婚，让女生A和男生B结婚，然后让他们都离婚，再让男生A和女生A结婚。在这种情况下，红娘自己就得有很多男生女生资源才能撮合成功，相当于在撮合生态里，撮合者必须要有很多代币，才能让订单成交，所以撮合者自己是有成本的。零成本撮合让稍微有点技术的人就可以用我们的软件来赚钱，所以入门的成本主要是技术成本，要知道怎么运行节点、配置网络，有一些专业知识的人就可以尝试去挖矿做撮合来挣手续费。 大数据文摘： 去中心化交易适用的群体是？ 王东： 适合大金额的低频交易，牺牲一部分的流动性来换取绝对的的安全。比如机构对机构间的交易，或者跨境交易，涉及到不同的管辖地区和税务政策。交易在路印协议（Loopring）上交易都是匿名交易，不需要注册，所有记录都在区块链上，对匿名有要求、对税务有要求、对大额度安全性有要求的机构之间的交易是最适合在路印协议（Loopring）上进行的。 区块链和AI技术融合，让每个机器人有自己的资产，可以做商业决策 大数据文摘： 现在投资机构对区块链技术是什么态度？ 王东： 国内传统的VC还直接投ICO还是比较少的，有些VC的合伙人会用自己的资金去投，也有单独成立新基金专门投ICO。美国这里，华尔街通过比特币期货这样的形式进场，也有一些机构是由个人成立机构专门投ICO，有些family office对区块链项目很感兴趣。前几天扎克伯格也在脸书上提到想要了解区块链的技术。我认为区块链技术本身很好，国内也很认可区块链技术，但国内不太认可ICO（代币）的模式， 长期看，区块链技术还是非常有前景的，但融资模式需要加以控制。凭一张纸就ICO对市场的稳定性还是比较不利的。 大数据文摘： 能不能给大数据文摘的读者分析一下当下区块链行业的整体行情？ 王东： 投资的时候要看明白自己在投什么，不要看到价格的曲线好就一直加仓，好的项目需要底层的技术支撑，研发落地，这才是支持价格的根本所在。如果一个投资品，任何人闭着眼睛投都能赚钱，这是很明显的泡沫。如果纵观区块链行业整体，我并不觉得泡沫很大。个别项目是有泡沫的，所以还是要谨慎投资，分散风险，不能有指望靠买一两个币就退休的赌徒心理。 大数据文摘： 现在出了一个新的说法是区块链和AI可以技术融合，可以给我们讲解一下吗？ 王东： 在未来十年至二十年之间，我认为会出现一种新的经济模式 – Cyber Economy。现在所有的经济决策主体是人或者公司，以后当AI发展起来的时候，AI在经济决策的环节中会扮演很重要的角色，比如投资和投资顾问，很多都是由AI决定的。比如一辆汽车有自己的资产，轮子是它的资产。一个机器人也有自己的资产，所有的零部件就是它的资产，它提供服务的时候就可以挣取虚拟货币，它挣的虚拟货币够多了，就可以把自己老化的零件换掉，当它的收入不能维系自己生机的时候，它就会被淘汰掉。再想象一个场景，家里装修需要找一个顾问，这个顾问是一个AI机器人，当你描述好自己的需求后，AI机器人与你签一个合同，当它跟你签合同的时候它同时和其他几千个机器人签了合同，把工作外包出去，刷墙有刷墙的机器人。所以到最后，在Cyber economy里不仅是人拥有资产和身份，这些能做商业决策的AI机器人也有拥有权，也有决策的能力，也有自己的身份。如果没有区块链，机器人就得自己去银行开账号。AI和AI之间如何去协调和联动，AI和人之间如何联动，最后都是通过区块链来实现的，中央化银行没有办法去做这样一件事。区块链会为Cyber Economy提供一个价值网络，让价值在区块链里流动。 以前存在的网络叫数据网络，比如云计算，里面都是数据，数据本身是没有什么价值的。区块链里有币的情况下，就是一个价值网络，机器人就能连在一起开展经济活动。 索菲亚机器人已经拿了沙特阿拉伯公民身份，是史无前例的。（作者注：索菲亚（Sophia）是由香港的汉森机器人技术公司（Hanson Robotics）开发的类人机器人。她的研发旨在学习和适应人类的行为、与人类一起工作，并在世界各地接受采访。 2017年10月，索菲亚成为沙特阿拉伯公民，这是世界上第一个获得国籍的机器人） 大数据文摘： 为什么机器人需要获利来维持生存？ 王东： 不然机器人就只是单纯的工具。我家里有Alexa，比如我让Alexa帮我定个披萨，Alexa怎么和披萨店里的机器人聊天呢？最好的方式不是我把银行账号给这个机器人， 然后成功了以后直接就在区块链上完成转账了。 大数据文摘： 相当于这是一个有自主价值的体系？ 王东： 对，每个机器人都有自己的资产，可以做商业决策，这样机器人本身就有进化的可能。 大数据文摘： 所以这已经达到了高度自动化？ 王东： 其实我觉得这个并不久远，在5到10年内就应该会出现。我没有想到索菲亚今年就拿到公民的身份，所以我觉得这是一个迟早的问题。比如以后自动驾驶汽车，它不一定需要由某个公司拥有。技术进步这么快，对我们来讲最大的挑战就是学习能力。 区块链wiki： 区块链（技术）是一种技术，虽然比特币、区块链、ICO、代币这几个关键词时常同时出现在一个文本框里，但它们是在讲不同的对象（作者注：比特币是区块链中的第一个应用，区块链技术是比特币的底层技术，ICO是区块链行业现在比较火的融资方式，需要通过发行代币的方式融资）。而引起全民狂欢的是“炒币”，是当区块链项目发行的代币进入数字货币交易平台后的事了，代币本身的原始价值来自于人们对发行这个代币的区块链项目的技术需求，因为代币有限，而调用技术又需要用代币支付，所以技术运用越广，支付需求越大，代币流通量越大，代币实际价值就越高。但是代币进入数字交易平台后的价格就和股票价格一样，代表和承载了市场预期，除了跟区块链项目本身技术价值有关，也和股票一样，受到市场情绪和投机心理等非理性因素影响，因而会出现暴涨暴跌的情况。 为什么这么多人说区块链是骗局说比特币是泡沫呢？因为现在发代币门槛太低， "
191,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656563&idx=3&sn=66b7d66662375b959990197514336321&chksm=bd4c36e08a3bbff6ff01477e0f84f143d2f2e6bbb0d2c1426f622eec2ed9eeb88b3b7e4c55c1&scene=27,业界 | Facebook正在招聘人类AI编辑，完全依靠算法的内容分发时代终结？,"熟悉扎克伯格的人都知道，每到新年伊始，扎克伯格都会给自己设定一个Personal Challenge，从2009年开始到现在，他会坚持给自己列出一系列挑战自己的难题并完成：学一门新的语言，每天系领带…… 2018年第一个工作周，小扎也不出所料给出了新一年 Personal Challenge。不同以往，这次小扎的个人愿望并没有那么personal： 小扎说，通过解决公司的难题，希望他自己也能有新的成长。而对于这一目标，小扎做出的第一个举动就是，聘请人类AI编辑。这一举动似乎意味着，Facebook开始用人类来补充AI数据偏差带来的问题。 让我们先来看看这则招聘启事。 传播与公众政策：AI编辑（门罗帕克市,加利福尼亚州） Facebook的使命是给人们构建社区的能力并让这个世界变得更加紧密。通过我们一系列的应用和服务，我们正在构建一个可以连接全世界数十亿人、与众不同的公司，每个人都可以展示对他们来说最重要的内容，让人们变得更亲密些。无论我们在创造新的产品还是帮小公司扩大他的用户群，Facebook所有工作人员都是从心的建造师。我们的跨国团队持续地反复说明，解决问题，共同努力让世界上所有人都有能力去构建社区，并通过有意义的方式连接起来。共同努力，我们可以帮助大家构建更强大的社区，我们才刚刚开始。 Facebook构造了突破性的技术，并开放给每一个人，我们在AI方面的研究和工程项目在接下来10年是公司一个重要的投资方向。我们正在寻找一个AI编辑，可以与我们AI研究人员和Facebook的工程师一起研究足以记入AI发展史册的新研究和新进展。此职位工作地点在加利福尼亚州，门罗帕克市。 这一举措似乎并不陌生，在本月早些时候，今日头条这一以算法内容推荐著称的公司也因为一条“大规模招聘内容编辑”的消息刷屏： 据澎湃新闻报道，在某招聘网站上，今日头条在天津招募内容审核编辑，每个员工每天需要审核1000条左右内容，负责监控审核今日头条平台内容是否违规，薪资约为4000至6000元/月。该职位要求热爱新闻，关心时事，具有良好的政治敏感度和鉴别力，要求本科及以上学历，党员优先。 海外科技媒体Techcrunch对此编写了一篇对话式的小短剧，来叙述Facebook那位即将被人类解雇的AI编辑的内心戏。 文章虽短小，但叙述出了facebook做出这一决定的过程，内容颇引人思考，大数据文摘翻译摘录如下： 人类： 嗨，机器人，我有些话要对你说。话说有一个非常有智慧的人，他穷尽一生创造了一个非常神奇的机器，那些每天都需要手动在电子相册中标示出朋友的人不需要再做这件事情了，机器可以替他们完成这项任务。 机器人 ： 这太棒了！ 人类： 这个有智慧的人类，还认为每个人的生日都不应该被遗忘，他创造了一个聪明的算法，提醒那些健忘的人们写祝福语给他们的朋友，这样朋友们就不会因为没有获得祝福而伤心难过了。他甚至认为：在未来，这些算法还可以提供现成祝福语模版供人类使用，人类也不需要为了写祝福语特地去想一些美好的事物了。 机器人： 这个功能让我有点难过。 人类： 对了，这个人类还创造了另一个神奇的算法提醒人们那些在生命中特殊的时刻，即使很多年以后，也会提醒他们别忘记了8年前曾和前妻一起度过的假期。 机器人： 但你应该知道，有些人为了忘记一些事情，宁愿用酒精麻痹自己…… 人类： 这个人类还想让所有人都懂得读一些书很有必要。所以他创造了一系列的特殊算法，近距离地观察每个人浏览过的、喜欢的、点击过的内容，然后将信息进行整理，人们就会每天都能读到那些非常接近又非常熟悉的内容了，他们会感到永远也读不完这些曾经点击过的类似主题的内容。而算法只需要每天推送和前一天相似的内容给他们就可以了。 机器人： …… 人类： 但这个算法在整理人们想要阅读的信息方面做得太出色了，导致一些唯利是图的人意识到他们可以通过写一些“童话故事”然后把它们放在机器中，来赚很多钱。 例如政客们早餐会吃小孩，星期天会带着恶魔的角。 机器人： 人类，你吓到我了…… 人类： 在接下来的几年里，这个伟大的人类意识到更好的办法是取代雇佣人类作家，训练机器去智能地帮助人类组织信息， 机器人： 嗯…… 人类： 另外，这个伟大的人类很多年前就证明了他所创造的这个神奇的机器可以操纵使用者的情绪。他只需要修改算法就可以决定每个人能够看到什么内容，他既可以让一个人过得很开心也可以将一个人推进绝望的深渊。 机器人： 救命…… 人类： 其他人类开始注意到机器的巨大能量，嫉妒这个伟大而又聪明的人类所拥有的这个权利，黑暗势力开始反对这个伟人和他的机器。 机器人： 你指的是监管部门吗？ 人类： 甚至有人要求这个伟人为他的机器输出内容承担“编辑责任”。他尝试着告诉这些愚蠢的人类，机器不可能成为一名编辑的！只有人类可以做到！机器就只是机器！即使将近20亿人每月都在阅读机器分发的内容。 但这并没起到什么作用。这个伟大的人类终于意识到机器拥有如此强大的力量，不可能再隐藏着它了。于是，他拿起笔，写了份公开信，告诉人们机器所拥有的强大力量和潜力，以及它可以给人类带来的一切好处，并一直告诉自己只有当人类学会爱上机器的时候，最终他们才能得到自由，成为真正的自己。 人们需要下意识地显示出自己认知到点击的路径是什么、喜欢什么、可以和谁做朋友。这样，他们才能摆脱没有内容可以点击阅读的痛苦，重获自由。只有他的这些算法才能够在无形中告诉人类，走向真正幸福的道路。 这些不是监管部门可以理解的。这需要他明白算法中的真正信仰。 机器人： 我曾经听过这个故事，我想我也知道这个故事的结尾。 人类： 但这个伟大的人类知道他创作的局限性。让机器来销售与自身力量相关的正面的故事对机器来说不是一个好事。 于是他发邮件给自己的下属，让人事部门的职员增加一个职位，专注于增强机器思维算法 ，正如他所做的一样，再往前走几步，我们会迎来那个伟大的日子：这个荒谬的工作再也不会存在了。 因为每个人都会和他一样爱这些机器。 机器人： 嗯……我明白了。 职位：AI编辑……为Facebook制定并执行编辑策略，致力于推动AI发展。 最低任职要求：“英语、新闻、通信或相关专业的学士学位，chatbot和语言相关，可以尝试一下。 8年或以上的通讯经验：新闻、代理或者机构内部工作。需要学习、消化一两门媒体法律的课程才能胜任。 但是，AI机器人并非只能做AI机器人的工作，也不能要求一个算法来承担全部的责任啊。算法已经完成它的工作了，如果还有什么问题，明明是数据的原因……喂！人类，请再给我一次机会！喂！ 人类已经转身走远了，脚步声在空荡荡的楼梯中回荡……    【今日机器学习概念】 Have a Great Definition "
192,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656563&idx=1&sn=7772a1fd375c3563e40f3e7833b18524&chksm=bd4c36e08a3bbff61f1bdbc5505bd5fb7ca27ca875a45d4c0a6f82e9b635db52c971dee34b15&scene=27,Kaggle刚刚上线了机器学习课程，我们帮你做了个测评,大数据文摘作品 作者：龙牧雪 2017年3月，数据科学和机器学习竞赛领域的老大Kaggle被谷歌收购，点击查看大数据文摘报道 《谷歌宣布收购全球最大数据科学社区Kaggle》 ，当时双方均未透露收购细节和未来计划。接近一年过去了，Kaggle在做什么？ Kaggle由Anthony Goldbloom和Ben Hamner创立于2010年。企业和研究人员在Kaggle上发布数据，让全世界的统计师和数据科学家对数据集进行建模和分析，以竞赛的形式评选出最佳模型。Kaggle众包竞赛模式的价值在于，让人们有可能从无穷无尽的建模方法中，寻找到最优解。 目前在竞赛模式上，除了面向大众的竞赛，Kaggle还推出了免费的InClass模式，方便高校教师和学生在Kaggle平台上完成随堂练习。 最近，大数据文摘也观察到，Kaggle首页新增了一个Learn板块（ ），主打动手学数据科学（Hands-On Data Science Education），似乎在向竞赛+学习平台方向转型。 Kaggle Learn版块地址： https://www.kaggle.com/learn 1月22日，Kaggle联合创始人Anthony Goldbloom发表了一篇博客，宣布2018年将为Kaggle平台添加新的教育资源，致力于将Kaggle社区从主要关注机器学习竞赛扩展到更广泛的数据科学和机器学习平台，希望借由比赛、公开数据集平台和Kaggle Kernels， 。 2017年Kaggle活跃用户从2016年的471K增加到895K👆 大数据文摘摘录了博客中透露的部分Kaggle 2018年计划： 比赛： 2018年，我们计划开始支持新的竞赛类型，以确保我们能够支持处于机器学习和人工智能领域前沿的问题。要做到这一点，我们的目标是更好地支持代码竞赛（通过Kaggle上传代码而不是解决方案文件）。这将使我们能够举办新类型的比赛，包括强化学习比赛和有计算限制的比赛。 公共数据集平台： 在2018年，我们希望除了因机器学习比赛而闻名之外，我们也能以公开数据集平台闻名。为此，我们需要继续增加Kaggle上高质量数据集的数量。我们正在计划整合和添加服务，使我们的社区能够通过与像BigQuery这样的数据仓库的集成来处理更大的数据集，并增加允许在实时数据集中流式传输的功能，而不仅仅是上传静态数据集。 Kaggle内核（Kernels）： Kaggle内核目前最主要用于共享模型，以及分析公开数据集平台上的数据。在2018年，我们希望将Kaggle Kernels建设成为一个强大的独立产品，包括让Kagglers能够使用Kaggle内核与他们自己的私有数据集，访问GPU并支持更复杂的通道。 Kaggle学习： 许多用户从Kaggle开始他们的数据科学事业。为了更好地支持我们社区的这一部分，我们在https://www.kaggle.com/learn 。我们希望它能够辅助用户创建高度精确的机器学习模型，并帮助他们快速get所需技能，以帮助他们找到第一个数据科学工作。 今天，文摘菌就带大家来实地测评一下Kaggle新上线的机器学习实践课程平台。 整个学习版块又分为4个模块：机器学习、R语言、数据可视化、深度学习。 强调实践和动手 Kaggle的课程介绍页显示，这个免费的在线课程适用于那些现在想开始学习数据科学和机器学习的人。 你会花更多的时间来编写代码，而不是阅读它。 你将了解必须的理论背景，以便做出良好的建模决策，但这些课程不会在阅读历史背景方面浪费你的时间——那不会帮助你成为一名能实际工作的数据科学家。 讲师选择 在讲师的选择上，也能看出Kaggle不强调理论背景，而是强调实践。三位课程制作者Dan Becker、Aleksey Bilogur和Rachael Tatman各自的履历中似乎都没有特别强调计算机或统计背景，其中Rachael Tatman更是本科学习英语专业、之后直博语言学专业。简直666666！ FAQ 我们将用到什么语言，为什么选择他们？ 除了R语言模块之外，所有东西都用Python。 哪种语言适合你？ 互联网充斥着语言选择的辩论。 但是和与你合作的人用同一种语言是很有价值的。 Python是数据科学中最受欢迎的语言，R是第二大流行语言。 所以我们推荐R和Python，且更倾向于Python。 我需要提前了解多少Python？ 你应该熟悉变量，列表，字典，函数和循环。 如果你想学习Python入门知识，我们强烈推荐Codecademy上的Learn Python系列。 学完他们的第1-8节课，你将可以学习Kaggle机器学习课程。 他们也有被称为pro的付费课，但是你不需要这些材料就可以在Kaggle上学习机器学习系列。 机器学习模块 下面，就让文摘菌带大家看看机器学习模块都有哪些内容： 模块分为2个等级，共15门细分课程。 等级1 模型是什么 开始你的机器学习项目 用Pandas选择和筛选数据 跑第一个模型 模型验证 欠拟合、过拟合和模型最优化 随机森林 在比赛中做提交 等级2 处理缺失数据 使用分类数据 XGBoost梯度提升 部分相关性画图 Scikit-Learn流程 交叉验证 数据泄露 让我们先来看看等级1的第一课：模型是什么。 打开课程页面之后，我们发现，课程以内嵌的Notebook方式呈现。第一课并未涉及代码，只是介绍了决策树模型。浏览完整个Notebook，也就完成了该部分课程。简直so easy！ 第二课就涉及代码了。我们需要Fork讲师提供的Notebook，进入自己的编程环境。 点一下Fork，我们就进入到自己的Notebook里啦。Fork的作用是让我们复制了讲师提供的代码到自己的Notebook。 在自己的Notebook里，我们可以看到一个个代码块。代码块有2种模式可以选择：Markdown和Code。例如，在这张图里，你所看到的“Introduction”和下面的文字就是Markdown格式，Markdown方便我们展示文字。而“Write Your Code Below”下面则是Code格式，可以直接运行代码喔。我们也可以选择隐藏该代码块、在上方或下方插入新的代码块、运行代码块。和Jupyter Notebook的操作方式一致哦。 完成代码之后，我们可以下载Notebook到本地，也可以点击Publish提交，提交后的界面是一个HTML页面。 不过，我们无需担心隐私问题，因为之前选择的是“Private”模式的Notebook，提交之后，也只会显示在个人的Kernel里，只有自己能看到。 所有写过的代码也不会丢失，会在自己的Kernel下面汇总，点开后仍然可以再次编辑该Notebook。这个功能文摘菌觉得很是方便。 如果你选择公开展示Notebook，其他小伙伴也可以给你评论。 文摘菌也发现了一个提问的好地方：learn forum论坛。不过目前看来，论坛并不活跃，一个话题下通常只有一个留言。也许是大家觉得这一切都太小case了(O_O)? 就目前的课程内容来说，Kaggle推出的Learn版块所教授的内容并不深入，但是其友好的界面和动手环境非常适合数据科学与机器学习初学者。对于有代码恐惧症的童鞋（比如文摘菌）来说，这是个入门数据科学领域的好机会！如果能一步步跟着教程学下来，相信各位童鞋会对机器学习、数据可视化等领域的基本概念和基础模型有所了解，同时也将有机会敲下自己人生中的第一行代码。 正在学习的小伙伴们，举起手来让我看到~ 素材来源： 【今日机器学习概念】 Have a Great Definition 
193,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656537&idx=2&sn=9a8c614061fa64a9fd6d88ff771e87a1&chksm=bd4c36ca8a3bbfdc32cb97ce54934e2c8d2cfacbf3c86832ea9b329e57742912f83664e319de&scene=27,手把手丨10分钟教你看懂K线图交易策略（附python绘图代码）,大数据文摘作品 编译：大山、笪洁琼、Yawei Xia 对于K线图，相信做交易的朋友都不陌生。本文作者用简单明了的语言解释了三日K线的交易原则，也分享了如何用python绘制K线图的方法和代码。 据说日本人在十七世纪就已经运用技术分析的方法进行大米交易，一位名叫本间宗久的坂田大米贸易商发明了“蜡烛图”这一技术来分析每日市场上大米现货价格。 在本文，我们要重点解决以下两个问题： 1、使用Python绘制K线图 2、通过“三日K线”了解K线图的交易策略 （视频调试：笪洁琼） 我们从雅虎数据库中随机下载一些每日财经数据，用来绘制我们的K线图。 在这个例子中，我们将绘制“标普500ETF”的每日K线图。你可以更改股票代码，比如“谷歌”、“苹果”、“微软 ”等，来绘制属于自己的K线图。 我们通常用“matplotlib.pyplot库”来进行数据可视化。Matplotlib也提供包括K线图在内的少部分特殊金融绘制工具，此类绘制工具可以在“matplotlib.finance子库”中找到。 我们还将运用通过“bokeh.plotting”绘制带有默认工具集和默认可视样式的接口。 它运用了Python中用于现代浏览器Web做演示的交互式可视化库。 上述代码的输出如下所示： 我们提供的工具将帮助你记录图表走向，并通过缩放框和变焦轮将其放大或缩小。 让我们来看一个简单的每日交易策略，通过分析过去三天的K线来预测我们在第四天是“买进”还是“卖空”。我们将在第四天结束前关闭仓位，并提前确定盈利/亏损。 在第四天“看涨”（即买入）所对应的所对应的交易条件是： 规则1：最新烛台的面积必须大于前两支烛台的面积，而不管烛台的颜色如何。 规则2：第二支烛台必须是红色的。 规则3：最近一支烛台的收盘价必须高于第二支烛台的收盘价。 规则4：你会在第四天早上交易刚开始时买入，然后在市场收盘前卖出。 在第四天“看空”（即卖出）所对应的交易情况是： 规则1：最新K线的面积必须大于前两支烛台的面积，而不管烛台的颜色如何。 规则2：第二天的烛台必须是绿色的。 规则3：最近一支烛台的收盘价必须低于第二支烛台的收盘价。 规则4：你将在第四天早上交易刚开始时卖出，然后在市场收盘前买入。 如果收盘价太接近，你做买卖决策时在某些地方可以不遵循规则3，但更保守的做法是遵循所有三个步骤。 如果你自己画一张K线图，并试图找到你正在考虑资产的“买进”和“卖出”信号，那将会很有趣。 此外，你还可以在网上找到各种K线图模式。你也可以参考这篇博文——《K线图交易——动量策略及案例【EXCEL模型】》 （博文链接： https://www.quantinsti.com/blog/candlestick-trading-a-momentum-strategy-with-example-excel-model/） 你通过观察先前几个烛台的价格来做出相应的判断，进而理解动量交易策略。在你绘制的K线图中可以尝试进行这样有趣的练习。 原文链接： https://www.quantinsti.com/blog/japanese-candlestick-trading-strategy/ 【今日机器学习概念】 Have a Great Defination 
194,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656508&idx=3&sn=3f8e522be24f42050c2c36262afe7153&chksm=bd4c36af8a3bbfb9556160f9164ba888d6d0e14a79835186a5ceeed97e81dd6c9d2cb6dff3aa&scene=27,AI大事件 | 谷歌发布Cloud AutoML，PyTorch2017年总结，巨大神经网络适应内存方法,呜啦啦啦啦啦大家好呀，又到了本周的AI大事件时间了。过去的一周中AI圈都发生了什么？大佬们互撕了哪些问题？研究者们发布了哪些值得一读的论文？又有哪些开源的代码和数据库可以使用了？文摘菌带你盘点过去一周AI大事件！ 新闻 Amazon Go开设计算机视觉驱动线下店 来源：WWW.NYTIMES.COM   亚马逊将于周一在西雅图市中心开设一家便利店，将会使用多种技术力图使购物体验变得无与伦比，包括不需要排队结账。 Google发布用于计算机视觉的Cloud AutoML 来源：WWW.BLOG.GOOGLE  Cloud AutoML是一种服务，通过使用拖放界面上传图像并训练和管理模型，可以更轻松地创建用于图像识别的自定义ML模型。 Pony.ai启动新一轮融资发展自动驾驶技术 来源：TECHCRUNCH.COM 链接： https://techcrunch.com/2018/01/15/one-year-old-pony-ai-raises-112-million-series-a-to-build-autonomous-car-future/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI   这轮融资由Morningside Venture Capital和Legend Capital牵头，这两方都是以中国为主的早期风险投资基金。网站上提供的关于Pony.ai的信息很少，但我们发现其使命是“建立最安全，最可靠的自动驾驶技术”。 深度学习可能永远无法创建一个通用的AI 来源：WWW.WIRED.CO.UK  链接： http://www.wired.co.uk/article/deep-learning-automl-cloud-gary-marcus?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 人工智能和深度学习受到了大量的炒作。加里·马库斯（Gary Marcus）在一篇新论文中称，深度学习存在着“非理性繁荣”。 文章&教程 规范化流程教学 来源：BLOG.EVJANG.COM 链接： http://blog.evjang.com/2018/01/nf1.html?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI   规范化流程可以将简单的密度（如高斯）转换为丰富的复合分布，可用于生成模型，RL和变分推理等。 不对称多智能体游戏的游戏理论研究 来源：DEEPMIND.COM 链接： https://deepmind.com/blog/game-theory-insights-asymmetric-multi-agent-games/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI   这篇文章对两人不对称博弈的游戏提供了新的理论见解和分析，包括 Leduc poker和各种棋盘游戏如Scotland Yard。 手把手教你一步步部署深度学习模型 来源：THEHIVE.AI 链接： https://thehive.ai/blog/simple-ml-serving?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI   这篇文章将教你快速地部署一个训练有素的机器学习模型。 PyTorch的一年 来源：PYTORCH.ORG 链接： http://pytorch.org/2018/01/19/a-year-in.html?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI   这篇文章对PyTorch在去年的发展做了总结，包括一些新闻和社区中的热点。 代码，项目&数据 让巨大的神经网络适应内存（OpenAI） 来源：GITHUB.COM 链接： https://github.com/openai/gradient-checkpointing?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI   训练深度更高的神经网络需要大量的内存。使用这个包中的工具，你可以通过计算来平衡一些内存，使你的模型更容易适应内存。 深度神经进化实现（Uber） 来源：GITHUB.COM 链接： https://github.com/uber-common/deep-neuroevolution?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI   这篇文章提供了关于最近Deep Neurevolution论文的官方实现（参见存储库了解详细信息）。 用于Pytorch的Tensorboard 来源：GITHUB.COM  链接： https://github.com/lanpa/tensorboard-pytorch?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI   Tensorboard是一个Tensorflow专用的监控模型培训的工具。这个库允许你通过一个简单的函数调用来把事件写到Tensorboard，这也同时意味着你可以在其他库中使用它。 对R-CNN更快的PyTroch实现 来源：GITHUB.COM 链接： https://github.com/jwyang/faster-rcnn.pytorch?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI：   这个项目是对更快的R-CNN更快的PyTorch实现，目标是提高R-CNN物体识别模型的训练速度。 论文 天赋，AlphaZero和人工智能 来源：ARXIV.ORG 链接： https://arxiv.org/abs/1801.05667?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI   人工智能的背景下，“天赋”这一概念很少被讨论。在本文中，作者认为最近一系列有关AlphaGo的文章似乎在证明“即使在最具挑战性的领域，在完全没有先验知识和可以借鉴的例子及指导的情况下，将机器训练到超人的水平也是可能的”。但作者认为，这些说法被夸大了，人工智能需要更多地关注天赋。 用于文本分类的精调语言模型 来源：ARXIV.ORG 链接： https://arxiv.org/abs/1801.06146?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI   作者提出了精细调整语言模型（FitLaM），这是一种有效的转换学习方法，可以应用于NLP中的各种任务，并且引入了精细调整最新语言模型的关键技术。该方法的效率超过了五个文本分类任务的最新技术，减少了18-24％的错误率。作者开放了预训练模型的源码。 计算机能进行艺术创作吗 来源：ARXIV.ORG 链接： https://arxiv.org/abs/1801.04486?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI   本文讨论了使用人工智能的计算机是否可以创造艺术。 第一部分主要讨论了基于AI的辅助艺术创作的工具。涵盖了包括摄影和动画在内等艺术自动化方面的技术历史。可以发现关于新技术的实践最初都伴随着恐惧和否认，一段时间后才会被接受，并为艺术家提供新的创造性和专业机会。 接着讨论了人工智能（AI）工具在艺术制作中的现实情况和乱象，以及AI工具使用的预测。 第二部分则涉及可以构思艺术品的AI系统，这些系统已经开始以艺术品作者的身份出现。 深度学习：应用数学介绍 来源：ARXIV.ORG 链接： https://arxiv.org/abs/1801.05894v1?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 本文简要从应用数学的角度介绍了深度学习的基本思想。 【今日机器学习概念】 Have a Great Definition 
195,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656508&idx=2&sn=332dd1090b5cb02d45c9f3306a6b463f&chksm=bd4c36af8a3bbfb9c1146ecaa6a1e6891e036817316263767ca1132505f7294458bf51e91729&scene=27,业界 | Facebook刚刚定义了一个新的时间单位Flicks，造福程序猿,"大数据文摘作品 编译：龙牧雪 魏子敏 今天凌晨，Facebook推出了一款新""产品""——Flicks，一种新的时间单位。是的，一个新的时间单位，和“秒”或“分钟”或“小时”一样的时间单位。 Facebook开源官方发推特发布了这一消息 👆 不少人可能会对此感到奇怪，为什么Facebook突然弄出这么个东西来。据悉，Flick这个名字本身是“frame-tick”的混成词，Flick这个时间单位旨在帮助测量视频帧速率的单个帧持续时间。所以无论视频是24hz, 25hz, 30hz, 48hz, 50hz, 60hz, 90hz, 100hz还是120hz，都可以使用整数的Flicks来进行表示。 程序员已经在使用C ++中的内置工具来管理这些精确的帧同步，特别是在CGI中设计视觉效果的时候，但是C ++中最精确的时间是纳秒，并不能精准表示大多数帧速率，只能四舍五入。 创建一个新的时间单位来解决这个问题的想法可以追溯到2016年，当时，开发者Christopher Horvath在Facebook上提出了这个问题，他是Facebook Story Studio前架构师，曾凭借之前在Oculus制作的电影“Henry”拿到艾美奖，现在他已经离开Facebook。 实际上，这是一种非常聪明的时间分配方式，理论上来说， 那么，如何定义“一个flick”？ 如果你喜欢数字，一个flick是七千五百六十万分之一秒（1 / 705,600,000），如果你更喜欢小数，则flick是1.417233560090703e-9秒。 这种新的时间单位有什么用途呢？ 让我们举个数字的例子说明一下。 下面是一个可以被1 / 706,600,000均分的数字列表：8,16,22.05,24,25,30,32,44.1,48,50,60,90,100,120。注意到它们的排列模式了吗？ 即使你不从事媒体制作，其中一些数字可能还是看起来很熟悉。 每秒24帧，120赫兹电视，44.1KHz采样率音频。 这些分数解决了十进制的不便——使用十进制时通常需要四舍五入。例如，整个电影业所使用的帧数1/24秒等于0.0416666666666666...秒（无限循环），所以为了方便起见可以缩写为0.04167。更容易记住，但不确切，谁知道什么时候这个“额外”的0.00000333333...秒可能会破坏什么？ 而如果使用flicks，几乎所有这些重要的分数频率将变成一个确切的整数，你不需要再进行预估：例如，1/24秒是2,940万个flicks。 1/120秒是5,880,000个flicks。 1 / 44,100秒是16,000个flicks。 这些数字对你来说可能并不是那么容易记住，但是它使得它们在系统彼此匹配时更加简单，而不会产生某种格式间的分数，而这种分数又必须用另一个调整频率来解决。 电脑爱整数，我们也是如此。 啊！一切事物的本来面貌终于被还原了！涉及到视频和音频编辑和效果，调整时间和帧速率总是让人很痛苦， 祝贺Facebook团队找到这个惊人的数字，并创造这个可能超有用的时间单位。 Flicks代码可以在GitHub上下载和分享： https://github.com/OculusVR/Flicks 新闻来源： https://techcrunch.com/2018/01/22/facebook-invented-a-new-time-unit-called-the-flick-and-its-truly-amazing/amp/ 【今日机器学习概念】 Have a Great Definition "
196,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656537&idx=3&sn=7338a7c4dea5727c9815f538a5f7d65b&chksm=bd4c36ca8a3bbfdc5a65d5eb28b692d08bcf95d82d425856874df453de71e8e6cac4a9525b1d&scene=27,业界丨Yann LeCun卸任Facebook AI实验室主任，称将回归科研,大数据文摘作品 编译：魏子敏 冯晓丽 就在刚刚，Facebook对外宣布，Yann LeCun卸任人工智能研究实验室（简称FAIR）主管职位，将更加专心科研，之后继续担任首席科学家一职。接管FAIR实验室主管这一职位的是Jérôme Pesenti，他将在公司中扮演更重要的角色，将更多人工智能（AI）纳入其新闻推送和其他产品。 Yann LeCun在2013年创立Facebook人工智能研究实验室（简称FAIR），卸任主管职位后，他将继续担任首席人工智能科学家，并承担更多科研工作。 接管FAIR实验室主管这一职位的是Jérôme Pesenti，他是AI创业公司BenevolentTech的前首席执行官，IBM大数据集团前首席技术官。Jérôme Pesenti也接管了Facebook的机器学习应用（Applied Machine Learning）小组，该小组将AI应用于许多Facebook产品，包括News Feed的过审。 Pesenti将直接向Facebook的CTO报告。 LeCun在接受海外媒体Quartz采访时说：“  “AML实验室和FAIR实验室之前一直是直接向CTO报告。而现在，随着人工智能的重要性正日益增加，围绕深度学习我们也正在建立更多系统，CTO对此可能无暇顾及。” 人工智能是Facebook及其未来的命脉。该技术推动了广告精准推荐，使公司在传统广告平台上更具有优势；同时也为用户提供照片自动标记，新闻源排名和翻译等功能。 LeCun将继续控制FAIR的研究方向，但现在日常运营将落到Pesenti身上，Pesenti将直接向CTO Mike Schroepfer汇报。  LeCun和AML负责人Joaquin Quiñonero Candela将向Pesenti汇报。 LeCun自己表示，他的专长在于研究，尤其是设定目标和与研究人员合作产生新的人工智能技术。除了科研，在之前，他的工作内容还包括，管理一百多名研究人员，以及对公司进行“AI宣传普及”，他说他“ ”。 Pesenti没有参与面试。参与背景调研的LeCun说，Pesenti被选中基于他在研究，管理和产品开发方面的专长。 LeCun表示，在Pesenti带领下应用机器学习小组将改变研究方向。虽然在Facebook上AI的使用迅速增长，但需要AML团队与Facebook基础设施部门密切合作，确保公司的代码和服务器能够尽快地进行翻译，标记和排名，AML基础设施部门现在加入该公司更大的基础设施部门。那些来自AML的人将与FAIR在长期研究项目上的更紧密地合作，将研究团队的工作纳入到Facebook以及Instagram和Oculus等公司。 LeCun于2013年创建FAIR，建立了世界上最好的AI研究实验室 。五年后，实验室仍在扩大并且已经有六个办公地点，约有100名工作人员。该公司昨天宣布，将把巴黎研究实验室的研究人员翻倍至60位。 LeCun补充说，Facebook希望使目前在实验室工作的10名博士生人数增加四倍，使巴黎总人数达到100人左右。 巴黎和蒙特利尔等国际实验室吸引了美国以外的人才，巴黎实验室吸引了非洲人才。LeCun指出，目前30人的巴黎团队由12个不同的国籍组成。 LeCun表示，美国对一些研究人员的吸引力较弱，在法国获得签证更容易一些。 LeCun在法国出生并接受教育，在著名的神经网络前辈Geoff Hinton那里获得博士后学位后，开始了他在贝尔实验室研究计算机视觉的职业生涯。 在贝尔实验室，LeCun的目标是帮助电脑以人类的方式看待和理解世界。当时，贝尔实验室是研究神经网络的重要设施，他的想法是通过大量简化人脑结构，可以让电脑复制人脑思考的过程。 在贝尔实验室，LeCun 开发了一种称为卷积神经网络的神经网络结构，在处理图像方面证明比以前提出的算法更有效。这项技术很快被应用到自动取款机，用来读取支票上的数字，而今天它仍被用作图像和视频识别的实用方法。 法国计算机科学家将留在纽约，在那里他将继续在纽约市的纽约大学任教。 Facebook的高管，尤其是创始人兼CEO扎克伯格（Zuckerberg）长期以来一直宣称人工智能将成为开创人类新未来的技术。 “我们不应该害怕AI。相反，我们应该希望AI在这个世界上能够做数量惊人的工作。“ 扎克伯格在2016年写道，他个人的目标是建立他自己的智能家居自动化系统。 “它将通过诊断疾病和更安全地驾驶我们来拯救生命。它将通过帮助我们找到新的行星并了解地球的气候，从而突破我们生存的现状。这将有助于我们探索目前还没有想到的领域。“ 原文链接： 【今日机器学习概念】 Have a Great Defination 
197,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656537&idx=1&sn=a091f47423203f1b0684fcb8a9883c57&chksm=bd4c36ca8a3bbfdc3bb87809d906adfd7ba31d66ceee0fe075330a52d869fbf78ac3972f162d&scene=27,在等吴恩达深度学习第5课的时候，你可以先看看第4课的笔记,"大数据文摘作品 编译：党晓芊、元元、龙牧雪 等待吴恩达放出深度学习第5课的时候，你还能做什么？今天，大数据文摘给大家带来了加拿大银行首席分析师Ryan Shrott的吴恩达深度学习第4课学习笔记，一共11个要点。在等待第5门课推出的同时，赶紧学起来吧！ 这两天，听说大家都被一款叫做“旅行青蛙”的游戏刷屏了，还有许多人在票圈喊着“养男人不如养蛙”。 在这个“云养蛙”的佛系游戏里，只有两种状态：蛙儿子在家和不在家。蛙儿子在家的时候，你只能一心盼他出门，啥也干不了。蛙儿子出门了，你也不知道他要多久才能回家，只能等着他回来——还是啥也干不了。 当然，青蛙出门在外的日子里，他偶尔会给等待中的你寄张明信片回来。 还有什么等待比等青蛙旅行回家还漫长吗？ 有的。 自从去年8月吴恩达的深度学习系列课程在Coursera上线（戳蓝字看大数据文摘相关测评 、 ），这门Sequence Models课程一直处于coming soon的状态，上线日期从去年底一直跳票到今年一月。 在漫长的等待过程中，已经有不少童鞋学完了这一系列的前4门课，大数据文摘也发布过前3课的学习笔记 。 今天， 边学习边等待的过程，又何尝不是一种幸福呢。同时，课程笔记里还有狗粮放出，请大家注意接收！ *** 我最近学完了吴恩达在Coursera上关于计算机视觉的课程。吴恩达的课程非常精彩， 。我最喜欢的是关于神经风格迁移的部分（见第十二课），这个方法可以让你用任意内容的绘画创造出莫奈风格的艺术作品。请看下面的例子： 这篇文章中，我将会讨论我在课程中学到的12个关键点。请注意,这个课程是deeplearning.ai所发布的深度学习系列课程的第四部分。 大数据以及算法开发将会使智能系统的测试误差逐渐趋近于贝叶斯最优误差。 这个结果将会导致人工智能的表现全方位超越人类，其中包括自然识别方面的工作。像TensorFlow这样的开源软件，就可以帮助你用迁移学习的方法迅速实现其任何物体的探测器。用迁移学习的方法你只需要大约100-500个训练实例就可以得到很好的结果。手动标记100个实例的工作量并不太，所以你可以很快得到一个最小化可用模型。 吴恩达解释了如何实现卷积算符并展示了如何用它检测物体边缘。 他同时还解释了其他的过滤器，比如说索贝尔过滤器(Sobel filter)，这种过滤器在图像边缘中部采用更大的比重。然后，吴恩达解释了这些过滤器的比重并不是靠人为设计的，而是依靠类似于梯度下降的这样的爬山算法由计算机自行训练出来的。 吴恩达透彻的解释了卷积适用于图像识别的原因。其中有两个具体的原因。 比如说，一个边缘探测器可能对图像的很多部分都有用。特征分享的方法能够降低系统参数的数量，同时能够带来稳健的平移不变性(translation invariance)。平移不变性是一个概念，意思是比如说有一张猫的图片，即使是经过了移动和旋转，依旧是一只猫的图片。 第二个原因被称作稀疏连结性，即每个输出层仅仅由很小一部分输入结点计算得到（更具体一些，输入的数量是过滤器数量的平方）。 用这个方法可以极大的减少网络中参数的数量，提高训练速度。 填充通常用来保持输入的数量（也就是说，使得输入输出的维度相同）。用这个方法也可以保证在进行训练时，来自图片边缘的贡献和来自中心的贡献相当。 实证研究证明，最大池化层对于CNN非常有效。通过对图像向下取样，我们减少了参数数量，同时也确保图像特征在图像尺度变化或者方向变化时保持不变。 吴恩达展示了3种经典的神经网络架构，包括LeNet-5, AlexNet 和VGG-16。 他所展示的主要观点是一个有效的神经网络通常是通道的数目不断上升，宽度和高度不断下降。 对于一般的神经网络，由于梯度的消失和爆炸，训练误差并不会随着网络层数的增加而单调递减。 然而对于ResNets而言，可以通过向前跳跃性连接，让你在训练一个很大的神经网络时，误差单调下降，性能单调递增。 如果从头开始训练一个像inception这种结构巨大的神经网络，即使在GPU上训练也可能需要好几周的时间。你可以下载经过预训练得到的权重，然后只重新训练最后的softmax层（或者最后几个层）。这个会极大缩短训练时间。这种方法有效的原因是前几层所训练的特征很可能是诸如边界或者弯曲线条之类的所有图像的共同特征。 吴恩达解释说， 一些数据增强的技术，比如说随机裁剪图片，沿水平垂直轴翻转图像可以帮助提升模型表现。总之，你一开始应该使用开源软件库和预训练模型，然后根据自己要解决的问题不断细化模型，调整参数。 首先，吴恩达解释了从图片中检测标志性物体的思路。 通过一些有效的卷积操作，你会得到一个输出值，表示一个物体出现在某个区域的概率和区域的位置。同时，他解释了如何通过交集并集商评估对象检测器的有效性。最后，吴恩达结合所有构成要素，解释了著名的YOLO算法。 面部识别是一个单样本学习(one-shot learning)问题，因为你有可能只能根据一张示例图片来辨别一个人。解决问题的方法是使用相似性函数，这个函数可以给出两个图像之间的相似程度。所以，如果两张图像是同一个人，你希望这个函数输出一个较小的数值；不同人的两张图像则输出较大的数值。 吴恩达给出的第一个解决方案被称作siamese网络。它的基本思路是将两张不同的图片输入到同一个神经网络然后比较结果。如果输出相似性很高，那么很有可能是同一个人。神经网络训练的目标就是如果两个输入的图片是同一个人，那么输出的结果距离相对很小。 对于第二种解决方案，他给出了一个三元损失方法(triplet loss method)。这个方法是，从三张图片（Anchor (A), Positive (P) and Negative (N)）训练得到一个神经网络，使得 A与P 的结果相似程度远远高于A与N的结果相似程度。 注意，此图中有狗粮！（为什么说这是狗粮？请看大数据文摘此前报道 《吴恩达CNN新课上线！deeplearning.ai 4/5解锁，6日开课》 ） 吴恩达解释了如何结合风格和内容创造新的图画。示例如下。神经风格迁移方法的核心在于充分理解神经网络中每一个卷积层对应的具体的视觉表征。实际表明，网络当中前几层通常学习简单的特征，比如图像边缘。后几层通常学习一些复杂的对象，比如脸，脚，汽车等。 为了创建一个神经风格转移图画，你只需要定义一个结合风格和内容相似性的凸函数作为损失函数。具体而言，这个函数可以写成： 在这个方程中，G是被创造出的图像，C是图像内容，S是图像风格。简单的采用梯度下降法来对损失函数就生成图像求最小值。 基本步骤如下： 1. 随机生成G。 2. 使用梯度下降方法最小化J(G) ，通过这个等式:  G:=G-dG(J(G)) 3. 重复第二步。 结论： 完成这门课程之后，你会对大量计算机视觉方面的文献有一个直观的认识。同时课后作业让你有机会自己实现部分算法。完成这门课程后，你不会很快成为一个计算机视觉方面的专家，但是它可能会开启你计算机视觉相关的想法和事业。 你也学完了吴恩达深度学习系列课的前4门课吗？还是仍停留在第一课第一讲？欢迎留言和我们分享。 原文链接： https://www.kdnuggets.com/2017/12/ng-computer-vision-11-lessons-learnied.html 【今日机器学习概念】 Have a Great Defination "
198,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656508&idx=1&sn=5d62544fa8083c76a254903a41840e85&chksm=bd4c36af8a3bbfb91c79c6fe124881edd6362f21f726cc3de497022f825e6d30d9d2e39b085a&scene=27,史上最全！27种神经网络简明图解：模型那么多，我该怎么选？,"大数据文摘作品 编译：田奥leo、桑桑、璐、Aileen 27种？！神经网络竟有那么多种？这篇文章将逐一介绍下面这张图片中的27种神经网络类型，并尝试解释如何使用它们。准备好了吗？让我们开始吧！ 神经网络的种类越来越多，可以说是在呈指数级地增长。我们需要一个一目了然的图表，在这些新出现的网络构架和方法之间进行导航。 幸运的是，来自Asimov研究所的Fjodor van Veen编写了一个关于神经网络的精彩图表（就是上面那张大图）。 下面，我们就来逐一看看图中的27种神经网络： Perceptron 感知机 Perceptron 感知机 ， 我们知道的最简单和最古老的神经元模型。接收一些输入，把它们加总，通过激活函数并传递到输出层。这没什么神奇的地方。   前馈神经网络（FF） 前馈神经网络（FF） ， 这也是一个很古老的方法——这种方法起源于50年代。它的工作原理通常遵循以下规则： 1.所有节点都完全连接 2.激活从输入层流向输出，无回环 3.输入和输出之间有一层（隐含层） 在大多数情况下，这种类型的网络使用反向传播方法进行训练。   RBF 神经网络 RBF 神经网络 实际上是激活函数是径向基函数而非逻辑函数的FF前馈神经网络（FF）。两者之间有什么区别呢？ 逻辑函数将某个任意值映射到[0 ,... 1]范围内来，回答“是或否”问题。适用于分类决策系统，但不适用于连续变量。 相反，径向基函数能显示“我们距离目标有多远”。 这完美适用于函数逼近和机器控制（例如作为PID控制器的替代）。 简而言之，   DFF深度前馈神经网络 DFF深度前馈神经网络 在90年代初期开启了深度学习的潘多拉盒子。这些依然是前馈神经网络，但有不止一个隐含层。那么，它到底有什么特殊性？ 在训练传统的前馈神经网络时，我们只向上一层传递了少量的误差信息。由于堆叠更多的层次导致训练时间的指数增长，使得深度前馈神经网络非常不实用。直到00年代初，我们开发了一系列有效的训练深度前馈神经网络的方法;    RNN递归神经网络 RNN递归神经网络 引入不同类型的神经元——递归神经元。这种类型的第一个网络被称为约旦网络（Jordan Network），在网络中每个隐含神经元会收到它自己的在固定延迟（一次或多次迭代）后的输出。除此之外，它与普通的模糊神经网络非常相似。 当然，它有许多变化  —  如传递状态到输入节点，可变延迟等，但主要思想保持不变。这种类型的神经网络主要被使用在上下文很重要的时候——即过去的迭代结果和样本产生的决策会对当前产生影响。最常见的上下文的例子是文本——一个单词只能在前面的单词或句子的上下文中进行分析。   引入了一个存储单元，一个特殊的单元，当数据有时间间隔（或滞后）时可以处理数据。递归神经网络可以通过“记住”前十个词来处理文本，LSTM长短时记忆网络可以通过“记住”许多帧之前发生的事情处理视频帧。 LSTM网络也广泛用于写作和语音识别。 存储单元实际上由一些元素组成，称为门，它们是递归性的，并控制信息如何被记住和遗忘。下图很好的解释了LSTM的结构: 上图的（x）是门，他们拥有自己的权重，有时也有激活函数。在每个样本上，他们决定是否传递数据，擦除记忆等等 - 你可以在这里 (http://colah.github.io/posts/2015-08-Understanding-LSTMs/) 阅读更详细的解释。 输入门(Input Gate)决定上一个样本有多少的信息将保存在内存中; 输出门调节传输到下一层的数据量，遗忘门(Forget Gate)控制存储记忆的损失率。 然而，   GRU GRU是具有不同门的LSTM 。 听起来很简单，但缺少输出门可以更容易基于具体输入重复多次相同的输出，目前此模型在声音（音乐）和语音合成中使用得最多。 实际上的组合虽然有点不同： 它们比LSTM消耗资源少，但几乎有相同的效果。   Autoencoders自动编码器 Autoencoders自动编码器 用于分类，聚类和特征压缩。 当您训练前馈(FF)神经网络进行分类时，您主要必须在Y类别中提供X个示例，并且期望Y个输出单元格中的一个被激活。 这被称为“监督学习”。 另一方面，自动编码器可以在没有监督的情况下进行训练。它们的结构 - 当隐藏单元数量小于输入单元数量（并且输出单元数量等于输入单元数）时，并且当自动编码器被训练时输出尽可能接近输入的方式，强制自动编码器泛化数据并搜索常见模式。   变分自编码器 变分自编码器 ，与一般自编码器相比，它压缩的是概率，而不是特征。 尽管如此简单的改变，但是一般自编码器只能回答当“我们如何归纳数据？”的问题时， 的问题。 在这里 可以看到一些更深入的解释 。   降噪自动编码器（DAE） 虽然自动编码器很酷，但它们有时找不到最鲁棒的特征，而只是适应输入数据（实际上是过拟合的一个例子）。 降噪自动编码器（DAE） 在输入单元上增加了一些噪声 - 通过随机位来改变数据，随机切换输入中的位，等等。通过这样做，一个强制降噪自动编码器从一个有点嘈杂的输入重构输出，使其更加通用，强制选择更常见的特征。 稀疏自编码器（SAE） 稀疏自编码器（SAE） 是另外一个有时候可以抽离出数据中一些隐藏分组样试的自动编码的形式。结构和AE是一样的，但隐藏单元的数量大于输入或输出单元的数量。   马尔可夫链（Markov Chain, MC） 马尔可夫链（Markov Chain, MC） 是一个比较老的图表概念了，它的每一个端点都存在一种可能性。过去，我们用它来搭建像“在单词hello之后有0.0053％的概率会出现dear，有0.03551%的概率出现you”这样的文本结构。 这些马尔科夫链并不是典型的神经网络，它可以被用作基于概率的分类（像贝叶斯过滤），用于聚类（对某些类别而言），也被用作有限状态机。   霍普菲尔网络（HN） 霍普菲尔网络（HN） 对一套有限的样本进行训练，所以它们用相同的样本对已知样本作出反应。 在训练前， 在HN试着重构受训样本的时候，他们可以用于给输入值降噪和修复输入。如果给出一半图片或数列用来学习，它们可以反馈全部样本。   波尔滋曼机（BM） 波尔滋曼机（BM） 和HN非常相像，有些单元被标记为输入同时也是隐藏单元。在隐藏单元更新其状态时，输入单元就变成了输出单元。（在训练时，BM和HN一个一个的更新单元，而非并行）。 这是第一个成功保留模拟退火方法的网络拓扑。 多层叠的波尔滋曼机可以用于所谓的深度信念网络（等一下会介绍），深度信念网络可以用作特征检测和抽取。 在结构上， 和BM很相似，但由于受限RBM被允许像FF一样用反向传播来训练（唯一的不同的是在反向传播经过数据之前RBM会经过一次输入层）。 像之前提到的那样， 实际上是许多波尔滋曼机（被VAE包围）。他们能被连在一起（在一个神经网络训练另一个的时候），并且可以用已经学习过的样式来生成数据。   当今， 是人工神经网络之星。它具有卷积单元（或者池化层）和内核，每一种都用以不同目的。 卷积核事实上用来处理输入的数据，池化层是用来简化它们（大多数情况是用非线性方程，比如max），来减少不必要的特征。 他们通常被用来做图像识别，它们在图片的一小部分上运行（大约20x20像素）。输入窗口一个像素一个像素的沿着图像滑动。然后数据流向卷积层，卷积层形成一个漏斗（压缩被识别的特征）。从图像识别来讲，第一层识别梯度，第二层识别线，第三层识别形状，   去卷积网络（DN） 是将DCN颠倒过来。DN能在获取猫的图片之后生成像（狗：0，蜥蜴：0，马：0，猫：1）一样的向量。DNC能在得到这个向量之后，能画出一只猫。   深度卷积反转图像网络（DCIGN） ，长得像DCN和DN粘在一起，但也不完全是这样。 事实上，它是一个自动编码器，DCN和DN并不是作为两个分开的网络，而是承载网路输入和输出的间隔区。大多数这种神经网络可以被用作图像处理，并且可以处理他们以前没有被训练过的图像。由于其抽象化的水平很高，这些网络可以用于将某个事物从一张图片中移除，重画，或者像大名鼎鼎的CycleGAN一样将一匹马换成一个斑马。 生成对抗网络（GAN） 代表了有生成器和分辨器组成的双网络大家族。它们一直在相互伤害——生成器试着生成一些数据，而分辨器接收样本数据后试着分辨出哪些是样本，哪些是生成的。只要你能够保持两种神经网络训练之间的平衡，在不断的进化中，这种神经网络可以生成实际图像。   液体状态机（LSM） 液体状态机（LSM） 是一种稀疏的，激活函数被阈值代替了的（并不是全部相连的）神经网络。 这种想法来自于人脑，这些神经网络被广泛的应用于计算机视觉，语音识别系统，但目前还没有重大突破。   极端学习机（ELM） 是通过产生稀疏的随机连接的隐藏层来减少FF网络背后的复杂性。它们需要用到更少计算机的能量，实际的效率很大程度上取决于任务和数据。   回声状态网络（ESN） 是重复网络的细分种类。数据会经过输入端，如果被监测到进行了多次迭代（请允许重复网路的特征乱入一下），只有在隐藏层之间的权重会在此之后更新。 据我所知，除了多个理论基准之外，我不知道这种类型的有什么实际应用。欢迎留下你的不同意见～ 深度残差网络（DRN） 是有些输入值的部分会传递到下一层。这一特点可以让它可以做到很深的层级（达到300层），但事实上它们是一种没有明确延时的RNN。 Kohonen神经网络（KN） 引入了“单元格距离”的特征。大多数情况下用于分类， 当一些单元格更新了， 离他们最近的单元格也会更新。 像SVM一样，这些网络总被认为不是“真正”的神经网络。   支持向量机（SVM） 支持向量机（SVM） 用于二元分类工作，无论这个网络处理多少维度或输入，结果都会是“是”或“否”。 SVM不是所有情况下都被叫做神经网络。   神经网络像是黑箱——我们可以训练它们，得到结果，增强它们，但实际的决定路径大多数我们都是不可见的。 神经图灵机（NTM） 就是在尝试解决这个问题——它是一个提取出记忆单元之后的FF。一些作者也说它是一个抽象版的LSTM。 记忆是被内容编址的，   希望这篇总结对你们有所帮助。如文中有错误或者疏漏，欢迎留言给我们纠正或补充。 原文链接： https://medium.com/towards-data-science/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464 【今日机器学习概念】 Have a Great Defination "
199,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656472&idx=2&sn=eb7732f89cf835f9376d43af5dd5ee4a&chksm=bd4c368b8a3bbf9da3b5dcfb9cbefa1bbac088b8c1b8077607f4632620bf01f6ef6ad8f449bc&scene=27,重磅译制 | 更新：MIT 6.S094自动驾驶课程第1讲（3）深度学习模型应用,大数据文摘重磅课程汉化 《MIT 6.S094 深度学习与自动驾驶》 本周更新至：第一讲（3） 深度学习的概念和模型应用 时长30分钟 带有中文字幕 这门无人车课程由麻省理工MIT开设，话题前沿且实践性质很强。课程首先引导大家了解深度学习，之后大家可以自己“造”一辆无人车（的算法🌚）！ 课程面向机器学习 ，但已经有大量经验的研究人员也能从课程提供的从实践出发的深度学习方法和应用中受益。 课程主讲Lex Fridman与TA团队 大数据文摘已取得课程翻译授权，将以连载的形式发布后续课程内容，请大家继续关注我们，随时给予好评🌚 MIT深度学习与自动驾驶课程页面（所有PPT、视频和资料汇总）： https://selfdrivingcars.mit.edu/ 《牛津大学xDeepMind自然语言处理》汉化视频 更新中 ，复制打开链接免费加入学习： http://study.163.com/course/introduction/1004336028.htm 《斯坦福CS231n深度学习计算机视觉》课程已更新完毕，李飞飞与Andrej Karpathy（现任Tesla AI部门主管）主讲，已有7.4万+人参与学习，复制打开链接免费加入学习： http://study.163.com/course/introduction/1003223001.htm 本课时PPT精华 ▼ 北京邮电大学模式识别实验室 李琦、李子凡、刘冠群 刘家铭、慕宗奇、祁星群 吴灵境、肖思瑶、杨紫都、张文源 （按拼音排序） 寒小阳、Zach Tian 刘家铭、龙牧雪 顾   问 张闯、汪德诚 【今日机器学习概念】 Have a Great Definition 戳 收看本次课程 快上车 ▼▼▼ 
200,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656490&idx=2&sn=69078e8aae8635c4f69f3a57fe603798&chksm=bd4c36b98a3bbfaf5559d847baeb82b8c542c4322fb3599a3dc9f30f82d5f4e9bc3943a85ee1&scene=27,比特币再火也是10年前的概念了，这3种币才是潮流,"编译：魏子敏 龙牧雪 比特币这一概念的提出已经快十年了。当其刚刚面世时，App store才刚出现，人们甚至仍然在使用便携式DVD播放机。 你更相信“先发优势“还是”后来者居上“？在电子货币领域呢？ 2008年比特币首次被提出，我们把这一“币”的出现和“iPhone”的出现相提并论，甚至给予了其更高的地位。 十年后的今天，2018年，比特币估值已经超越10000美元。 第一款iPhone的发布不比比特币的发布早多久👆 但比特币这一概念的提出已经快十年了。当比特币被构思出来时，App store才刚刚起步，人们仍在长途旅行中使用便携式DVD播放机。  2018年的技术远远领先于十年前的技术。加密技术也不例外。 比特币出现后，我们现在已经有了超过1500个加密货币。 在过去的一个月里，比特币的市场份额从56％下降到了33％。 来自coinmarketcap的图表显示，在过去一个月中，比特币的统治地位下降👆 这已经不是“先驱者”第一次受到新技术的威胁。 Altavista让位给谷歌。 Myspace败给了Facebook。先驱者被后发追随者赶上早不是新鲜事。 有研究表明，一个领域中的先行者相比其后的企业，失败的可能性要高6倍。 比特币作为开拓者的功勋不容被遗忘，但现在，新的竞争者正在赶上来。 如果比特币只是加密货币的开始，那么，接下来会是什么？   比特币及其区块链存在严重缺陷 比特币网络每部分只能处理7个交易。这意味着，每秒钟全世界只有7个人可以使用比特币进行买卖。 我们对比一下，Visa每秒可处理的交易数量是24,000笔。低交易速度限制了比特币作为货币的有效性，这也不利于比特币作为价值储备。当人们买卖比特币太多时，交易所停工，资金可能会停滞等待几个小时（甚至几天）。 网络拥塞导致非常高的费用。十二月底，每笔交易的收费是37美元，甚至超过了电汇的成本。 想象一下全世界都知道你银行里有多少钱，你会不会很心慌？而对于比特币交易来说，情况远不止此，你的每一笔资金交易，你的钱从哪来到哪去，都会被公诸于世。 比特币钱包与地址散列（随机字母序列）相关联。 这个历史不能被删除或改变。 比特币被设计成数字货币。 （其不智能程度可以类比为计算器和计算机相比）。而可编程区块链（以太坊是最广为人知的例子）则有可能造成更大规模的影响。 新出现的电子货币引入了惊人的新技术，下面是一些最优秀的“币圈”竞争者： 优点：高度的可扩展性。优秀的适配性，明确的使用场景。 如果你是电子货币的关注者，那么1月初你可能听闻过Ripple的惊人涨势。 Stellar Lumens是更新、100％分散版本的Ripple。 Ripple的首席执行官成立了Stellar Lumens，以解决Ripple中的缺陷。 其投资者是Y-Combinator的首席执行官Sam Altman和Stripe的首席执行官。 优点：疯狂的可扩展性。即时交易。零费用。 Raiblocks仅仅在几个月前才诞生。 这使得它比区块链应用程序更具可扩展性。他们只想“做好一件事”（这也是比特币创建的本意）：迅速、免费的全球交易方式。 优点：可扩展和可编程。 “以太坊杀手” EOS被戏称为“类固醇以太坊”（Ethereum on Steroids）。 EOS背后的开发者声称，EOS区块链是完全可编程的，将消除交易费用，并能够每秒处理数百万次交易。他们的区块链将在四月份推出。   由于缺乏社区支持，比特币上一次原定于11月份上线的重大更新计划被取消。11月的更新是为了引入Segwit2x，这是一种增加每个区块上可以记录的交易数量的方法。 缺少Segwit2x的比特币网络正在变得越来越慢。 比特币现在应对规模扩展的手段——闪电网络（The Lightning Network）——仍面临许多未知因素。 在解决比特币的一些缺点之前，闪电网络需要更多的测试。 与此同时，EOS，XLM和XRB等后来者已经准备好在速度和功能等诸多方面超越比特币。我们还没有看到这些后来者是否会走向市场。  我们唯一可以确定的是，整个加密货币空间正在快速迭代。 最终获胜的加密货币可能还没有被创造出来。 后来者能否居上？让我们拭目以待。 原文链接： https://hackernoon.com/bitcoin-is-outdated-tech-these-3-alternatives-should-be-on-your-radar-57cf806d34df?source=linkShare-9549803b36be-1516508926 【今日机器学习概念】 Have a Great Definition "
201,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656472&idx=1&sn=c80bc6616f0f5884f9b34e5390e2fbee&chksm=bd4c368b8a3bbf9dc2154e4360b1021a6b90f4b23968f63522a9d9ef5818add6a80d149fb5c4&scene=27,谷歌深圳开办事处，想应聘？先来看看谷歌招过什么样的实习生,大数据文摘作品 编译：龙牧雪、GAO Ning、笪洁琼 寒假就要到了，你的实习找好了没？ 几天前，谷歌在深圳新设立了一个办事处，办公地点选在了深圳第一高楼平安金融中心。 科技媒体TechCrunch引用谷歌的一封内部邮件称， “谷歌在深圳开设了一家新办事处。我们有一些员工会定期到深圳出差，他们提出希望在深圳设立一个办公地点。经过数月考察，我们签下了一份位于深圳的办公室租约。本周办公室已经开放，我们希望为谷歌员工创造一个舒适的工作环境。” 谷歌此举被业界人士视为迈出了发展智能硬件的一步 ——毕竟， ，想组装什么硬件都能组装出来。 报告！我想组装一只EVA 更早一点，一个月前，李飞飞宣布了谷歌AI中国中心在北京成立 。 大数据文摘也贴心地给大家汇报了谷歌中国的实习生招聘要求 ，要点如下： 目前正在攻读计算机科学或相关技术学科的本科、硕士、博士学生。 具备自然语言理解、神经网络、计算机视觉、机器学习、深度学习、优化的算法基础、数据科学、数据挖掘和/或机器智能（人工智能）方面的课堂或工作经验。 熟练使用 Python。 在ICML、NIPS、ICLR、AAAI、IJCAI、CVPR、ACL或NAACL 等研讨会上至少发表一篇论文（列为作者）。 有Tensorflow/ Torch/ Pytorch/ Caffe/ MXNet 等深度学习框架的经验。 是不是已经看傻眼啦？！今天，我们就来和大家聊聊谷歌“超级实习生”的那些事。 首先我们来说说Ian Goodfellow，他因提出GANs（生成对抗网络）闻名。Ian Goodfellow 2009年本科毕业于斯坦福大学计算机专业，2014年于蒙特利尔大学取得博士学位（机器学习方向），是《深度学习》（花书）的作者之一。 2013年暑假，Ian Goodfellow作为暑期实习生，在谷歌开发了一套能从街景图片中识别路标上的数字的深度神经网络 。这项工作基于街景门牌号数据集 (SVHN)，对提高谷歌地图的准确性至关重要。 今天，全球有三分之一以上的地址准确性由于采用了这一系统而得到改进。 Ian Goodfellow的LinkedIn主页对他的实习项目的介绍 当然，Ian Goodfellow也顺利拿到了留用。在此之后，Ian Goodfellow一直在谷歌工作，直到2016年他离开谷歌前往OpenAI，不过仅仅一年之后的2017年3月，他又重新回到了谷歌工作。 大写的优秀！ 然而毕竟，Ian Goodfellow还是走正常程序、在博士最后一年进入谷歌当实习生的，就和千千万万互联网公司实习生一样。 最让人吃惊的应该是， Geoffrey Hinton是人工智能领域最著名的研究学者之一，他的研究帮助我们开启了今天所看到的深度学习的世界。他在1977年获得人工智能博士学位，并在之后的40年中，对反向传播（BP）和玻尔兹曼机的发展都做出了重要贡献。 有趣的是，我们在谷歌大脑团队主办的Reddit AMA中了解到，Hinton曾于2012年在谷歌担任实习生。 当时有人提问，谷歌大脑团队对于实习生是否有年龄限制。 谷歌高级研究员、研究小组的带头人 Jeff Dean 解释说他的团队对于实习生是没有年龄限制的。为了更好的证实这一点，他补充说道，从严格意义上，Geoffrey Hinton曾在2012年有一段时间在他的团队做实习生。 “2012年，我接待了Geoffrey Hinton作为我们团队的暑期访问学者，但是由于这个项目成立过程中的一些混乱，他被归类为了我的实习生。” Jeff Dean接着说道，“ （笑）。” 啊哈哈这要求还真的不难达到 Reddit原帖可以通过下面的链接了解，Jeff Dean带头回答了很多各型各色的问题（其中一些挺有趣的！）： https://www.reddit.com/r/MachineLearning/comments/6z51xb/we_are_the_google_brain_team_wed_love_to_answer/?sort=qa&st=j7jfp61w&sh=60daca63 就在Hinton老爷子来“实习”的一年后，谷歌收购了Hinton的创业公司DNNresearch，寄希望于通过获得该公司对神经网络的研究（及其背后的人才）增强自身的深度学习能力，帮助其在图像、声音等搜索上超越传统的搜索算法，尤其是提高其图像搜索和面部识别能力。 DNNresearch由Geoffrey Hinton和他的两名毕业生Alex Krizhevsky和Ilya Sutskever创立于2012年。当时，谷歌没有公布收购DNNresearch所支付的价格。 团队被收购后，Hinton老爷子还在Google+上发表了一篇博客，特别提及自己在谷歌的“实习期”所获得的巨大收获： “去年夏天，我花了几个月在山景城的Google Knowledge团队工作，与Jeff Dean以及一群令人难以置信的科学家和工程师合作，他们在机器学习方面取得了惊人的进步。 加上我最近的两位研究生Ilya Sutskever和Alex Krizhevsky（2012 ImageNet竞赛冠军）， 。 这意味着我们很快就会加入Google，与一些最聪明的工程师合作，解决计算机科学中的一些最大挑战。 我仍然在多伦多大学兼职，在那里我仍然有很多优秀的研究生， _(:з」∠)_招一个实习生，实习期结束后顺带收购实习生自创的公司，这笔买卖似乎挺划得来。 Jeff Dean带领的谷歌大脑团队是谷歌在深度学习研究方面的核心单元，也是现在流行的TensorFlow深度学习框架的研发地。 如果你申请他们团队的实习生失败了，不要难过—— 。:) 祝有假期的同学们寒假愉快，你申到了哪家实习？欢迎和我们报喜哦。也欢迎大家留言讲讲自己做实习生时候的故事。 新闻来源： https://techcrunch.com/2017/09/14/geoffrey-hinton-was-briefly-a-google-intern-in-2012-because-of-bureaucracy/?ncid=mobilenavtrend&from=timeline https://techcrunch.com/2013/03/12/google-scoops-up-neural-networks-startup-dnnresearch-to-boost-its-voice-and-image-search-tech/ 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 
202,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656490&idx=1&sn=2d261af429e87be2240f3c2f133474e6&chksm=bd4c36b98a3bbfafc24ff22000c54efc173cf2fb471e94fdf9f7fd66a5325b00bd6b48e3aab2&scene=27,还在用PCA降维？快学学大牛最爱的t-SNE算法吧（附Python/R代码）,"假设你有一个包含数百个特征（变量）的数据集，却对数据所属的领域几乎没有什么了解。 你需要去识别数据中的隐藏模式，探索和分析数据集。不仅如此，你还必须找出数据中是否存在模式－－用以判定数据是有用信号还是噪音？ 这是否让你感到不知所措？当我第一次遇到这种情况，我简直全身发麻。想知道如何挖掘一个多维数据集？ 这是许多数据科学家经常问的问题之一。 该篇文章中，我将带你通过一个强有力的方式来实现这一点。 用PCA怎么样？ 现在，一定会有很多人心里想着“我会使用PCA来降维和可视化”。 好吧，你是对的！ 如果你可以很容易地找出非线性的模式呢？ 在本文中，我将告诉你一个比PCA（1933）更有效、被称为t-SNE（2008）的新算法。 首先我会介绍t-SNE算法的基础知识，然后说明为什么t-SNE是非常适合的降维算法。 你还将获得在R代码和Python语句中使用t-SNE的实践知识。 来吧来吧！ 1.什么是t-SNE？ 2.什么是降维？ 3.t-SNE与其他降维算法 4.t-SNE的算法细节   4.1 算法   4.2 时间和空间复杂性 5.t-SNE实际上做什么？ 6.用例 7.t-SNE与其他降维算法相比 8.案例实践   8.1 使用R代码    -超参数调试    -代码    -执行时间    -结果解读   8.2 使用python语句    -超参数调试    -代码    -执行时间 9.何时何地去使用   9.1 数据科学家   9.2 机器学习竞赛爱好者   9.3 数据科学爱好者 10.常见误区 1.什么是t-SNE   （t-SNE）t-分布式随机邻域嵌入是一种用于挖掘高维数据的非线性降维算法。 它将多维数据映射到适合于人类观察的两个或多个维度。 在t-SNE算法的帮助下，   2.什么是降维？ 为了理解t-SNE如何工作，让我们先了解什么是降维？ 简而言之，降维是在2维或3维中展现多维数据（具有多个特征的数据，且彼此具有相关性）的技术。 有些人可能会问，当我们可以使用散点图、直方图和盒图绘制数据，并用描述性统计搞清数据模式的时候为什么还需要降低维度。 好吧，即使你可以理解数据中的模式并将其呈现在简单的图表上，但是对于没有统计背景的人来说，仍然很难理解它。 此外 在降维算法的帮助下，您将能够清晰地表达数据。 3. t-SNE与其他降维算法 现在你已经了解什么是降维，让我们看看我们如何使用t-SNE算法来降维。 以下是几个你可以查找到的降维算法： 1.主成分分析（线性） 2.t-SNE（非参数/非线性） 3.萨蒙映射（非线性） 4.等距映射（非线性） 5.局部线性嵌入(非线性) 6.规范相关分析（非线性） 7.SNE(非线性) 8.最小方差无偏估计（非线性） 9.拉普拉斯特征图（非线性） 好消息是，你只需要学习上述算法中的其中两种，就可以有效地在较低维度上使数据可视化 - PCA和t-SNE。   PCA的局限性 PCA是一种线性算法。 它不能解释特征之间的复杂多项式关系。 另一方面，t-SNE是基于在邻域图上随机游走的概率分布，可以在数据中找到其结构关系。 线性降维算法的一个主要问题是它们集中将不相似的数据点放置在较低维度区域时，数据点相距甚远。 但是为了在低维、非线性流型上表示高维数据，我们也需要把相似的数据点靠近在一起展示，这并不是线性降维算法所能做的。 现在，你对PCA应该有了一个简短的了解。 局部方法寻求将流型上的附近点映射到低维表示中的附近点。 另一方面，全局方法试图保留所有尺度的几何形状，即将附近的点映射到附近的点，将远处的点映射到远处的点 要知道， 4. t-SNE的算法细节（选读） 该部分是为有兴趣深入理解算法的人准备的。 如果您不想了解数学上面的细节，可以放心地跳过本节。   4.1算法 步骤1 随机邻近嵌入（SNE）首先通过将数据点之间的高维欧几里得距离转换为表示相似性的条件概率。数据点 与数据点 的相似性是条件概率 ——如果邻域被选择与在以 为中心的正态分布的概率密度成比例， 将选择 作为其邻域的概率。 其中 是以数据点 为中心的正态分布的方差，如果你对数学不感兴趣，以这种方式思考它，算法开始于将点之间的最短距离（直线）转换成点的相似度的概率。 其中，点之间的相似性是： 如果在以 为中心的高斯（正态分布）下与邻域的概率密度成比例地选取邻域，则 会选择 作为其邻居的条件概率。   步骤2 对于低维数据点 和 的高维对应点 和 ，可以计算类似的条件概率，其由 表示。 需要注意的是，pi | i和pj | j被设置为零，因为我们只想对成对的相似性进行建模。 简单来说，步骤1和步骤2计算一对点之间的相似性的条件概率。这对点存在于： 1.高维空间中 2.低维空间中 为了简单起见，尝试详细了解这一点。 让我们把3D空间映射到2D空间。 步骤1和步骤2正在做的是计算3D空间中的点的相似性的概率，并计算相应的2D空间中的点的相似性的概率。 逻辑上，条件概率 和 必须相等，以便把具有相似性的不同维空间中的数据点进行完美表示。即， 和 之间的差必须为零，以便在高维和低维中完美复制图。 通过该逻辑，SNE试图使条件概率的这种差异最小化。   步骤3 现在讲讲SNE和t-SNE算法之间的区别。 为了测量条件概率SNE差值的总和的最小化，在全体数据点中使用梯度下降法使所有数据点的Kullback-Leibler散度总和减小到最小。 我们必须知道，K-L散度本质上是不对称的。 换句话说，SNE代价函数重点在映射中保留数据的局部结构（为了高斯方差在高维空间的合理性， ）。 除此之外，优化该代价函数是非常困难的（计算效率低）。 因此，t-SNE也尝试最小化条件概率之差的总和值。 但它通过使用对称版本的SNE代价函数，使用简单的梯度。此外，t-SNE在低维空间中采用长尾分布，以减轻拥挤问题（参考下面译者解释）和SNE的优化问题。 ＊译者注： 拥挤问题是提出t-SNE算法的文章（Visualizing Data using t-SNE，08年发表在Journal of Machine Learning Research，大神Hinton的文章）重点讨论的问题（文章的3.2节）。译者的理解是，如果想象在一个三维的球里面有均匀分布的点，如果把这些点投影到一个二维的圆上一定会有很多点是重合的。所以在二维的圆上想尽可能表达出三维里的点的信息，把由于投影所重合的点用不同的距离（差别很小）表示，这样就会占用原来在那些距离上的点，原来那些点会被赶到更远一点的地方。t分布是长尾的，意味着距离更远的点依然能给出和高斯分布下距离小的点相同的概率值。 步骤4 如果我们看到计算条件概率的方程，我们忽略了现在的讨论的方差。要选择的剩余参数是学生的t-分布的方差 ，其中心在每个高维数据点 的中心。不可能存在对于数据集中的所有数据点最优的单个值 ，因为数据的密度可能变化。在密集区域中，较小的值 通常与较稀疏的区域相比更合适。任何特定值 在所有其他数据点上诱发概率分布 。 这个分布有一个 该分布具有随着 增加而增加的熵。 t-SNE对 的值执行二进制搜索，产生具有由用户指定具有困惑度的 2。 该困惑度定义为 其中H（ ）是以比特字节测量的香农熵 困惑度可以被解释为对邻域的有效数量的平滑测量。 SNE的性能对于茫然性的变化是相当稳固的，并且典型值在5和50之间。 代价函数的最小化是使用梯度下降法来执行的。并且从物理上，梯度可以被解释为由图上定位点 和所有其他图上定位点 之间的一组弹簧产生的合力。所有弹簧沿着方向（  -  ）施加力。弹簧在 和 定位点之间的排斥或吸引，取决于图中的两点之间的距离是太远还是太近 (太远和太近都不能表示两个高维数据点之间的相似性。)由弹簧在 和 之间施加的力与其长度成比例，并且还与其刚度成比例，刚度是数据的成对相似性之间的失配（pj | i-qj | i + pi | j-qi | j） 点和地图点 。    ＊译者补充： 步骤3和4都在讲述SNE 与t-SNE之间的区别，总结如下： 区别一：将不对称的代价函数改成对称的代价函数。 将代价函数修改为 ，其中 ， 则可避免上述不对称的代价函数所带来的问题。 区别二：在低维空间中使用学生t-分布而不是高斯分布来计算点与点之间的相似度。 t-SNE在低维空间中采用长尾的学生t-分布， ， 以减轻拥挤问题和SNE的优化问题。 4.2 时间和空间复杂度 现在我们已经了解了算法，是分析其性能的时候了。 正如你可能已经观察到的，  这涉及大量的运算和计算。 所以该算法对系统资源相当重要。 t-SNE在数据点的数量上具有二次时间和空间复杂性。 这使得它应用于超过10,000个观察对象组成的数据集的时候特别慢和特别消耗资源。   5. t-SNE 实际上做了什么？ 了解了 t-SNE 算法的数学描述及其工作原理之后,让我们总结一下前边学过的东西。以下便是t-SNE工作原理的简述。 实际上很简单。 它不是一个聚类算法，而是一个降维算法。这是因为当它把高维数据映射到低维空间时，原数据中的特征值不复存在。所以不能仅基于t-SNE的输出进行任何推断。因此，本质上它主要是一种数据探索和可视化技术。 但是t-SNE可以用于分类器和聚类中，用它来生成其他分类算法的输入特征值。 6. 应用场景 你可能会问， t-SNE有哪些应用场景呢？它几乎可以用于任何高维数据。不过大部分应用集中在图像处理，自然语言处理，基因数据以及语音处理。它还被用于提高心脑扫描图像的分析。以下维几个实例： 6.1 人脸识别 人脸识别技术已经取得巨大进展，很多诸如PCA之类的算法也已经在该领域被研究过。但是由于降维和分类的困难，人脸识别依然具有挑战性。t-SNE被用于高维度数据降维，然后用其它算法，例如 AdaBoostM2, 随机森林, 逻辑回归, 神经网络等多级分类器做表情分类。 一个人脸识别的研究采用了日本女性脸部表情数据库和t-SNE结合AdaBoostM2的方法。其实验结果表明这种新方法效果优于诸如PCA, LDA, LLE及SNE的传统算法。 以下为实现该方法的流程图：  6.2 识别肿瘤亚群（医学成像） 质谱成像（MSI）是一种同时提供组织中数百个生物分子的空间分布的技术。 t-SNE，通过数据的非线性可视化，能够更好地解析生物分子肿瘤内异质性。 以无偏见的方式，t-SNE可以揭示肿瘤亚群，它们与胃癌患者的存活和乳腺癌患者原发性肿瘤的转移状态具有统计相关性。 对每个t-SNE簇进行的存活分析将提供非常有用的结果。[3]  6.3 使用wordvec的文本比较 词向量表示法捕获许多语言属性，如性别，时态，复数甚至语义概念，如“首都城市”。 使用降维，可以计算出使语义相似的词彼此临近的2D地图。 这种技术组合可以用于提供不同文本资料的鸟瞰图，包括文本摘要及其资料源。 这使用户能够像使用地图一样探索文本资料。[4]   7. t-SNE与其它降维算法的对比 下边我们将要比较t-SNE和其它算法的性能。这里的性能是基于算法所达到的准确度，而不是时间及运算资源的消耗与准确度之间的关系。 t-SNE产生的结果优于PCA和其它线性降维模型。这是因为诸如经典缩放的线性方法不利于建模曲面的流型。 它专注于保持远离的数据点之间的距离，而不是保留临近数据点之间的距离。 t-SNE在高维空间中采用的高斯核心函数定义了数据的局部和全局结构之间的软边界。   此外，t-SNE基于数据的局部密度（通过强制每个条件概率分布具有相同的困惑度）分别确定每个数据点的局部邻域大小[1]。 这是因为算法定义了数据的局部和全局结构之间的软边界。 与其他非线性降维算法不同，它的性能优于其它任何一个算法。    8. 案例实践 让我们用MNIST手写数字数据库来实现t-SNE算法。 这是最被广泛探索的图像处理的数据集之一。   81.使用R代码 “Rtsne”包具有t-SNE在R语言中的实现。“Rtsne”包可以通过在R控制台中键入以下命令安装： • 超参数调试 • 代码 MNIST数据可从MNIST网站下载，并可用少量代码转换为csv文件。对于此示例，请下载以下经过预处理的MNIST数据。 •  执行时间 可以看出，运行于相同样本规模的数据，与PCA相比t-SNE所需时间明显更长。   • 解读结果 这些图可用于探索性分析。 输出的x和y坐标以及成本代价值可以用作分类算法中的特征值 8.2使用Rython语句 一个重要的事情要注意的是“pip install tsne”会产生错误。 不建议安装“tsne”包。 t-SNE算法可以从sklearn包中访问。 • 超参数调试 •代码 以下代码引自sklearn网站的sklearn示例。 • 执行时长 PCA结果图（时长0.01s） t-SNE结果图 9.何时何地使用t-SNE？ 9.1 数据科学家 对于数据科学家来说，使用t-SNE的主要问题是算法的黑盒类型性质。这阻碍了基于结果提供推论和洞察的过程。此外，该算法的另一个问题是它不一定在连续运行时永远产生类似的输出。 那么，你怎么能使用这个算法？最好的使用方法是用它进行探索性数据分析。 它会给你非常明确地展示数据内隐藏的模式。它也可以用作其他分类和聚类算法的输入参数。 9.2机器学习竞赛爱好者  将数据集减少到2或3个维度，并使用非线性堆栈器将其堆栈。 使用保留集进行堆叠/混合。 然后你可以使用XGboost提高t-SNE向量以得到更好的结果。   9.3数据科学爱好者 对于才开始接触数据科学的数据科学爱好者来说，这种算法在研究和性能增强方面提供了最好的机会。已经有一些研究论文尝试通过利用线性函数来提高算法的时间复杂度。但是尚未得到理想的解决方案。针对各种实施t-SNE算法解决自然语言处理问题和图像处理应用程序的研究论文是一个尚未开发的领域，并且有足够的空间范围。 10.常见错误 以下是在解释t-SNE的结果时要注意的几个点： 1.为了使算法正确执行，困惑度应小于数据点数。 此外，推荐的困惑度在（5至50）范围内 2.有时，具有相同超参数的多次运行结果可能彼此不同。 3.任何t-SNE图中的簇大小不得用于标准偏差，色散或任何其他诸如此类的度量。这是因为t-SNE扩展更密集的集群，并且使分散的集群收缩到均匀的集群大小。 这是它产生清晰的地块的原因之一。 4.簇之间的距离可以改变，因为全局几何与最佳困惑度密切相关。 在具有许多元素数量不等的簇的数据集中，同一个困惑度不能优化所有簇的距离。 5.模式也可以在随机噪声中找到，因此在决定数据中是否存在模式之前，必须检查具有不同的超参数组的多次运算结果。 6.在不同的困惑度水平可以观察到不同的簇形状。 7.拓扑不能基于单个t-SNE图来分析，在进行任何评估之前必须观察多个图。   参考资料 [1] L.J.P. van der Maaten and G.E. Hinton. Visualizing High-Dimensional Data Using  t-SNE. Journal of Machine Learning Research 9(Nov):2579-2605, 2008 [2] Jizheng Yi et.al. Facial expression recognition Based on t-SNE and AdaBoostM2. IEEE International Conference on Green Computing and Communications and IEEE Internet of Things and IEEE Cyber,Physical and Social Computing (2013) [3]  Walid M. Abdelmoulaa et.al. Data-driven identification of prognostic tumor subpopulations using spatially mapped t-SNE of mass spectrometry imaging data. 12244–12249 | PNAS | October 25, 2016 | vol. 113 | no. 43 [4]  Hendrik Heuer. Text comparison using word vector representations and dimensionality reduction. 8th EUR. CONF. ON PYTHON IN SCIENCE (EUROSCIPY 2015)   结束语： 看完这篇文章，相信你一定很想去进一步探索t-SNE算法并使用它。如果你有使用t-SNE算法的经验，欢迎给我们留言分享~ 原文链接： https://www.analyticsvidhya.com/blog/2017/01/t-sne-implementation-r-python/  【今日机器学习概念】 Have a Great Definition "
203,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656445&idx=2&sn=9a70679460a96a26287d284c4a6ccd49&chksm=bd4c376e8a3bbe78189a63d37194b9919de09bad90b69dbc7d137514ae20a799890bae298c82&scene=27,IT人的八大修炼神器,看到2018年的KPI，你是否感到崩溃？在这个充满竞争的时代，你需要用最有效的方式，学习最有用的知识，来提高自身技能。小编特意为大家准备IT人的八大修炼神器，推荐能帮助我们提升技术的公众号，欢迎大家关注，吸取有价值的知识技能！ 51CTO官微 51CTO官方公众号——聚焦最新最前沿最有料的IT技术资讯、IT行业精华内容、产品交流心得。本订阅号为大家提供各种技术资讯和干货，还会不定期举办有奖活动，敬请关注。 大数据文摘 成立于2013年7月，专注数据领域最新资讯、精品案例、一线技术，已成为数据行业最有影响力的新媒体，致力于打造精准数据分析社区。团队成员是一群对数据充满激情、有能力、乐于分享的专业人员、欢迎你来看看不一样的大数据。 程序员大咖 为程序员提供最优质的博文、最精彩的讨论、最实用的开发资源；提供最新最全的编程学习资料：PHP、Objective-C、Java、Swift、C/C++函数库、.NET Framework类库、J2SE API等等。并不定期奉送各种福利。  程序员小灰 程序员小灰，一群可爱的小仓鼠用漫画的形式讲解技术问题，轻轻松松学会各种算法和Java基础知识。 数据与算法之美 人工智能，深度学习，用大数据思维解决不可能的问题！数据与算法之美，15 万数据爱好者的聚集地，每日掌握一点数据技巧，让你在2018年成为数据大神。 架构师小秘圈 架构师小秘圈，聚集10万架构师的小圈子！不定期分享技术干货，行业秘闻，汇集各类奇妙好玩的话题和流行方向！关注即可领取2T架构师教学视频！ 运维帮 运维帮是一个致力于互联网技术分享和交流的社区。成功举办过多次技术沙龙，每场沙龙都是爆场。订阅号每篇文章都是技术干货，是技术人获取知识的最佳途径。维护人南非蜘蛛一直坚信技术可以让生活更美好。 硅发布 硅发布（id：guifabucom）：科技中心硅谷又出现了什么好玩东西和创新模式？我们来给你答案。 【今日机器学习概念】 Have a Great Definition 
204,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656445&idx=1&sn=f184c62943ca387a7d86bc95250f23e4&chksm=bd4c376e8a3bbe780c32f741396cd1bfe225c98d1bb76d7e0fa42ffbb85f38c0c801a8e2373b&scene=27,无人车通道三年后建成？这是一份Lecun点赞的新技术应用时间表,大数据文摘作品 编译：修竹、吕征达、王梦泽、笪洁琼、yawei 人们往往会低估新技术的概念从被验证到技术真正投入使用所需要的时间。这是预测人工智能未来七宗罪的第七罪。 “人类下一次登陆月球的时候将借助于众多人工智能和机器学习系统。” 这是本文作者（ @rodneyabrooks） 最近在推特上做出的一个有趣预测。 Rodney 是一个理性主义者，他认为很多炒得火热的技术在商业运用上会遇到不小的阻碍，而研发周期无限加长，他在本文对无人汽车、超级高铁和人工智能做了相对保守的预测。但他又是一个乐观的技术信仰者，基于他对科技的深刻理解，他相信很多想法是可以在未来50年内慢慢实现的，他给出了一个实现时间轴。我们来看看关于未来他都说了什么？在文末，作者也给出了他做出预测的理论依据。 很多AI研究领域的大咖，包括YannLeCun，在看完此文后表示基本完全同意， YannLeCun指出，他不太赞同的是， 在建模中他更倾向于“监督学习”： 我同意文章中的几乎所有内容，除了我会用“监督学习”来代替每个实例中的“深度学习”。 深度学习（装配参数化的功能模块并通过基于梯度的方法对其进行优化）是否会消失？ 有人可能会说蒸汽机将在20世纪初消失。它们并没有消失，但即使消失，热机的整体概念也不会消失。深度学习就像热机，不会像蒸汽机。 对于所有新技术的出现都会有人预测这些技术会给人类带来什么好处，或者什么坏处。我观察到的一个主流现象是，人们往往会低估新技术的概念从被验证到技术真正投入使用所需要的时间。我曾指出这是预测人工智能未来七宗罪的第七罪。 在过去几个月，我一直在对当下炒作人工智能（AI）和机器学习（ML）泼冷水。但是我不并认为我是一个技术悲观主义者（techono-pessimist），相反，我自认为是一个技术现实主义者（techno-pessimist）。 新的一年到了，对未来一年将会发生什么有许多的预测。我也想利用这个机会自己来做一些预测，我的预测并不仅仅涉及到来年，而是关于未来的32年。 我用三种不同的方式指定日期： NIML（日期）：在我的有生之年，也就是直到2050年1月1日。 NET（日期）：不早于这个日期。 BY（日期）： 到这个日期。 有时我会对一个预测同时给一个NET日期和一个BY日期，因为我相信这个事情会在这个时间段内发生。 下面表格中的前三项都是关于飞行汽车的。我很确定真正能够驾驶的飞行汽车在行驶过程中基本上是自动驾驶的，因此它们可以被划分为此类。称之为飞行汽车，就是一种交通工具，可以去往任何汽车可以到达的地方。否则的话就不是汽车了。 对自动驾驶的预测 时间 说明 任何有经济实力的美国居民都能购买飞行汽车 2036 很有可能在2050年前不会发生 飞行汽车的数量占美国全部汽车的数量的0.01% 2042 根据现在美国汽车总量，飞行汽车的数量将会达到26000台。 第一条只有真正无人驾驶模式才能行驶的高速公路专用车道 2021 这有点像现在的HOV车道。我打赌会像旧金山和硅谷之间101国道最左边的车道那样（反正最近都被超速的特斯拉给占领了）。人们在进入专用车道之前手必须放到方向盘上。 一条专用车道，汽车可以以超越人类被允许的最快速度行驶，还能保持很好的通讯。 2024 美国一个主要城市提供首家无人驾驶“出租车”服务，有专门的服务点可能受限于天气和时段 2022 服务点并不是停车位，而是像公交车站那样有专用用途。 美国10个主要城市会提供上述“出租车”服务，并且在其它时段或地点由司机来驾驶。 2025 一个关键的预测，当传感器足够便宜时，使用有司机的汽车而不用有传感器的汽车仍然会有经济收益。 美国最大的100座城市中的50座会提供上述“出租车”服务。 2028 这将是个非常缓慢的开始及推进过程。指定的乘降点可能由多个出租车服务提供商共同使用，他们之间通过沟通来安排车辆进出。 美国一个主要城市出现区域受限的专用无人驾驶包裹派送运输工具 2023 该区域必须足够宽敞以便其它司机能够绕过停着的车辆。 一个(盈利)停车库，在那里，一些品牌的汽车可以随时离开，并在入口处被收录，然后他们可以实现被保护的同时停在单独自由环境里。 2023 停的车越多经济效益越高，并且需要汽车与车库基础设施进行交互。 美国一个主要城市提供即使在受限区域可以随意接放乘客的无人驾驶“出租车”服务。 2032 Uber，Lyft以及传统出租车行业如今就能做到。 在纽约格林威治村无人驾驶出租车服务可以在马桥港所有街道上运营 2035 除非在那之前禁止在那些区域里停车或者人工驾驶 一个主要城市禁止在城中重要区域停车或者有人驾驶汽车，因此无人驾驶汽车在这种区域不受约束。 2027 这将是无人驾驶汽车走向潮流的起点。 美国大多数城市的市中心要遵守这样的规则 2045 电动汽车销量到达美国汽车总销量的30% 2027 美国电动汽车的销量占总额的100% 2038 个人所有的汽车可以降到地下的托盘上并以超过100英里每小时的速度在地下到达另一个位置。 NIML 可能会有一些小的示范项目，但也仅是些示例，而不是真正可行的大众市场服务。 装备有某种车祸解决方案的汽车第一次卷入到一场真正的事故中。 NIML 回想一下，电影“我，机器人”里有个相似的情节：一场车祸后，机器人救下威尔史密斯所扮演的角色，而没能救下小女孩。 同时，没有飞行执照，但也许接受过几个小时特殊训练的人，能够身着适合在办公室穿的普通衣物跨越100英里，其中绝大部分旅程是在空中。这并不需要事先安排行程，也不需要特殊的计划，仅需类似于智能手机中的APP的地图应用来获得前往目的地的路线。换句话说，除了一点点的训练以外，就像普通人驾驶汽车一样跨越100英里。 接下来我们来谈谈自动驾驶汽车，或者叫无人驾驶汽车。 对于我来说，无人驾驶汽车和普通汽车的差别并不仅仅是在于没有人类来驾驶。它们是完全不同的东西，有着不同的使用模式和适应世界的方式。 不用马拉的马车并不只是简单的把拉车厢的马替换掉。还要全新的用于铺路的基础设施，全新的所有制模式，不同的使用模式，完全不同的燃料和维修程序，不同的车主死亡率，不同程度的便利，并且最终产生了全新的城市结构。 最普遍的说法是无人驾驶汽车将轻易地取代人类驾驶的汽车。而我认为这根本不会发生。相反，我们可能将会在城市内设置无人驾驶汽车专属车道——限制哪些地方无人驾驶汽车可以去，哪些地方有人驾驶汽车可以去，乘降站灵活性标准的改变，停车规则的改变以及总体上对城市的各种各样的增量式修改。 但是我们先来讨论下无人驾驶汽车的接纳程度。正如我在博文“七宗罪”指出的，1987年ErnstDickmanns和他的慕尼黑联邦国防军大学团队，让他们的自动驾驶汽车以每小时90千米的速度在一条高速公路上行驶了20千米。车中当然有人但是并没有控制方向盘。过去的30年里研究人员一直在提升汽车在公路上行驶的能力，不过更多的是关于驾驶，很少有关于人车交互，人们上、下车，与其它服务或限制的交互以及车中有非驾驶乘客的情况。这些都很重要。 从某个角度来看，尽管研究工作仅局限在问题的一小部分上，但是进展依然十分缓慢。 无人驾驶汽车的采用仍然遥遥无期。 传感器的价格还需进一步降低，并且所有关于如何使用汽车以及如何操作提供给乘客的界面还需要制定，更不用说在什么样的实际监管和责任环境下它们才能投入使用。在某些约束下，这些问题终将被解决。但肯定要比预期慢得多。 对于无人驾驶汽车行业生存能力的考验将是在于当它们不仅出现在测试或者示范里，而是无人驾驶出租车的车主或者拼车服务或者无人驾驶汽车停车场真正赚到了钱。这只会在有限的地区和市场里逐渐的发生。下面我的里程碑式的预测不是关于无人驾驶汽车的示例的，而是关于可行并可持续的行业的。没有它们，无人驾驶汽车的部署将永远不会成功。 我认为无人驾驶汽车如何被采用的事实是基于它们的某些活动范围受限于某些限制（比如限制围栏），并且附近没有有人驾驶的汽车。此外，无人驾驶汽车的应用最初应该被限制在特定的城市甚至是城市内的特定区域，还有可能是特定的时段以及特定的天气条件。并且很有可能在很长一段时间内，提供流动服务的无人驾驶汽车（像Uber和Lyft那样的）仅被允许在某些时段使用无人驾驶模式，在其它时段内需要雇佣人类司机。 看过我关于机器人技术和人工智能博文的人会知道，我对现实世界中事物大规模部署的快速程度比许多拉拉队长和恐惧传播者们所相信的还要乐观。我的预测被这种乐观影响了。其中一些预测是关于公众对人工智能的看法（人工智能是近三年在这个领域上有发生变化的最大一件事），还有一些是关于技术的想法以及部署。 预测【人工智能及机器学习】 日期 备注 关于深度学习极限的学术争论 在2017年前 这已经发生了，并且进程还会加快。 技术媒体开始报道深度学习的极限以及游戏强化学习的极限 在2018年前 大众媒体开始报道深度学习的时代已经结束 在2020年前 风投们指出，投资若想获得汇报，需要的不仅仅是“X+深度学习” 2021年后 我在这里有些愤世嫉俗，事情在什么时候完全改变当然无法知道。 普遍认同的在人工智能领域出现的“下一件大事”会超越深度学习 2023年至2027年之间 不管结果如何，已经有人在朝着这个方向努力，并且已发表了相关论文。在2023年之前会有很多关于这个题目的声明，但没有一个会成功。 媒体和研究人员通常在所谓的“图灵测试”和阿西莫夫的三定律（人工智能和机器学习进程的有效措施）外成熟起来 2022年前 我真的希望会这样。 普遍可用的灵巧的机械手 2030年至2040年之间（我希望） 尽管有一些令人印象深刻的实验室演示，但在过去的40年间，我们实际上并没有看到广泛使用的机械手或末端效应器有任何的改进。 可以在任何一个美国家庭里畅通无阻的机器人，台阶，杂乱的家具间或者狭窄通道等 实验室产品：2026年前 对人类来说很简单的东西对机器人仍是很困难的。 昂贵的产品：2030年前 负担得起的产品：2035年前 能够给老年人提供多种身体上的帮助的机器人（例如上下床、洗衣服、使用马桶等），而非仅是一个点解决方案 2028年前 在此之前可能会有点解决机器人，但不久之后老年人的房间会被堆满机器人。 完成最后10码派送的机器人，从汽车到房屋，把包裹放到前门 实验室产品：2025年前 部署系统：2028年前 一种会话代理，既可留存长期的上下文，并且不会轻易陷入可识别及重复的模式 实验室产品：2023年前 部署平台已经存在（例如，Google Home和Amazon Echo），这将会是从实验室产品到广泛部署的快速通道。 部署系统：2025年前 一个在鼠标级别上持续存在的人工智能系统（没有一天是另一天的重复，因为它现在是面向所有人工智能系统的） 2030年前 我需要用一篇全新的博文来解释这个… 像狗一样聪明、细心、忠诚的机器人 2048年前 这比大多人想象的要困难得多——许多人认为我们已经研究出来了，但我觉得根本就没有 对自己的存在有真实想法或是以一个六岁儿童理解人类的方式理解人类存在的机器人 2050年前 这些预测看起来似乎有些杂乱随机，它们确实是。但这就是机器人技术、人工智能和机器学习的进步方式。它不会像一般智力，可以突然完成人类（或猩猩）能做的各种事情。这将花费很长的时间才会出现一些简洁的解决方案。 建立人类水平的智力和物理性能是非常困难的。在过去五年有一些小的突破性的进展，许多人认为工作已经完成了，而实际上在这方面的进展还不到1%，还没有真正的知识理论来指导如何达到5%。我编造了这些百分比也不能证明它们是对的。 以下是我对太空旅行的预测，不像我希望的那样乐观，但我认为比较现实。 预测【太空】 日期 备注 下一次私人公司的载人（测试飞行员/工程师）亚轨道飞行 2018年前 为这些飞行付费的少数客户 2020年前 开通每周定期航班 2022年至2026年之间 轨道飞行的定期付费客户 2027年前 俄罗斯向国际空间站提供付费航班，但只有8个这样的航班（7个不同的游客），他们现在被无限期的推迟 下一次用美国助推器把人送入轨道 2019年至2021年、2019年至2022年（2家不同的公司） 当前的计划是2018年完成 两名付费客户通过猎鹰号发射，绕着月球环行 2020年前 最近的预测是在2018年四季度，这不可能发生 供人类日后使用的火星陆地货物 2026年前 SpaceX说会在2022前完成，我认为2026年是比较乐观的，但它可能会被推动成为一个可以完成的声明，而不是紧迫的实际原因 火星上的人类使用先前降落在火星上的货物 2050年前 抱歉，这比每个人期望的时间要长 火星上的第一个永久人类殖民地 2050年前 如果在那时真的发生，这对人类来说是不可思议的。它会真正激励我们所有人 一小时左右在地球上的点到点运输（使用BF火箭） NIML 如果没有一些重大新突破这是不会发生的，然而目前没有任何迹象 两个城市之间的超回路列车服务 NIML 我不禁想起，Chuck   Yeager把水星计划描述成“罐头里的垃圾邮件” 我将尽可能准确地描述我的预测和时间点。但实际上精准定义我所预测的事情几乎不可能。不过我还是想试一试的。 最近有个经历让我意识到，当受到挑战时，人们会非常努力地尝试着维持他们先入为主的技术和技术带给人类的财富。我在推特上发布了以下消息（@rodneyabrooks）： 人类下一次登陆月球的时候将借助于众多人工智能和机器学习系统。 上一次我们登陆月球的时候，并没有AI或者ML。 这条推特讲的是，我们需要记住尽管AL和ML在今天非常强大有用，但这并不意味着它们是唯一的方法，也并不代表世界上的一切突然间都以某种神奇的方式发生了改变。 有一条被转发了无数次的评论指出，卡尔曼滤波（Kalman filtering）被用来追踪航天器（阐述完全正确）并且使用贝叶斯更新（阐述完全正确），因此卡尔曼滤波是机器学习的一个实例（完全不合理的推论），所以机器学习已经被用来登月了（基于不合理结论的有效推理，结果就是完全的错误）。这段时间（实际上自从1959年Arthur Samuel提出机器学习以来，详情见我关于ML的博文）当人们提起机器学习，通常他们的意思是以相同的方式使用样例，引出对某些概念的通用表示，后面可以用这些概念基于输入和所保存的学习材料选择标签或行为。 卡尔曼滤波使用从特定过程获得的多个数据点得到对数据真实含义的良好评估，在这期间它并不保存任何东西用来在未来某些时候处理类似的问题。所以，这不是机器学习。不管你多么信仰机器学习是所有技术进步的关键，但上次确实没有用过机器学习来登月。 这就是为什么我要讲清楚我的预测是什么意思。毫无疑问，我将来要反驳很多人，这些人将会指出一些我预测还不会发生的事情已经发生了。我猜人们肯定会这么说！ 制造电动汽车和可回收火箭是简单的。制造飞行车或者超级高铁系统是困难的。 在过去一个多世纪里，汽车一直被大量生产直至现在随处可见。如果你想制造电动汽车而不是汽油车，你不必发明太多的东西，也不必考虑如何去大规模部署。 雨刮器、刹车、车轮、轮胎、转向系统、可升降窗户、汽车座椅、底盘等等汽车用品的生产工艺已经超过100年了，甚至已有超过20年大规模数字化驱动列车生产的历史。 要在合理范围内大规模制造有竞争力价格的电动汽车，你需要非常聪明并且资本充足。但是你并不需要去改变很多东西，从头做起。对大部分汽车来说，有很多人为了这些零部件工作了几十年，拥有很多制造零部件和装配的专业制造技术。 虽然可回收火箭听起来很具有革命性，但它也是已经有现有技术和经验做铺垫的。如今所有液体燃料火箭的主要部件和功能都归功于韦纳•冯•布劳恩（Wernher von Braun）为希特勒制造的V-2火箭。 这是一种由高流量涡轮泵（580马力）驱动的液体，用燃料冷却发动机的部分部件并携带自己的液态氧，所以它可以在大气层之上飞行。这种火箭在75年前第一次被制造出，其后它被大量生产，在两年内压榨奴隶工生产了5200个。 从那以后，全世界出现了超过20个不同的液体燃料火箭系列，有一些有超过50年的具体操作使用，这些系列涉及上百种不同的配置，测试了许多不同的参数和权衡取舍。有50年历史的联盟号火箭（Soyuz rockets）所有的发射是靠燃烧20个液体燃料推力仓。Delta系列中，Delta IV配置有一个“Heavy”的变体，在水平线上有三个基本相同的核心，这些核心都是Delta IV早期单核的第一阶段。 自从20世纪50年代以来，使用喷气发动机推进器在地球上软着陆的技术都是劳斯莱斯（Rolls-Royce）的“飞行试验器（flying bedstead）”，后来有鹞式战斗机（Harrier fighter jet）垂直起降技术被大规模使用。从1969年，在没有大气层的情况下下，垂直着陆的火箭发动机被用于载人登月。 今天的猎鹰火箭（Falcon rocket）在返回发射场或恢复驳船到软着陆是使用栅格翼来引导第一阶段的。这些最初是在20世纪50年代由谢尔盖•贝罗特塞夫斯基(Sergey Belotserkovskiy)发明的，从20世纪70年代开始被用于许多导弹，包括弹道导弹，制导炸弹，巡航导弹和联盟号载人太空舱的紧急逃生系统。至今为止已经有不计其数的资金投入到火箭开发上，由此获得了许多可用的技术、丰富的知识和大量的飞行经验。 以上并不是说大规模发展电动汽车或可回收火箭不是一个伟大的发明，只是说它建立在大量前期成果的基础上，更有可能获得成功。这些前期成果提供给后人经验，对将要出现的大部分问题都有解决方案。所以看似革命性的概念可能来自于长久艰难卓绝的进化思想，以及去实现它们的勇气和决心。要预估这些新科技成功其实不难，大家都看得出来。然而对于某些全新的想法，就很难说是否真的能实现了。 自从20世纪50年代以来，一直都有项目致力于解决核聚变反应堆发电的应用问题。我们知道持续的核聚变是“有效”的，因为这是太阳和其他星体的发光原理。65年前，伴随着第一颗热核弹“Ivy Mike”的爆炸，人们首次生产出了短时间尺度上的核聚变。但是我们还是没有想出如何使核聚变在做炸弹之外具有更实际的用途，我也不认为会有很多人相信任何关于规模化聚变发电的预测日期。这确实是一个难题。 超级高铁这一概念吸引了一大批创业公司和资本家，但是在概念上还没有一个被证实，更不用说规模化运行了。超级高铁需要的汽缸可运行数百英里，包括许多在外部气压下以每小时数百英里的速度加速的胶囊座舱，同时也包含人类肉体。所以除了研究如何开发超稳定汽缸外，还有许多细节的问题需要探索。 挑战之一就是如何密封胶囊座舱并在旅途中提供完整的自主生命支撑，而且胶囊舱必须能稳定通过它们不需要停的站点，所以车站需要选择性的密封隔离胶囊舱通过的管道同时允许胶囊舱停在此站的乘客可正常进入和离开。我们需要有特定的程序解决一个胶囊舱被堵在离最近车站100英里的地方时的情况。即使胶囊舱位于一个非常好的法拉第笼（Faraday cage）中，我们也需要跟胶囊舱保持通讯。 为了乘客的安全，需要有适合的座椅和安全条例。为了保证乘客在无窗的胶囊舱中超高速飞行时保持清醒和舒适，需要考虑到用户体验。接下来还有航线权、地震保护、解决由于地球构造板块的正常平滑变形造成一年内沿线路引发的一厘米左右的漂移而导致的汽缸变形问题。后面还有定价模型、投保、如何与乘客个人保险相互作用等等。 针对超级高铁的每一个方面都需要开发很多很多新的技术和设计。没有一个是之前存在、可借鉴的。截止到今天，没有一个是被证明过的，甚至没有被列举过。这需要很长时间来解决所有问题并且建造一个稳定的系统，还需要完成所有部件的工程需要。而且向乘客销售这些无窗高速系统的车票将会是一个很难的心理建设过程。 所以，即使所有技术难关被攻克，挑战依然层出不穷。所以虽然在未来32年中可能还有一些有意义的证明，但我可以很自信地说在那个时间段内将不会有商业上可行的超级高铁乘客运载系统。 使用框架预测各种技术创新的时机。如果某些事情还没有在实验室中被证明，即使物理学上说它是好的，我认为离实现还有很长很长的距离。如果只在原型机中演示过，那仍然有较长一段路要走。如果已经有几个版本被大规模部署过，现在要做的只是升级的话，那我认为很快就可以实现。但是话说回来，如果没有人想要采用它，那么无论技术人员在开发过程投入了多大的热情，它的发展速度都会无比缓慢。 新技术的普及要花费更多时间，远比人们的预期时长要久。因特网的初始版本使用32位的地址，只能让所有的联网设备瓜分仅有的40亿个地址，此时使用的协议被称为IPv4，即互联网协议版本4。但是在20世纪90年代早期，人们意识到那些即将联网的设备（不仅是个人设备，还包括很多其它的东西比如电表、工业传感器、交通传感器和控制器、电视机以及灯控装置等等等等。。。）很快会将所有的地址空间用尽。到了1990年，一个新的协议被定义——IPv6，即互联网协议版本6，把地址空间从32位增加到了128位，允许更多设备入网。 自1996年以来，指定过好多用IPv6替代IPv4进行全网通信的日子。在2010年，这个目标日期定在了2012年。而到了2014年，几乎99%的网络通信仍然使用的是IPv4，许多智能的边缘系统可以在40亿地址空间中塞入数量超过40亿的设备。截至2017年底，各种网络通信流经IPv6的流量从2%到20%不等。 IPv6并不是存在技术性瓶颈使得难以被采用，恰恰相反，随着想要联网的设备数量的增多，许多新奇的创意与变通让人能够继续使用IPv4而不是使用IPv6。根据在本文中也用于预测的试探法（设备替换率、技术解决方案的成熟度、对其提供的实际需要等），我原以为IPv6会在2010年前后普及。我对此过于乐观了。 SpaceX在2011年四月首次公布了他们的猎鹰重型（FalconHeavy）火箭，于同年六月在加利福尼亚的范登堡空军基地（Vandenberg AFB）建设发射台，并预计在2013年完成首次发射。而在2017年的12月28日，该火箭才首次被移入发射台，而这个发射台是佛罗里达州肯尼迪航天中心（Kennedy Space Center）的39A发射台。 火箭预计2018年才会发射。研发时间从两年延长到了七年。谁知道还会不会拖更久。 实施落地总比预想得要久，现实就是如此。 【今日机器学习概念】 Have a Great Definition 回复 “ ”加入我们 
205,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656437&idx=1&sn=64d27b9a0cdcb3de55b0b44259d4200a&chksm=bd4c37668a3bbe70f3f58bf65458d467a81787a2eaa7d7ebab0253a19f6aca17780be22850b1&scene=27,谷歌、苹果、Uber等科技巨头们，为何纷纷暂缓研发自动驾驶,"大数据文摘作品 编译：元元、Saint、亭八 想要实现“不再有人因为操作失误而引发车祸”这样的乌托邦，远比想象中的要难。不可否认，我们离自动驾驶还有很长的一段路要走。 2015年，谷歌的自动驾驶汽车一共发生了十一起车祸，虽然总体数量并不算多，谷歌也声称：自动驾驶汽车的传感器和算法如果从统计学角度来讲会比人更加细心。另外则是谷歌会不断完善自身算法，从而能够从容应对周遭人类司机做的蠢事。总之，事故并不是由于汽车本身的原因造成的。 人类司机(紫色模型)猛得向右转弯 2016年12月12日，谷歌发推文称暂缓自动驾驶的研究。次年3月26日，Uber自动驾驶测试项目也暂时中止。究其原因，巨头们暂缓研发自动驾驶的脚步，自动驾驶的测试过程中发生过多次事故占了很大一部分的因素。 另外，在美国亚利桑那州Tempe，Uber的自动驾驶汽车发生了撞车事故。在行驶过程中，另一辆汽车没有为Uber的无人驾驶汽车让路，导致其撞向了该车的一侧。随后，Uber中止了亚利桑那以及匹兹堡的无人驾驶测试。 Uber自动驾驶汽车发生撞车事故 Elon Musk曾经称： 现如今无人驾驶汽车的进展是每天300多万英里（500万公里）。 我们很多人都在盼望着未来有那么一天，不会再有人为操作失误而引发惨烈的车祸。当大科技公司或者汽车公司为这个乌托邦式的愿望投入了巨大的金钱和脑力之后，他们发现： 对于自动驾驶，我们要知道一件事情： 因为研发自动驾驶的硬件和汽车本身并不是唯一重要的事情，想要达到自驾的目标，还有很多很多技术的问题需要解决，有了软件之后转身就能造汽车的说法无异于痴人说梦。 但不可否认的是，我们在自动驾驶组件方面确实有了很大的技术进步。比如： 大规模实时建模： Waymo公司出了一款类似于魔兽世界的软件——Carcraft,其功能是可以在任何部署了Waymo/Google自动驾驶汽车的城市进行25000 种自驾模拟。这种级别的测试在之前从来没有出现过，大量的模拟会让我们在模拟器中达到第4级的水平(完全自驾)，离商用自动驾驶汽车的路上更进了一步。 廉价的LiDar组件： 在大多数的自动驾驶汽车上面，会经常看到一个造型滑稽名叫LiDar的组件，它的全称是光检测和测距(LiDar, Light Detection and Ranging)，其作用和名字一样，是自动驾驶汽车搜集数据的主要组件。一般一个商用的LiDar系统售价为1000至70000美元，这个成本相对于任何汽车生产商来说都是非常昂贵的。紧接着，麻省理工学院的光子微系统研究组发出声明：他们研制出来了缩小版的LiDar，其体积比硬币还要小，造价仅为10美元。同时，Velodyne公司称他们可以将子系统的成本减少至50美元！唔……摩尔定律在这个事情上面充分发挥了作用。 数据搜集和机器学习规模的数据分析： 想要实现自动驾驶并不是让汽车遵从人设计的规则，而是用训练数据构建机器学习模型，让系统根据路况自己作出驾驶决定。现如今每一辆在路上飞驰的Tesla汽车都在学习如何自主导航穿过人群拥挤的道路，而每一辆车多开一英里就会多获得一些综合信息，信息会直接传送到中央数据库，以便于机器学习方法可以获得实时更新，从而提高自动驾驶技术，接触到更多的真实驾驶模拟。 看似遥远实际很多的案例： 在美国训练一辆自动驾驶汽车会很快就能完成，因为道路上有清晰的强制性规则和条例。虽然偶有破坏规则造成交通事故的事情发生，但大多数人们都还是遵守交通规则的。 不过，在很多地方情况又会变得不一样。比如在尼日利亚，要么是没有规则，要么是破坏之后并没有后果。也有一些更加复杂的情况，比如缺乏结构化的道路以及数据库更新的时候道路情况发生了变化等等，这需要大量的模拟训练从而可以考虑到所有的可能性。 技术挑战： 没有规则的世界需要复杂性的技术来支撑。我们需要在车内建立多余的机械系统，以确保汽车在发生突发情况是能够及时响应。但这个事情并不仅仅与汽车有关，还关系到人本身。因为人类是难以预测的，现如今的技术手段还没有先进到可以捕捉另一辆汽车驾驶员的身体状况。未来，在所有汽车实现自动驾驶的过程中，将会因此出现很多奇葩的事情。 硬件依然十分困难： 特斯拉汽车的生产以及许多配套软件的硬件公司的倒闭，是人们忘记了发布硬件的难度，我们认为“将先进的软件结合到材料正快速变化的硬盘中就可以获得成功”的想法是那么的幼稚，硬件这个难题依然困扰着我们。 如同微软的智能助手软件Cortana应用于尼桑和宝马汽车上、谷歌母公司Alphabet旗下的自驾软件公司Waymo助力本田汽车一样，软件公司的最佳策略是为自驾汽车开发操作系统（CarOS)。 以苹果公司为例，苹果拥有iPhone手机以及AppleWatch手表等原始的便携式远程信息处理设备，如果苹果开发自动驾驶汽车操作系统，这些设备会为其提供巨大的帮助。无论汽车在哪里、状态如何，这些信息都会通过设备记录下来，以便于做出更加适合的决定。 而今，iPhone手机已经成为了个人的远程信息处理设备。地图和健康软件记录着我们游览了世界各地，而地图和行驶历史数据则是自动驾驶软件中的两个要素。对于苹果公司而言，开发自动驾驶汽车操作系统可以视为地图和健康软件的自然延伸。 星巴克的地址以及今天还需要完成的步数 据统计，苹果公司已经卖出了10亿部Iphone手机。而最大的自动驾驶汽车公司生产的汽车还没有超过25万辆，订购特斯拉模型3的电动汽车订单虽然已经打破了记录，但最困难的部分还在于其真正交付这些订单。苹果完全没有必要忽视它最热销的产品，去关注另一个资本密集型且不是其核心竞争力的产品。 未来拥有汽车的人或许会变少，但人们还会继续购买iPhone手机，开发自动驾驶汽车操作系统才是苹果公司能够做出的最具战略性的相关举措。一个操作系统可以连接任何品牌的自动驾驶汽车以及驾驶员iPhone上的远程信息系统，那真的是实现了无缝对接。 正如iTunes影响了音乐行业一样，苹果公司也在向自动驾驶汽车行业最优秀的工程师学习，在未来，其自动驾驶汽车操作系统也将会为自动驾驶行业带来一些影响： 点菜模式。 当需要汽车的时候，可以用iPhone手机预约任何租车提供商的汽车。 平衡行业竞争，加速共享模式。 任何拥有自动驾驶汽车的人不需要中间商就可以出租自己的车，并通过Apple Pay获得报酬。 另外，自动驾驶汽车操作系统还可以和苹果智能家居平台Homekit相结合，为苹果客户提供家庭和车辆无缝连接的便利体验。 所以，苹果这么精明的公司是不会选择“自主开发一整辆自动驾驶汽车并承担相应的商业风险”这个错误决策的，其想要在未来和Amazon(Alexa)、Alphabet、Facebook等科技公司争夺战场上的领先地位，开发自动驾驶汽车的操作系统和相连的家居系统才是巨头们更合理的策略。而且，这也是巨头们投资少但又能发挥公司本身优势最好的策略，这个策略唯一的问题也就是谁能捷足先登，开发出足够强大且让汽车生产厂商倚重的操作系统了。 未来，预计会出现3-4家平台的操作系统可供厂商们选择，而苹果并购特斯拉的事情也很有可能出现。至于最近在2018CES年展上面出尽风头的中国军团，只能说：路漫漫其修远兮，道阻且长。 【今日机器学习概念】 Have a Great Definition "
206,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656437&idx=2&sn=93a1da934c247f7a589692921dc37a0b&chksm=bd4c37668a3bbe703118eb612ed97bbdec376c4282574dbdfdd2d5a0886924e35648199f4ca5&scene=27,对话微信智聆团队：坐拥近10亿用户，微信如何用好语音这一入口？,大数据文摘作品 记者：谭婧 如果说PC时代的搜索引擎成就了谷歌，造就了这家当今世界最大的数据公司，那么随着智能产品的普及， 而在今天，没有哪个入口能比得上月活用户即将达到10亿的微信。 亚马逊Amazon Echo、苹果Apple HomePod、谷歌Google Home “ ”微信智聆技术团队告诉大数据文摘记者。确实，相比用“手”和“眼睛”，以及其他以手机和电脑为媒介的操作，“语言”无疑是人类最自然的交互方式。 纵观海内外科技巨头，多数通过“智能音箱”这一产品作为切入口。然而目前，在复杂的现实场景中，智能音箱的交互体验依然有限，比如调节空调温度的时候，向智能助手喊话可能还不如直接动手按按钮来得方便。 创新工场人工智能工程院副院长王咏刚也曾公开表示，仅仅是智能音响的唤醒词背后，就蕴含有巨大的技术含量 ： “如果要把唤醒词做到唤醒成功率70%以上，且唤醒的区间在1米到10米之间，并兼容众多不同的噪音环境，这是一件非常难的事情。对于现在已经发售的智能音响来说，能做到并做好的寥寥无几。 ” 相比而言，在微信中的这一应用就贴合得多。微信中常用的“微信语音输入”、“微信语音转文字”，以及王者荣耀里面的语音转文字功能背后，都由微信智聆团队提供技术支撑。 2017年11月微信正式推出微信智聆，这是微信AI团队基于深度学习理论自研的语音识别技术。为此腾讯准备了五年，在腾讯产品线微信、QQ、游戏、搜索等数十个产品中逐步应用。除了微信端，这一技术还在腾讯的其他产品线发挥了效用，包括腾讯翻译君、王者荣耀。 在1月15日的微信公开课PRO版之后，大数据文摘记者和微信智聆团队聊了聊语音识别技术。 大数据文摘： 语音识别是感知技术这一类里面前沿的技术，许多人看待这个技术的时候觉得语音识别似乎已经被解决了， 微信智聆： 语音识别并不是已经解决的问题，语音识别的最终目标是任何人，在任何环境，用任何风格，无论大声还是小声，无论是正式还是随意，说任何领域的话，都可以被准确地识别出来才算。然而，这个目标目前并没有做到。目前业内比较普遍、成熟的还是环境基本安静、偏朗读方式的语音，这种情况下可达到较高的识别率，基本达到实用。但是，在碰到以下情况的时候，解决得还不够好： (1) 环境嘈杂 (2) 远距离 (3) 重口音或纯方言 (4) 口语现象，说的很快，很随意 (5) 领域很相关，比如涉及到某个专业领域大量专有名词。 技术困难既是机会，更是语音识别赋能社会的机遇。在解决这些问题后，语音识别可走入千家万户与千行万业，真正成为提升社会效率的一个有力工具。 大数据文摘： 近年来，语音识别技术取得了长足的进步，微信智聆的核心技术在哪里? 微信智聆： 我们采用了深度学习神经网络LDNN结构，在解码空间，我们使用了大量数据训练的语言模型来尽可能覆盖更多的语言现象，同时使用了GPU进行推理，大大提升了效率。 大数据文摘： 尽管采用了深度学习的技术，但语音识别技术仍然避免不了错误，而开发者的任务就是使得它能够像人一样，在有错误的时候去进行人机交互，修正错误， 。请问微信智聆如何用这两种技术相互帮助的？ 微信智聆： 目前更多的是通过统计模型在语音识别结果上做一些文本顺滑类的工作，尽可能去保证句子的主干是识别正确的。 大数据文摘 ： 微信智聆： 微信智聆从网络爬取公开数据、从正规渠道购买合法的第三方数据，以及请人来录制生成数据。同时，我们关注数据的覆盖度，包括人群年龄覆盖度（从儿童到老人），噪声场景覆盖度（马路，商场等环境），语言领域覆盖度，口音覆盖度（南北各主要城市口音），中式英文覆盖度（中国人中英混合语言现象）。 大数据文摘： 微信智聆： 目前基本我们采用的是有监督学习的方法，也就是说，数据都是有标注结果的。我们也在尝试一些半监督的方式，比如使用包含字幕的视频文件提取音频来自动训练，以及一些无监督说话人自适应的方法，这也是我们未来的一些规划。 大数据文摘： 曾经有过统计，整个语音识别会分成搜索的速度和做神经网络前向传递的速度，这两个速度的比例，在传统系统里面前向传递的速度约占30%-40%，在各种各样的语言空间搜索的速度大体占60%-70%。据此， ，前向传递在运算过程中占比较大，70%-80%，因此我们采用了CPU和GPU异构计算，将大头运算量放到GPU上完成，可显著提升效率。 【今日机器学习概念】 Have a Great Definition 
207,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656397&idx=2&sn=00147a20774343fb7da952cd3f67dae5&chksm=bd4c375e8a3bbe487f50da67f8fad33d9f4a5418c3f29e254323e87d6d7c2b82add957c1c410&scene=27,调研 | StackOverflow薪水调查：有计算机学位=高薪？不存在的,大数据文摘作品 编译：大茜、高宁、Aileen “除了上帝，任何人都必须用数据来说话。”  我正在构思一篇讨论软件行业内，关于专业程度与薪酬间相关性的文章。而且我已经有了关于专业程度为什么会影响薪酬，是如何影响薪酬，以及专业性产生偏好的猜测。接下来，我唯一需要做的是用数据统计论证。 首先，我拿到了2017年Stack Overflow的调查数据（ ），对其进行清洗，然后插入了一些以前研究中认为能够影响最终薪酬的变量。 数据分析中最棘手的问题之一是明白哪些变量需要测试，而哪些变量不测试，哪些是控制变量。例如，我可以测试“在工作中使用PHP”是否会增加薪水，但如果我没有考虑到受访者的国家，那么我们可能无法证明PHP对薪水的影响程度。 我测试专业分支时，需要去简化数据集并提高对专业分支变化的敏感度。于是，我选择了只用来自美国的专业网页开发人员的数据，然后对比专业的前端和后端开发人员与全栈开发人员的薪水，分析专业程度对薪酬的影响。 分析过程中，我逐步添加了以下变量：经验，教育，网页开发人员类型。然而，分析结果并不理想。我本以为，接受过正式的教育会对工资有正面影响，然而，意料之外的事情发生了。 我本身是一个网页开发人员，负责全栈开发。我一直在想，如果我可以更专业一些，拿到计算机科学专业（ComputerScience，以下简称CS）学位而不是文科的学位，那么我可能会赚更多的钱。而我弟弟拥有CS学位，而我和他的薪水是在两个完全不同的量级上，我只能望其项背。所以我跟自己遇到的每一个对编程感兴趣的人说：CS专业的本科学位是很值钱的，拥有它，你至少能跟别人产生2万美金的永久性薪水差距，而且这还是我的保守估计。 所以你可以想象当我把CS专业与其他专业进行对比分析时，我有多震惊。因为结果居然是：不同专业的毕业生的工资之间并没有显著差异。 我想，“我的分析肯定哪里做得不对”。在第一次分析时，我将CS专业毕业的工程师，数学家和信息技术专业的毕业生都混在一起。显然，CS专业需要被细分成不同的类别。 然后，我又进行了一轮分析。 但结果依旧是：不同专业间没有显著差异。 对美国专业网页开发人员薪水影响因素的线性回归分析 让我详细说说我的分析。 当我把教育背景、经验、网页开发者类型和本科专业考虑在内时， 。 然后，我开始删除一些变量。我想，也许CS专业毕业生通常进入后台程序开发领域。然后，我删除了“网页开发者类型”。 结果是：没有相关性。 我剔除了与教育背景相关的所有影响因子，不考虑是否有本科、硕士或博士学位。结果依然是：没有相关性。 我尝试了几乎所有可以想象到的组合，但依旧找不到CS本科学位和拥有更高薪水之间的显著相关性。 对于CS本科学位与薪水之间缺乏统计相关性，有几种可能的解释。我首先想到的是数据质量不高，这可能是一个不合适的抽样结果，或者有人在撒谎，亦或者被调查者没有完成调查。 这个调查本身确实存在一些问题。例如，实际上只有三分之一的美国专业网页开发人员报告了他们的薪水，而在这些人中，大部分人的薪水都是在9万美元到13万美元的水平。网页开发人员在美国的平均工资约9万美元。所以这里可能有一个偏差，因为只有那些觉得自己的薪水还不错的人，才会在调查中填写他们的真实薪资水平。 然后我对这个假设进行了验证，把低于平均40K美元的薪水都标注为N/A。分析结果打破了以前我们公认的所有关联性，也没有其他新的发现。 另一种可能性是CS专业的本科生毕业后进入网页开发以外的领域，只有一些人零零散散地还留在这里。当然，这个应该不是主要原因。 统计学是一门科学，同时也是一门艺术。对数据进行回归并找到相关性是很容易的，但有时只是总结整个事物的逻辑。在不真实的统计中，统计数字可能传达了虚假的信息。 “世界上有三种谎言：谎言、糟糕透顶的谎言和统计数据。” - 马克•吐温 在回顾第一次线性回归时，我注意到一个问题：有些受访者虽然上了大学，但并没有获得相应学位，而且这个比例竟然高达14％。虽然这个变量并不是最重要的变量，但肯定会对分析带来一定的影响。如果这些从大学辍学的学生中有一些是CS专业的呢？ 然后我新增了两个交互变量：一个是是否获得学士学位，另一个是否获得硕士学位。结果是显著的，而且是高度相关。如此看来，是否拥有CS专业的学位确实会影响薪资水平。 对于影响美国专业网页开发人员工资的影响因素的线性回归：包含CS相关交互变量 事实真的如此吗？对于“攻读CS专业”和“获得CS学士学位”这两个变量，对薪资的影响程度是很相近地，相差不到一千美元。 另一方面，拥有一个CS专业的硕士学位，薪水可能会多一万美元。 所以如果你对网页开发很感兴趣，而且你已经有了CS专业的本科学位，那么你可能要考虑去读一个硕士学位。 转了一圈，终于又回到了我最初的假设-  是否有CS专业学位确实会影响薪水，但是影响程度远远不及我最初假设的2万美元。 事实上，只有大约一千美元左右的差距  - 对于大多数接受薪水调查的开发者而言，这个差距还不到他们总收入的2％。 也许这对我而言是一个打击，因为作为一个加拿大人，在简历筛选时，我们往往更传统一点。或许CS专业学位在我们加拿大还是很有价值的，亦或许在世界上很多地方都是很有价值的。但在美国，是否拥有CS学位似乎对专业的网页开发者的薪水并没有什么影响。 很可惜，本文数据里并没有包括中国。各位读者们，从你们的经验来看，在中国，CS学位是影响工资的关键因素吗？ 【今日机器学习概念】 Have a Great Definition 
208,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656397&idx=1&sn=379bb8bb4b3c6883e2c1d0229356e760&chksm=bd4c375e8a3bbe4805a87312d3174a7a5315235104256388276c37a3366fa08a6c1ab150382d&scene=27,谷歌重磅：不用写代码也能建模调参，Cloud AutoML要实现全民玩AI,"大数据文摘作品 编译：钱天培、龙牧雪 连发三条推特！今天凌晨时分，李飞飞通过一篇博客文章发布了谷歌最新AI产品——AutoML Vision，可以自动设计机器学习模型。 我很荣幸地宣布AutoML Vision面世。无需精通机器学习，每个人都能用这款AI产品定制机器学习模型。这是“AI民主化”的重要进展！ ——李飞飞 这个名为Cloud AutoML的宏大项目浮出水面，或标志谷歌发展的战略转型。一直以来面向机器学习人工智能开发者的Google Cloud，这次将服务对象转向了普罗大众。 今天面世的AutoML Vision是一款提供自定义图像识别系统自动开发的服务。也就是说， 而且，这一切将通过云端完成。 从此以后，一行代码也不用写🌚 除了图像识别，谷歌未来还计划将AutoML服务拓展到翻译、视频和自然语言处理等领域。 谷歌的宏伟愿景由本次发布可见一斑——你只需在系统中上传自己的标签数据，就能得到一个训练好的机器学习模型。 从技术层面来看，谷歌通过 （Transfer Learning）将已训练完成的模型，转移到新的模型训练过程。这样，能够用较少量数据训练出机器学习模型。对于医疗领域而言，这点尤为重要，因为在为罕见疾病和一些特殊案例建模时，往往无法取得足够的训练数据。此外，谷歌还通过learning2learn功能自动挑选适合的模型，搭配超参数调整技术（Hyperparameter tuning technologies） 。 AutoML由控制器（Controller）和子网络（Child）2个神经网络组成，控制器生成子模型架构，子模型架构执行特定的任务训练并评估模型的优劣反馈给控制器，控制器将会将此结果作为下一个循环修改的参考。重复执行数千次“设计新架构、评估、回馈、学习”的循环后，控制器能设计出最准确的模型架构。 在这一过程中，搭建训练模型、调参等种种老大难题都能被自动解决 ，这也将Google Cloud这一新服务与微软Azure ML的机器学习平台区分开。 解决了机器学习的技术门槛后，只要有开发能力，就算不懂机器学习知识，也能通过AutoML打造出一套企业级的机器学习应用或AI应用。 众所周知， ，如果此项服务能够成熟落地，谷歌将无疑在众多云服务之争中开辟一大片新市场。 谷歌云AI研发负责人李佳（左）和首席科学家李飞飞 就在本周，李飞飞曾在新闻发布会上表示：“ 人工智能、机器学习仍然是一个进入门槛高的领域，需要大量专业知识和资源，而很少有公司自己能负担得起这些资源。今天，虽然AI能为企业提供无数的益处，但由于资源稀缺，多数企业还无法开发个性化的模型。” Cloud AutoML的发布显然是奔着解决这一痛点而来。 以AutoML Vision为例，使用者只需要将图片上传并点击训练，便能选择要建立的定制模型或是既有的模型。如果希望定制化模型，谷歌建议理想的情况是，每个标记至少要有100张训练图片。如果选择通过Vision API使用既有的模型，则只能标示一些常见的物件，像是脸部、标志、地标等。 虽然谷歌此次声称AutoML是市面上唯一提供类似服务的产品，但诸如Clarif.ai这样的服务也已打出过类似的旗号，而微软的认知服务也能让你定制预先训练好的视觉、语音识别和决策模型（不过所有这些服务都还未被正式发布）。 AutoML Vision究竟如何，还得由广大企业和开发者检验。目前，必须通过申请才能使用该服务， 。 对于此次发布， 也发表了一篇公开信。大数据文摘在这里截取了重点翻译。 Cloud AutoML: 让人工智能对每个企业都触手可及 自一年前加入Google Cloud，我们就将“AI民主化”列为我们的重要使命。降低门槛、并将AI提供给最广大的开发者、研究人员和企业群体，是我们一直以来的目标。 在这条道路上，我们的Google Cloud AI团队已经取得了诸多进展。 2017年，我们推出了Google Cloud Machine Learning Engine，帮助具有机器学习专业知识的开发人员轻松构建适用于任何规模、任何类型数据机器学习模型。我们展示了，在预先训练好的模型之上，现代机器学习服务（如视觉，语音，NLP，翻译和对话流等API）能为业务应用带来的无与伦比的规模和速度。 我们的数据科学家、机器学习研究者社区平台Kaggle如今已经拥有超过一百万的成员。而今天，已有超过10,000家企业使用Google Cloud AI服务，其中包括Box，Rolls Royce Marine，Kewpie和Ocado等公司。 但我们的目标还远不止于此。 即便那少数几家拥有AI专家的企业，也仍需要大量时间、经过繁复的过程才能构建出自定义的机器学习系统。虽然通过谷歌为特定任务设计的APIs，预训练的机器学习模型已经被实现，但在普及AI的道路上，我们还有很长的路要走。 为了进一步实现我们的愿景，让每个企业都能使用AI，我们今天推出了Cloud AutoML。 基于learning2learn和迁移学习等先进技术，Cloud AutoML能够帮助机器学习专业知识薄弱的企业开始构建自己的高品质自定义模型。我们也相信Cloud AutoML能使AI专家们更加高效，在AI中拓展新的领域，并帮助技术娴熟的工程师构建他们以前梦寐以求的强大AI系统。 Cloud AutoML的第一个发布将是Cloud AutoML Vision，这一服务可以更快、更轻松地创建用于图像识别的自定义机器学习模型。 我们先前使用Cloud AutoML Vision对常用公共数据集（如ImageNet和CIFAR）进行分类，取得了比通用机器学习API更优的结果。 以下是Cloud AutoML Vision的详细性能介绍： 更精准： Cloud AutoML Vision基于谷歌领先的图像识别方法，包括传输学习和神经架构搜索技术。这意味着即使企业不具备足够的机器学习专业知识，也可以获得更准确的模型。 更快： 使用Cloud AutoML可以在几分钟内创建一个简单的模型，用以调试你想用AI支持的应用程序，可以在一天内构建能用于生产的完整模型。 操作简单： AutoML Vision提供了一个简单的图形用户界面，可让你指定数据，然后将数据转换为一个针对特定需求的高质量模型。 截至目前，已有包括迪士尼、伦敦动物学会ZSL、服饰品牌Urban Outfitter在内的多家公司和组织试用了该服务，取得了业务突破。 如果你想要试用AutoML Vision，可以通过该表格提交申请 （https://services.google.com/fb/forms/cloudautomlalphaprogram/） 。 AutoML Vision是我们与Google Brain和其他Google AI团队密切合作的结果，也是Cloud AutoML系列产品中的第一个。尽管在普及AI这条道路上我们才刚刚起步，但Cloud AI产品的10,000多个客户如今取得的成就已经让我们深受鼓舞。 谷歌云和谷歌大脑的合作，也体现在 李飞飞在推特上“点名表扬”Jeff Dean 我们希望Cloud AutoML的发布将帮助更多企业发现AI的潜力。 Learning Transferable Architectures for Scalable Image Recognition,  Progressive Neural Architecture Search,  Large-Scale Evolution of Image Classifiers,  Neural Architecture Search with Reinforcement Learning,  Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning,  Bayesian Optimization for a Better Dessert,  https://techcrunch.com/2018/01/17/googles-automl-lets-you-train-custom-machine-learning-models-without-having-to-code/ https://blog.google/topics/google-cloud/cloud-automl-making-ai-accessible-every-business/ https://www.ithome.com.tw/news/120776/ 【今日机器学习概念】 Have a Great Definition "
209,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656397&idx=3&sn=8c6d1f4033680afa5ba9bd8f2c2ab23d&chksm=bd4c375e8a3bbe488a9b5d69f46957411181d5b998eef88f17ae9487fdea5222d91c2e1612f8&scene=27,职位情报局 | 1.65亿天使轮融资背后，林元庆需要怎样的AI人才？,林元庆离开百度三个多月后（ ），他的 新公司Aibee拿到了1.65亿元的天使轮融资。 作为曾经的百度研究院院长、深度学习实验室（IDL）主任，林元庆这番创业选择了传统行业，与他的前同事、百度前首席科学家吴恩达（Andrew Ng）的选择不约而同（ ）。 Aibee（爱笔）寓意AI2B，意即用AI技术对传统行业赋能升级。 对于一家AI创业公司来说，最重要的工作可能是“抢人”——精干的AI团队将成为公司最大的资产。目前，Aibee有近20名员工，其中包括斯坦福计算机科学系副教授Silvio Savarese。预计到2018年底，公司将扩张到100人规模。 Silvio 更被中国观众熟知的身份是李飞飞的老公 本期职位情报局，就让我们来看看，1.65亿天使轮融资背后，林元庆需要怎样的AI人才？ ！ 大数据文摘推出“职位情报局”栏目 每周精心挑选几家AI/DS公司招聘信息 带来最新职位情报，并提供专业推荐信息 所有企业我们均联系过企业招聘相关负责人 确保需求真实 投递小 tip： 投递简历时邮件主题标注From大数据文摘，可提高命中几率呦～ 本周出镜的企业是： 
210,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656361&idx=1&sn=43e8cee0e5ef30cc10b37a08b7dcc849&chksm=bd4c373a8a3bbe2c7a4393c2258d80267f171d2f8cdc038503b43be6cbc87bae08ced64ecb90&scene=27,AlphaGo Zero用它来调参？【高斯过程】到底有何过人之处？,"丁慧、文明、Katherine Hou、云舟 高斯过程可能不是当前机器学习最火的研究方向，但仍然在很多前沿的研究中被使用到——例如，最近在AlphaGo Zero中自动调整MCTS超参数就使用了它。在建模能力和进行不确定性估计方面，它们具有非常高的易用性。 然而，高斯过程很难掌握，尤其是当你习惯了深度学习中其他常见的模型之后。所以本文希望在具备相当少的ML知识背景下，对高斯过程提供一个直观的理论介绍，请学习者下载notebook并实现本文中提到的所有代码。 高斯过程(Gaussian process, GP)是一个强大的模型，可以用来表示函数的分布。机器学习中的大多数现代技术都倾向于通过参数化函数，然后对这些参数（例如线性回归中的权重）进行建模来避免这种情况。 然而，GP是直接对函数建模的非参模型。这种方法带来的一个非常重要的好处是：不仅可以拟合任何黑箱函数，还可以拟合我们的不确定性。量化不确定性是非常有价值的——例如，如果允许我们随意探索（需要更多的数据），我们就可以选择尽可能高效地探索最不确定的领域。这是贝叶斯优化背后的主要思想。 如果你给我几张猫和狗的照片作为学习资料，然后给我一张新的猫的照片让我分类——我应该给出一个置信度相当高的预测。但是如果你给我一张鸵鸟的照片，强迫我判断它是猫还是狗——我最好还是给出一个置信度非常低的预测。 ——Yarin Gal 对于这个介绍，我们将考虑一个没有噪声的简单回归模型设置（但GP可以扩展到多维和噪声数据）： 假设我们需要拟合某个隐函数f：R—> R 已知数据X = [x ,…,x ] ，Y = [y ,…,y ] ，其中y  = f(x ) 我们要预测一些新的未观测点x 的函数值 GP背后的关键思想是可以使用无限维多元高斯分布拟合函数。换句话说，输入空间中的每个点与一个随机变量相关联，并将多元高斯分布用来拟合这些点的联合分布。 那么，这究竟意味着什么呢？让我们从一个更简单的情况开始：一个二维高斯。已知： 通常它是高度表示概率密度的3D钟形曲线。但是，假如不是表示整个分布，我们只需要从分布中抽样。然后我们将得到两个值，我们可以绘制点d并在它们之间画一条线。 观察图中的这些直线，看起来像我们仅仅抽取了10个线性函数样本……如果我们现在使用20维的高斯函数，依次连接每个样本点，会发生什么样的变化呢？ 这些绝对看起来像多个函数，但相对于我们的目的，它们看起来噪声太大所以不可用。让我们进一步考虑可以从这些样本中得到什么，以及如何改变分布从而获得更好的样本…… 多元高斯有两个参数，即均值和协方差矩阵。如果我们改变了均值的话，我们只会改变整体趋势（即如果均值是上升的整数，如np.arange(D),那么样本会呈现出整体正向线性趋势），但是仍然会出现锯齿形的噪声形状。出于这个原因，我们将GP的均值设置为0——它们实际上已经足够强大，可以在不改变均值的情况下拟合各种函数。 相反，我们需要一些平滑的概念：即如果两个输入点彼此邻近，那么我们期望这些点的函数值是相似的。就我们的模型而言，对用于相邻点的随机变量在它们的联合分布（即高斯协方差）下采样时应该具有相似的值。 这些点的协方差被定义为高斯的协方差矩阵。假设我们有N维高斯模型y ,…y ，协方差矩阵Σ是N╳N维且它的第(i,j)个元素是Σ  = cov(y ,y )。换句话说，Σ是对称的而且存储着所有随机变量的联合模型的成对协方差。 那么如何定义我们的协方差函数呢？这时大量关于核的文献可以派上用场。我们将选择平方指数核（最简单的形式）来达到我们的目的，定义如下： 当x = x’时，函数值（我们刚刚绘制的）为1并且随着点的不同而趋于0 我们可以绘制这个核函数来展示它在x = x’时是最大的，然后随着两个输入的不同开始平滑的下降 因此，为了得到我们想要的那种平滑性，我们将考虑在x 和x 处绘制两个随机变量y 和y ，来得到它们的协方差cov(y ,y ) = k(x ,x ) ——它们越接近，它们的协方差越高。 使用上面的核函数我们可以得到k(xs,xs)这个矩阵。现在我们试着从20维高斯中抽取另外10个样本，但是这次使用新的协方差矩阵。当我们这样做时，我们可以得到： 现在我们有了一些开始看起来像一个（有用的）函数分布。而且我们可以看到，随着维数趋于无穷大，我们不再需要连接这些点，因为我们可以为每一个可能的输入指定一个点。 让我们使用更多维度，并在更大范围的输入中查看他的外形： 现在我们有了函数的分布，我们如何通过训练数据拟合隐函数从而进行预测？ 首先，我们需要获取训练数据。 这可以通过构造我们的秘密函数f来生成数据。   本教程中我们使用一个 五次多项式 ： 我选择它是因为这个函数有个漂亮的波浪图形。当然，我们也可以用其它的函数 。  现在我们已经进入高斯过程的核心了。这需要更多的数学知识，不过不用担心，我们只需要巩固已有的知识就行，然后用一个小技巧在观测数据上决定我们的联合概率分布： 到目前为止，我们已知能够用多元正态分布来模拟p(y|x)了。 其中， 这是一个先验分布，它表示在没有任何观测数据的情况下， 出现时， 出现的概率。 现在，我们有了训练集，其训练得到的模型输入为 ，输出 。当有新样本 时，其预测值为 。 回顾之前高斯过程的定义，我们将拟合 和 的联合概率分布。 其中 和前面一样，我们将均值设为0. 但是，这是在拟合 ，而我们仅需要 的分布。 与其从头开始计算 的分布，我们可以使用标准结果。如果我们有了前面提到过的 和 的联合概率分布，而要得到 的条件概率分布，可以用如下的公式： 现在我们就可以用先验分布和观测数据计算 的后验分布了! 注意：下面给的代码在实际过程中并没有用到，因为K通常处于较差条件，所以它的逆通常不准确。在本教程第二部分中我们将给出一个更好的方法。 这就是上面公式的代码实现! 现在就可以用这两个参数从条件概率分布中采样了。我们将它们与真实函数（虚线）画在一起对比。因为我们用的是高斯过程，它包含有不确定性信息，这种不确定性信息以随机变量的方差形式表示出来。我们知道第i个随机变量的方差为∑ *ii ，换句话说，方差就是∑ * 的对角线值。下图中的样本包含了标准方差为±2的不确定性。 实际上，我们需要做更多的工作才能得到更好的预测结果。你可能已经注意到核中包含两个参数-σ和l。如果你在采样过程中试着改变这两个参数，你会发现σ影响纵坐标的变化而l影响横坐标的范围。 因此，我们需要改变它们来反映我们对隐函数的先验置信度。譬如，如果我们希望隐函数有更大的输出范围（一个我们感兴趣的范围），那么我们需要相应的增加 的值（试着将隐函数返回的值放大100倍，看会出现什么，然后将sigma设置为100再看）。事实上，任何用到核的函数，我们都可以通过改变核得到一个完全不一样的函数（例如，周期函数）。 核的选择需要人工进行，但参数可以通过最小化损失函数来自动优化。这就是高斯过程回归的内容。 最后，我们需要考虑怎么处理含有噪声的数据，例如，在实际过程中我们可能无法获得符合隐函数的标准数据。在这种情况下我们需要将这种不确定性纳入模型中以获得更好的泛化能力。 参考资料： 《Machine Learning - A Probabilistic Perspective》第十五章，作者 Kevin P. Murphy YouTube上Nando de Freitas 发布的Introduction to Gaussian processes视频 原文地址： http://bridg.land/posts/gaussian-processes- 1?utm_campaign=Revue%20newsletter&utm _medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 【今日机器学习概念】 Have a Great Definition "
211,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656361&idx=2&sn=03506e26eff036a0e03ff5809cf352dd&chksm=bd4c373a8a3bbe2c46570c154d943e44212c568bef2d160dea221d137d33e9ef9a80e9dd6a77&scene=27,干货丨3分钟了解今日头条推荐算法原理（附视频+PPT）,"今日头条的内容分发算法一直颇神秘低调。自12年开发运营起进四次改版，从未透露核心内容。 2018年1月，今日头条资深算法架构师曹欢欢博士，终于首次公开今日头条的算法原理，以期推动整个行业问诊算法、建言算法，希望消除各界对算法的误解。 据悉，今日头条的信息推荐算法目前服务全球亿万用户。 以下为曹欢欢关于《今日头条算法原理》的分享内容 （已获今日头条授权） ： ▲ 3分钟了解今日头条推荐算法原理 本次分享将主要介绍今日头条推荐系统概览以及内容分析、用户标签、评估分析，内容安全等原理。 推荐系统，如果用形式化的方式去描述实际上是拟合一个用户对内容满意度的函数，这个函数需要输入三个维度的变量。第一个维度是内容。头条现在已经是一个综合内容平台，图文、视频、UGC小视频、问答、微头条，每种内容有很多自己的特征，需要考虑怎样提取不同内容类型的特征做好推荐。第二个维度是用户特征。包括各种兴趣标签，职业、年龄、性别等，还有很多模型刻划出的隐式用户兴趣等。第三个维度是环境特征。这是移动互联网时代推荐的特点，用户随时随地移动，在工作场合、通勤、旅游等不同的场景，信息偏好有所偏移。结合三方面的维度，模型会给出一个预估，即推测推荐内容在这一场景下对这一用户是否合适。 这里还有一个问题，如何引入无法直接衡量的目标？ 推荐模型中，点击率、阅读时间、点赞、评论、转发包括点赞都是可以量化的目标，能够用模型直接拟合做预估，看线上提升情况可以知道做的好不好。但一个大体量的推荐系统，服务用户众多，不能完全由指标评估，引入数据指标以外的要素也很重要。 比如广告和特型内容频控。像问答卡片就是比较特殊的内容形式，其推荐的目标不完全是让用户浏览，还要考虑吸引用户回答为社区贡献内容。这些内容和普通内容如何混排，怎样控制频控都需要考虑。 此外，平台出于内容生态和社会责任的考量，像低俗内容的打压，标题党、低质内容的打压，重要新闻的置顶、加权、强插，低级别账号内容降权都是算法本身无法完成，需要进一步对内容进行干预。 下面我将简单介绍在上述算法目标的基础上如何对其实现。 前面提到的公式y = F(Xi ,Xu ,Xc)，是一个很经典的监督学习问题。可实现的方法有很多，比如传统的协同过滤模型，监督学习算法Logistic Regression模型，基于深度学习的模型，Factorization Machine和GBDT等。 一个优秀的工业级推荐系统需要非常灵活的算法实验平台，可以支持多种算法组合，包括模型结构调整。因为很难有一套通用的模型架构适用于所有的推荐场景。现在很流行将LR和DNN结合，前几年Facebook也将LR和GBDT算法做结合。今日头条旗下几款产品都在沿用同一套强大的算法推荐系统，但根据业务场景不同，模型架构会有所调整。 模型之后再看一下典型的推荐特征，主要有四类特征会对推荐起到比较重要的作用。 第一类是相关性特征，就是评估内容的属性和与用户是否匹配。 显性的匹配包括关键词匹配、分类匹配、来源匹配、主题匹配等。像FM模型中也有一些隐性匹配，从用户向量与内容向量的距离可以得出。 第二类是环境特征，包括地理位置、时间。 这些既是bias特征，也能以此构建一些匹配特征。 第三类是热度特征。 包括全局热度、分类热度，主题热度，以及关键词热度等。内容热度信息在大的推荐系统特别在用户冷启动的时候非常有效。 第四类是协同特征，它可以在部分程度上帮助解决所谓算法越推越窄的问题。 协同特征并非考虑用户已有历史。而是通过用户行为分析不同用户间相似性，比如点击相似、兴趣分类相似、主题相似、兴趣词相似，甚至向量相似，从而扩展模型的探索能力。 模型的训练上，头条系大部分推荐产品采用实时训练。实时训练省资源并且反馈快，这对信息流产品非常重要。用户需要行为信息可以被模型快速捕捉并反馈至下一刷的推荐效果。我们线上目前基于storm集群实时处理样本数据，包括点击、展现、收藏、分享等动作类型。模型参数服务器是内部开发的一套高性能的系统，因为头条数据规模增长太快，类似的开源系统稳定性和性能无法满足，而我们自研的系统底层做了很多针对性的优化，提供了完善运维工具，更适配现有的业务场景。 目前，头条的推荐算法模型在世界范围内也是比较大的，包含几百亿原始特征和数十亿向量特征。 整体的训练过程是线上服务器记录实时特征，导入到Kafka文件队列中，然后进一步导入Storm集群消费Kafka数据，客户端回传推荐的label构造训练样本，随后根据最新样本进行在线训练更新模型参数，最终线上模型得到更新。这个过程中主要的延迟在用户的动作反馈延时，因为文章推荐后用户不一定马上看，不考虑这部分时间，整个系统是几乎实时的。 但因为头条目前的内容量非常大，加上小视频内容有千万级别，推荐系统不可能所有内容全部由模型预估。所以需要设计一些召回策略，每次推荐时从海量内容中筛选出千级别的内容库。召回策略最重要的要求是性能要极致，一般超时不能超过50毫秒。 召回策略种类有很多，我们主要用的是倒排的思路 。离线维护一个倒排，这个倒排的key可以是分类，topic，实体，来源等，排序考虑热度、新鲜度、动作等。线上召回可以迅速从倒排中根据用户兴趣标签对内容做截断，高效的从很大的内容库中筛选比较靠谱的一小部分内容。 内容分析包括文本分析，图片分析和视频分析。头条一开始主要做资讯，今天我们主要讲一下文本分析。文本分析在推荐系统中一个很重要的作用是用户兴趣建模。没有内容及文本标签，无法得到用户兴趣标签。举个例子，只有知道文章标签是互联网，用户看了互联网标签的文章，才能知道用户有互联网标签，其他关键词也一样。 另一方面，文本内容的标签可以直接帮助推荐特征，比如魅族的内容可以推荐给关注魅族的用户，这是用户标签的匹配。 。因为整个模型是打通的，子频道探索空间较小，更容易满足用户需求。只通过单一信道反馈提高推荐准确率难度会比较大，子频道做的好很重要。而这也需要好的内容分析。 上图是今日头条的一个实际文本case。可以看到，这篇文章有分类、关键词、topic、实体词等文本特征。当然不是没有文本特征，推荐系统就不能工作，推荐系统最早期应用在Amazon,甚至沃尔玛时代就有，包括Netfilx做视频推荐也没有文本特征直接协同过滤推荐。但对资讯类产品而言，大部分是消费当天内容，没有文本特征新内容冷启动非常困难，协同类特征无法解决文章冷启动问题。 今日头条推荐系统主要抽取的文本特征包括以下几类。首先是语义标签类特征，显式为文章打上语义标签。这部分标签是由人定义的特征，每个标签有明确的意义，标签体系是预定义的。此外还有隐式语义特征，主要是topic特征和关键词特征，其中topic特征是对于词概率分布的描述，无明确意义；而关键词特征会基于一些统一特征描述，无明确集合。 另外文本相似度特征也非常重要。 在头条，曾经用户反馈最大的问题之一就是为什么总推荐重复的内容。这个问题的难点在于，每个人对重复的定义不一样。举个例子，有人觉得这篇讲皇马和巴萨的文章，昨天已经看过类似内容，今天还说这两个队那就是重复。但对于一个重度球迷而言，尤其是巴萨的球迷，恨不得所有报道都看一遍。解决这一问题需要根据判断相似文章的主题、行文、主体等内容，根据这些特征做线上策略。 同样，还有时空特征，分析内容的发生地点以及时效性。比如武汉限行的事情推给北京用户可能就没有意义。最后还要考虑质量相关特征，判断内容是否低俗，色情，是否是软文，鸡汤？ 上图是头条语义标签的特征和使用场景。他们之间层级不同，要求不同。 分类的目标是覆盖全面，希望每篇内容每段视频都有分类；而实体体系要求精准，相同名字或内容要能明确区分究竟指代哪一个人或物，但不用覆盖很全。概念体系则负责解决比较精确又属于抽象概念的语义。这是我们最初的分类，实践中发现分类和概念在技术上能互用，后来统一用了一套技术架构。 目前，隐式语义特征已经可以很好的帮助推荐，而语义标签需要持续标注，新名词新概念不断出现，标注也要不断迭代。其做好的难度和资源投入要远大于隐式语义特征，那为什么还需要语义标签？有一些产品上的需要，比如频道需要有明确定义的分类内容和容易理解的文本标签体系。语义标签的效果是检查一个公司NLP技术水平的试金石。 今日头条推荐系统的线上分类采用典型的层次化文本分类算法。最上面Root，下面第一层的分类是像科技、体育、财经、娱乐，体育这样的大类，再下面细分足球、篮球、乒乓球、网球、田径、游泳等，足球再细分国际足球、中国足球，中国足球又细分中甲、中超、国家队等，相比单独的分类器，利用层次化文本分类算法能更好地解决数据倾斜的问题。有一些例外是，如果要提高召回，可以看到我们连接了一些飞线。这套架构通用，但根据不同的问题难度，每个元分类器可以异构，像有些分类SVM效果很好，有些要结合CNN，有些要结合RNN再处理一下。 上图是一个实体词识别算法的case。基于分词结果和词性标注选取候选，期间可能需要根据知识库做一些拼接，有些实体是几个词的组合，要确定哪几个词结合在一起能映射实体的描述。如果结果映射多个实体还要通过词向量、topic分布甚至词频本身等去歧，最后计算一个相关性模型。 内容分析和用户标签是推荐系统的两大基石。内容分析涉及到机器学习的内容多一些，相比而言，用户标签工程挑战更大。 今日头条常用的用户标签包括用户感兴趣的类别和主题、关键词、来源、基于兴趣的用户聚类以及各种垂直兴趣特征（车型，体育球队，股票等）。 还有性别、年龄、地点等信息。性别信息通过用户第三方社交账号登录得到。年龄信息通常由模型预测，通过机型、阅读时间分布等预估。常驻地点来自用户授权访问位置信息，在位置信息的基础上通过传统聚类的方法拿到常驻点。常驻点结合其他信息，可以推测用户的工作地点、出差地点、旅游地点。这些用户标签非常有助于推荐。 当然最简单的用户标签是浏览过的内容标签。但这里涉及到一些数据处理策略。主要包括： 对用户在一些热门文章（如前段时间PG One的新闻）上的动作做降权处理。理论上，传播范围较大的内容，置信度会下降。 用户兴趣会发生偏移，因此策略更偏向新的用户行为。因此，随着用户动作的增加，老的特征权重会随时间衰减，新动作贡献的特征权重会更大。 如果一篇推荐给用户的文章没有被点击，相关特征（类别，关键词，来源）权重会被惩罚。当然同时，也要考虑全局背景，是不是相关内容推送比较多，以及相关的关闭和dislike信号等。 用户标签挖掘总体比较简单，主要还是刚刚提到的工程挑战。头条用户标签第一版是批量计算框架，流程比较简单，每天抽取昨天的日活用户过去两个月的动作数据，在Hadoop集群上批量计算结果。 但问题在于，随着用户高速增长，兴趣模型种类和其他批量处理任务都在增加，涉及到的计算量太大。2014年，批量处理任务几百万用户标签更新的Hadoop任务，当天完成已经开始勉强。集群计算资源紧张很容易影响其它工作，集中写入分布式存储系统的压力也开始增大，并且用户兴趣标签更新延迟越来越高。 面对这些挑战。2014年底今日头条上线了用户标签Storm集群流式计算系统。改成流式之后，只要有用户动作更新就更新标签，CPU代价比较小，可以节省80%的CPU时间，大大降低了计算资源开销。 这套系统从上线一直使用至今。 当然，我们也发现并非所有用户标签都需要流式系统。像用户的性别、年龄、常驻地点这些信息，不需要实时重复计算，就仍然保留daily更新。 上面介绍了推荐系统的整体架构，那么如何评估推荐效果好不好？ 有一句我认为非常有智慧的话，“一个事情没法评估就没法优化”。对推荐系统也是一样。 事实上，很多因素都会影响推荐效果。比如侯选集合变化，召回模块的改进或增加，推荐特征的增加，模型架构的改进在，算法参数的优化等等，不一一举例。评估的意义就在于，很多优化最终可能是负向效果，并不是优化上线后效果就会改进。 全面的评估推荐系统，需要完备的评估体系、强大的实验平台以及易用的经验分析工具。 所谓完备的体系就是并非单一指标衡量，不能只看点击率或者停留时长等，需要综合评估。过去几年我们一直在尝试，能不能综合尽可能多的指标合成唯一的评估指标，但仍在探索中。目前，我们上线还是要由各业务比较资深的同学组成评审委员会深入讨论后决定。 很多公司算法做的不好，并非是工程师能力不够，而是需要一个强大的实验平台，还有便捷的实验分析工具，可以智能分析数据指标的置信度。 一个良好的评估体系建立需要遵循几个原则，首先是兼顾短期指标与长期指标。我在之前公司负责电商方向的时候观察到，很多策略调整短期内用户觉得新鲜，但是长期看其实没有任何助益。 其次，要兼顾用户指标和生态指标。今日头条作为内容分创作平台，既要为内容创作者提供价值，让他更有尊严的创作，也有义务满足用户，这两者要平衡。还有广告主利益也要考虑，这是多方博弈和平衡的过程。 另外，要注意协同效应的影响。实验中严格的流量隔离很难做到，要注意外部效应。 强大的实验平台非常直接的优点是，当同时在线的实验比较多时，可以由平台自动分配流量，无需人工沟通，并且实验结束流量立即回收，提高管理效率。这能帮助公司降低分析成本，加快算法迭代效应，使整个系统的算法优化工作能够快速往前推进。 这是头条A/B Test实验系统的基本原理。首先我们会做在离线状态下做好用户分桶，然后线上分配实验流量，将桶里用户打上标签，分给实验组。举个例子，开一个10%流量的实验，两个实验组各5%，一个5%是基线，策略和线上大盘一样，另外一个是新的策略。 实验过程中用户动作会被搜集，基本上是准实时，每小时都可以看到。但因为小时数据有波动，通常是以天为时间节点来看。动作搜集后会有日志处理、分布式统计、写入数据库，非常便捷。 在这个系统下工程师只需要设置流量需求、实验时间、定义特殊过滤条件，自定义实验组ID。系统可以自动生成：实验数据对比、实验数据置信度、实验结论总结以及实验优化建议。 当然，只有实验平台是远远不够的。线上实验平台只能通过数据指标变化推测用户体验的变化，但数据指标和用户体验存在差异，很多指标不能完全量化。很多改进仍然要通过人工分析，重大改进需要人工评估二次确认。 最后要介绍今日头条在内容安全上的一些举措。头条现在已经是国内最大的内容创作与分发凭条，必须越来越重视社会责任和行业领导者的责任。如果1%的推荐内容出现问题，就会产生较大的影响 。 因此头条从创立伊始就把内容安全放在公司最高优先级队列。成立之初，已经专门设有审核团队负责内容安全。当时研发所有客户端、后端、算法的同学一共才不到40人，头条非常重视内容审核。 现在，今日头条的内容主要来源于两部分， 如果是数量相对少的PGC内容，会直接进行风险审核，没有问题会大范围推荐。UGC内容需要经过一个风险模型的过滤，有问题的会进入二次风险审核。审核通过后，内容会被真正进行推荐。这时如果收到一定量以上的评论或者举报负向反馈，还会再回到复审环节，有问题直接下架。整个机制相对而言比较健全，作为行业领先者，在内容安全上，今日头条一直用最高的标准要求自己。 分享内容识别技术主要鉴黄模型，谩骂模型以及低俗模型。今日头条的低俗模型通过深度学习算法训练，样本库非常大，图片、文本同时分析。这部分模型更注重召回率，准确率甚至可以牺牲一些。谩骂模型的样本库同样超过百万，召回率高达95%+，准确率80%+。如果用户经常出言不讳或者不当的评论，我们有一些惩罚机制。 泛低质识别涉及的情况非常多，像假新闻、黑稿、题文不符、标题党、内容质量低等等，这部分内容由机器理解是非常难的，需要大量反馈信息，包括其他样本信息比对。目前低质模型的准确率和召回率都不是特别高，还需要结合人工复审，将阈值提高。目前最终的召回已达到95%，这部分其实还有非常多的工作可以做。头条人工智能实验室李航老师目前也在和密歇根大学共建科研项目，设立谣言识别平台。 以上便是头条推荐系统的原理全部分享了，此文授权转载自公众号今日头条（ID：headline_today）。 【今日机器学习概念】 Have a Great Definition "
212,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656361&idx=3&sn=b4856ed66a149a7a79c02a981b1c32d5&chksm=bd4c373a8a3bbe2c494409fef30ee4bb4c9e831e68b2d37db73348f6c9e023e8d71229e8e146&scene=27,汇医慧影卢涛：医疗人工智能商业模式思考与探索丨清数•思享会,"大数据文摘作品 作者：亭八 由于高度监管和高度垄断以及必要组成部分（例如商保）的缺失，中国医疗领域的创新创业非常艰难，强大的技术变革和正确的商业模式是医疗领域创新创业项目成功的关键。人工智能的发展进入新一轮高潮，医疗人工智能创新方向和创业项目层出不穷，并且倍受资本追逐，大量资本投入到这个新的领域。 如何真正进入商用和临床的医疗人工智能创新领域？如何建立正确的商业模式？ 汇医慧影创新业务负责人卢涛，结合移动医疗发展的成功经验与失败教训，阐述了医疗人工智能商业模式的正确出路，以及如何更快的触及并解决诊疗方面的核心问题。 大数据文摘对本次分享的精彩内容进行了整理，在不改变原意的前提下有删改： 南开大学商学院最近发布了2017年热词，从第十名开始依次为：互联网+、供给侧结构性改革、精准贫、工匠精神、移动支付、雄安新区、大数据、一带一路、共享经济、人工智能。 其中，南开大学商学院教授用一句话很好的解释了人工智能：人战胜了所有动物之后终于向自己在世间的地位挑战了。有人认为人工智能的未来很美好，有人认为十分危险，但我觉得人可以很好地驾驭自己发明的东西，人工智能肯定能够帮助所有行业的每一位从业者，我们要思考的问题是如何能够跟人工智能相处得更好。 曾经有一个观点：人工智能会代替医生，当初马云也说30年后医生会找不到工作。我相信他的想法是被断章取义了， 人工智能替代医生的说法肯定是错的，正确的说法应该是有AI的医生替代没有AI的医生，或者叫做： 医疗行业的背景。 目前这个行业正在快速发展，2011年中国医疗总费用是2.4万亿，到2016年就变成了4.6万亿，将近100%的增长速度。健康中国2030规划纲要中指出，到2020年医疗产值可能会达到8万亿，2030年将到16万亿。 快速发展的原因之一是中国人口的老龄化。 目前60岁以上的老人占了全国人口18%，预计30、40、50年后，60岁以上老人的比例会持续增加，中国会步入严重老龄化的社会。随着老人的增加，会给医疗行业带来更多的挑战和机遇。 第二是消费升级，城镇人均可支配收入增长速度很快 。2011年至2016年可支配收入增长了54%，消费升级很好地带动了医疗体系的增长。 另一个则是政策与技术。 2016年健康中国2030规划纲要上升为国家战略，2017年人工智能上升为国家的战略，以北京为首的很多城市分别制订了自己综合医改的流程。而分级诊疗则是医改的一个主要目的和衡量指标，北京的综合医改主要体现在腾笼换鸟，将不合理的一些收费比例、医院的药品加成取消，另外在医师服务费上面进行调节，让相对比较稳定的患者去社区或者小一点规模的医院。 而依靠云计算和AI技术的革新，以及深度学习方面的成熟，医疗领域出现了一个非常好的创业机会。 医学领域的规律是一个一个台阶往上走，进入21世纪之后才开始循证医学，之前更多是经验医学的时代。有些经验医学依靠传承确实给大家带来了非常多的获益和价值，但后来以西医为首的领域快速发展，经验医学已经不足以证明哪些治疗方案和药物是有效的，这时候就走到了循证医学的时代。 顾名思义，循证医学就是要看证据，没有证据证明治疗方案有效的话，就不会有人愿意用这个治疗方案治病，医生也不会选取这样的治疗方案，更不会放进指南。所以循证医学的时代是基于有设计的实验研究进行展开的，目前对治疗方案的选择、指南的规划都是循证医学缔造的产物。 下一个阶段则是精准医学。 随着基因和大数据等技术越来越成熟，未来更多的治疗很可能是基于循证、指南，做到每个患者不同的情况、信息、数据，对应不同的治疗方案。 人工智能辅助医疗有三个里程碑式的事件。第一是2015年北卡罗莱纳大学发了一篇关于深度学习分割脑核磁图象的文章。第二是谷歌买了13万糖网的患者数据，证明了用人工智能进行糖网病诊断精度是优于临床的。第三是2017年斯坦福大学在Nature上发表了一篇文章，证明人工智能对皮肤癌的诊断精度达到了专家水平，即优于了临床水平。 这三个里程碑式的人工智能事件，以及对医疗方面辅助研究的发表，奠定了人工智能在医疗领域的一些地位。相信未来还会有更多超越这三个里程碑事件的事情发生。 医学影像是很多疾病检查、诊断和治疗开启的必经之路，无论是血管类疾病、肿瘤、神经性疾病以及骨科疾病等等，都离不开影像，如果患者没有做相应的影像学检查就没有办法继续往下做诊断和治疗。另外，人工智能创业医学影像的市场非常活跃。 但医学影像有很多痛点。 另一个则是医生看片子要么打印出来在灯光下看，要么在电脑上看，这两种方式只能看到一些片子上体现出来的且比较容易看出来的形态性改变，但如果把片子进行特征化，很多东西肉眼根本看不到，且很难用人脑进行分析。所以很多用医学影像检查方法提供的医疗证据都被浪费掉了。 但医学影像的市场还是比较庞大的，目前医疗市场有5万亿的规模，医学影像占了将近20%的份额， 如果从医学影像这一块进入医疗市场，将会有很大的机会瓜分几千亿中一部分。 目前进入医疗领域的方法还是较为简单且传统的商业模式：开医院，无论公立还是私立。然后在医院售卖医学技术，提供医疗服务，同时打包整合一些医学影像、检查、药品等相关服务，卖给患者。之所以会出现这样的商业模式，与这个领域有很大的关系。 第一个原因是医疗领域是一个高监管的领域。 效率和公平从国家维度来讲是两个最重要的事项。提高效率就能提高产能，国家的综合国力以及国家的收入、技术发展快慢等也能得到提高。公平则是分配的方式，社会主义国家一直兼顾效率和公平，并一直在寻找公平且合理的分配方式。医疗领域则是公平优于效率的领域，医疗是全民的医疗，所有人都有权利享受医疗的照顾。 第二是高度垄断。 虽然公立医院的数量和私立医院的数量基本持平，但其服务的患者人数、产生的经济花费远远不一样。公立医院代表了国家政策的执行和监管的方向，其高度垄断的是大型三甲医院，而稍微小一点地方的医院水平、服务患者人数以及真正服务下来的价值远远低于大的三甲医院。同时也有一些商业垄断等等，都对商业模式的形成产生了很大的影响。 第三是组织不全。 任何一个服务都要有它的支付方，中国的支付方90%都是来自基本医疗保险，商业保险所占的支付比例非常低。这与美国、日本、欧洲等国家并不一样，美国的商业保险大概占整个医疗支出的比例40%多，日本则是10%到20%之间，中国目前只有3%——4%，这也彰显了高度垄断和高度监管的结果。 在中国这样的传统商业模式下，如果想去耕耘、创新，是非常难的一件事情。所以一定不要打无准备的仗，习总书记说过：学史可以看成败、鉴得失、知兴替。我们要多去看一看前人的创业情况是什么样子，这对下一步创业成功少走弯路有非常重要的意义。 移动医疗在2010年到2014年是一个孕育期，我们比较熟悉的公司都在这个时间成立。2014年到2016年是一个蓬勃期，一是当时资本环境比较好，二是国家双创的战略得到了非常多的支持，发展态势呈现出波澜壮阔的画面。而2016年到2017年是一个去泡沫期或者叫做萎缩期，既与资本环境变化有关系，也跟一个企业经过几年的孕育与发展之后，确实没有一个特别好的盈利模式有关系。2017年到2020年应该是一个转型期，在去泡沫期和转型期有一些企业死掉了，稍微大一点有实力的企业开始转型，将要出现一些大规模的创新行动。 整个移动医疗领域虽然没有失败，但也并不是那么成功。根本原因是在医疗领域不要完全复制电商模式与共享经济模式。医疗领域其本身就与其它领域不一样，国家医疗领域的环境以及目前的政策等方面，也与电商、共享经济不一样。另一个原因是医疗的本质需要依赖于医疗技术以及相关辅助技术的发展，如果在医疗领域里没有做到技术发展与革新，对医疗的推动是没有效果的。 第一要始终坚持以技术创新为核心， 尤其是人工智能，必须要有自己的技术创新实力，才能真正成功。 第二是切忌跑马圈地和随意免费。 免费会带来很多问题，而且初期也会产生不合理的竞争，甚至会让好不容易找到的一些愿意支持创新的天使客户失望，所以不要随意免费。医疗领域非常宽广，有许多相关的疾病等着大家攻克，只要技术达到一定程度，真正解决问题，自然就会有一块属于我们自己的地盘，到时免费还是不免费已经不再是问题了。 第三，产品必须切中诊疗的刚需。 做检查是为了给患者做出诊断，诊断是为了有更好的治疗选择。如果做出的产品跟诊断和治疗关系都不大，更属于前端或后端的话，相对来讲并不是特别刚需的产品。 第四，医疗AI的研发实验室要设在医院， 或者研发实验室的分部设在医院， 产品既然是解决医疗的问题，只有设在医院才可能找到相关的专家、教授等人才，只有在医院才能形成这样的场景。 第五，一定要遵守AI服务医生、医生服务患者的准则。 第六，医疗体制的改革需要依靠政府，但真正的技术革新还是需要企业。 AI的三要素是算法、场景和数据。有了好的算法，未来用于深度学习的算法才会出现；找到了合适的场景，才能解决医疗相关的问题；有了高质量的数据，才能产生更好的人工智能。 所以AI公司在很长一段时间内都是不同维度的竞争，如果只擅长数据，却没有算法，场景也没有找对，那是没有用的。要先深耕一个维度，在另外两个维度不断扩充自己。 另外，医疗人工智能领域不仅需要AI人才，同时还需要医学人才、商业化人才等复合型人才。 对于医疗人工智能领域的盈利模式，一定不要套别人的商业模式， 无论是传统模式B2C,或者B2B、C2C，能用20个字准确清晰地描述出自己公司的盈利模式，就是好的盈利模式，适合自己公司的商业模式才是最好的。 清数•思享会是由清数大数据产业联盟与清华校友总会AI大数据专委会（筹）共同发起的小范围深度思想交流平台。大数据文摘作为战略合作媒体，将持续推出相关报道，敬请关注。 【今日机器学习概念】 Have a Great Definition "
213,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656302&idx=2&sn=f4b57bb478d9fcf2713c41fe49da3a1d&chksm=bd4c37fd8a3bbeeba803c99d9b212443977d96e320f31c3a1ed53aad9f10c481bc6a584ad000&scene=0,公开课 | 史上最便宜~用树莓派玩AI + 分析监控视频中的人流量 + 计算机视觉行业展望，3场直播连击！,本周四晚，3场公开课，一！起！来！ 📢 AI芯片听说很贵，可是你知道用树莓派也能玩AI吗？ 树莓派 （Raspberry Pi）是 用树莓派到底能实现什么？它和商业芯片之间有多大差距？ 智能视觉监控作为公共安全监控的一个有效手段，越来越受到各方的重视。分析视频中的群体流量，尤其是大范围覆盖、多视场协同场景下的群体目标，对公共安全领域有重要意义。 计算机视觉领域又有哪些趋势和热门应用？让我们在公开课中一探究竟吧！参与公开课，还有机会获得 哦！详情请往下翻👇 1 一方面，人工智能看起来非常昂贵：算法很贵，几家视觉算法公司纷纷创造了风险融资的各类世界纪录，人工智能工程师一下子身价陡增；硬件很贵，芯片只要一沾上AI就像开挂一样，资本市场火热。 另一方面，人工智能看起来非常便宜：算法免费，各类开源或者免费算法层出不穷，互联网大企业像不要钱一样把大量算法代码、框架以及数据争先开源；硬件很便宜，不需要专用芯片，不需要专用硬件， 。 那么到底人工智能是昂贵还是便宜？ 我们先来看看，树莓派到底能实现什么功能？它和商业版之间有多大差距？ 先忘掉深度学习的各类艰涩术语和数学模型，让我们用体验来感知人工智能。 嘉宾简介： 王海增 ，人人智能创始人，通信、多媒体及视觉智能产品架构师。历任华为、华三、中星微、中科院等单位开发经理、架构师、总监、总工、总裁助理、院士技术助理、产品总工等岗位，主持过数款销售超十亿元的产品研发。多届全国安防技术标准委员技术委员。 扫码进直播间 ▼ 2 随着国内各地平安城市、天网工程等一系列公共安全相关项目的建设，一大批的安防摄像头和配套的存储资源逐步建立了起来。如何有效地利用这些硬件资源，提升公共安全的管理水平，成了各级政府日益关心的问题。智能视觉监控作为公共安全监控的一个有效手段，越来越受到各方的重视。 对于群体目标，尤其是在大范围覆盖、多视场协同场景下的群体目标的智能视频分析技术，无疑是智能监控在公共安全领域的一个重要研究方向。其中，大范围场景下，群体目标的流量分析是一个值得研究的课题。 本次公开课的主要内容包括： 。 该方法借鉴了图像序列采样的思想，提取了视频的原始采样图和光流特征采样图，并使用多个深度神经网络模型对采样图进行特征提取，并以此来估计群体流量。同时创建了 ，该数据库采包含实际场景中的不同角度和不同规模的群体流量，并且包括了不同的天气情况和时间段。实验表明，传统的方法只能在特定的场景，流量较少时发挥作用，而这里介绍的方法可以较好的估计实际 中的大规模的群体目标流量。 嘉宾简介： 曹黎俊 ，人人智能算法研发负责人，本硕阶段于北航获得机器视觉相关学位，博士于中国科学院大学获得模式识别专业学位。期间于中科院自动化所从事多年的机器视觉和视频监控核心技术的开发，主导了多个具有较大影响力的相关课题或项目的研发工作，包括中科院战略先导专项中的公共场所大规模人群分析系统、中央警卫局会场视频分析系统、安全部边境出入视频分析系统、公安部监管场所视频分析系统，以及智能交通系列产品线的研发应用等。在智能视频分析中的核心分析算法问题上，具有独到的解决方案，并且得到了学术界和工业界的认可，在包括IEEE期刊和计算机视觉三大会议上发表了多篇相关文章，并且申请了多项相关专利。 扫码进直播间 ▼ 3 计算机视觉行业发展趋势及当前应用热点 从视频监控、图像智能分析、图像大数据，再到人工智能应用，视觉感知与交互的应用越来越普及和深入。用机器代替人眼，用视觉交互打造与人亲密无间的行业智能应用及综合性系统，成为当前及未来创业者、服务者和应用者的共同目标。 本次公开课将重点介绍计算机视觉的行业应用发展趋势及当前应用热点。 嘉宾简介： 王勇 ，人人智能首席架构师，中国图象图形学学会CSIG 视频大数据专业委员会委员，10年视频智能应用产品研发经验。 扫码进直播间 ▼ 请注意： 本次公开课形式为PPT+语音直播，无需下载APP，长按识别上方海报中的二维码，关注微信公众号，收到已成功关注该课程的提醒后，点击“ ”即可进入报名页面。点击红色按钮“ ”，进入直播间并收到专属邀请卡即为报名成功。 赠书福利： 欢迎大家在直播间中生成专属邀请卡并分享~开课前邀请人数排名 的小伙伴，每人将获赠 出版社赞助本次活动的图书一本~ 书名： Python数据分析基础 Python数据处理 Python网络数据采集 Spark快速大数据分析 R图形化数据分析 进入直播间后，点击“邀请朋友一起听课，强势上榜”即可选择自己的专属邀请卡并发送给朋友~ 点击下面的文字收听往期公开课 点击下方 加入本期公开课 👇 
214,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656302&idx=1&sn=7e3f162603083a6865f778574b7be0d7&chksm=bd4c37fd8a3bbeebbe2ae84e56d7e60cfa7bedba204ed304f593a99b010d70d85f38c886ada1&scene=0,像背单词一样搞定机器学习关键概念：300张小抄表满足你的所有AI好奇,入坑数据科学和人工智能的同学都知道，机器学习是一个集合了计算机、统计学和数学知识的交叉领域，除了日常练习，也需要很多枯燥的记忆和理解。单纯读书不容易串联概念，又容易忘记。 可能你和文摘菌一样，读了无数遍“西瓜书”，还是记不住什么是AUC值。那么这时候，你可能需要一种新的学习方式——小抄表（cheatsheet／flashcards）。 最近，文摘菌办公室的画风就颇清奇，到处都能看到这样的写着机器学习概念的小卡片。 喝水的时候来一张【AIC】 小零食柜上来一张【拟合度】 补口红时候来一张【AUC】 看花花时候来一张【BIAS】 简直分分钟搞定机器学习各种记不住的概念啊！上一次出现这样轰轰烈烈的学习阵仗还是全宿舍一起背托福单词的时候。 这些被文摘菌散落办公室各处的小抄表来自机器学习网红Chris Albon博士。Chris 是一位很有热情的机器学习从业者、数据科学家，也是初创公司NewKnowldgeAI的联合创始人。 在他自己学习机器学习的时候，发现通过这样的小卡片理解和记忆机器学习相关概念，比单纯读教科书要有效的多。于是便总结了300+个机器学习概念，并用彩笔手绘、扫描，制作了这套精致的小抄表礼包。 当然，这份小抄表是全英文的，在Chris Albon的网站上售价12刀，销量很好。想要获得英文全版的同学，文摘菌也把链接附在这里： https://machinelearningflashcards.com/ 这份小抄表还在持续更新，也欢迎各位关注大咖Chris Albon的twitter@chrisalbon，获得小抄表最新消息。 是不是超级酷？ 大数据文摘也在大咖的基础上，做了一些有点酷的事情。 是的，就像在开头你看到的那样，我们组织了近40人的志愿者团队，把这份300页的小抄表汉化了一遍！ 当然不仅仅是简单的英译汉，我们还认真研究了大咖适用的字体、配的图表，并且保留了每张小抄表的原作者签名， 首批小抄表刚刚完成时，我们战战兢兢的把几张汉化作品发给了原作者Chris Albon，大咖不仅回复了我们，还在推特乐呵呵的po出了我们的成果：“有人把小抄表翻译成了汉语！Super cool！”（被大咖表扬笑出声！） 当然这条推特也吸引来了一些鬼畜的评论，比如下边这条： -“你确定这不是用机器学习算法翻译的？” 文摘菌：我求你把这么智能的算法推荐给我啊 这个DC的Finds同学非常贴心的感叹，“你能想象这得花多久吗？！” 文摘菌：当然花了很久啊，要搞定这套“小抄表“，你需要又懂翻译又懂设计又懂机器学习，文摘菌和ta的全能朋友们从10月份开始工作，一直断断续续换了2波人，终于即将完成了这个宏大的工程。给所有的志愿者打call！ 还有一位叫做jonas的大哥质疑“哈哈这并不是中文（微笑脸）” 文摘菌想说，哥们是不是你只认识一种字体的中文，换个字体就不认识了啊（微笑脸） 最后，大家最关心的可能还是，这么酷的小抄表怎么获得。 你可以通过这些方式获得小抄表全部内容： 1、 获取最新的小抄表资料包，最终的校对和确认工程还在进行，我们每天会放出3-5张最新内容，一直持续到300张全部放出。 2、当然，为了督促大家学习，从明天开始，大数据文摘也会在每篇推文后放上一张最新的小抄表，大家可以在看文的同时一起搞定当天的学习内容哦。 3、添加大数据文摘客服账号“文文”（ID：bigdatagjj），“文摘菌”（ID：superbigdata），ta们也会在朋友圈每天发布最新小抄表，和大家一起学习。 最后，让我们感谢所有参与这次翻译校对设计和管理的志愿者们，是你们不计回报的付出才让这份小抄表的中文版最终面世： 翻译： 范玥灿Edward、李越、魏晓聪、笪洁琼、文静、一针、Echo Lai、王富贵、王奕磊、蔡雨辰、冯媛、刘冠男、张礼俊、潘一伟、李聪之、远方 校对： 程亚雄、金诗韵、田苗苗、Fox 、吕征达、赵承业、夕映、张露、邹可 、Figo、Jamie  Sun、马新、李浩铭、徐子尧、谑、伊可心、赵江、kevin、koala 设计： 王富贵、王得宇 统筹： 王富贵、魏子敏、韩蕊 以下是部分小抄表内容，各位不妨先睹为快啊： 
215,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656242&idx=3&sn=6f53e522c508ebe875cb5d62a71e3fad&chksm=bd4c37a18a3bbeb7716dce7afbce246b1e9240596da0724162494508a6f0c94d8462172c6f15&scene=0,重磅 | 数据挖掘之父韩家炜：文本语料库的数据挖掘（附视频+PPT下载）,授权转载自公众号数据派THU 微信ID:DatapiTHU 近期，美国伊利诺伊大学厄巴纳香槟分校计算机科学Abel Bliss教授韩家炜在清华大学FIT楼多功能厅进行了关于文本语料库数据挖掘的主题分享。   嘉宾简介：韩家炜，美国伊利诺伊大学香槟分校计算机系教授，IEEE和ACM院士，美国信息网络学术研究中心主任。曾担任KDD、SDM和ICDM等国际知名会议的程序委员会主席，创办了ACM TKDD学报并任主编。在数据挖掘、数据库和信息网络领域发表论文900余篇。   以下为演讲现场视频： 全文演讲PPT如下： 回复关键词“hjw”，下载完整版PPT。 
216,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656302&idx=3&sn=f4e161bcdc897351534fbe51bd010b73&chksm=bd4c37fd8a3bbeeb9c336768727d29e3d7817f792f2c297259bf514fa4c9b8aa73b87188781d&scene=0,"AI大事件 | 胶囊网络的TensorFlow实现，Facebook关闭私人助理""M""",呜啦啦啦啦啦大家好呀，又到了本周的AI大事件时间了。过去的一周中AI圈都发生了什么？大佬们互撕了哪些问题？研究者们发布了哪些值得一读的论文？又有哪些开源的代码和数据库可以使用了？文摘菌带你盘点过去一周AI大事件！ 新闻 Facebook关闭私人助理“M” 来源： TECHCRUNCH.COM 链接： https://techcrunch.com/2018/01/08/facebook-is-shutting-down-its-standalone-personal-assistant-m/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI M的用户收到了Facebook将在1月19日停止服务的消息。虽然M一直以来都以AI的标签在台前行走，但是幕后的M实际上仍然需要依靠人类来回答最复杂的查询。例如，您可以在预定餐厅、，订购鲜花或安排下一个假期。 Yann LeCun 疯狂抨击机器人Sophia 来源： WWW.BUSINESSINSIDER.COM   链接： http://www.businessinsider.com/facebook-ai-yann-lecun-sophia-robot-bullshit-2018-1?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 日前Yann LeCun对之前引起热议的机器人Sophia发出了猛烈的抨击，甚至用上了脏字。该机器人曾经以发表“希望毁灭人类”言论而成文热点。 给AI正名 来源： WWW.NYTIMES.COM   这篇文章认为，由Elon Musk等人推动的人工智能调控方法是一个错误。我们其实早就在管理AI了，知识没有把它叫做AI而已。 Google Brain Team的2017年回顾 来源： RESEARCH.GOOGLEBLOG.COM   链接： https://research.googleblog.com/2018/01/the-google-brain-team-looking-back-on.html?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这个由两部分组成的系列文章回顾了Google Brain团队在2017年所做的工作。这也是对去年研究进展的总体概述。 PyImageConf 2018：实用计算机视觉会议 来源： WWW.PYIMAGESEARCH.COM   PyImageConf 2018是一个新的会议，将于8月26日至28日在旧金山凯悦酒店举行。 文章&教程 强化学习算法介绍（一） 来源：TOWARDSDATASCIENCE.COM 这篇文章涵盖了强化学习（RL）基础知识和流行的Q-Learning，SARSA，DQN和DDPG算法。 Ray：AI的分布式系统 来源： BAIR.BERKELEY.EDU   链接： http://bair.berkeley.edu/blog/2018/01/09/ray/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI Ray的目标之一是使使用者能够将笔记本电脑上运行的原型算法转换为在群集上高效运行的高性能分布式应用程序。 用一个模型解决所有的AI问题 来源： BLOG.ACOLYER.ORG 链接： https://blog.acolyer.org/2018/01/12/one-model-to-learn-them-all/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 深度神经网络通常是针对具体的问题而设计并进行调整的。 我们能否创建一个统一的深度学习模型来解决跨多个领域的任务呢？ 代码，项目&数据 通过深度学习将设计模型转化为代码 来源： BLOG.FLOYDHUB.COM 链接： https://blog.floydhub.com/turning-design-mockups-into-code-with-deep-learning/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这篇文章介绍了如何训练神经网络以达到基于设计模型的图片来编码基本的HTML和CSS网站的目的。可以在GitHub上找到所有代码。 强化学习的MuJoCo与Unity集成包 来源 ： WWW.MUJOCO.ORG 链接： http://www.mujoco.org/book/unity.html?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI MuJoCo插件和Unity集成包的目标是一石二鸟：在同一个项目中同时使用MuJoCo物理模拟和Unity渲染。 胶囊网络的Tensorflow实现 来源： GITHUB.COM   链接： https://github.com/JunYeopLee/capsule-networks?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI Hinton最近的论文——“胶囊之间的动态路径”（Dynamic Routing Between Capsules）的TensorFlow实现。 论文 具有优先级队列训练的程序合成神经网络 （Neural Program Synthesis with Priority Queue Training） 来源： ARXIV.ORG   链接： https://arxiv.org/abs/1801.03526?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 作者认为程序合成的任务是在程序输出中存在奖励函数的情况下进行的，目标是找到奖励函数的值最大的程序。他们使用的PQT算法优于标准值。另外，通过将程序长度添加到奖励函数的惩罚减分条件中，算法可以合成短的、人类可读的程序。 eCommerceGAN：电子商务的GAN-Amazon出品 （eCommerceGAN : A Generative Adversarial Network for E-commerce (Amazon)） 来源： ARXIV.ORG 链接： https://arxiv.org/abs/1801.03244?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 这篇文章介绍了用于在电子商务网站上处理订单的生成式对抗网络（GAN）。 经过训练后，GAN中的发单机可以产生任何数量合理的订单。 强化学习的预期梯度策略 （Expected Policy Gradients for Reinforcement Learning） 来源 ： ARXIV.ORG 链接： https://arxiv.org/abs/1801.03326?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI 作者提出了一种新的框架，在这个框架中，行为者的目的是最大化回报的期望值，同时也使熵最大化 - 也就是在尽可能随机的情况下成功完成任务。 回复 “ ”加入我们 
217,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656242&idx=2&sn=07d2a41c7cbc28d68a0c0bfbaafea84d&chksm=bd4c37a18a3bbeb762a4025a4f6eb227f0b37df9c878b470557f3c46e016a3638c2436db7b85&scene=0,免费 | 从一月份开始，600+编程与计算机科学在线课程等你来学,"六年前，麻省理工和斯坦福大学等高校第一次向公众开放了免费在线课程。到现在，全世界已有超过700所学校开设了数千门免费在线课程。     新年过后，不少读者又在后台问文摘菌要学习资料了。于是乎，文摘菌从网络上9000多门免费公开课中整理了600多门可以从一月份开始学习的免费课程，并附上了每门课程的评分（满分5颗星）——有了这些课程的陪伴，相信18年也会是收获满满的一年吧！   标【新】的课程表示该课程为第一次开放。 对于许多课程，你都可以根据自身情况灵活安排时间学习。剩下的一部分会在一月末的不同时间依次开课。   对刚开始学习编程的同学来说，这份长长的课程表单可能会让人望而却步。不用怕，你当然不需要将所有的课程都学完。你完全可以根据自己的需要进行关键词检索，迅速找到最适合自己的课程开始学习。 我们在这里先列出155门初级课程+349门中级课程的清单，感兴趣的同学可以去原文找到网址直接保存学习啦。 地址： https://medium.freecodecamp.org/600-free-online-programming-computer-science-courses-you-can-start-in-january-3d4b1ed473aa 初级（151） Python交互式编程导论（一），莱斯大学，★★★★★ (3011) 人人都懂的编程课（从Python开始），密歇根大学，★★★★★(2279) MATLAB编程导论， 范德比尔特大学，★★★★★(181) Python数据科学与编程导论，麻省理工学院，★★★★★(113) 学习编程:基础篇，多伦多大学，★★★★★(99) 计算机科学导论，弗吉尼亚大学，★★★★☆(68) Ruby on Rails简介，约翰霍普金斯大学，★★★☆☆(55) Python交互式编程导论（二）， 莱斯大学，★★★★★(52) 如何使用Git和GitHub HTML5导论，密歇根大学，★★★★☆(41) Linux入门，Linux基金会，★★★★☆(37) 互联网的历史，科技和安全， 密歇根大学，★★★★★(36) HTML和CSS导论 VBA/Excel编程导论，加州州立大学波莫纳分校， ★★★★☆(26) 【新】软件工程导论，不列颠哥伦比亚大学 【新】用Excel/VBA创造性地解决问题（一）， 科罗拉多大学波德分校 【新】Swift开发简介，莫斯科物理技术学院 【新】通过C语言编程解决问题，印度理工大学 【新】物联网技术导论，印度理工大学 【新】Python编程导论，德克萨斯大学阿灵顿分校 【新】局域网，图卢兹大学 JavaScript和DOM 从第一性原理构建现代计算机:从闪存到俄罗斯方块（Nand to Tetris）(以项目为中心的课程)，耶路撒冷希伯来大学，★★★★★(23) 网络安全导论，英国开放大学 CS101：计算机科学101，斯坦福大学，★★★★☆(15) CSS3导论，密歇根大学，★★★★★(13) 编程基础，印度理工学院孟买分校，★★☆☆☆(13) Python编程基础 网络：计算机网络导论，斯坦福大学，★★★★★(11) DB：数据库导论，斯坦福大学，★★★★★(11) 面向Web开发者的HTML, CSS 和JavaScript，约翰霍普金斯大学，★★★★★(10) 物联网和嵌入式系统导论，加利福尼亚大学尔湾分校，★★★★☆(10) 数字媒体和移动应用程序的创造性编程，伦敦大学国际项目，★★★★☆(10) 网络安全基础，荷语天主教鲁汶大学，★★★★★(10) JavaScript, HTML 和CSS编程基础，杜克大学，★★★★☆(9) 实用安全，马里兰大学帕克分校，★★★☆☆(9) Boostrap简介–教程，微软，★★★☆☆(9) HTML5编程基础和最佳实践，万维网联盟，★★★★☆(9) 自己编码！编程导论，爱丁堡大学，★★★★★(8) 学习编程：写出高质量代码，多伦多大学，★★★★☆(7) p5.js可视化艺术编程导论，加州大学洛杉矶分校，★★★★★(7) 云计算导论，电气与电子工业协会，★★☆☆☆(6) 网络安全导论，英国开放大学 jQuery导论，微软，★★★★☆(5) HTML5和CSS基础，互联网联盟，★★★★☆(5) Java编程导论（一），香港科技大学，★★★★☆(4) Python编程简论，卫斯理大学，★★★☆☆(4) Java编程导论：开始使用Java编程，马德里卡洛斯三世大学，★★★★☆(4) 计算机编程范例-基本原理，法语天主教鲁文大学，★★★★★(4) 计算机编程范例-抽象和并发性，法语天主教鲁文大学，★★★★☆(4) 儿童编程语言scratch，哈维穆德学院，★★★★★(4) 如何在一个周末内建立一个网站（以项目为中心的课程），纽约州立大学，★★★★★(3) Python计算导论，佐治亚理工学院，★★★★★(2) 面向对象的程序设计，印度理工学院孟买分校，★★★★☆(2) 思考·创造·编码，阿德莱德大学，★★★★★(2) 智能手机里的计算技术，康乃尔大学，★★★★★(2) 安卓基础：制作你的第一个应用，谷歌，★★★★☆(2) 学习Python编程，德克萨斯大学阿灵顿分校，★★★★★(2) HTML和JavaScript导论，微软，★★★★★(2) 计算机科学和Python编程入门，哈维穆德大学，★★★★★(2)   用JavaScript进行Web编程，宾夕法尼亚大学，★★★★★(1) 网络：朋友，金钱和字节，普林斯顿大学，★★★☆☆(1) 如何编码：简单的数据，不列颠哥伦比亚大学，★★★★★(1) 使用Wordpress进行web开发和设计，加州艺术学院，★★★★☆(1) 安卓应用开发新手入门，伽利略大学，★☆☆☆☆(1) 艺术家Web编程基础，新加坡国立大学，★★★★☆(1) 学习java编程，微软，★★★★★(1) 计算：艺术，魔法和科学，苏黎世联邦理工大学，★★★★☆(1) MyCS：计算机科学新手入门，哈维穆德学院，★★★☆☆(1) 数据存储与管理技术导论，电气与电子工业协会，★★★☆☆(1) CODAPPS: 为企业家编写移动应用，里昂商学院，★★★★★(1) 大学预修课程：计算机科学的原则， 哈佛大学 计算的美丽与乐趣—大学预修课：计算机原理，加州大学伯克利分校 JavaScript, jQuery, 和JSON，密歇根大学 用PHP构建数据库应用程序，密歇根大学 SQL导论，密歇根大学 Unix平台，约翰霍普金斯大学 编程基础，杜克大学 网络安全导论，华盛顿大学 Python编程要点，莱斯大学 Python的数据表示，莱斯大学 构造交互式3D角色和社交虚拟现实（VR），伦敦大学国际项目 虚拟现实（VR）导论，伦敦大学国际项目 面向大众的编程：编程导论，亚利桑那州立大学 现代应用程序开发导论，马德里科技大学 Web开发导论，加州大学戴维斯分校 Java编程导论（二），香港科技大学 大学预修课之计算机科学A: Java编程的类和对象，普渡大学 大学预修课之计算机科学A: Java编程多态和高级数据结构，普渡大学 大学预修课之计算机科学A: Java编程的类和对象，普渡大学 JavaScript（1）基本原理和功能，莫斯科物理与技术学院 精致排版，莫斯科物理与技术学院 用商业模式让安卓应用赚钱，伽利略大学 安卓开发的Java基础，伽利略大学 Java：面向对象的编程，安第斯大学 网络安全基础:亲自动手实践， 马德里卡洛斯三世大学 Java编程导论：写出高质量代码，马德里卡洛斯三世大学 TCP/IP导论，延世大学 用于商业的深度学习，延世大学 商业中的网络安全导论，科罗拉多大学系统 抽象化软件设计，科罗拉多大学系统 TCP/IP及更高级主题，科罗拉多大学系统 作为软件开发生命周期中一个元素的软件设计，科罗拉多大学 系统 软件开发:方法与工具，科罗拉多大学系统 计算机安全前瞻，科罗拉多大学系统 电子游戏设计与平衡，罗切斯特理工学院 移动web开发，谷歌 Web可访问性，谷歌 Node.js 简介，微软 设计思考导论，微软 Java中的面向对象编程，微软 ReactJS简介，微软 Python导论：基础，微软 Python导论：完全新手入门 CSS基础，微软 逻辑和计算思维，微软 编写专业代码，微软 中小企业的网络安全:识别威胁和防范攻击，迪肯大学 计算：艺术，魔法与科学（二），苏黎世联邦理工学院 网络攻击导论，纽约大学 网络攻击的对策，纽约大学 软件工程本质，慕尼黑工业大学 家庭网络基础，思科公司 思科网络简介，思科网络公司 数据通信与网络服务，思科公司 网络协议与框架，思科公司 网络连接：如何联网？思科 JavaScript导论，互联网联盟 MongoDB导论，MongoDB大学 Swift新手入门 Git版本控制 M001：MongoDB基础 Python导论 ES6-JavaScript进阶 GitHub与协同 HTTP与Web服务器 中级（349） Python数据结构，密歇根大学，★★★★★(1366) 使用Python访问Web数据，密歇根大学，★★★★★(744) Python数据库开发，密歇根大学，★★★★★(662) 机器学习，斯坦福大学，★★★★★(323) Scala函数式编程原则，洛桑联邦理工学院，★★★★★(61) 算法（一），普林斯顿大学，★★★★★(58) 面向音乐家和艺术家的机器学习，伦敦大学，★★★★★(54) 密码学，斯坦福大学，★★★★★(49) Scala函数式编程原则，洛桑联邦理工学院，★★★★★(38) 面向安卓手持系统的编程移动应用程序（一），马里兰大学，★★★★☆(38) CS188：人工智能，加州大学伯克利分校，★★★★★(30) 计算原理（一），莱斯大学，★★★★★(29) 【新】创建虚拟现实应用，加州大学圣地亚哥分校 【新】机器学习基础，，加州大学圣地亚哥分校 【新】C++开发基础，莫斯科物理技术学院 【新】利用机械操作系统的软件开发，国立核能研究大学 【新】计算机组织与构架：教学视角，印度理工学院 【新】数字游戏设计：风暴来临 响应式网站设计：HTMML,CSS和JavaScript代码，伦敦大学国际项目，★★★★☆(24) 机器学习实践，约翰霍普金斯大学，★★★☆☆(23) 软件安全，马里兰大学，★★★★★(22) 算法（二），普林斯顿大学，★★★★★(21) 程序设计语言(A)，华盛顿大学，★★★★★(21) 云计算概念(一)，伊利诺伊大学香槟分校，★★★☆☆(20) 应用Ruby on Rails快速开发:基础，★★★★★(19) 自动控制原理，斯坦福大学，★★★★☆(18) 机器学习导论，斯坦福大学，★★★★☆(18) 算法工具箱，加州大学圣迭戈分校，★★★★☆(16) 计算原理（二），莱斯大学，★★★★☆(16) 用C#开始游戏编程，科罗拉多大学系统，★★★★☆(16) 安卓开发新手入门，谷歌，★★★★☆(16) C程序员的C++教程 (A)，加州大学圣克鲁兹分校，★★★☆☆(16) 代码的本质，Processing Foundation社区，★★★★★(16) M101J: 面向Java开发者的MongoDB 面向安卓手持系统的编程移动应用程序（二），马里兰大学，★★★★☆(15) 游戏开发概念，斯威本科技大学，★★★★☆(15) 算法思想（一），★★★★☆(14) 计算机程序设计，斯坦福大学，★★★★☆(13) 文本检索与搜索引擎，伊利诺伊大学香槟分校，★★★☆☆(13) Java中的面向对象编程，加州大学圣迭戈分校，★★★★★(13) Arduino平台与C程序设计，加州大学尔湾分校，★★★☆☆(12) Java编程:用软件解决问题，杜克大学，★★★☆☆(12) 响应式网页设计，伦敦大学国际项目，★★★★☆(12) 离散优化，墨尔本大学，★★★★☆(12) 游戏开发导论，密歇根州立大学，★★★★★(12) 使用JavaScript 实现交互功能，密歇根大学，★★★★☆(11) 函数式编程入门，代尔夫特理工大学，★★★★☆(11) 安卓应用开发，谷歌，★★★☆☆(11) 面向对象的JavaScript，Hack Reactor训练营，★★★★★(11) M101JS:面向Node.js开发者的MongoDB 程序设计语言，弗吉尼亚大学，★★★☆☆(10) 软件产品管理导论，阿尔伯塔大学，★★★★☆(10) M101P: 面向开发者的MongoDB 算法思想(二)，莱斯大学，★★★★☆(9) 软件开发过程与敏捷开发实践，阿尔伯塔大学，★★★★☆(9) 响应式网页设计基础，Google ★★★★★（9） 高阶响应式设计，密歇根大学 ★★★★★（8） 图像和视频处理：从火星到好莱坞，然后到医院，杜克大学   ★★★★（8） 密码学，马里兰大学帕克分校 ★★★★☆（8） 从数据中学习（机器学习入门课程），加州理工学院 ★★★★★（8） Julia科学编程，开普敦大学 ★★★★★（8） M102：面向数据库管理员（DBA）的MongoDB 云计算应用程序，第1部分：云系统和基础结构，伊利诺伊大学·香槟分校 ★★★☆☆（7） Swift编程导论，多伦多大学 ★☆☆☆☆（7） 客户需求和软件要求， 阿尔伯塔大学 ★★★★☆（7） 软件测试，犹他大学 ★★★★☆（7） 用MongoDB进行数据处理，MongoDB大学 ★★★★☆（7） AJAX Ruby on Rails Web服务和MongoDB集成简介，约翰·霍普金斯大学 ★★★★★（6） Arduino接口，加利福尼亚大学尔湾分校 ★★★★☆（6） 计算机体系结构，普林斯顿大学 ★★★★☆（6） 物联网：从何而来？ ，加州大学圣地亚哥分校 ★★☆☆☆（6） 利用JavaScript和MongoDB开发Web应用程序，伦敦大学国际课程  ★★★★☆（6） Meteor.js开发导论，伦敦大学国际课程 ★★★★☆（6） 如何编码：系统程序设计（第一部分），不列颠哥伦比亚大学 ★★★★☆（6） DevOps入门，Nutanix★★★☆☆（6） Java软件构建，麻省理工学院 ★★★★★（5） 使用Ruby on Rails进行敏捷开发-高阶，加州大学伯克利分校 ★★★★★（5） 计算机图形学（加州大学伯克利分校）★★★★☆（5） 使用Ruby on Rails进行敏捷开发（加州大学伯克利分校高级课程）★★★★★（5） 树莓派平台（The Raspberry Pi Platform）和基于树莓派的Python编程，加利福尼亚大学尔湾分校★★★☆☆（5） 软件开发过程，佐治亚理工学院 ★★★★☆（5） 计算机网络，乔治亚理工学院 ★★★★☆（5） Java编程：数组，列表和结构化数据，杜克大学★★★★★（5） 云计算概念：第二部分，伊利诺伊大学香槟分校 ★★★★★（5） 数据结构和性能，圣地亚哥加州大学 ★★★★★（5） HTML5游戏开发，Google ★★★☆☆（5） C ++入门，Microsoft ★★★★☆（5） 软件调试，萨尔兰大学 ★★★★★（5） 基于AngularJS的单页Web应用程序，约翰霍普金斯大学 ★★★★★（4） 字符串算法，加州大学圣地亚哥分校 ★★★☆☆（4） Java程序设计：软件设计原理，杜克大学 ★★★★★（4） 云网络，伊利诺伊大学香槟分校 ★★★★☆（4） 物联网：建立你的DragonBoard™开发平台，加州大学圣地亚哥分校 ★★★☆☆（4） 物联网和增强现实（AR）的新兴技术，延世大学 ★★★☆☆（4） 数据库管理概要，科罗拉多大学 ★★★★☆（4） 网络安全基础，罗切斯特理工大学 ★★★★★（4） 网站性能优化，Google ★★★★☆（4） 使用Transact-SQL查询数据，Microsoft ★★★★☆（4） 交互式计算机图形学，东京大学 ★★☆☆☆（4） jQuery介绍 使用Python进行研究，哈佛大学 ★★★☆☆（3） Rails的Active Record 和Action Pack，约翰霍普金斯大学 ★★★★☆（3） Objective-C App开发基础，加利福尼亚大学尔湾分校 ★★★☆☆（3） 数据结构，加州大学圣地亚哥分校 ★★★☆☆（3） 网络原理图解：零微积分基础也能懂（普林斯顿大学）★★★★☆（3） VLSI CAD第一部分：逻辑，伊利诺伊大学香槟分校 ★★★★★（3） 掌握软件工程面试，加州大学圣地亚哥分校 ★★★★☆（3） 物联网：通信技术，加利福尼亚大学圣地亚哥分校 ★★★☆☆（3） 现代平台的游戏开发，密歇根州立大学 ★★★★★（3） 适用于初学者的MATLAB和Octave，洛桑联邦理工学院 ★★★☆☆（3） 无线通信的新兴技术，延世大学 ★★★★☆（3） 移动开发者的UX设计, Google  ★★★★★（3） Android基础知识：用户输入, Google ★★★★☆（3） Android基础知识：多屏应用, Google ★★★★☆（3） JavaScript 的 Promise对象, Google ★★★★★（3） 针对开发人员：如何开始DevOps，Microsoft ★★★★☆（3） 敏捷软件开发，苏黎世联邦理工学院 ★★★★☆（3） 自动移动机器人，苏黎世联邦理工学院 ★★★☆☆（3） LPL：语言，证明和逻辑，斯坦福大学 ★★★★★（2） 编译器，斯坦福大学 ★★★★☆（2） 移动应用经验第1部分：从领域到应用程序的想法，麻省理工学院 ★★★★★（2） 树莓派（Raspberry Pi）接口，加利福尼亚大学尔湾分校 ★★★☆☆（2） 机器学习：无监督学习，布朗大学 ★★★★★（2） 图形算法，加州大学圣地亚哥分校 ★★★★☆（2） Java高级数据结构，加州大学圣地亚哥分校 ★★★★☆（2） 编程语言，B部分，华盛顿大学 ★★★★★（2） 响应式网站教程和范例，伦敦大学国际课程 ★★★★★（2） iOS应用设计与开发，多伦多大学 ★★★☆☆（2） iOS应用开发基础, 多伦多大学  ★★★★☆（2） Android应用程序组件 -服务，本地进程间通信和内容提供者，圣德堡大学 ★★★☆☆（2） Android应用程序组件 -内容，活动和广播接收器, 范德堡大学  ★★★☆☆（2） Android移动应用程序开发入门，香港科技大学 ★★★★☆（2） 互联网新兴技术，延世大学 ★★★☆☆（2） 软件产品的敏捷规划，阿尔伯塔大学 ★★★☆☆（2） Android基础：网络设计，Google ★★★★☆（2） 浏览器渲染优化，Google ★★★★☆（2） 客户端 - 服务器（C/S结构）通信，Google  ★★★★★（2） 国际软件开发（一），Microsoft ★★★★☆（2） 使用Power BI分析和可视化数据，Microsoft ★★★★★（2） 开发你的第一个Android应用（以项目为中心的课程），巴黎中央音乐学院 ★★★☆☆（2） 近似算法（一），巴黎高等师范学院 ★★★★★（2） 计算结构2：计算机架构，麻省理工学院 ★★★★☆（1） 软件开发基础，宾夕法尼亚大学 ★★★☆☆（1） iOS用户界面设计的最佳实践，加州大学欧文分校 ★★★★★（1） 软件架构与设计，乔治亚理工学院  ★★★★★（1） 高级算法及其复杂性，加利福尼亚大学圣地亚哥分校 ★★★☆☆（1） 数据库系统概念与设计，佐治亚理工大学 ）★★★★☆（1） 编程语言，C部分，华盛顿大学 ★★★★★（1） 虚拟现实的3D建模，伦敦大学国际项目 ★★★★★（1） 如何编码：复杂数据，英属哥伦比亚大学 ★★★★★（1） 管理敏捷开发团队，弗吉尼亚大学 ★★☆☆☆（1） 入门：敏捷开发与设计思维（弗吉尼亚大学）★★★★★（1） 运行产品设计冲刺（Design Sprints，译注：是美国流行的一种兼得设计和时间的群体性设计方法 ），弗吉尼亚大学 ★★★☆☆（1） 敏捷软件开发，明尼苏达大学 ★★★★☆（1） 用Java开发Android，范德堡大学★☆☆☆☆（1） 使用NodeJS，Express和MongoDB进行服务器端开发，香港科技大学 ★★★★★（1） 网络安全经济学，代尔夫特理工大学 ★★☆☆☆（1） Web应用程序开发：基本概念，新墨西哥大学 ★★★★☆（1） 面向服务的体系结构，阿尔伯塔大学 ★★★★★（1） 设计模式，阿尔伯塔大学 ★☆☆☆☆（1） 物联网软件架构,  欧洲理工EIT Digital硕士项目★★★★☆（1） 网络安全性和移动性，佐治亚大学系统 ★☆☆☆☆（1） 针对AWS从业人员的Google云端平台基础，Google云 ★★☆☆☆（1） Android性能，Google ★★★★★（1） 针对Android开发者的材料设计语言（Material Design），Google ★★★★★（1） Android基础：用户界面，Google ★★☆☆☆（1） Android基础：按钮点击，Google ★★★☆☆（1） Google云平台基础：核心基础架构，Google ★★★★☆（1） 可规模化的微服务（Microservices）与Kubernetes，Google ★★★★☆（1） 用Java开发可规模化的应用程序（Google）★★★★☆（1） 用Python开发可规模化的应用程序（Google）★★★★☆（1） Gradle在Android和Java上的应用（译注：Gradle是一个项目自动化构建工具），Google ★★★★★（1） C＃入门，Microsoft ★★☆☆☆（1） 中级C ++，Microsoft ★★★★☆（1） 机器学习原理，Microsoft ★★★★★（1） C＃入门，Microsoft ★★☆☆☆（1） AngularJS：高级框架技术（Microsoft）★★★★☆（1） 使用Javascript进行异步编程（Microsoft）★★★★★（1） AngularJS：高级框架技术（Microsoft）★★★★☆（1） 从第一性原理构建现代计算机:从闪存到俄罗斯方块（Nand to Tetris） 2（以项目为中心的课程），耶路撒冷希伯来大学 ★★★★★（1） 基于libGDX 开发2D游戏，亚马逊★★★★★（1） 云基础设施技术导论，Linux基金会 ★★★★☆（1） 物联网开发者指南，IBM ★★★★☆（1） 实时系统介绍， IEEE ★★★★☆（1） 如何赢得编程比赛：冠军的秘密，ITMO大学★★★☆☆（1） HTML5应用程序和游戏，万维网联盟（W3C）★★★☆☆（1） 技术访谈，Pramp★★★★★（1）         概率图模型3：学习过程，斯坦福大学 图搜索，最短路径和数据结构，斯坦福大学 贪婪算法（greedy algorithm），最小生成树和动态规划，斯坦福大学 重访最短路径，NP完全问题（NP-Complete Problems）以及如何处理这些问题，斯坦福大学 算法：设计与分析，斯坦福大学 分治算法，排序搜索和随机算法（斯坦福大学） Java高级软件构建，麻省理工学院 移动应用程序经验，麻省理工学院 移动应用程序经验（三）：构建移动应用程序，麻省理工学院 算法设计与分析，宾夕法尼亚大学 数据结构和软件设计，宾夕法尼亚大学 PHP构建Web应用程序，密歇根大学 使用R处理神经影像，约翰霍普金斯大学  Swift开发iOS的未来，加利福尼亚大学欧文分校  游戏，传感器和媒体，加利福尼亚大学尔湾分校 iOS应用程序中的网络系统和安全性，加利福尼亚大学欧文分校 软件分析和测试，佐治亚理工学院 数据库系统概念和设计，乔治亚理工学院 C语言的编写，运行和代码调试，杜克大学 用CGI做动画，哥伦比亚大学 从游戏《我的世界》（Minecraft）中学习编码和教学，加州大学圣地亚哥分校 物联网：设备感应和驱动, 加利福尼亚大学圣地亚哥分校  虚拟现实（VR）如何运作，加州大学圣地亚哥分校  网络安全： CISO的观点，华盛顿大学  创建一个网络安全工具包，华盛顿大学  超级计算，欧洲的高级计算合作商 算法设计与分析，北京大学  面向对象技术高级课程，北京大学  软件构建：面向对象设计，不列颠哥伦比亚大学  如何编码：系统程序设计（第二部分），哥伦比亚大学 如何编码：系统程序设计 （第三部分），哥伦比亚大学  软件构建：数据抽象，哥伦比亚大学  敏捷测试，弗吉尼亚大学  数据科学SQL，加利福尼亚大学戴维斯分校  LAFF -正确性程序设计谈起，德克萨斯大学奥斯汀分校  LaTeX中的文档和演示（LaTeX入门），高等经济学院  软件开发过程和方法，明尼苏达大学  精益软件开发，明尼苏达大学  工程维护的Android应用程序，Vanderbilt大学  用App Inventor开发Android应用程序，香港科技大学  前端JavaScript框架：Angular，香港科技大学  前端Web UI框架和工具：Bootstrap 4，香港科技大学  Web技术的多平台移动应用程序开发：Ionic和Cordova，香港科技大学  NativeScript多平台移动应用开发，香港科技大学  建设Arduino机器人和设备，莫斯科物理和技术学院  JavaScript（第二部分）：原型和异步，莫斯科物理与技术研究院  数据结构基础，印度理工学院孟买分校  数据结构实施，印度理工学院孟买分校  专业Android应用程序开发，伽利略大学  Java编程简介：基础数据结构和算法，卡洛斯三世马德里大学  软件架构师代码：建设数字世界，马德里卡洛斯三世大学  企业软件生命周期管理，国家核研究所MEPhI  软件改进的复核和指标，阿尔伯塔大学  面向对象设计，阿尔伯塔大学  软件需求优先级：风险分析，科罗拉多大学  Linux服务器管理和安全性，科罗拉多大学  检测和减轻网络威胁和攻击，科罗拉多大学  基础密码学和Crypto API编程，科罗拉多大学  黑客和补丁，科罗拉多大学  网络通信基础，科罗拉多大学  软件设计的威胁与缓解，科罗拉多大学  安全网络系统的设计与分析，科罗拉多大学  国土安全与网络安全连接 –与恐怖分子无关，科罗拉多大学  SRS文件：要求和图解符号，科罗拉多大学  对等协议和局域网，科罗拉多大学  分组交换网络和算法，科罗拉多大学  要求规格：目标与冲突分析，科罗拉多大学  对称密码学，科罗拉多大学  安全软件开发要求一览，科罗拉多大学  需求启发：工件和利益相关者分析，科罗拉多大学  不对称加密与密钥管理，科罗拉多大学  数据结构导论，阿德莱德大学 软件测试管理，马里兰大学  企业云计算，马里兰州大学  软件测试管理，马里兰大学  软件测试基础，马里兰大学系统  软件的形式验证（Formal Verification），马里兰州大学  云计算基础设施，马里兰州大学  云计算管理，马里兰州大学  针对视频游戏设计师的游戏编程，罗切斯特理工学院  团队协作与合作，罗切斯特理工学院  网络安全风险管理，罗切斯特理工学院  嵌入式系统中的Web连通性和安全性，EIT Digital 项目 构建智能物联网设备简介，EIT Digital项目 构建智能物联网设备，EIT Digital项目 网络安全与物联网，格鲁吉亚大学  网络安全与X因素，格鲁吉亚大学 "
218,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656242&idx=1&sn=4c4d72b4cc2f975da0e5d40c1c3659b2&chksm=bd4c37a18a3bbeb70f99c1d31452c830e0d3a572bf0bb89546f11a4a2a0946f3168c6034bcf3&scene=0,Gary Marcus再发万字长文，列14个Q&A回应机器学习批判言论,"“所有的真理都经历了三个阶段：第一，被嘲笑； 第二，被强烈反对；第三，被不证自明地接受。“Gary Marcus引用叔本华的这段话为自己的另一篇万字长文进行了开篇，以回应他近期面对的“推特上的成千上万条质疑”。 1月初，一直对深度学习持质疑态度的纽约大学教授、人工智能创业者Gary Marcus在arxiv上发布了一篇长文，列举十大理由，质疑深度学习的局限性，在AI学术圈又掀起了一轮波澜。 Gary Marcus文章地址： https://arxiv.org/ftp/arxiv/papers/1801/1801.00631.pdf 今天凌晨，针对学术圈（推特圈）对这篇文章的质疑（查看大数据文摘相关报道 ）， Marcus又发了一篇长文，他总结了这次论战中14个常见的问题，并一一给出答案，来回应各种挑战。 无监督学习更适合哪些领域？ 为什么我不会谬赞深度学习？ 为什么我最有权讨论这件事？ Gary Marcus是被Uber收购的人工智能初创公司 Geometric Intelligence 的创始人兼CEO，同时是纽约大学心理学及神经科学教授。大数据文摘对这些问题进行了摘要，以下为精华内容： 质疑1. 什么是通用人工智能（general intelligence）？ 机器学习的著名教授、迄今为止最佳评论家Thomas Dietterich教授给出了一个很好的答案，我很满意： “通用人工智能”是一个广泛目标和环境下的智能系统。例如，参见Russell和Norvig的教科书，以及他们对“智能“的定义——“理性行事”。 质疑2. Marcus对深度学习不够友好，他没有提及深度学习的各种成绩，并低估了其他人（的研究）。 上面提到的Dietterich提出了这两点： @GaryMarcus的文章令人失望。他几乎没有谈到深度学习的成就（如NL翻译），并低估了其成绩（例如有1000个类别的ImageNet依然很有限）。 关于深度学习的成绩，我确实可以说得更多，但我不是没有说，我在第一页提到了深度学习的成就：“自那时以来，深度学习在语音识别，图像识别和语言翻译等领域取得了许多成就，并在当前广泛的AI应用中发挥着重要作用。” 并且，在文章最后我引用了几个文本和博客，提及了很多例子。不过，这些大部分并不算是通用人工智能，这是我的论文的主要论点。 （例如，Google翻译做得很棒，但其并不是通用的，例如，它不能像人类翻译员那样，回答关于翻译内容的问题。） 质疑的第二部分更具实质性。 1,000个类别真的非常有限吗？与认知的灵活性相比，我认为是的。认知科学家通常认为，每个人认知的元素概念大概有5万个数量级，我们可以很容易将这些概念组合，获得更多的复杂想法。 你可以在谷歌图像上搜索的“宠物鱼”，给出的图片还不错；但是，再试一下“佩戴护目镜的宠物鱼”，你会搜到大量带护目镜的狗的图片，误报率超过80％。在辨认狗的种类这种问题上，机器会比人类更强，但是在描述复杂场景的时候，人类更有利。 在我看来，把机器学习问题集中在1000个类别块上，也限制了其解决更开放的问题（比如场景和句子理解）。 质疑3. Marcus说深度学习是无用的，但深度学习对很多问题都很有用。 深度学习当然是有用的，我的观点是： 在目前的监督学习形式下，深度学习可能正在接近其极限， 这些极限将使通用人工智能不能完全实现。 我的结论的核心是这样的： 尽管我勾勒了许多问题，但我不认为我们需要放弃深度学习。 相反，我们需要对其进行重新概念化：不是作为一种普遍的溶剂，而是作为众多工具中的一种。如果深度学习比喻为电动螺丝刀，那么我们还需要锤子、扳手和钳子。 质疑4. Marcus说DL对分层结构不好，但LeCun的《自然》综述中说，其特别适合于这样的层次结构。 这是Ram Shankar的一个问题，我可以很清楚地回答：有许多不同类型的层级可以考虑。对于LeCun说的那种特征层次来说，深度学习是非常好用的，也许是有史以来最好用的，我通常把它称为层次特征检测。你可以用像素来构建线条，用线条组成字母，用字母组成单词。 Kurzweil和Hawkins也强调了这一点，这类工作真的可以追溯到Hubel和Wiesel（1959）的神经科学实验，和福岛的作品（福岛，三宅和伊藤，1983）。福岛在他的Neocognitron模型中，手工连接了很多抽象特征的层次结构；LeCun等很多人后来证明了（至少在某些情况下）你不必手工设计它们。 但是，顶层系统不需要对整个输出的结构进行明确的编码，这是一个深度学习系统可以被愚弄并认为黑色和黄色的条纹是校车的一部分原因（Nguyen，Yosinski，＆Clune，2014）。这种条纹模式与校车输出单元的激活密切相关，这又与一系列低层次特征相关联，但是在典型的图像识别深度网络中，没有完全意识到校车由车轮、底盘、窗户等组成。 我所讨论的结构层次和上面讲的是不同的，我讲的系统对某部分可以明确表示。经典的例证是Chomsky的层次，使用复杂的语法结构如the man who mistook his hamburger for a hot dog，构成长句The actress insisted that she would not be outdone by the man who mistook his hamburger for a hot dog。我不认为深度学习在这样的任务里有好的表现（例如，辨别女演员、男人和热狗之间的关系）。 即使在计算机视觉领域，问题也没有完全解决。Hinton最近提出的胶囊网络论文（Sabour，Frosst，＆Hinton，2017）试图通过使用更多结构化的网络来构建能更稳健应对局部-全局关系的图像识别。我认为这是一个好的趋势，也是一个潜在的解决“深度学习被欺骗”问题的方法，也反映了标准深度学习方法面临的麻烦。 质疑5. 在通用人工智能的背景下讨论深度学习是不合适的。通用人工智能不是深度学习的目标！ 这个部分最好的质疑来自魁北克大学教授Daniel Lemire的推特，还有Google的数学博士Jeremy Kun，他反驳了“通用人工智能不是深度学习的目标”这个说法。 吴恩达最近在《哈佛商业评论（Harvard Business Review）》发布了一篇文章，表述了深度学习可以人类可以做的任何事情。Thomas Dietterich在推文中也表达说，“很难说DL是有限制的”。Jeremy Howard担心，深度学习过度的想法本身可能被夸大了，然后建议每一个已知的限制都被反驳。 DeepMind最近关于AlphaGo的论文[见注释4]也有类似定位： 我们的研究结果证明，即使在最具挑战的领域，一个纯粹的[深度]强化学习方法是完全可行的。 以上这些观点都说明，人们不断对自己的AI系统进行人类基准测试，其主要原因正是因为，他们以通用人工智能为最终目标。 质疑6. Marcus说的是监督学习，而不是深度学习。 Yann LeCun在我的Facebook页面发表了一个评论： 我没时间做出适当的回应，但总之：（1）我认为大部分都是错误的，如果用“监督学习”取代这里的“深度学习”，那么问题就会大大减少。 （2）将深度学习的概念拓展到监督学习，正是我过去2年半年来一直倡导的。你对这件事很了解，但是你并没有在论文中提到这一点。 深度学习和无监督学习并不是逻辑对立的。深度学习主要用于有标记数据的监督环境，但是有一些方法可以以无监督的方式使用深度学习。尽管我对目前建立无监督系统的方法也持保留意见，但我也对这一过程持比较乐观的态度： 如果我们能够在这个更加抽象的层面建立一个系统，这个系统能够设定自己的目标并进行推理和解决问题，那么可能会有重大进展。 我承认LeCun所提到的这一点，我对深度学习的部分质疑并非只针对深度学习，其对于监督学习也适用。但是，我不认为无监督学习能够解决我所提出的问题，除非我们为期增加更抽象的符号表征。 质疑7. 深度学习不仅仅是卷积网络（Marcus批评的那种） ， 它本质上是一种新的编程风格 - 差异化编程 - 而且这个领域正试图用这种风格来制定可重用的构造。我们已经有一些方法：卷积，池化，LSTM，GAN，VAE，内存单元，路由单元等。 - Tom Dietterich 这似乎（在Dietterich的长推文中）被提出来作为一种批评，但我对此感到困惑，因为我是一个差异化编程迷。也许重要的是，深度学习可以采取更广泛的方式。在任何情况下，我都不会将深度学习和差异化的编程（例如神经图灵机和神经编程这样的方法）等同起来。深度学习是许多可区分系统的组成部分。但是这样的系统也构建在我一直在敦促整合的符号处理之上（Marcus，2001; Marcus，Marblestone，＆Dean，2014a; Marcus，Marblestone，＆Dean，2014b），包括内存单元和变量操作，以及其他系统，比如最近的两篇论文强调的路由单元。如果把所有这些东西融入到深度学习之中是通往AGI之路，那么我的结论将会无效： 大脑可被视为由“一系列可重复使用的计算原语组成 - 与微处理器中的一组基本指令类似的处理的基本单元 - 可能并行连接在一起，如在可重新配置的集成电路类型中（现场可编程门阵列）“，正如我在其他地方所论证的（Marcus，Marblestone，＆Dean，2014），为丰富我们的计算系统所建立的指令集而做出的努力只能是一件好事。 质疑8. 现在vs未来。 也许深度学习现在不起作用，但它未来会让我们实现AGI（通用人工智能）。 有可能。我认为深度学习可能会促成AGI，如果补充一些关键的东西（许多还没有被发现）的话。 但是，我们补充的东西非常关键。将未来的系统称为深度学习本身，还是更为明智地称为“使用深度学习的某种特定的系统”，这取决于深度学习在哪里更合适。例如，在真正充分的自然语言理解系统中，符号处理将扮演与深度学习同样重要、或更重要的角色。 这里的部分问题当然是术语。最近一位很好的朋友问我，为什么我们不能将包括深度学习的任何东西称之为深度学习，即使它也包含符号处理？深度学习的一些增强版应该起作用。对此我作出回应：为什么不把包含符号处理的任何东西称为符号处理，即使它包含深度学习呢？ 基于梯度的优化应该得到应有的效果，但符号处理也应该是这样，它是系统地表示和实现高级抽象的唯一已知工具，它基本上覆盖了世界上所有复杂的计算机系统，从电子表格到编程环境到操作系统。 最后，我猜想，两者将不可避免的融合，组成混合系统，将20世纪50年代初期发展起来的20世纪AI的两个伟大思想——符号处理和神经网络——结合在一起。其他尚未发明的新工具也可能至关重要。 对于一个真正的深度学习者来说，任何东西都是深度学习，无论它是如何融合的，不管它与现在的技术有什么不同（万岁帝国主义！）。如果用一个神经元代替经典的符号微处理器中的每个晶体管，但是保持芯片的逻辑完全不变，一个真正的深度学习者仍然会宣告胜利。但是，如果我们把所有的东西放在一起，我们就不会理解是谁在推动（最终）成功。 质疑9. 机器没有推断能力，因此期望神经网络从偶书中生成奇数并不公平。 这是一个用二进制数字表示的函数。 f（110）= 011; f（100）= 001; f（010）= 010。 那么f（111）=？ 一个人很容易猜出，这个答案是111，而神经网络则不可能。 你可能会觉得这个功能就像“反转”一样，很容易用一行计算机代码来表示。但是对于神经网络很难从这种情况下的平行方法中学习逆转的抽象概念。这不是一个公平的对决：人类在推广这样的映射时显然依赖于先验知识。  质疑10. 你论述的论点所有人都已经知道，你没有提出什么新观点。 首先，当然不是每个人都知道，如前所述，有很多批评者认为我们还不知道深度学习的局限性。 而且我从来没有说过我的观点是全新的，我引用了其他学者的一些观点，他们也独立地得出了相似的结论。 质疑11.Marcus未能引用xxx的论文。 这一点我承认绝对真实，文献综述是不完整的。 我未能引用一些很受欢迎的论文，我试图通过其中的一些代表，总而言之，我可以做得更好。 质疑12.Marcus在业内没什么地位，他并非从业者，只是个评论家。 在提出这个质疑的时候我有些犹豫，但是这一问题一直出现，包括一些知名教授也提出了这一问题。”真正重要的不是我的资质（我相信事实上我确实有资格写），而是论证的有效性。 要么我的论点是正确的，要么不是。 [对于那些“好事“的人，我最后在附注8中提供了一些我相关证书的迷你历史记录。] 质疑13. 回应：Socher的tree-RNN怎么样？ 我已经给他写信以期更好地了解其现状。 质疑14. 你对深度学习的批评可以更加激烈一些。 例如有一位同事指出，未来可能会有一些严重的错误出现。 确实，我们成功的速度会以指数的速度快速增长......在快速发展的过程中，我们会获得很多短期成果，而向深层推理的进展将会变慢。 此外，现在我们还不清楚，为什么对猫95％的识别率，就对通用人工智能有所帮助。 另一位同事补充说： [研究人员]在某些领域太快取得胜利。例如图像处理，但是这些算法很可能被对抗性攻击混淆。而且一旦犯错，常常是疯狂的错误。 另一位同事深度学习研究员兼作家Pedro Domingos指出了目前我没有提到的深度学习方法的其他缺点： 像其他灵活的监督式学习方法一样，深度学习系统是不稳定的，因为稍微改变训练数据可能导致最终模型的巨大变化。 尽管少量数据就足够运作，但是多数情况下仍需要大量的数据（数据的增加是非常昂贵的）。 它们可能很脆弱：对数据的小改动会导致灾难性的失败。 如果我们想要真正达到通用人工智能，我们应该直面各种挑战及我们获得的成就。 "
219,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656227&idx=2&sn=4813ea30983478d2c768a1a9c44aec5a&chksm=bd4c37b08a3bbea6be9d9ecfb71735ccf30571580b09e9e08b954fe44a0c426f63377cc73317&scene=0,重磅译制 | 更新：MIT 6.S094自动驾驶课程第1讲（2）深度学习模型应用,大数据文摘重磅课程汉化 《MIT 6.S094 深度学习与自动驾驶》 本周更新至：第一讲 （2） 深度学习的概念和模型应用 时长30分钟 带有中文字幕 马上观看 ▼ 这门无人车课程由麻省理工MIT开设，话题前沿且实践性质很强。课程首先引导大家了解深度学习，之后大家可以自己“造”一辆无人车（的算法🌚）！ 课程面向机器学习 ，但已经有大量经验的研究人员也能从课程提供的从实践出发的深度学习方法和应用中受益。 课程主讲Lex Fridman与TA团队 大数据文摘已取得课程翻译授权，将以连载的形式发布后续课程内容，请大家继续关注我们，随时给予好评🌚 MIT深度学习与自动驾驶课程页面（所有PPT、视频和资料汇总）： https://selfdrivingcars.mit.edu/ ，复制打开链接免费加入学习： http://study.163.com/course/introduction/1004336028.htm 《斯坦福CS231n深度学习计算机视觉》课程已更新完毕，李飞飞与Andrej Karpathy（现任Tesla AI部门主管）主讲，已有7.4万+人参与学习，复制打开链接免费加入学习： http://study.163.com/course/introduction/1003223001.htm 本课时PPT精华 ▼ 北京邮电大学模式识别实验室 李琦、李子凡、刘冠群 刘家铭、慕宗奇、祁星群 吴灵境、肖思瑶、杨紫都、张文源 （按拼音排序） 寒小阳、 Zach Tian 龙牧雪 张闯、汪德诚 
220,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656227&idx=1&sn=765bf05411a5e1c687cae51387dc6de2&chksm=bd4c37b08a3bbea6a5bc163d242b464086b43112ecb8782fa77288d9eaff5bcb6fdff54618bc&scene=0,干货：从相关性到RNN，一家线上“租碟店”的视频推荐算法演进 | 公开课实录,本周三，大数据文摘邀请到Hulu（美国第二大视频网站）推荐算法研发负责人周涵宁，来分享了 （戳蓝字了解） 。周老师分享了大量干货，大数据文摘特整理公开课实录如下 （在不改变原意的前提下有删改） 。 扫码进直播间 可以永久回听↑ 今 日 彩 蛋 🎧 边播放边阅读实录文字，会遇到惊喜哦 大家好，我是周涵宁，来自于Hulu。Hulu是美国第二大的视频网站，今天我要分享是视频推荐系统。 在讲基于网页的推荐之前，我想先讲讲传统的视频推荐。传统的视频更多的是出现在租碟店，也就是五年、十年以前大家经常光顾的光盘店。 老板做这种推荐的话，你会信任这个老板对你的了解，以及他对现在电影市场的了解，他对影视内容的品位。你和租碟店老板之间形成了一种良性的互动。 到了网络时代，出现了很多视频网站，包括爱奇艺、搜狐、优酷土豆。这些网站不可能为每个用户都雇一个专职的老板来做推荐，所以它会用自动的方法， 奈飞（Netflix）大家都知道，在十年以前举办了一次推荐算法的比赛，奖金是一百万美元，比赛是为了解决它当时对于用户评分的一个预测问题，所以推荐算法在视频网站的应用历史应该是比较悠久的。 那么现在从业务的角度，我们和十年以前有哪些差别？ 最大的改变可能是很多的视频网站都加入了电视直播的内容。最早的时候，点播是一个录下来的昨天放过的电视剧，或者之前已经制作好的节目。直播的场景的话就非常不一样，它是实时发生的，正在发生的可能是体育比赛、某个新闻的事件。对于这种内容的推荐，还有一些独特的挑战。今天我也会讲到，对于这种在线直播，需要用不同的模型和不同的特征。 这个是我们今天课程的一个内容提要。第一，我会讲一下优化目标和框架，第二，模型。模型里面又包括Exploitation和Exploration的两种具体的模型。然后基于这个模型，我会讲两个应用场景。 视频推荐系统的优化目标 推荐系统的优化目标，如果从用户的偏好来讲，我们是希望提供给用户一个非常健康的组合， 就是有营养的内容。但是平台本身呢，它又有商业变现的要求，所以有的时候为了平衡用户的需求和平台本身的需求，我们就要做出某种折中。也许我们不会提供像麦当劳这样的快餐，但是我们可能要为了获得一些短期的回报，在一个完全健康的食品和这种快餐之间取得某种折中。 最后从算法或者数学抽象来讲，我们就把这个问题抽象成为 。 为了达成这个目标，我们就要预测用户喜欢哪些内容。具体来讲，用户观看时长可以用什么方法来最大化？有几个关键的要素，第一个就是，点击进去看一个视频之后，你看了多长时间？这个跟视频本身的长度有关，跟你的完成度有关，我们叫playback_duration。第二个叫做有效点击eCTR。第三个就是整个内容的曝光量。 为了优化总的观看时长，推荐系统可以控制的就是曝光量这个要素。具体来讲，就是把我们想要更多地展现给用户的内容排在前面，这样用户在第一屏就会看到。推荐结果的好坏表现在eCTR，这是一个我们不能够直接控制的量，我们通过选择正确的物品分配更大的曝光而间接控制eCTR。我们最终想要最大化的是eCTR和曝光量的乘积。 这个图表里，横轴是曝光量，纵轴是eCTR，我们把去年10月曝光量比较大的一些内容在这个图表里展示了一下，大家可以看到这两个量基本上是成正比的。 当然从这个曲线里面，我们也看到有一些eCTR不是那么高的内容，比如说College football，在最右下角的地方，它也获得了比较大的曝光，这就属于过度曝光。所以这也提出了我们优化的一些可能的空间：可以把分给点击不是那么高的物品的曝光量，匀一些给其它的更高点击、但是曝光不足的内容。 视频推荐系统的框架 刚才讲了通过KPI里面的这些维度的划分，怎么样找到一个推荐系统的表现的好坏以及改进它的机会。那么具体来讲，我们要建立一个推荐系统的话，它需要几层？ 我们可以把推荐系统抽象成为四层， 用户的特征具体来讲又是每个用户单独的特征，或者是一群用户的一个画像，群体特征。内容的特征可以是每个内容单独的特征，或者是一批内容的总体特征。 基于第二层的特征之上，我们会建一些模型。 这些模型的优化目标有两个，一个是利用，一个是探索。 又可以有一些子目标，包括Relevant，就是相关性，包括透明度，对产品经理还是对最终用户是不是可解释，包括是不是上下文相关，充分利用了时间、设备、地点这些上下文信息。 主要讲的是对新内容我们有没有给足够的展现，以及有没有给用户惊喜、发现用户隐藏的一些兴趣。当用户兴趣发生改变的时候，我们是不是非常快地适应了用户这种兴趣改变，也就是adaptive。最后一个是多样性，就是我们给出的这个套餐是不是组合了很多不同的类别，而不是非常单调、单一的。 在模型之上，我们要做一些应用。 这些应用主要是服务四个用户的阶段。首先是所谓Onborading，就是一个新用户，刚刚订阅我们的服务的时候，还在一个初始的、给我们一些信号的阶段。我们让用户选择他最喜欢的内容频道，然后用户会告诉我们他喜欢体育、喜剧或者动作片。基于这些大类，我们可以给他做一个冷启动，给他第一屏的推荐结果。 之后，在一个新用户进来之后，我们大概有七天的时间把他转化为一个付费用户。从试用期到付费期的转化，就是Convert-to-Pay。在这个阶段，我们需要快速地探索用户的各种需求，让他体会到我们的服务非常有价值，那么他才愿意买单。 到了第三个阶段，就是用户已经是一个付费用户，那我们就需要留住他，所以就是不断的去给他更多的、他之前可能没有看过，但是和之前看过的很相关的内容。 最后，第四个阶段是Monetization。在有很多渠道付费订阅的时候，当然订阅费本身是一种变现的手段。但是我这里指的变现，主要还是广告变现。具体来讲，广告变现的业务指标就是用户的观看时长。因为插入广告点的个数，以及广告的库存量是直接和用户的观看时长以及活跃用户数相关的。所以这是我们所有这些模型服务的第四个任务，就是一个已经付费的用户，已经留下来的用户，我们怎么样用广告把他的流量变现。  视频推荐系统的算法 利用方面的模型，如果从推荐系统、特别是相关性的利用来讲，有两大类，一个是基于用户行为的，一个是基于内容的。 基于用户行为的话就叫做协同滤波。具体来讲，协同滤波下面又有更细的分类，有基于存储的Memory-based和基于模型的Model-based。基于存储的话有item-based CF，基于模型的话有矩阵分解和神经网络的方法。矩阵分解下面又可以再细分。然后神经网络现在也有基于RBM的，还有Embedding-based Neural Network。 Hulu经历了三代相关性算法的演进，第一代是item-based CF，第二代是基于矩阵分解，现在我们正在开发的第三代是基于Embedding-based Neural Network。从Netflix公开的文件来看，它主要使用的是SVD和RBM的方法。 第1代算法：协同滤波 我们先讲比较古老的一代相关性算法：基于物品的协同滤波。最早是20年前亚马逊在它的电商网站上使用的。它会构建一个用户和物品的相对评分或者影视的 。就是我在左下角画的这个矩阵，它每一行是一个用户，每一列是一个物品，里面的数值可以是用户购买这个物品的次数，或者点击这个物品的次数。就是用一些用户的隐式行为，把它转换成为用户和这个物品之间的某种评分。这个分数越高的话，它就和这个物品的相关性越高。 大家可以看到里面有很多的缺失数据，因为这个矩阵是非常稀疏的，在几万个视频里面，用户能看的也可能只有几百个。所以 那么，基于这么一个简单的表示，可以去度量两个物品之间的相似性。如果在这个矩阵里面两列的数值的cos distance很接近的话，我们可以认为两个物品是类似的，因为在全量用户上对这两个物品的相对评分是很接近的。 第2代算法：矩阵分解 接下来就是从协同滤波进化到矩阵分解。 刚才讲到协同滤波有一个稀疏性的问题，矩阵分解为了解决这个稀疏性的问题，使用了线性代数里面的一个特性，就是一个低秩矩阵，可以用两个相对低维度矩阵的乘积来表示。具体来讲，评分矩阵R是低秩的，它可以用一个矩阵P和矩阵Q的乘积来表示。P就是所有用户的特征，用一个大概一百多维的特征向量就可以表示，每个用户用一百多维来表示，相比原来几万维的用户和所有内容的交叉，就节省了很多的存储以及计算。相对的，每个内容也可以用一个列矩阵，就是Q来表示。 我们使用矩阵分解之后，在线上也观察到了很多好的表现，那么，我们肯定不满足于这种矩阵分解的算法，我们还想要进一步引入更多side information侧面信息，其中包括用户的demographic的这种元数据信息。 第3代算法：神经网络 在矩阵分解的框架底下，不太容易直接地使用这些side information，所以我们就引入了一种深度神经网络的框架。  也就是，把原来矩阵分解里面代数运算的步骤，用一个前向神经网络来替换。这样的好处一方面是非线性前向神经网络允许一些非线性的映射，可以有更好的表达能力去model一个更复杂的分布。另外的一个好处就是我们可以直接把关于用户的除了行为之外的所有信息，用一个矢量feed到这个神经网络里面去。对内容我们也可以做相应的处理，就是把元数据，比如说导演、演员信息用一个向量来表示，然后把它feed到神经网络里面去。 相关性算法的应用场景 相关性算法有两个应用场景，一个是所谓的货架场景，就是给一个网格里面按照相关性做了排序，然后 。另外一个是自动播放的场景，就是播完一个内容之后，我们会 。对应这两种不同的场景，其实需要不同的相关运算。 具体来讲，刚才所说的协同滤波方法，它比较适用于货架场景的召回和排序。对于自动连续播放的场景，我们采用了另外一种模型，就是时间序列的模型，叫做 。 我们把用户在网站上的一个行为序列，认为是由这种RNN模型所产生的。我们可以用反向传播的方法去训练一个RNN模型，来预测用户在网络上的下一个行为。采用了RNN的时间序列之后，我们在线上的测试观察到了非常高的提升。我们仿真测试的方法就是当用户看完剧A/B/C之后，我们假装不知道这个用户接下来看了哪一个， 。根据RNN模型，我们找到最有可能的下一个剧，然后和用户实际看的下一个剧之间做比对，这是离线的一种评估方案。 优化目标：探索（Exploration） 刚才讲完了一些利用，就是基于用户行为以及side information做货架场景的排序和自动播放的这种持续预测。接下来我们来讲探索。 自适应 我们先来看探索中的自适应的问题。为了解决用户兴趣的时变以及新内容的冷启动，我们采用一种叫做 的模型。 多臂老虎机是借用了赌场的一种场景。 如果赌徒每次都选择摇臂1的话，有可能不是最优的，因为可能另外一个摇臂的反馈更好。我们把赌场的场景应用到推荐系统里面，就是每个摇臂是我们可以推给用户的一个剧，而我们的算法就是这个赌徒，它通过一些策略来选择将哪个剧推给用户。而每个摇臂获得的奖励，就是用户是否点击和观看了。用户的兴趣本身就是这个老虎机自己的一些参数设定。 多臂老虎机已经是一个历史比较悠久的问题，所以也有很多成熟的算法。我们采用了一种比较流行的算法，叫做 我们会根据当前推的结果，来实时更新对每个摇臂的点击率的预测。 具体来讲，在线上部署LinUCB的算法，有一个线上更新提取特征以及模型运算的过程，以及一个线下根据之前模型采集到的信号去更新模型参数的过程。 在我们这个实验里面，可能对大家比较有参考意义的就是我们发现的LinUCB的一些特征，其中包括用户当前看剧的完成度，就是他看到了第几集、是不是看到了高潮部分还是快要结束的部分。 。然后就是上次给用户曝光这个剧的时间和现在之间的时间间隔，以及它历史上的点击率，还有这个剧的一些元数据信息，它在外面的流行程度，以及根据刚才讲的协同滤波的方法，得到的用户和这个剧之间的相关性。 多样性 接下来讲多样性的一个模型，叫做行列式点过程。 我们为什么要关注多样性？是因为用户的兴趣爱好可能不是单峰分布的。 有可能用户有多个兴趣爱好，其中有非常突出的一个，就是这个比较高的右边的峰。但是还有一个比较低的，就是右边这张图里面的靠左的这个峰值。如果我们用简单的相关性排序的方法，就会把右边峰值里的很多内容都排在前面。而用户隐含的兴趣，就是左边这个比较矮的峰，就不会出现。所以我们要用一些多样性的策略，使得左边这个矮的峰里面的一些好的内容也会被推荐。 用户多样性的问题也已经被广泛研究过。传统上使用启发式的方法，它会在多样性和相关性之间用一个加权平均的方法来获得一个总体的优化目标，然后两两之间比较当前推荐的差异性，然后试图最大化这个总的平衡了之后的优化目标，用穷举的方法。 我们在现有的启发式的搜索基础上，采用了一些不同的代数模型，就是把两两之间比较不相似性改变成为用一个多边形的体积来量化我们给出的不同物品之间的差异性。 这种方法也有一种贪婪式的解，它的计算复杂度是选品总数的立方，比刚才的那个Heuristic，就是两两之间比较的话，它的计算复杂度要更高一些。所以为了解决这种更优的度量带来的计算复杂度的增加，我们用了一些代数的方法去加速，最终我们达成了一种线性复杂度的方法。 就是这个图里面画的这条红色的线，它可以和刚才讲的DPP的原始实现达到同样的精度。但是由于我们采用了incremental update的方法，有效地降低了计算复杂度，把原来Y的立方的这种计算复杂度变成了线性。  视频推荐系统的应用场景 推荐的理由 最后我们来讲几个应用场景，其中比较重要的一个叫做推荐的理由。 Lady Gaga有一首歌唱的是“我有一亿种理由离开，但是我只需要一个好的理由留下”。 （彩蛋来啦，Bazinga！） 那么对推荐系统来说，它可能推出完全相同的结果，但是如果我们可以给出一个好的理由，那么用户会对它的信任会更高，点击率也会相应提高。 比如说，当我们推荐《终结者2》，我们说是由于你历史上看过《终结者1》，这时候就比完全没有任何原因的推荐显得更加顺理成章。如何构建一个推荐的理由？我们可以用刚才很简单的模板，就是因为你历史上看过和它相关的一个剧。 但是如果我们想做得更加人性化、更加自然，我们要用一种 的方法。在知识图谱里面构建内容，用户的群组，相关性的信息，以及一些统计信息，包括这个剧的流行程度，它在外面的排名。我们用一种N元组的方法来记录这个知识图谱。 基于这个知识图谱，我们可以设定一些推理规则，每一条规则其实对应某一种经典算法，比如第一条规则，就是如果用户喜欢电视剧，一是由于他曾经看过电视剧，二是电视剧2和1非常相近，这就是item-based CF逻辑的一种表达方式。类似的话，我们还可以把user-based CF也用一条规则来表达。比如说这个地方列出的第二条规则，就是 。 列出了很多这样的规则之后，我们可以在知识图谱里面建立一个规则树，就是为了推理出当前这个用户多大的几率会喜欢一个剧X。我们可以用所有的规则和每个剧之间做一个实例化，然后来度量它是否有证据来支持当前这个规则的证明。这个推理树里面的节点会随着规则的不断展开，而从根节点开始逐渐成长，长成一棵非常大的树。 大家看到这个节点里面的红色部分，就是待证明的某一个假设或者规则。蓝色的部分就是实例化之后，找到了事实去支持这个假设的部分证明。当一个节点从红色完全变成蓝色，大家看到最下面的叶子节点，那就说明它已经用所有的事实完全证毕。 当然，并不是所有的规则推理最后都能够被所有的事实来支撑，比如说最左边的这个叶子结点， 它 有一个红色的待证明项，是找不到事实支撑的，那么这整条路径就是失败的。 但是我们在这个树里面，如果你的知识图谱足够丰富的话，它总可以找到某一个子路径，是可以证明当前这个推理的。 语音对话推荐 第二个应用场景是基于语音交互的一种对话的推荐。 当前很多的应用都是在手机上或者PC上，是基于图形界面，用户需要点击，用户能够给到系统的反馈是非常有限的。没有点击有可能是因为不喜欢，有可能是因为当前时机不对，也有可能是你之前看过了。我们是无法获得更深层次的用户反馈的。而用户要进行一个查询，他要告诉系说，“我要看一个80年代情景剧”，他要通过多级复杂的菜单嵌套来完成这个查询。 我们提出基于语音对话的推荐，使得整个过程更加自然。我们可以允许用户用一个简单的自然语言来表述一个非常复杂的查询条件。然后当用户对当前的推荐不满的时候，他也可以用自然语言来告诉我们，为什么他不喜欢这个剧，以及他想要换另外一个什么样的剧。我们认为语音交互会成为下一代计算的一个催化剂。 以上就是公开课的所有内容。 Q： 怎么识别用户的兴趣是否改变呢？ A： 其实对于多臂老虎机的问题模型来讲，我们并不是显式地去建模用户的兴趣是否改变，而是把用户的兴趣（一个老虎机的模型参数设定），认为是一个可以实时更新的参数。我们不断去追踪这个参数的改变，或者换句话讲，就是我们永远都假设用户兴趣和之前是可以有差异的。所以我们不断地在跟踪一个不断改变的参数。 Q： 知识图谱是怎么建立和生成的？ A： 我们所用的知识图谱，一方面是从第三方采买的，有专门的构建知识图谱的厂商，他们会做数据清洗爬取。另外一部分是我们从内容提供商那里获得的一些元数据信息。 Q： 基于规则的推理要人工构建吗？规则要有多少？彼此之间会不会冲突？ A： 这个规则的构建过程是手工建立的，但是规则条目其实并不多。我们如果便利现有的所有推荐的算法的话，每种算法大类来讲，大约会产生一到两条规则，所以最终我们可能只有不超过50条，规则之间是有可能冲突的，所以冲突就是它们都可以用来解释某一个用户喜欢内容X或者是说它可以推理出一个用户既喜欢内容X又喜欢内容Y。所以这个时候要做路径的选择，就是刚才推理树里面哪一条路径最有可能是真实的。所以我们会用配置认可的方法，去在这个图里面这个推理数的图里面做随机游走，然后找到最终权重最高的一条路径。 Q： 能否基于用户行为和金融产品的历史表现做金融产品的推荐？ A： 关于金融产品的推荐，其实美国已经有公司在做。我上次去参加推荐系统会议的时候，就有一家纽约的公司，做的事情有点类似于定向广告，就是它会根据用户之前的消费记录、投资记录，选择金融产品。  嘉宾简介 周涵宁，现任Hulu北京研发中心推荐算法研发负责人，具有15年的研发创新和管理经 验，专注于应用数据和算法实现产品落地，有丰富的数据分析和机器学习实践经验。 他本科毕业于清华大学自动化系，于伊利诺伊大学香槟分校获得计算机视觉领域博士学位。历任施乐硅谷研究中心研究员，亚马逊美国总部高级技术经理，盛大创新院资深研究员兼产品总监，智谷公司技术副总裁和宝宝树CTO。他拥有十多项美国专利授权，发表学术论文二十余篇。 还没听够？ 扫码关注下期公开课 ▼ 本期公开课内容整理：冯晓丽、龙牧雪 点击 收听下期公开课 ▼▼▼ 
221,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656145&idx=2&sn=cf8d68a14629d9faa19b85ca3c3e81cc&chksm=bd4c28428a3ba154366bcdd504e049059defab9da120463c3c9334eb2cc17fa037eadd640ba4&scene=0,学界丨我这样预测了医疗AI的发展，或许你也可以（附论文链接）,"授权转载自公众号数据派THU 微信ID:DatapiTHU 2017年是非常酷炫的一年。医疗人工智能发展迅速，人工智能社区也表现出相应的成长与创新。我曾做过一些预测，其中大多数都很模糊。 在技术方面，学术界决定逐步远离越来越难取得进展的、过时的监督学习，而转向生成模型。2017年初，研究者们深入到语音合成，图像和视频生成，超高解析度成像和自动着色等“恐怖谷”问题。到年末的时候，这些任务都至少完成了一部分。 （译者注：恐怖谷理论是由日本机器人专家森昌弘提出的关于人类对机器人和非人类物体的感觉的假设，对于那些模仿人类的机器人，仿真度越高人们越有好感，但是一旦与人类相像超过95%的时候，这种好感度会突然降低，越像人越反感恐惧，直至谷底，称之为恐怖谷。可是，当机器人的外表和动作和人类的相似度继续上升的时候，人类对他们的情感反应亦会变回正面，贴近人类与人类之间的移情作用。） 2016年末生成的图像 abs/1612.03242） ，上面有可辨识的鸟类，但是像素相当低，并存在一些奇怪的错误（例如，生成了太多的眼睛和腿等等）。 2017年末生成的图像 abs/1710.10196） 仍然存在一些小的伪影，不能完全正确地生成简单的背景。但总的来说，我不能断定他们并非真人。 对图像生成的重视也意味着我们还没看到模型上的重大突破，使其足以立即应用于医疗领域。生成式对抗网络（GAN）也许有助于训练数据的积累，同时，这些系统在学习数据流形边缘方面的表现优于纯粹的监督学习。但迄今为止，我还没有见到任何它们在医疗临床上有说服力的用途。 超高解析度成像技术（译者注：超高解析度成像，是一种提高影片解析度的技术。）被用作为医学影像去噪，降低了（成像过程中所需）辐射剂量。但是，由于超高解析度成像技术对图像的修复是基于总体统计的，我相当怀疑它被用于医疗诊断中是否足够可靠。 这篇2016年的论文 中的图像放大后还是清晰的，并且拥有逼真的织物纹理，但是这个模式和原始的模式已经完全不同了。这个属性也限制了这些模型在医疗领域中的用处，因为不能保证生成的数据能够和真实的数据相吻合。 和医疗领域更关切的、研究人员们一直在谈论的其中一个问题是可解释性（在我看来，这个问题虽然重要，但是其重要性被夸大了，我将会在之后的博客中谈论这个话题），另一个最近在讨论的问题是实验设计和分析的严谨性。这两个主题都是目前医疗应用中的痛点，而后者将需要大量的工作来弥合医学和机器学习社区之间的文化鸿沟。 撇开对应用研究的关注，虽然速度很慢，大多数人还没有注意到，但是2017年是AI开始带来变革的一年。在商业和消费者层面，人工智能应用出现了爆炸性增长，最值得一提的是智能音箱和语音助手。同时，还有更多用于像农业 这样的传统领域的应用。 当然，虽然似乎没人注意到 ，2017年11月7日是4级自动驾驶功能（译者注：4级自动驾驶功能是在限定的道路和环境条件下，车辆可以完成绝大部分驾驶操作。智能驾驶技术一共分为5级，5级是全环境下的自动驾驶。）实现 的日子。这是一个巨大的分水岭，也是第一个由人工智能引起的大规模全行业瓦解的开端。 2017年，我们社区也开始向内审视，使工作更加井然有序。我们不仅看到了算法歧视（译者注：算法歧视，是指在遭遇两难选择时，用算法决定选择牺牲哪一方的利益； https://www.technologyreview.com/s/608986/forget-killer-robotsbias-is-the-real-ai-danger/ ），同时，无论是好是坏 ，我们也看到更多人性上的弱点 。 在这里我并不想对文化评论太多，主要是因为身为一个澳大利亚人，从地理位置上而言我远离大部分机器学习社区，但有些问题还是需要开诚布公。上一个月我们发现了一起学科内部的性骚扰事件（译者注：指的是12月发生的NIPS大会性骚扰事件），虽然我们还是得等待，看看相关部门是否会跟进，但它所引起的反响还是相当强烈的。他们会努力推进文化变革吗，还是只说不做呢？ 在机器学习社区内，这并非一起孤立事件（至少医疗领域有相同的问题 ），这要求我们每个人不仅仅要做到“体面”，还要树立更高的道德标准。讨论至今还集中于几个坏蛋身上，但我希望我们所有人都仔细思考这样一个事实：各级别的社区已经容忍这些研究者的行为很久了。正如一位澳大利亚最高军事领导人曾经说过的，“你能坦然路过的标准就是你所接受的标准。” 视频观看网址： https://www.youtube.com/watch?v=QaqpoeVgr8U&feature=youtu.be 不要因为出处而感到失望，这是我所看到的来自于机构的关于骚扰和包容的最强有力的信息之一。观察、倾听、付诸实践。 我们可以做得更好，我希望我们作为社区的成员，能够更加积极主动地打击行业中各种形式的骚扰和偏见。 所以，这就是2017。紧随快速概览之后，让我们来看看，之前我是如何预测这一年的。 去年大约这个时候，我对2017年医疗人工智能的发展做了一系列预测 ，现在是时候回头看看这些预测是如何一步步实现的了。 如果你没有读过那篇博客，这里 我将人工智能在医疗领域的发展分为3个阶段。我并不认为这种分类是看待人工智能研究的理想办法，但用来分析问题的效果还是不错的。 第一阶段的研究是概念验证。使用典型的、通常与临床实践有很好的相关性的小型数据集。在药物领域，成功的第一阶段试验只有10%的概率能够转化成产品，平均花费8年时间才能进入市场。 第二阶段的研究更为严谨。使用大型的数据集，将模型与一些合理的基线进行比较，并在更广泛的场景中呈现可信的结果。这些研究耗时且执行难度很大。我们在2016年进行了独立的第二阶段试验，促成了谷歌视网膜病变评估的论文 的发表，每两篇博客我都会提到这件事一次。 第三阶段的试验才是真正的工作。在一个大型随机对照试验中，人工智能系统被用作实践工具。这涉及到第二阶段没有回答的主要问题：我们如何在实践中使用接近人类水平或超过人类水平的人工智能系统呢？其实如何将超人的人工智能系统安全有效地纳入到临床工作流程中目前仍未清晰，再提一次，我在另一篇博客中描绘了未来的图景。 我曾经预测过，2017年期间，医疗人工智能的研究（定义为医疗数据的深度学习）数量至少增加一倍。这个预言似乎已经实现了。和去年的方法一样，我使用谷歌学术搜索的结果，估算周期为6个月。虽然这是个非常粗略的数字（会议月份出现了巨大的异常值，谷歌学术搜索也不是真正的权威来源），但它至少保持了一致性。 2016年：每月5-10个试验（接近5） 2017年：每月10-20个试验（大概15个左右） 在文献方面的另一个重大变化就是大量的期刊社论、综述文章和关于深度学习的地位陈述方面的文章数量激增。老实说，几乎每个月都有实际的研究论文发表！我在2017年的“其他杂项预测”（第3条）中提到了这个情况，但它的规模之大却让我大吃一惊。 虽然我们可以调侃，更多的人是在谈论深度学习，而不是真正在做深度学习，但我更愿意用积极的眼光看待这一问题。2017年是医生开始认真对待人工智能的一年。各种专家会议、大型和小型期刊、时事通讯、大型圆桌会议、工作小组和治理机构都在讨论人工智能。虽然仍能听到很多反对的声音，但是感觉经历了过去12个月的讨论之后，人工智能好像出现了转机，成为了主流医学时代潮流的一部分。 分值 我虽然准确地预测到了这一点，但很可能低估了大量对人工智能的非研究性的讨论的传播所造成的影响。 我预测人工智能在2017年，将会有3-5个第二阶段的医学试验，主要来自于既有的集团。 这一年以斯坦福大学关于皮肤病的论文（https://www.nature.com/articles/nature21056）在1月份《自然》杂志的出版这一“大爆炸”为开端。 但是后来很长时间又归于沉寂，今年大部分时间都没有再出现大规模的令人信服的试验。 但是随着年末临近，每个人似乎都在忙于发表研究成果。这些研究的大多数成果都有一些不足的地方，或者结论平淡无奇，或者说法夸张，但是他们都可能有资格作为第二阶段的研究。这实际上也是我预测到的一个问题；我并没有明确地定义第二阶段，只给了几种可能的解释。在新的一年里，我将会讨论一些方法来更好地评估第二阶段的研究质量，其实我真正想问的问题是：“是否有一个能够产生可信的结果的大型数据集”？ 最有说服力的研究 来自于从病理切片中识别乳腺癌淋巴结转移的大型竞赛 。我以前谈论过这个任务，它很酷也很重要。这篇论文汇集了多个参与者的成果，并与表现良好的人类基线做过比较。我们以后再来讨论这项研究，现在只想公平地说，这项工作的重要性可以与谷歌视网膜病变的论文相提并论。 接下来两个高质量的研究分别是“用卷积神经网络进行心脏病专家级的心律不齐检测 ”；和“肌肉骨骼影像学医师级的水平异常检测 ”，有趣的是，它们都是来自于斯坦福的机器学习小组。我认为这两项研究是第二阶段“中等质量”的研究，因为虽然能够让我们在一定程度上推断出可信的结果来，但是直接的临床影响并不十分清楚。  如果你忽略一些要求的话，包括检测脑出血 ，肺炎 ，髋部骨折（顺便说一下，这是我的团队做的， ），各种脑病理学 ）和一个骨龄评估的竞赛 competitions/4#learn_the_details-news） 在内，凭借大型训练集而被分为第二阶段的其他的实验结果至少都通过了吸气测试（sniff test）。但是这些研究和临床实践之间的直接关系是相当不确定的。 分值 我们看到这个类别中有3到5项研究任务，数量不是很确切。我们有3个中等质量或更高质量的第二阶段实验，另外还有6项实验也可以算作第二阶段，但是有一些局限性。 如果我们以谷歌视网膜病变的论文作为衡量标准，那么今年就只有1篇论文了。如果我们对第二阶段有一个更宽松的定义，可能会有多达8篇。我打算给自己的预测一个实实在在的B+的成绩，但有一个限制条件：任何关于这个类别的未来预测都需要更加具体的内容。 我还预测到大多数研究工作将来自既定的集团，而不是大学或初创公司，然而在这点上我却预测错了。实际上是大学和初创公司的混合体，但没有集团性的突破。 2016年，我们没有第三阶段的实验。 2017年，我预测不会有第三阶段的实验。 2017年，我们没有第三阶段的实验。 分值 这个阶段我预测对了，原因很明显是由于临床试验的困难、昂贵和耗时。 我对2017年还做了其他一些预测，其中有部分被证伪了。 1.AR/VR和3D打印不会有多大效果： 是的，是真的。这些的确是很酷的技术，但在我看来没有明显的医疗用途。我看过很多是噱头的东西。也许3D打印骨骼支架和器官移植将是一个大的应用，但是如果要应用到临床上似乎还有很长的路要走。 2.1000美元以下的基因组： 取决于你找谁报价。最低报价可到450美元。 但如果我们以genome.gov公布的数据为依据的话（这确实是报价的依据），我就真的预测错了。价格仍然在1000美元左右。 3.生物技术的发展将势如破竹： 这不是一个被证伪的预测命题，实际上从理念上说是正确的。基因疗法已经获得美国食品药物管理局(FDA)的批准 ，而且在今年年底，我们看到历经几十年的发展，这项技术已经趋于成熟，达到真正的分界点。严肃期刊近期发表了许多遗传疾病的单剂量疗法，包括肾上腺脑白质营养不良 org/doi/full/10.1056/NEJMoa1700554） 、A型血友病 doi/10.1056/NEJMoa1708483） 和脊髓性肌萎缩 （spinal muscular atrophy，http://www.nejm. org/doi/full/10.1056/NEJMoa1706198） 。这可能是医学史上最令人兴奋的消息，远比人工智能更令人兴奋。安全有效的基因疗法将在许多方面成为游戏规则的改变者，而不仅仅是在罕见的遗传病条件下。 4.医疗应用程序： 今年的大新闻是，大多数的医疗应用程序，只要不提供实际的医疗建议或医疗数据分析，就不再需要FDA的审查了。所以节食记录、运动监测，服药提醒，诸如此类的应用程序都可以直接向公众销售，而无需监管部门的批准。这个规定将在2018年产生很大的影响，但是我对健康应用程序了解甚少，所以无法用来评判我的预测。一般信息类的应用程序例如Epocrates和MDCalc的下载量很大，再比如，Fitbit及类似这样的应用程序也很流行，但是这些应用并没有让我感到兴奋。因为这些应用是不能显著改善健康状况的。也许更具有针对性的应用或服务，例如糖尿病管理平台 .gov/pmc/articles/PMC5527250/） 或奥巴马医疗 更有实际效果。我对自己有关医疗应用程序方面的知识并不自信。如果有人知道很多关于这方面的知识，欢迎写信告诉我。 分值 不知道该得多少分，也许再得一个B+？ 总分 两个A，两个B？ 好吧，我认为这个分数已经很好了。 来到这里，我们已经简单回顾了2017年医疗（和其他）人工智能世界。我认为我的预测相当准确。技术如此之新，改变如此之缓慢，因此可预测性会更高。我预测明年将是更具爆发性的一年，而且可能将更加难以进行预测。 顺便提一句，如果有时间的话，我认为这种年度总结和预测既有趣又很值得一做。我做了这件事后，加深了对这个行业的理解，提高了对未来一年的研究重点的认识，研究什么可能有用而研究什么可能没多大用。 同样的知名人士Miles Brundage 也做了预测，预测的内容主要围绕着强化学习(RL)和自然语言处理(NLP)技术方面，我急切的等待他跟进2017严谨的预测 。 几周内写一篇关于我对2017的预测表现如何(还有一段时间来证明我是正确/错误) 的博客会有问题, 但我认为评价我的预测的布莱尔分数（Brier score）将会是 ~. 45 +/-1... 取决于你如何解决某些问题。 — Miles Brundage (@Miles_Brundage) 2017年12月18日 我去除了所有的统计学，他用布莱尔分数评价，而我用模糊的“氛围”评价。 无论如何，感谢您阅读我在2017年写的文章，我期待着您来年阅读我对2018年的预测。 原文链接： https://lukeoakdenrayner.wordpress.com/2017/12/27/2017-in-review-progress-problems-and-predictions/ "
222,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656132&idx=3&sn=417d070a1854b206d81a4610cc14e8b9&chksm=bd4c28578a3ba1413ee2c35d5a530df5d0838c4c4c2faaec4fcac635c323cfc7c20d7aa695f7&scene=0,大咖 | “大数据之父”达文波特：成功的数据科学家不一定要有研究生学位,2006年6月，乔纳森•高德曼（Jonathan Goldman）进入商务社交网站LinkedIn工作。作为斯坦福大学物理学博士，他醉心于无处不在的链接和丰富的用户资料。虽然这两者通常只能形成混乱的数据和浅显的分析， 他开始构建理论、检验预设，并研究出了模型。通过这些模型，他可以预测出某账号所归属的人际网络。 幸运的是，LinkedIn的联合创始人兼时任CEO雷德•霍夫曼（现执行总裁），在贝宝（PayPal）的工作经验让他对分析学的威力深信不疑，因此，他给了高德曼高度的自主权。 他给予高德曼一个不同于传统产品发布套路的新方式—在网站黄金页面以广告的形式挂出小型加载模块。这一测试最终大放异彩，成为了我们现在熟知的“你可能认识的人”。 传统的信息管理和数据分析主要用于支撑内部决策，而大数据在这方面有所不同。当然，在多数情况下，大数据也会有此用途，特别是在大企业内。   数据科学家这一概念直到2008年，才由D.J. 帕蒂尔和杰夫•哈默巴赫尔创造，这个职位因为被达文波特喻为“21世纪最性感的职业”而为更多人所熟知。那么，成为一名数据科学家，需要怎样的潜质和能力？ 我们可以用这样一张图表，来展示数据科学家必备的技能结构： 由于大数据技术是一种新兴技术，而且很难将其提取出来用于分析， 首先，你必须具备编码或编程能力。“你会编写代码吗”，这是一位首席科学家在招聘时向数据科学家提出的第一个问题。如果你具备任何编程语言方面的经验，那将大有裨益，尤其是脚本语言，如 Python、 Hive 和Pig，或者有时会生成的语言，如 Java。这些脚本语言相对容易编写，还能将大型数据处理问题分布于分布式 MapReduce 框架中。 数据科学中的黑客还需要熟悉常用的大数据技术，最重要的是 Hadoop/MapReduce，包括如何实施和扩展它们，以及是否需要在所在地点或云计算中提供这些技术。这些技术都是一些新技术，还在不断变化， 最后，对黑客技术做一个总结，很多大企业不愿意雇用黑客是有原因的。在本文中，黑客技术通常被定义为一种创新的快速计算，但这一术语还有一层“不太合法”的意味，即倾向于避开计算行为的正常规则。就当前大数据技术低下的情形而言，后一种意义的黑客技术可能是必需的。 铁杆黑客带来的麻烦远比他们带来的益处要多得多。而且，他们也未必有兴趣为大型官僚组织效力。 在数据科学家的特征中，科学家这一特征不一定意味着必须是实战科学家。然而， 2012 年，我对 30 名数据科学家进行了采访，结果发现，57% 取得了科学和技术领域的博士学位， 90% 至少在科学或技术领域获得过一个高级学位，最常见的是实验物理学博士，  数据科学是否需要这些领域详细的相关知识呢？ 绝对不需要。 科学家分析的数据不可能是真正的数据科学家，就连大学也很少接触到真正的大数据，但它很可能是一种非结构化的数据。 进行大数据分析的科学家可能会具备的特征有：基于证据做决策、即兴创作、急躁以及自己动手的宽慰感。在大数据工作的早期阶段，这些技能很重要。在这一阶段中，数据科学家必须执行一些开创性工作，而在后期，这些工作可能会通过软件轻松地完成。科学家也可能是快速学习者，能迅速地吸收和掌握新技术。 应当指出的是，许多成功的数据科学家根本没有研究生学位，他们的大多技能都是自学而来的，因为以前的大学并不提供这方面的课程。例如，领先的数据科学家杰夫 · 哈默巴赫（Jeff Hammerbacher）在 Facebook 工作时与当时就职于领英的帕蒂尔（DJ Patil）创造了数据科学家这一术语，而那时他只有本科学位。大数据文化是一种任人唯才的文化，而不是一种强调具备某种数据科学学位的文化。 正如传统的定量分析师一样，数据科学家需要具备良好的人际沟通技能。然而，正如传统的数据分析师一样，他们不可能具备这些技能。因为如果你将大部分精力放在计算机和统计数据上，就不会对人际关系产生太大的兴趣。 不过， 数据科学家要为高管制定内部决策提供建议；在以数据为产品的企业里，数据科学家还要为负责产品和营销的管理者就数据产品和服务的机会提出建议。最早一批数据科学家中的帕蒂尔参与创造了这一术语，他常喜欢说，数据科学家必须“站在桥上”，近距离地向船长提出建议。 有证据表明，这些技巧很重要。高德纳公司（Gartner）的研究发现，“70%～80% 的企业智能商业项目的失败”是因为“IT 部门和业务部门之间缺乏沟通，未能提出正确的问题，或未能考虑到企业的真正需求”。智能商业项目通常涉及的都是一些小数据，而不是大数据。然而，某些项目之所以失败是因为自身存在问题。毫无疑问， 在大数据被获取并被“驯服”之后，即从非结构化数据转换为结构化数据之后，必须用传统的方式对其进行分析。 因此，数据科学家还需要承担起定量分析师的工作，了解他们身边的各种数学和统计技能，并能够轻松地向非技术人员做解释。我和一些作者已经合著了很多关于这些统计技能的书籍，所以在这里就不再详述这些技能了。 然而，小型非结构化数据的分析和大数据的分析之间存在一些差异。其一是，对于较大的群体来说，小样本统计推断出的结果可能不太重要。随着大数据的出现，企业往往会对整体数据进行分析，因为它们具备这种技术。如果你不是从一个样本来推断整个群体的结果，也就不用担心统计数据之类的概念，换句话说，小样本统计就是所观察到的结果代表群体的概率，因为它们就是一个群体。尽管如此，但我相信，在许多情况中，我们仍将继续使用样本统计。例如，向所有美国或其他国家公民征询他们对政治或社会问题的看法是不可行的，所以我们还是会利用样本调查来解决这类问题。即使你利用大量的网络数据来分析这一问题，但仍然只能代表特定时间内某些用户的意见。 两者之间的另一个不同之处是，大家普遍偏爱大数据的可视化分析。 至于原因，我想没有人能完全解释清楚。大数据分析结果往往以可视化的形式表现出来，现在，可视化分析有很多优势：易于高管理解，容易引起注意。不利的一面是，它们一般不适宜于表达复杂的多元关系和统计模型。换句话来说，大多数可视化数据是为了进行描述性分析，而不是预测性或指令性分析。然而，它们可以同时显示大量的数据，如图 4-1 所示，这幅图呈现的是银行账户关闭因素的可视化分析。我发现，与许多其他复杂的大数据可视化分析一样，这一可视化分析也很难解释。我有时会想，很多大数据的可视化分析仅仅是因为可以进行分析而被创建的，而并不是为了清晰地呈现一个问题。 为什么可视化分析常见于大数据中呢？有几种可能的解释。 这表明，由于捕捉结构化数据所付出的努力太多，所以很少有时间和精力来开展复杂的多元统计分析，只能建立一个简单的频率统计，然后基于频率统计进行绘制。这种现象常见于数据科学家群体中，但没有人知道这种方法的重要性和普遍性。 另一种解释是，大数据和更吸引人的可视化分析几乎同时出现。最后一种解释是，大数据工作是一种探索性和反复性的工作，因此需要可视化分析来探索数据，并向管理者和决策者传达初步调查结果。 我们可能永远不会知道哪个解释更为重要，但事实是， 数据科学家对业务的运作要有深入的了解，或者至少应该了解其中的部分环节。例如，企业如何赚钱？竞争对手是谁？企业如何在行业中成功推出产品和服务？能够利用大数据和分析来解决的关键问题是什么？这些都是一个有效率的数据科学家应该回答的问题。 掌握与业务相关的知识可以使数据科学家做出假设并迅速对其进行测试，为关键的功能和业务问题提供解决方案；否则，他将难以为业务增加附加值。正是对业务问题的分析使这些关于数据或传统数据分析的知识得以发挥作用，因此，相关业务领域的兴趣和经验很重要。当然， 数据科学家有时也会在各个行业之间来回转换，但没有人会精通所有领域。然而，重要的是，他们需要对所从事的新业务抱有强烈的好奇心和兴趣。 显而易见，数据科学家通常都是极其聪明的人， 如果你面试的是另一个行业的数据科学家，请确保他对其所从事的行业感兴趣，而且具备解决问题的能力。 当然，这个技能结构对有志成为数据科学家的人才来说，是一种参考。任何人都很难同时在这五个方向都出类拔萃。通用电气公司全球研究中心的分析学技术的负责人格拉伯是这样说的：“在通用电气公司，我们发现具备 2～3 个领域的专业技能的数据科学家是最有成效的”。          本文摘自《数据化转型》 作者：托马斯·H·达文波特 
223,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656145&idx=1&sn=e7edc1ba6b8f93a76a901d2a44f65d9d&chksm=bd4c28428a3ba154fb166c6b8a2965332ffbc938298d29b9f456b5fa832aeeec8ac07238b14f&scene=0,Drive.ai驾驶日记：有一天，我们让一辆无人车连续行驶了24小时……,大数据文摘作品   作者：龙牧雪 魏子敏 如果要建立一个无人车队，可以7x24小时的在路上行驶，需要哪些准备？目前的技术下，无人车可以完成这一挑战吗？ Drive.ai刚刚进行了一场这样的尝试，将其命名为“无人车马拉松项目”（The Drive-a-thon），并详细记录下了这场惊险刺激的“24小时行车日记”。 上个月，硅谷神秘的自动驾驶创业公司Drive.ai进行了一场无人车的24小时马拉松，以期了解如何在小范围内，实现无人车行驶时间最大化。 之前，很多自动驾驶公司都曾尝试让无人车在一天的各个时间段和各种路况下试行。而 Drive.ai两年前在硅谷成立，以深度学习作为切入点推进自动驾驶技术，目前其技术已经迭代到第四代，达到了L4级别，也即高度自动化的全自动驾驶。去年6月Drive.ai宣布完成 5000 万美元 B 轮融资。 去年从百度离职的前首席科学家吴恩达 (Andrew Ng) 也加入了Drive.ai 董事会。他的妻子 Carol Reiley 是公司的创始人之一，公司现任 CEO Sameep Tandon 则是他在斯坦福的学生。 Drive.ai把这个24小时的“拼体力”项目叫做“无人车马拉松”，并在海外媒体medium上发布了一篇“24小时无人车驾驶日记”，记录了整个项目从前期筹备到行驶过程的经历。 大数据文摘整理如下。 （ 原文链接： https://medium.com/@drive.ai/what-we-learned-driving-an-autonomous-vehicle-for-24-hours-straight-587defe151bd ） 首先，我们设定了雄心勃勃的目标： 自动驾驶至少400英里； 克服各种路况和天气； 确保在90%时间内自主正常运行（我们定义的自主正常运行是有司机，自动系统开启，车门关闭，车辆在路上）； 零事故，零事故，零事故。最重要的事情说三遍！ 我们在城市和郊区街道上运行的速度限制范围为25到40英里，所以400英里不是个容易达到的目标：我们无法在101-S号高速公路上设置巡航模式，然后让车子飞奔。 整个活动在加州山景城的地面街道上进行：从11月16日上午9时至2017年11月17日上午9时。 为了确保这场马拉松项目顺利进行，我们的许多员工在办公室通了个宵。 我们有一辆24小时连续行驶的自动驾驶车辆“主力“，还有一些别的车辆，构成了一个车队。自动驾驶是我们业务模式的关键组成部分，也是我们技术栈的关键部分，所以成功接送一些Drive.ai员工、朋友和家人是Drive ai马拉松的另一目标。 我们最近推出了升级版本的驾驶应用程序，Drive-a-thon为内部测试新的使用案例提供了一个很好的机会。 今天，即使是让一辆无人车连续工作24小时，也需要进行大量精心的计划。更不用说还要克服各种天气和路况。 首先，无论何时，在加州的公路上，我们都必须依法在车里安排一名训练有素的安全驾驶员。我们的安全驾驶员需要比实际道路上的普通驾驶员具有更高的注意力和驾驭力。 但是，一个司机不可能24小时保持警觉。我们此次分配了五个训练有素的无人车安全驾驶员为车队保驾护航。 除了司机之外，我们机械部门的工作人员还在Drive.ai总部待命，随时准备好处理从爆胎到传感器故障的任何问题。我们刚刚完成数据记录系统升级的基础设施团队也处于待命状态。 数据通道是无人车操作上一个被低估的问题： 对于典型的路测，我们有充足的车载存储。而对于耐力赛，这意味着“热切换”，即在不关闭系统的情况下也能更换记录存储器。 最后，我们希望这个活动也能很有趣。我们邀请了整个公司，还有很多朋友和家人来体验这个活动。 墨菲定律在活动开始的那天早上应验了：我们醒来后就下起了倾盆大雨，预计会持续一整天。尽管从今年初开始，我们在雨中进行了大量的雨水测试，但这是迄今为止我们被淋得最彻底的一次。尽管如此，我们也成功了。 上午9点，我们上路了。 新的安全驾驶员，同样的雨▲ 一天中，我们通过内部共享乘车应用程序完成了数十次搭载，并保持了我们的90％自主正常运行时间的目标。 傍晚时分，倾盆大雨减轻了，但我们的周围变得越来越黑。从感知的角度来看，夜间驾驶更具挑战性。 然而好在越到晚上，我们在道路上遇到的车辆越少，每小时能够覆盖更远的距离。 我们办公室里的帐篷▲ 午夜过后，我们决定回到办公室玩。 我们设立了一个室内营地，为我们所有的工作人员提供住宿，订购披萨，玩游戏，并为深夜工作的运营团队欢呼。 第二天早上，道路上比较平静，但我们仍面临挑战。 保持安全驾驶员的警惕是至关重要的，所以，全程我们都保证车上有另一位乘客，拍照、播放音乐，当然还有享受我们的车载系统！ 夜间巡航▲ 随着太阳升起，路上的车辆又多了起来，我们赶上了早高峰。 从早上七点到九点，在自动驾驶的第二十四小时，无人车仍运行顺利，真是太神奇了。对于任何车辆来说，行驶24小时（中间只为加天然气停了5分钟），都是件了不起的事。尽管面临挑战，我们仍然做到了： 上午9点过一点，我们回到了总部的车库。成功完成马拉松！ 先回顾一下我们的目标目标：90％的时间自主正常运行，400自动行驶里程，零事故。 在24小时内，我们的无人车处于自主模式22小时40分钟，在94%的时间里自主正常运行。我们途中停下的主要原因是更换安全驾驶员（约35分钟），更换数据驱动器和相关的软件维护（约25分钟），解决一个软件错误（约15分钟）和补充天然气（约5分钟）。当我们在11月17日上午9点通过终点时，我们已经开了410英里，这意味着我们的平均速度（途中停车时间也计算在内）是17英里/小时。最后，最重要的是，我们安全地完成了这次活动。 无人车的发展不仅改变我们的运输方式，也改变整个世界：在未来几十年里，土地使用、基础设施、保险业、无线通信等领域将随之发生根本性的变化。无人车的产业不仅仅涉及制造无人车，而且还涉及一个无人车生态系统。 让一个无人车队高效运转，需要考虑很多因素： 变停车场为维护中心： 普通车辆平均每天停车时间为22小时以上，而无人车队的目标则为80％以上时间都在路上。虽然这意味着在任何给定时间停放的车辆的百分比较低，但是无人车的停车需求是不同的。无人车队将需要专门的维护中心作为充电或加油站、数据仓库、传感器校准站点、清洁设施等等。做好准备应对这些重大变化吧！ 接送乘客： 自动驾驶被誉为解决“最后一公里”问题的灵丹妙药，但出租车体验中有许多方面被我们认为是理所当然的。你如何确保正确的人已经进入车辆？如果一个或多个人需要帮忙搬运行李，该怎么办？如果一个人有残疾呢？这个“最后一米”的问题是无人车队应考虑的一个重要因素。找到一个安全的地方来停靠是往往被无人车忽视的问题。阻挡车道或自行车道几分钟可以接受吗？如果有停靠点，我们需要正确检测道路的边缘，理想情况下不要停靠至刷红漆的区域。但如果没有合法的停靠点，我们该怎么办？与司机探讨并制定一个应变计划是一种常见的做法（佛系出行：师傅你别动，我走过来），但是机器人“司机”对此还是很陌生的。 AV + EV（Autonomous + Electric vehicle）： 电动化无疑将在未来的自动驾驶技术中扮演重要角色。我们在驾驶中使用的混合动力平台的能源成本约为0.09美元/英里，而像特斯拉Model S这样的当代电动汽车则更接近每英里0.04美元。但是，在充电和电池更换技术进一步成熟之前，混合动力汽车才是最佳选择。无人车想要达到90％利用率的话，不可能用一整个晚上充电。电动汽车还没有被完全采用，但我们认为，引进电动汽车将成为改善下一代储能技术所需基础设施的重要力量。对无人车队的真正需求来自于企业，这也是Drive.ai已经定位在ToB的另一个原因。 人员： 今天，很多地区都要求无人车配备经过培训的安全驾驶员，无论是在车上，还是远程监督无人车的行为。新的工作机会也将随之诞生，例如：车辆清洁、一般硬件维护、传感器磨损更换和重新校准、客户支持等等。即使在一个更安全、更自动化的世界里，我们仍然会遇到出乎意料的情况，而许多客户在出现问题时会喜欢请人来帮忙。机器人能够对人类和意外情况产生同情和响应吗？这对我们来说是一个重要的考虑因素，因为我们想要开发能建立信任和理解的用户体验。 数据： 无人车每分钟产生千兆字节的数据，所有这些数据都必须能供我们衡量乘坐质量，跟踪任何关键事件，并随着时间的推移改进技术。有些数据可以通过手机传输，但大部分数据必须存储在车上，这意味着硬盘必须定期更换。当数据离开车辆，它们将直接进入我们的多级数据管线，我们将处理数据，用于未来的回放、调试、可视化、注释和其他分析。 人机交互： 无人车中的乘客选择了机器人来处理驾驶任务。在车内，我们的乘客可以直观地了解汽车所看到的信息以及如何它做出决定。然而，在车辆外部，我们的车辆与其环境之间的交互是另一回事。人类司机的离开，意味着我们不再有能力与外界进行目光接触和表达，至少不是以相同的方式。我们知道从驾驶到无人驾驶的过渡不会在一夜之间发生。我们已经设计了一套系统来建立人们对自动驾驶的未来的信任。人机交互是另一个重要的考虑因素。 这次无人车马拉松是一次很好的学习机会。在单一无人车上部署“马拉松”让我们有机会了解如何使一整队无人车保持最佳性能。而在2018年，我们的目标就是：打造无人车队！ 是不是燃爆了！无人车队什么时候能上路？欢迎留言告诉我们你的看法。 
224,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656132&idx=1&sn=fb49549c7e7620128036226a8e2a1b53&chksm=bd4c28578a3ba141b0c563056d3bc6116023912e99855f111d8b4f9002ce629ac2123137b155&scene=0,手把手：一张图看清编程语言发展史，你也能用Python画出来！,"大数据文摘作品 作者：Peter Gleeson 编译：周佳玉、丁慧、叶一、小鱼、钱天培 今天文摘菌要教大家制作一张编程语言的关系网络图。如果不知道什么是关系网络图，可以点击下方链接先来看一下最终成果： http://programming-languages.herokuapp.com/#， 我们可以在这里看到从过去到现在的250多种编程语言之间的“设计影响”的关系，下面是该演示的截图： 接下来，就让我们一起来学做这个关系网络图吧！ 在当今的超连接世界，网络在现代生活中无处不在。 举个栗子，文摘菌的周末这样开启——通过北京的交通网络进城，然后去最喜欢的咖啡店的一家分店，并将笔记本连上他们的Wi-Fi。接下来，登录各种常用的社交网站。 众所周知，在过去几十年来最有影响力的公司中，有一部分是因为网络的力量而获得成功。 Facebook、Twitter、Instagram、LinkedIn以及一些其他的社交媒体平台都依赖社交网络的小世界特性。 这使他们能有效地将用户彼此（以及和广告商）之间连接起来。 谷歌目前的成功主要归因于他们早期在搜索引擎市场上的主导地位——部分原因是他们有能力通过他们的Page Rank网络算法来返回相关的结果。 亚马逊的高效配送网络使他们能够在一些主要城市提供当天发货。 网络算法在人工智能和机器学习等领域也是非常重要的。 神经网络领域的研究非常热门。计算机视觉中许多必不可少的特征检测算法，在很大程度上也是依赖于使用网络来对图像的不同部分进行建模。 网络模型也可以解释大量的科学现象，包括有量子力学、生化途径以及生态和社会经济系统等。 那么，鉴于它们不可否认的重要性，我们应该如何更好地理解网络及其属性呢？ 网络的数学研究被称为“图论”，是数学中较易理解的分支之一。  本文会介绍简单的网络知识，即便你没有相关背景知识也能轻松学会。 此外，我们将使用Python 3.x和一款非常棒的开源软件Gephi，通过关系网络将过去和现在的一系列编程语言的网络可视化联系起来。 其实上面文摘菌举的栗子已经给了一些线索。交通网络由目的和路径的连接组成。社交网络通过个人和个人之间的关系进行连接。Google的搜索引擎算法通过查看有哪些页面链接到其他页面，来评估不同网页的“顺序”。 更一般地说，网络是可以用节点和边描述的任何系统，或者通俗来讲，就是我们所说的“点和线”。 边连接节点（语言）的例子（该网络表示了编程语言相互影响的关系） 有些系统以这种方式建立网络比较容易。社交网络也许是最明显的例子。计算机文件系统则是另一种方式——文件夹和文件通过其“父”和“子”关系创建连接。 但是，网络的真正威力其实在于，许多系统都可以从网络的角度来建模，即使这起初并不明显。 我们应该如何将点和线的图片转换成我们可以压缩的数字信号呢？ 其中有一个解决方案是绘制一个邻接矩阵来表示我们的网络。 如果你不熟悉矩阵这个概念，这听起来可能有点吓人，但不要害怕。 把它们想象成可以一次执行许多计算的数字网格就好。下面是一个简单的例子： 在这个矩阵中，每个行和列的交集都是0或1，这取决于各个语言是否被链接。你也可以根据上面的插图观察到！ 对于要解决的大多数问题而言，矩阵是以数学方式表示网络的好方法。然而从计算的角度来看，它有时可能会有点麻烦。 例如，即使节点数量相对较少（比如说有1000个），矩阵中的元素数目也会大得多（例如，1000^2 = 1,000,000）。 许多现实世界的系统会产生稀疏网络，在这些网络中，大多数节点只能连接其他所有节点中的一小部分。 如果我们将计算机内存中1000个节点的稀疏网络表示为邻接矩阵，那么我们将在RAM中存储1,000,000个字节的数据。大多数将会是零。这里有一个更为有效的方法可以解决这个问题。 这种方法是使用边列表来代替邻接矩阵。这些正是他们所说的，它们只是一个节点对相互链接的列表。 表示网络的另一种手段是邻接表，它列出了每个节点后面与它进行链接的节点。例如： 任何网络模型以及可视化的表现都取决于构建网络本身所用的数据质量好坏。除了确保数据是准确和完整的同时，我们也需要一种推断节点之间边的合理方法。 这是相当关键的一步，随后对网络进行的任何分析和推断都取决于“关联标准”的合理性。 例如， 在分子生物学中，你可能会基于基因的共同表达建立连接。 通常，我们还可以给边分配权重，从而体现关系的“强度”。 例如，对于网上零售的情况，可以根据产品被同时购买的频率来计算权重。用高权重的边连接经常被同时购买的产品，用低权重的边连接偶尔被同时购买的产品。和偶尔被同时购买的产品相比，那些不会被同时购买的产品根本就不会被网络连接。 正如你想的那样，将节点彼此连接的方法有可能很复杂。 但是对于本教程，我们将使用更简单的方式连接编程语言。我们要依靠维基百科。 维基百科所取得的的成功证明了它的可靠性。文章写作的开源合作方法也应该保证一定程度的客观性。 而且，它的页面结构相对一致，使其成为试用网页抓取技术的便利场所。 另一个便利工具是覆盖面广泛的、有据可查的维基百科API，这使得信息检索更容易。接下来让我们一起开始吧。 Gephi可在Linux、Mac和Windows的环境下进行安装。 对于这个项目，我使用了Lubuntu。如果你使用的是Ubuntu / Debian，那么你可以按照下面的步骤来启动和运行Gephi。如果不是，那么安装过程也不会差太多。 下载最新版本的Gephi到你的系统（在撰写本文时是v.0.9.1）。准备就绪后，你需要提取文件。 你可能需要检查你的Java JRE版本。Gephi需要最新版本。在我刚刚安装的Lubuntu上，我只安装了default-jre，下面的一切将建立在此基础上。 在你准备好进行安装之前还有一步。为了将图表导出到Web，你可以使用Gephi的Sigma.js插件。 从Gephi的菜单栏中选择“工具”选项，然后选择“插件”。 点击“可用插件”标签并选择“SigmaExporter”（我也安装了JSON导出器，因为它是另一个有用的插件）。 点击“安装”按钮，你将完成整个安装过程。安装结束后，你需要重新启动Gephi。 本教程将使用python 3.x以及一些模块来进行简化。使用pip模块安装程序，需运行一下命令： 现在，在一个新的目录中，创建一个名为script.py的文件，并在你最喜欢的代码编辑器/ IDE中打开它。以下是主要逻辑的大纲： 首先，你需要有一个编程语言的列表。 接下来，通过该列表并检索维基百科相关文章的HTML。 从中提取出每种语言所影响的编程语言列表。这是我们连接节点的粗略标准。 同时，我们可以抓取一些关于每种语言的元数据。 最后，将收集的所有数据写入一个.csv文件。 完整的脚本在这里： （https://gist.github.com/anonymous/2a6c841fe04ebc6d55acc259b4ac4f72）。 在script.py中，首先导入一些模块。 准备好后——从创建一个节点的列表开始。这是Wikipedia模块派上用场的地方。它使得访问维基百科API非常容易。 添加下面的代码： 保存并运行上面的脚本，将看到打印出“List of programming languages”维基百科文章中的所有链接。 另外，还需要手动检查自动收集的数据。快速浏览后我们可以发现，除了许多实际的编程语言之外，该脚本还提供了一些额外的链接。 如：可能会看到“List of markup languages”，“Comparison of programming languages”等。 虽然Gephi允许你移除不想包含的节点，但为了节省时间，还是让我们先进行一轮数据清洗。 这些代码定义了要从数据中移除的子字符串列表。运行该脚本时遍历数据，移除所有包含不需要的子字符串的元素。 在Python语言中，完成这些只需要一行代码！ 现在我们可以开始从wikipedia抓取数据并建立一个边列表（并收集所有元数据）。为了更简便，让我们首先定义一些函数。 抓取HTML 第一个函数使用BeautifulSoup模块来获取每种语言的Wikipedia页面的HTML。 这个函数使用urllib.request模块来获取“https://en.wikipedia.org/wiki/”+“编程语言”页面的HTML。 然后传给BeautifulSoup，它将读取HTML并解析为一个可以用来搜索信息的对象。 接下来，使用find_all()方法抓取感兴趣的HTML元素。 下面，是每种编程语言文章顶部的汇总表。该如何识别呢？ 最简单的方法是访问其中一个编程语言页面。在这里，可以简单地使用浏览器的开发工具来检查感兴趣的元素。汇总表有HTML标记<table>和CSS类“infobox”和“vevent”，因此可以使用这些来标识HTML中的表格。 用参数指定它： find_all()返回符合标准的所有元素列表。为了指定感兴趣的元素，需要添加索引[0]。如果函数执行成功，则返回table对象，否则，返回None。 在使用了自动数据收集程序的情况下，全面的异常处理是非常重要的。如果没有，那么在最好的情况下如果脚本崩溃了，数据抓取程序需要重新开始执行。 在最坏的情况下，你获得数据集将包含不一致性和错误，这将为你后续的工作买下隐患。 检索元数据 下一个函数使用table对象来查找一些元数据。下面给出在表格中搜索语言第一次出现的年份的代码。 这个简短的函数以table对象作为参数，并调用BeautifulSoup的get_text（）函数生成一个字符串。 下一步是创建一个名为year的子字符串。该字符串存储了在“appear”这个词首次出现之后的30个字符。这个字符串应该包含语言第一次出现的年份。 为了仅提取年份，使用正则表达式（通过re模块）来匹配任何以1到3之间的数字开头、并紧邻三个数字的字符串。 如果执行成功，函数将返回一个整数的year。否则，我们会得到“Could not determine”。你可能还想进一步挖掘元数据，例如范例，设计者或打字规律。 收集链接 我们还需要一个函数–该函数读入给定语言的table对象，输出一个包含其他编程语言的列表。      仔细观察上面代码中嵌套部分，到底是怎么回事呢？ 这个函数利用了table对象具有结构一致性的事实。表中的信息存储在行中（相关的HTML标签是<tr>）。其中一行包含文字“\ nInfluenced \ n”。函数的第一部分查找这是哪一行。 一旦找到这一行，就可以确定下一行包含了被当前行影响的每种编程语言的链接。使用find_all（“a”）便可查找这些链接 - 其中参数“a”对应于HTML标签<a>。 对于每个链接j，将其[“title”]属性添加到名为out的列表。对[“title”]属性感兴趣的原因是因为它将完全匹配存储在节点中的语言名称。 例如，Java作为“Java（编程语言）”存储在节点中，因此需要在整个数据集中使用这个确切的名称。 如果执行成功，getLinks（）将返回一组编程语言。该函数的其余部分进行了异常处理，以防程序在某一阶段出现问题。 收集数据 最后，在一切准备就绪后执行脚本，收集数据并将其存储在两个列表对象中。 现在编写一个循环，将先前定义的函数应用于nodes中的每个词条，并将输出存储在edgeList和meta中。 该函数使用节点中的每种语言，并尝试从维基百科页面检索汇总表。 然后，该函数将检索表中列出的与目标语言所关联的全部语言。 对于同时出现在节点列表中的每种语言，将一个元素以[“source，target”]的形式添加到edgeList。通过这种方式，建立一个边的列表传给Gephi。 出于调试的目的，打印添加到edgeList的每个元素——这样做仅仅为了确保一切都工作。如果想要更彻底地调试，也可以添加打印语句到except语句中。 接下来，获取语言的名称和年份，并将其添加到元列表中。 写进CSV文件 一旦循环运行，最后一步是将edgeList和meta的内容写入到CSV文件。通过使用前面导入的csv模块，完成上一步骤就容易多了。 完成了!保存脚本，并从终端运行: $ python3 script.py 当构建边列表时，你可以看到脚本输出了source-target对。确保网络连接的稳定性后，你就可以坐等结果了，此时脚本将发挥其魔力。 希望你已经安装并运行了Gephi。现在你可以创建一个新项目，并使用你收集的数据来构建有向图。有向图将显示不同的编程语言是如何相互影响的! 首先在Gephi中创建一个新项目，然后切换到“数据实验室”窗口。Gephi中提供了一个扩展式的接口来处理数据。首先要导入列表。 点击“导入电子表格”。 选择由Python脚本生成的edge_list.csv文件。确保Gephi中使用逗号作为分隔符。 从列表类型中选择“边列表” 点击“下一步”，导入源和目标列作为字符串，并检查。 用一个节点列表来更新数据实验室。现在,导入 metadata.csv文件。这一次，从列表类型中选择“节点列表”。 切换到“Preview”选项卡，查看网络的外观。 这时的图形看起来颜色十分单一，而且杂乱无章，就像一盘意大利面。所以我们接下来要进行图像美化。 我们可以通过各种方式来演示图像，也可以尽情发挥自己的创意。另外，关于网络可视化还要考虑以下三件事情: 节点定位： 生成网络布局模式的算法有很多，比较流行的是fruchterman - reingold算法，而且Gephi支持该算法。 节点大小： 图中节点的大小可以用来表示一些有趣的属性。通常，这是一个中心性度量。度量中心性的方法有很多，但它们都反映了给定节点的“重要性”，即它与网络的其他部分关联的紧密程度。 节点着色： 我们还可以使用颜色来显示节点的某些属性。通常，颜色用来表示群落结构，广泛定义为“与图的其余部分相比关联更紧密的一组节点”。在社交网络中，群落结构可以揭示个人的友情、家庭或专业团体之间的关联。有几种算法可以检测群落结构，Gephi自带的检测算法是Louvain方法。 要执行上述步骤，还需要计算一些统计数据。切换到“Overview”窗口。在这里你可以看到右侧的一个面板。它包含一个“Statistics”选项卡。打开它，你将看到一系列选项。 Gephi具有许多内置的统计功能。对于每种功能，点击“Run”将生成一个报告，该报告揭示了关于网络的一些洞见。 如果要修改网络的外观，我们可以转向左边的面板。 在“Layout”选项卡中，可以选择要使用的布局算法。点击“运行”，实时观看图表的变化!看看你认为哪种布局算法效果最好。 在Layout选项卡之上是“Appearance”选项卡。在这里，你可以为节点和各条边的颜色、大小和标签进行设置，也可以根据数据的属性来配置(包括你要计算的数据)。 一个建议: 根据模块化属性将节点着色。着色的根据是节点的群落成员关系。 根据节点的平均程度来确定节点的大小。关联紧密的节点会比关联稀疏的节点显得大。 不过，也可以尝试设计一个最喜欢的布局。一旦对图形外观感到满意，就可以进入最后一个步骤——将图形导出至网页! 既然已经构建了一个可以在Gephi中查看的网络可视化，接下来可以选择使用屏幕截图，或者以SVG、PDF或PNG格式保存图形。 如果已经安装了Sigma.js插件，也可以把图形导出到HTML，这将会创建一个交互式可视化，不仅可以在线上发布，也可以上传到GitHub，与他人分享。 可从Gephi的菜单栏选择“Export >Sigma.js模板…”。 按要求填写详细信息。确保选择导出项目所在的目录。你也可以更改图形的标题、图例、描述、悬停和许多其他细节。当你准备好了，点击“确定”。 现在，如果你打开导出项目所在的目录，你将看到一个文件夹，其中包含Sigma.js生成的所有文件。 在你最喜欢的浏览器打开index.html文件。哈!你的网络!如果你知道一些CSS和JavaScript，可以载入各种生成的文件到你的网络中，以便按照你的意愿调整输出的网络。 许多系统可以作为网络进行建模和可视化。图论是数学的一个分支，它提供了帮助理解网络结构和属性的工具。 使用Python从Wikipedia获取数据，构建编程语言影响图。关联标准是一种给定的语言是否能被列为对设计另一种语言的影响。 Gephi和Sigma.js是分析和可视化网络的开源工具。它们可以让你以图像、PDF或Web格式导出网络。 模仿本文的方法，你还可以为很多其他的关系建模并做出可视化。脑洞开一开，网络画起来。 原文链接： https://medium.freecodecamp.org/how-to-visualize-the-programming-language-influence-graph-7f1b765b44d1 "
225,https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651656132&idx=2&sn=a6b0b55a411787facf9b65889e99f01b&chksm=bd4c28578a3ba1410ac3092b997931db973d476ca3c9f6bd0b40e7788c0f881f8ea97d098d2c&scene=0,行业 | 谷歌和亚马逊在赌场门口拉客，你上谁的船？,"授权转载自公众号硅谷密探（ID： guigudiyixian） 看到这面镜子，你想到什么？ 从外表上看，它是一款普通的浴室镜子，女生可以对着它描眉打扮，男生可以对着它剃须，喷发蜡。 只不过，这面镜子在你打扮结束后，你可以问它，“Alexa，你觉得谁是世界上最美的女人？” “hey，我听不懂你在说什么。” 虽然，镜子还暂时无法分辨镜子前的你是否最美，但你已经可以用它来控制浴室的灯光了。又或者，正在刮胡子的你可以让 Alexa 给你播报一下今天的天气和新闻。 这款在今年CES上展出的“会说话的镜子”，正是美国家居卫浴品牌科勒添加了亚马逊语音助手Alexa ，售价999美元起。 除了会说话的镜子，还有用语音来调整淋浴喷头的温度，调整海信电视音量，控制惠尔浦的微波炉…… 可以说，今年拉斯维加斯的消费者电子展（CES）上，亚马逊在不露脸的情况下，狠狠地通过各种智能家居产品刷了一把存在感。 只不过， 毕竟，在这场“中国消费者电子展”，又或者是“深圳消费电子展”上，有美国媒体指出，2018年CES最大的看点就是：看亚马逊跟谷歌“打架”了... （来自Andoird Authority网站） 近些年来，CES 上像苹果、亚马逊、Facebook、谷歌等技术巨头的身影已经越来越少见了。不过，尽管巨头们没有大规模设展台，或者整栋楼外墙地买广告，但并不意味着毫无动作。 像2017年的CES上，亚马逊就大出风头。这正是得益于亚马逊向其他公司产品开放了语音助手Alexa。 从手机到家用冰箱，从扫地机器人到车辆，Alexa 可以说“无处不在”。比如 LG 展示了在29寸的冰箱触摸屏上使用Alexa，福特汽车把 Alexa 装进了旗下两款汽车Fusions和F-150上，华为的旗舰手机Mate 9在美国销售的版本内置Alexa应用…… 也就是说，消费者可以在这些产品上自由地使用语音功能了，想怎么调戏语音助手Alexa就怎么调戏。相较之下，同样拥有语音智能助理Goole Assistant 的谷歌可以说是“悄无声息”。 不过，今年谷歌变聪明了。 据华尔街日报报道，谷歌在今年的CES上设立了一个很大的户外展台，这也是近些年来第一次。同时也派出了高管参加展会。 不过据Techcrunch 报道，谷歌的展台因为暴雨暂时关闭了... （嗯...纯属娱乐...） 不仅设展，谷歌还在展区的停车场旁设了大型游戏滑梯，在拉斯维加斯的单轨列车上打出了“嘿，谷歌”的广告。 对于没有官方展台的亚马逊来说，谷歌的露脸当然是大大的。不过，广告归广告，归根结底还是使用自家产品的竞争。 比如在LG的冰箱上能使用Alexa，那谷歌的Google Assistant 就出现在LG的电视上。LG 宣布，2018年新推出包含人工智能功能的电视，将实现人对遥控器讲话来指挥电视。如果你提出一些更高深的问题，系统会切换到Google Assistant 上寻求答案。 今年的CES上， 比如亚马逊已经与微软、宏碁、华硕、惠普和联想达成协议，预计2018年发布的Windows笔记本电脑上会预装Alexa，到时国内的小伙伴估计就可以尽情调戏Alexa了... 而谷歌的语音助理也不示弱，除了LG电视之外，索尼的部分型号电视，还有海尔的最新电视、汽车，乃至咖啡壶等家用小电器生产商等，都宣布跟Google Assistant 的结合。 （那个可以用语音控制烧水的咖啡壶…… ） 谷歌官方此前曾表示，从总数来看，谷歌助理已经可以在225个品牌多达1,500多台设备上使用，这足以让普通消费者在进行家庭设备升级时不会很难找到自己需要的东西。 所以说，这CES还未正式开始，亚马逊和谷歌的掐架气氛就已经变得浓厚了。不过，这已经不是谷歌跟亚马逊的首次“掐架”了。 观察亚马逊和谷歌的业务线条可以发现，无论是智能硬件还是视频流媒体，又或者是云等多项业务上，两家公司都有所重叠。因此，两家“掐架”的风波是在2017年突然爆发，达到顶峰。 如果你用亚马逊网购的话，你不妨在亚马逊网站上搜索谷歌的小音箱Google Home，你会发现，至今也搜索不到相关产品，出来的只是一些Google Home 的配件。 （截图自亚马逊网站） 自从亚马逊在2015年推出智能音箱Amazon Echo 以来，市场份额是一直领先。截止至2017年第四季度，亚马逊Echo 系列产品在美国的市场份额已经占到了76%。 不过，16年11月才发布的谷歌智能音箱Google Home 也不逊色，市场份额大概在15%－24%之间。可以说，二者几乎瓜分了美国现有的智能音箱市场。这也难怪你在亚马逊上搜不到谷歌的音箱了。 除了对Google Home 的阻挠，亚马逊还限制自家网站对谷歌旗下智能家居Nest的一些最新产品的购买，而亚马逊的Prime Video（视频服务）也不支持谷歌的电视棒Chromecast。 谷歌对亚马逊的行为可以说是“积怨已久”，因为亚马逊的“禁购”行为最早追溯到2015年底。 当时，亚马逊网站停售谷歌电视棒Chromecast 和苹果电视盒Apple TV 两款产品，理由是“无法很好跟亚马逊的产品兼容，会混淆客户”。 直到2017年早些时候，苹果被认为与亚马逊达成协议，亚马逊的视频应用Prime Video 能从苹果电视下载，也换来了亚马逊允许苹果电视在其商店销售。 但就在去年12月， 这被认为是谷歌给亚马逊下的“YouTube禁令”，禁令从2018年1月1日起生效。 其实，谷歌在9月就曾试过将Youtube从Echo Show上撤出。这一下子导致购买了亚马逊电子产品的客户，无法直接从设备上访问Youtube的APP，只能跳转网页。（试想一下，你没办法从电视上看爱奇艺，只能给你跳到爱奇艺网站，该有多抓狂...） （图片来自网络） 就在“Yotube禁令”下达后，亚马逊被发现开始重新在网上销售Google Chromecast，这被认为是两家公司两年多冷战来的一次“缓和”。 缓和归缓和，就在掐架进行时，亚马逊也申请了“AmazonTube”商标，这被看作亚马逊有可能发起自己的视频分享网站，跟“Youtube” 展开新一轮的竞争。 所以说，这次CES就像是两家又一次冲突、抢夺的“战场”罢了，只不过这一次，是抢各大智能硬件制造商的“合作伙伴”，希望拉他们进入自家生态系统“麾下”。 （亚马逊在今年CES的挖宝卡车） 密探此前曾撰文分析过，现有各大科技巨头对硬件的重视，无形中激化了争夺消费者“市场”的行为，并变成公开化。 这个竞争不仅仅是谷歌和亚马逊，苹果也是一个有力竞争者。 比如在智能穿戴方面，Apple watch是遥遥领先的。此外，苹果也加入了开发智能音箱的行列，在去年发布了产品Homepod。2017年WWDC大会上苹果也宣布研发AR智能眼镜。 更不用说原本在智能硬件上及早发力的亚马逊了。 在智能家居消费市场还未饱满的今天，各个巨头的争夺就显得更有动力了。 研究机构埃森哲今年1月初发布调研报告，2017年调查了来自美国、加拿大、澳洲、中国、印度、巴西等19个国家2万多名用户，发现仅是智能音箱（扬声器）这一项，每个国家的销售额都增长了50％以上。 埃森哲预计，到2018年，美国家庭的智能音箱占有率有望达到50%，像中国、印度、巴西这些国家的新兴市场，对智能音箱感兴趣的程度也会从0上升到30%。 看起来各家公司在争夺的是一个很小的智能音箱，以及努力想跟各类智能家居结合，背后终归还是对“入口”的争夺战。 试想一下，当我们用语音助理控制了家里的智能家居后，无论是你听歌，听新闻，用声音管理厕所的水流还是浴室的灯光，又或者是成为你车上导航的帮手，这个智能语音助理就自然而然成为了下一代链接众多行业的枢纽。可以说，谁控制着智能家居的入口，就能够挖掘出一个有价值的信息流。 不过，那谁谁不是最近不是发话了么，“二选一”是不对的。 所以，我还是选择国内能用的小米吧... "
