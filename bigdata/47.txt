 大数据文摘

大数据文摘字幕组作品

大家好呀！YouTube网红小哥Siraj又来啦！
这次他将为我们讲解Deep Q Learning――谷歌为了这个算法收购了DeepMind。

点击观看视频
时长9分钟
带有中文字幕


这个算法是干什么的呢？
答案就是：用来玩游戏的！



2014年，谷歌花了5亿多美元收购了位于伦敦的一家小公司：DeepMind。在此之前，DeepMind在2013年12月的NIPS大会上发表过一篇关于用深度强化学习来玩视频游戏的论文Playing Atari with Deep Reinforcement Learning，后续研究成果Human-level control through deep reinforcement learning在2015年2月上了《自然》的封面。再后来，深度学习+强化学习的玩法用在了围棋上，于是我们有了阿法狗。



回头看看让DeepMind起家的Deep Q Learning，看上去只是一个非常简单的软件，一个专门为Atari视频游戏设计的自动程序。可是，它被视为“通用智能”的第一次尝试――论文显示，这种算法可以应用至50种不同的Atari游戏，而且表现均超过人类水平。这就是深度Q学习器。



用超级玛丽来举个例子。我们拥有游戏的视频片段作为数据输入，用马里奥移动的方向来标注数据。这些训练数据是连续的，新的视频帧持续不断地在游戏世界产生，而我们想知道如何在这个世界中行动。



看上去，最好的办法是通过尝试。不断尝试，不断犯错，这样我们就会了解我们与游戏世界的最佳互动形式。



强化学习就是用来解决这类问题的。每当马里奥做了一些有助于赢得游戏的动作，正标签就会出现，只是它们的出现有延迟。相比起把它们叫做标签，更确切的叫法是“奖励Reward”。

我们将整个游戏过程表示为一个由状态（State）、动作（Action）和奖励（Reward）构成的序列，每个状态的概率仅仅取决于前一个状态和执行的动作，这叫做“马尔科夫特性”，以俄罗斯数学家马尔科夫命名。这个决策过程称之为马尔科夫过程。


如果把某个点之后一系列的奖励表示成一个函数，这个函数值就代表游戏结束时，可能出现的最佳得分。当在给定的状态下执行给定的动作之后，此函数用于衡量该状态下某个动作的质量（Quality），这就是Q函数，也叫魁地奇函数，啊不，质量函数。



当马里奥决定执行哪个可能的动作时，他将选择那些Q值最高的动作，计算Q值的过程，就是学习的过程。



那么如何超越超级玛丽这一个游戏，将算法推广到其他游戏中呢？戳上文视频了解更多吧！

原视频地址：（大数据文摘经授权汉化）
https://www.youtube.com/watch?v=79pmNdyxEGo

本期工作人员

翻译：周杨  IrisW  高树
校对：晓莉
时间轴+后期：龙牧雪
监制：龙牧雪


优质课程推荐｜《机器学习工程师》
往期学员评价（by小白菜）

实战班的课程内容非常贴近实际工作，将完整的机器学习项目流程，包括数据清洗、数据采样、特征工程、模型选择－调优－融合、模型评价，完整地学习和实战了N遍。课程中的项目涉及数值预测、自然语言处理、金融风控、推荐系统等，并且配备了在线实验平台，是一门可以提升机器学习项目实战能力的课程。

快上车！MIT的这门自动驾驶课，学完可以自己造一辆“无人车”（汉化视频连载第一弹）